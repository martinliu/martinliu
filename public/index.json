[{
    "title": "Elastic 可观测性工作坊",
    "date": "",
    "description": "从 Elastic Stack 搭建开始直至云原生应用的运维和管理",
    "body": "本工作坊包括本地虚拟机版本、AWS 和腾讯云共三个版本，目标是用实践的方式理解 Elastic 可观测性解决方案。可观测性是管理云原生以应用复杂且分布式运维难点的关键所在。\n简介 Elastic 可观测性解决方案是基于 Elastic Stack的一站式解决方案。该解决方案具有完备的日志、指标、APM 和可用性采集能力，可以在大规模和云原生的环境下完成基于服务质量目标的管理。本实战工作坊基于多层架构的宠物商店为示例应用，手把手的引导参与者搭建可观测性管理平台，体验分层次的收集整合、分析、关联和搜索运维数据的全过程。\n为什么要做这个工作坊？  关于可观测性的各种一小时方案/产品分享，无法让听众理解相关概念 而实操的上机动手实验才能让新手迅速入门，熟手快速提高 大量 ELK 用户只使用到了日志部分，还不了解可观测性方案全貌 社区里存在着大量误解，如“APM 工具等于可观测性” 等等，急需系统的普及正确的观念  动手实验 本工作坊的最佳实践方式是在老师的引导下，在线下进行。其次是在视频的指导下自学。所有动手实验的目标是理解可观测性解决方案的各个组成部分，以及为什么要使用这些工具？而且这个整个方案的实施过程和顺序也是经过精心设计的，目标是让理论和实际彻底融会贯通。\n您将会学到：\n 搭建单节点 Elasticsearch 服务，并且配置好 Kibana 管理图形管理界面。 学习可观测性的基本感念和实施步骤 搭建和配置服务健康检查的探针 部署采集操作系统性能监控指标的流程 配置操作系统日志的采集和分析工具 搭建用于 APM 追踪分析的后台服务 运行一个多层架构的宠物商店应用，对各个子服务进行 APM 监控埋点 配置常用的服务质量监控大屏  本工作坊课程基于如下的应用系统。\n应用基本概况：\n 多层宠物商店应用系统 所有组件都部署在一个虚拟机上 包括前端、后端和内置的数据库 使用到的而技术有 JavaScript、NodeJs 和 Java Spring 等。 本应用系统是被监控的对象  Elastic Stack 的基本状况：\n 版本 7.9.3 组件 Elasticsearch、Kibana、APM、Filebeat、Metricbeat 和 Heatbeat。  实验环境：\n 本地虚拟机环境，打包好的虚拟机里包含了所有必要的软件包和演示应用。 AWS 云环境，本课程所使用的公共 AMI 操作系统镜像：宁夏区 ami-0e5a0e294902966af 北京区 ami-0e1382088b62cb38d 腾讯云环境，基于腾讯云提供的 Elasticsearch 服务，演示用的虚拟机在制作中，稍后会发布到云市场。 阿里云环境，基于阿里云提供的 Elasticsearch 服务，课件正在开发中。  可观测性构建四步法 可观测性依赖于应用系统自身和监控工具平台的配合实现。\n分层次的构建可观测性的推荐过程如下：\n STEP0：使用 Heatbeat 构建轻量灵活的服务健康检查能力 STEP1：使用 Metricbeat 构建全面细致的指标采集能力 STEP2：使用 Filebeat 构建高维度的日志采集能力 STEP3：使用 APM 构建分布式应用系统的全堆栈追踪能力  通过以上的四个构建步骤，使用 Elastic Stack 实施四大服务质量监控能力的构建，搭建了持续统一运维管理的工具平台。\n使用 SRE 基于‘用户旅程’或‘系统边界’的 SLO 分析设定方法，从 Elastic Stack 的已有数据采集能力中，选取第批直接可用的 SLI 采集点。在基于 SLO 的监控过程中，不断的优选 SLI，调整告警的数量和质量，为开发团队提供持续有效的反馈。\n使用 Canvas 的画布功能，定制如下的 SLO 监控大屏。\n工作坊课件 讲师 PPT 下载： https://docs.qq.com/slide/DUGRzYVVTU3ZxblBP\n本地虚拟机环境 可以使用本地的 VirtualBox 或者 VMWare 的虚拟机环境，配合以下课件完成所有练习。\n ‘Elastic Stack 单节点搭建’ 课件 ‘Elastic 可观测性方案’ 课件  AWS 云计算环境 可以使用 AWS 云计算（中国区北京或宁夏区）环境，配合以下的课件完成所有练习。\n ‘Elastic Stack 单节点搭建’ 课件 ‘Elastic 可观测性方案’ 课件  腾讯云计算环境 可以使用腾讯云计环境，配合以下的课件完成所有练习。\n 在本环境下，不需要搭建 Elastic Stack 的服务器，参展下面课件的第二步骤，创建 Elasticsearch 服务集群。 ‘Elastic 可观测性方案’ 课件  阿里云计算环境 可以使用腾讯云计环境，配合以下的课件完成所有练习。\n 课件开发中。\n",
    "ref": "/blog/workshop-elastic-observability/"
  },{
    "title": "博客换一个新样式",
    "date": "",
    "description": "将所有可能都放在了 Github 上。",
    "body": "这是一个拖了很久的工作，旧的样式被改的太乱了，已经无法继续使用了，更新一下重新来过。\n新主题 这次选择了名为 “HUGO FUTURE IMPERFECT SLIM” 的模板。\n它的功能非常丰富：\n 界面简洁，兼具丰富的格式，博客文章有头图 带有侧栏 带有 ‘about’ ‘categories’ ‘contact’ 等独立页面格式，无头图 具有多语言支持和菜单选择 带有搜索页面 带有讨论功能  这些都是今后可以使用到的功能。\n网站所在位置 DNS 使用 Cloudflare 解析，启用了完全 HTTPS 访问，附加 https 重定向的页面规则。\n在 Github 上启用了 github-page 的自定义页面，并且支持 https 访问。\nGithub 上使用 master 作为开发分支，更新后部署到 gh-pages 分支。\n网站的部署 部署使用了 Github Action 的功能。\n# Workflow to build and deploy site to Github Pages using Hugo # Name of Workflow name: Deploy github-pages # Controls when the action will run. Triggers the workflow on push or pull request # events but only for the master branch on: push: branches: [ master ] # A workflow run is made up of one or more jobs that can run sequentially or in parallel jobs: # This workflow contains a single job called \u0026quot;deploy\u0026quot; deploy: # The type of runner that the job will run on runs-on: ubuntu-latest # Steps represent a sequence of tasks that will be executed as part of the job steps: # Step 1 - Checks-out your repository under $GITHUB_WORKSPACE - name: Checkout uses: actions/checkout@v2 with: submodules: true # Fetch Hugo themes fetch-depth: 0 # Fetch all history for .GitInfo and .Lastmod # Step 2 - Sets up the latest version of Hugo - name: Setup Hugo uses: peaceiris/actions-hugo@v2 with: hugo-version: 'latest' # Step 3 - Clean and don't fail - name: Clean public directory run: rm -rf public # Step 4 - Builds the site using the latest version of Hugo # Also specifies the theme we want to use - name: Build run: hugo --minify # Step 5 - Create name file - name: Create cname file run: echo 'martinliu.cn' \u0026gt; public/CNAME # Step 6 - Push our generated site to our gh-pages branch - name: Deploy uses: peaceiris/actions-gh-pages@v3 with: github_token: ${{ secrets.DEPLOY_KEY }} publish_dir: ./public 后续事项  样式表加载问题 就文章头图加载问题 多分支工作 ",
    "ref": "/blog/change-back-on-github-page-again/"
  },{
    "title": "DevOps Coach 周刊 #6",
    "date": "",
    "description": "推荐 DevOps 教练学习的全球新闻，文章，宕机事件和流行工具",
    "body": "宕机  上一周新发的宕机事故。 近期全球重大宕机事故的分析总结、事后回顾。   May your queries flow and your pagers stay silent. \u0026ndash;Dave, Betsy, Niall, Stephen, and Ken\n 上周新发事故  Zoom 无法开始和加入会议， 官方报道 https://status.zoom.us/incidents/1z2lrf4nrv8p Slack 多个功能模块服务降级，甚至无法使用，官方：https://status.slack.com//2020-08/960bbb3c9d49a3cc Let\u0026rsquo;s Encrypt 数据中心硬件方式故障导致 API 报错，官方：https://status.io/pages/incident/55957a99e800baa4470002da/5f45330250878c04bf3fb6eb NZX 新西兰证券交易所遭受重大DDoS攻击导致NZX停电，交易停止。媒体：https://www.stuff.co.nz/business/122562006/major-ddos-attack-causes-nzx-power-outage-trading-halt eBay宕机。服务器状态最新，DNS故障和服务不可用的错误错误，媒体：https://www.express.co.uk/life-style/science-technology/1329281/eBay-down-server-status-DNS-failure-service-unavailable-error Heroku 发生大量的 H100 报错，官方：https://status.heroku.com/incidents/2101 Fastly CDN 服务商的服务发生多区域性能故障，官方：https://status.fastly.com/incidents/p1lwmmv2j2gq Cloudflare 上周发生的这个问题，我的个人 blog 也遇到了，Google 的搜索索引服务记录了那些 500 错误，我也感到非常诧异；第三方传输供应商问题导致HTTP 5xx错误增加； 官方：https://www.cloudflarestatus.com/incidents/hptvkprkvp23  鳄鱼杯：2020年第二季度最大宕机颁 来源：https://statusgator.com/blog/2020/08/21/5-biggest-outages-of-q2-2020/\n任何可能发生的坏事都会发生。这句古老的谚语100%适用于技术行业，在这个行业中，崩溃和中断远比销售和营销团队希望我们想象的要常见得多。然而，与基础设施打交道的DevOps工程师知道，要确保所有东西都能一直按预期工作是多么困难\u0026ndash;并配置监控，实际跟踪系统的健康状况，帮助防止崩溃和停机。\n在StatusGator，我们监控800多个基于云的服务的状态页面，并向用户提供即时通知。我们拥有堆积如山的宕机和中断数据，并能看到全貌，因此我们决定每季度制定一份最高宕机时间列表。我们希望我们的发现能够激励DevOps工程师去看看其他人是如何处理服务中断的，以便他们能够提高自己的可靠性。\n请继续阅读，了解2020年第二季度的五大故障，以及Slack、Zoom、GitHub、IBM Cloud和T-Mobile在这些危机中如何行动。我们还对这些故障的结果进行了评级，并很乐意听到您对我们评级的看法。\n第一名 Slack 全球范围的服务中断, May 12, 2020 Slack是全球数千家公司的主要沟通方式，因此其稳定的正常运行时间是最重要的问题。因此，当用户在美国东部时间晚上7:30左右停止发送和接收Slack消息时，情况迅速升级为一个全面的问题。与之前的故障期间不同，这影响到了整个Slack生态系统：没有人能够登录Slack，也没有人能够收到任何通知。\u0026ldquo;Slack宕机了吗？\u0026quot;，用户们自问自答，答案是毋庸置疑的 \u0026ldquo;是！\u0026rdquo;\n美国东部时间晚上10:26，Slack报告全面恢复了服务，并再次为造成的不便道歉。更重要的是，他们在Medium上发表了一份详细的事后报告，解释了问题背后的原因，他们为克服这个问题所采取的行动，得出的结论，以及他们正在采取的措施，以消除类似情况再次发生的机会。\n欢迎阅读这篇事后总结，它的技术性很强，但即使是普通人也很容易理解。Slack在这里展示了他们对用户群成员\u0026ndash;包括开发者和大众用户群\u0026ndash;的关心，这篇文章所投射出的信心令人钦佩。\n这里需要注意的是，虽然问题本身是在美国东部时间上午8:30开始的，但直到美国东部时间晚上7:30左右，多名用户报告了Slack的问题，这个问题才完全被人察觉。在Slack团队意识到这一情况之前，他们在应用内部（当时大部分已经宕机）、Twitter上、Downdetector上、Slack网站（很快就宕机了）以及其他许多渠道进行了报告。\n第二名 Zoom 宕机, May 17, 2020 自冠状病毒大流行以来，随着越来越多的人远程工作和学习，Zoom的使用率急剧上升。Zoom状态页面的订阅量也是如此，自4月份以来，StatusGator中的订阅量急剧上升。\n除了企业被迫开始远程办公外，许多教会和其他公共组织也开始使用Zoom来举行周日弥撒、会议以及举办公共活动。因此，虽然周日不是工作日，但英国的许多付费账户很快就发现他们无法主持或加入Zoom会议（免费账户似乎没有受到影响）。这个问题通过多种渠道被报告，包括Twitter和监控Zoom状态的StatusGator。\nZoom发言人回应称，承认意识到了这一情况，并提到这只影响了一个子集的用户。然而，我们都知道子集可能是1%或99%，Zoom没有提供任何关于受影响用户量的说明。提供更透明的受影响用户的比例是一个高质量状态页面的标志，这是Zoom应该改进的地方。\n第三名 GitHub 又无法访问了. June 29, 2020 自从GitHub被微软以75亿美元收购后，GitHub似乎又下降了很多。原因尚未披露，我们只能猜测原因。也许是与GitHub基础设施与微软系统的整合有关。也许是因为GitHub的发展速度更快，增加了更多的功能。无论如何，从收购到现在已经快两年了，用户发现GitHub的持续宕机时间越来越长。我们对GitHub状态页面的独立分析证实，在过去的两年里，宕机变得更加频繁。\n微软正在努力将GitHub变成一个比以前更好的开发者场所。这家雷德蒙德巨头在今年早些时候让所有的付费计划变得更加实惠，并免费提供一些关键功能，将更多的工具放在IT专业人士的手中。微软、苹果、AWS、谷歌、Facebook和其他数千家公司使用GitHub来存储和运行他们的代码仓库，因此它的正常运行时间是最重要的。\n然而，GitHub在2020年6月29日出现了两个小时的故障。整个网站及其服务都无法访问，因此许多开发人员甚至无法推送代码或部署他们的应用程序，因为GitHub集成的数量没有响应。自然，这引起了很大的反响，并导致GitHub除了状态页面外，还推出了每月的可用性报告，对每次中断的原因和结果进行了详细的解释。\n第四名 IBM Cloud 挂了，服务状态页面有更新, June 10, 2020 任何基于云的服务都会犯的最大错误之一就是将其状态页面托管在自己的基础设施上。看来IBM云就是这么做的，所以当它的整个基础设施在6月份有几个小时无法访问的时候，它的状态页面也随之而来。我们本可以期待IBM在今年3月的达拉斯宕机事件后得出一些结论，但是，显然，他们并没有理会，或者说没有做出足够的努力。\n于是，在2020年6月10日，IBM云基础设施在全球范围内宕机。这次宕机使得Watson AI、IBM Cloud Foundry、Kubernetes Service、云对象存储、身份访问和管理、VPS的VPN、App Connect等功能完全无法访问。幸运的是，IBM Cloud状态页面只在中断初期无法使用，后来才断断续续地可用。这也是为什么StatusGator还能向订阅了IBM Cloud状态页面的用户发送提醒的原因。\n该公司完全没有告知中断的原因，以及为缓解影响所采取的措施。后来从一个独立的监控服务机构了解到，一个第三方网络提供商广泛使用了流量路线，导致IBM云配置带宽严重受限。IBM专家对系统进行了重新配置，并恢复了运行，但随后并没有官方的解释或公告\u0026ndash;这让用户非常失望。\n这不是IBM第一次在公共关系上失败，我们认为，也不会是最后一次。这可能是他们尽管提供了多样化的有竞争力的云服务，却远远落后于AWS、谷歌云平台、微软Azure和其他云服务商的原因之一。\n但IBM能做什么呢？自然是有一个独立的状态页面! 下面只是他们可以使用的一些变种。\n第五名 T-Mobile冲洗其网络下水道，2020年6月15日。 作为美国、欧盟和英国最大的移动网络运营商之一，T-Mobile最近发现自己正处于一场完美的风暴之中，它在美国各地连续13个小时无法提供语音和短信服务。外界观察家马修-普林斯（Matthew Prince，CEO@Cloudflare）认为，\u0026ldquo;T-Mobile对他们的网络进行了一些改变，但这些改变出了问题，导致他们的用户出现了一连串的故障\u0026rdquo;。他还表示，\u0026ldquo;这场灾难几乎可以肯定完全是T-Mobile团队自己造成的\u0026rdquo;。\n相反，T-Mobile技术总裁Neville Ray在推特上表示，虽然这确实是一个 \u0026ldquo;影响全国用户语音和文字服务的重大问题\u0026rdquo;，但它源于第三方供应商的系统故障，T-Mobile的工程师正在努力修复。随后，他在博客中详细阐述了这一话题，并对故障原因进行了解释。\n引用雷先生的话说：\u0026ldquo;据悉，触发事件是东南部的第三方供应商的租用光纤电路故障。这是每一个移动网络都会发生的事情，所以我们与我们的供应商合作，建立冗余和弹性，以确保这种类型的电路故障不会影响客户。这种冗余让我们失败了，导致了过载的情况，然后又因为其他因素而变得更加复杂'。这导致IP池过载，美国所有地区都发生了崩溃。\n由于无法接触到大多数服务，T-Mobile的客户开始报告Facebook、Instagram和其他平台无法使用，而实际上离线的是他们的移动运营商网络。Business Insider报道称，虽然T-mobile客户将故障归咎于AT\u0026amp;T和Verizon，但这两家运营商都是在正常的负载水平下运营的。不过，前述Neville Ray的帖子表示，T-Mobile正在采取一切必要措施，通过为所有核心系统建立双重弹性和冗余措施，确保未来不可能发生此类事件。\n可以看到，公司无法明确表达自己的立场，从一开始就不愿意承担失败的责任，以及在故障发生后缺乏透明度，都没能让T-mobile毫无污点地走出困境。这甚至导致了他们面临大规模DDoS攻击却未能击退的传闻。\nStatusGator为第二季参赛者颁奖 让我们根据这些宕机事件的发现、相关公司的沟通以及每个事件的结果来评定。\n新闻 软件发布  Kubernetes 1.19 发布了， 它由34项增强功能组成。10个增强版转为稳定版，15个增强版在测试版，9个增强版在alpha版。 AWS 发布新的 EBS 卷类型 (io2) 提高 100x 持久性，和 10x 倍的 IOPS/GiB Tekton Hub 预览版上线，随着该项目对底层流水线和构建的定义的日臻成熟，开放出一个相关的自由市场也是必然的，开源生态催生出来的上下游技术提供和消费的模式正在普及中，无周边生态的很难获利和发展，https://hub-preview.tekton.dev/  DevOps 大会/峰会 中国 DevOps 社区流水线大赛 \u0026ndash; Pipeline Craft Championship  8 月 18 日开始为期两个月，免费活动 报名：https://wj.qq.com/s2/6852880/c181 活动官网：https://Pipeline.devopsmeetup.com  SnykCon  将在10月21日/22日举行一个关于所有应用安全和 DevOps 的在线活动。免费注册，CFP现在开放。 https://snyk.io/snykcon/  推荐和分享你感兴趣的大会和峰会给我和其它人吧？发邮件到：martin@devopscoach.org\n文章   这是一篇很好的文章，讲述了在整个组织中获得变革的支持时，自动化这个词所带来的问题，以及为什么观念很重要。\n  https://blogs.starcio.com/2020/08/avoid-calling-it-automation.html\n  什么是Kubernetes Operators，为什么它对SRE很重要？\n  在Kubernetes Operators: 自动化容器编排平台》中，作者Jason Dobies和Joshua Wood将Operators描述为 \u0026ldquo;其应用的自动化站点可靠性工程师\u0026rdquo;。鉴于SRE的多方面经验和多样化的工作量，这是一个大胆的说法。那么，Operators到底能做什么呢？\n  https://www.blameless.com/blog/what-is-a-kubernetes-operators-and-how-to-automate-sre\n  探讨遗留IT系统的隐秘世界。探讨了一些值得注意的事件，以及我们需要更多地了解如何建立可长期运行的系统。\n  https://spectrum.ieee.org/computing/it/inside-hidden-world-legacy-it-systems\n  一篇文章，讲述了随着组织的发展，增加一个总括性的平台团队的风险，以及为什么向平台组件和重用发展可以更具扩展性。\n  https://kislayverma.com/organizations/a-case-against-platform-teams/\n  NoOps Go on Cloud Run\n  https://medium.com/@peter.malina/noops-go-on-cloud-run-689d92215c5c\n  工具  werf/werf : GitOps 交付工具 ovh/cds : 企业级持续交付和 DevOps 自动化开源平台， markphelps/flipt 一个现代的功能开关方案 fluxcd/toolkit ： 用 GitOps 的方式组装 CD 流水线的体验版工具包。   学习资源 本周推荐如下 B 站学习资源。\nJenkins+Ansible+Gitlab自动化部署（CI/CD）\n https://www.bilibili.com/video/BV1Dp411Z7Lf 持续集成在工作中的应用。  通俗易懂ElasticSearch 项目实践课程\n https://www.bilibili.com/video/BV1wA411n7LY 搜房网实例项目讲解  【Python趣味教学】99%相似度！手把手教你用Python制作超级玛丽游戏\n https://www.bilibili.com/video/BV1G54y197C2 前26集都在这了，爱编程的小伙伴们，一起来重现童年经典吧！  Kubernetes教程 k8s企业级DevOps实践\n https://www.bilibili.com/video/BV1c64y1F7wP k8s是一个开源的，用于管理云平台中多个主机上的容器化的应用，Kubernetes的目标是让部署容器化的应用简单并且高效（powerful）,Kubernetes提供了应用部署，规划，更新，维护的一种机制。  ",
    "ref": "/blog/devopscoach-weekly-6/"
  },{
    "title": "Elasticsearch 3 节点集群搭建 (7.9.0)",
    "date": "",
    "description": "高可靠性 3 节点的 ES 集群适用于各种应用场景",
    "body": "最近发布的 Elastic Stack 7.9 ，带来了很多新的特性。Elastic Agent 统一集成数据采集代理是一大亮点。另外还看增加了企业搜索、端点安全防护等组件。Ingest Manager 统一 Beat 配置管理功能让我们向 SaaS 风格的监控工具又迈进了一步。由代理端自行注册到后端，在后端统一纳管所有被管理服务器，将是一种以后非常通用的模式。这样做的好处是：将数据采集端点的配置工作量和复杂度降低到最低。Beats 的各种相关独立模块也在平行的发布，这种双轨模式也可以让用户更弹性的做出选择，能最大程度的保持旧版本部署环境管理模式的延续性。 Ingest manager 的前提条件是：后台 ES 需要启用 api key 安全，启用 ES 客户端的 HTTPS 访问。我们也可以看到这两个功能选项也有其非常广泛的应用需求。本文将用最简单的文字，向你描述一套 3 节点的 ES 集群的搭建方式，这套系统的核心特性如下：\n 启用用户名和密码认证 启用集群内 es 节点间 transport.ssl 通讯加密 启用 es 的 http 客户端 http.ssl 加密通讯 安装脚本中包括创建数字证书的必要命令（没猜错的话，大部分人可能会在这一步花费大量时间）  演示环境介绍 我使用的是本地的测试环境，环境配置如下：\n Mac OS vagrant virtualBox - CentOS 8 Elastic Stack 7.9.0 ip 和主机名分配见 Vagrantfile 文件 Vagrant 的 vagrant-hostsupdater 插件实现了 Mac OS 主机和所有虚拟机的 host 文件 DNS 解析的同步，保证所有相关虚拟机都可以解析其它虚拟机的 FQDN，尽量模拟生产环境。  本文所使用的所有配置文件和安装脚本见：https://github.com/DevOps-Coach/elasticstack.git\n➜ elasticstack git:(master) ✗ vagrant up es1 es2 es3 Bringing machine 'es1' up with 'virtualbox' provider... Bringing machine 'es2' up with 'virtualbox' provider... Bringing machine 'es3' up with 'virtualbox' provider... ==\u0026gt; es1: Importing base box 'bento/centos-8'... ==\u0026gt; es1: Matching MAC address for NAT networking... ==\u0026gt; es1: Checking if box 'bento/centos-8' version '202002.04.0' is up to date... 省略中间大量输出。。。。。。 es3: ● elasticsearch.service - Elasticsearch es3: Loaded: loaded (/usr/lib/systemd/system/elasticsearch.service; enabled; vendor preset: disabled) es3: Active: active (running) since Thu 2020-08-27 05:55:21 UTC; 223ms ago es3: Docs: https://www.elastic.co es3: Main PID: 4205 (java) es3: Tasks: 41 (limit: 11499) es3: Memory: 1.2G es3: CGroup: /system.slice/elasticsearch.service es3: ├─4205 /usr/share/elasticsearch/jdk/bin/java -Xshare:auto -Des.networkaddress.cache.ttl=60 -Des.networkaddress.cache.negative.ttl=10 -XX:+AlwaysPreTouch -Xss1m -Djava.awt.headless=true -Dfile.encoding=UTF-8 -Djna.nosys=true -XX:-OmitStackTraceInFastThrow -XX:+ShowCodeDetailsInExceptionMessages -Dio.netty.noUnsafe=true -Dio.netty.noKeySetOptimization=true -Dio.netty.recycler.maxCapacityPerThread=0 -Dio.netty.allocator.numDirectArenas=0 -Dlog4j.shutdownHookEnabled=false -Dlog4j2.disable.jmx=true -Djava.locale.providers=SPI,COMPAT -Xms1g -Xmx1g -XX:+UseG1GC -XX:G1ReservePercent=25 -XX:InitiatingHeapOccupancyPercent=30 -Djava.io.tmpdir=/tmp/elasticsearch-14730718416313121303 -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/var/lib/elasticsearch -XX:ErrorFile=/var/log/elasticsearch/hs_err_pid%p.log -Xlog:gc*,gc+age=trace,safepoint:file=/var/log/elasticsearch/gc.log:utctime,pid,tags:filecount=32,filesize=64m -XX:MaxDirectMemorySize=536870912 -Des.path.home=/usr/share/elasticsearch -Des.path.conf=/etc/elasticsearch -Des.distribution.flavor=default -Des.distribution.type=rpm -Des.bundled_jdk=true -cp /usr/share/elasticsearch/lib/* org.elasticsearch.bootstrap.Elasticsearch -p /var/run/elasticsearch/elasticsearch.pid --quiet es3: └─4360 /usr/share/elasticsearch/modules/x-pack-ml/platform/linux-x86_64/bin/controller es3: es3: Aug 27 05:54:54 es3.zenlab.local systemd[1]: Starting Elasticsearch... es3: Aug 27 05:55:21 es3.zenlab.local systemd[1]: Started Elasticsearch. es3: Provisioning script works good! es3: Please access Elasticsearch https://192.168.50.13:9200 最后的系统登录验证命令：\n➜ elasticstack git:(master) ✗ curl --cacert certs/ca/ca.crt -u elastic 'https://es1.zenlab.local:9200/_cat/nodes?v' Enter host password for user 'elastic': ip heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name 192.168.50.13 26 95 8 0.03 0.31 0.18 dilmrt - es3 192.168.50.12 33 95 0 0.01 0.14 0.09 dilmrt - es2 192.168.50.11 36 93 1 0.06 0.16 0.12 dilmrt * es1 以上命令需要输入 elastic 用户的密码，es1 节点初始化了所有 Elasticsearch 内置用户的密码，需要复制 console 中的那一段密码信息备用。\n创建以上所有数字证书和秘钥文件的种子文件是 certs/instance.yml ：\n# instance.yml instances: - name: 'es1' ip: ['192.168.50.11'] dns: [ 'es1.zenlab.local' ] - name: \u0026quot;es2\u0026quot; ip: ['192.168.50.12'] dns: [ 'es2.zenlab.local' ] - name: 'es3' ip: ['192.168.50.13'] dns: [ 'es3.zenlab.local' ] - name: 'es4' ip: ['192.168.50.14'] dns: [ 'es4.zenlab.local' ] - name: \u0026quot;es5\u0026quot; ip: ['192.168.50.15'] dns: [ 'es5.zenlab.local' ] - name: 'es6' ip: ['192.168.50.16'] dns: [ 'es6.zenlab.local' ] - name: 'es7' ip: ['192.168.50.17'] dns: [ 'es1.zenlab.local' ] - name: \u0026quot;es8\u0026quot; ip: ['192.168.50.18'] dns: [ 'es2.zenlab.local' ] - name: 'es9' ip: ['192.168.50.19'] dns: [ 'es3.zenlab.local' ] - name: 'lk' ip: ['192.168.50.20'] dns: [ 'lk.zenlab.local' ] 这里一次性生产了所有我这个本地测试环境里可能用到的数字证书文件。\nElasticsearch 安装脚本 下面是第一个 Elasticsearch 节点的安装脚本和注释，pre-install-es1.sh ：\n#!/bin/bash # author: Martin Liu # url:martinliu.cn #指定安装的版本 elastic_version='7.9.0' #开始安装流程 echo \u0026quot;Provisioning a Elasticsearch \u0026quot;$elastic_version\u0026quot; Server...\u0026quot; sudo date \u0026gt; /etc/vagrant_provisioned_at #配置 ES 需要的操作系统参数 sudo swapoff -a sudo sysctl -w vm.max_map_count=262144 sudo sysctl -p sudo sh -c \u0026quot;echo 'elasticsearch - nofile 65535' \u0026gt;\u0026gt; /etc/security/limits.conf\u0026quot; #设置个性化 SSH 登录提示信息 sudo sh -c \u0026quot;echo '**** -- -- -- -- -- -- -- -- ****' \u0026gt; /etc/motd\u0026quot; sudo sh -c \u0026quot;echo '**** Welcome to Elastic Stack Labs' \u0026gt;\u0026gt; /etc/motd\u0026quot; sudo sh -c \u0026quot;echo '**** -- -- -- -- -- -- -- -- ****' \u0026gt;\u0026gt; /etc/motd\u0026quot; sudo sh -c \u0026quot;echo '*' \u0026gt;\u0026gt; /etc/motd\u0026quot; #安装 ES 软件包 sudo rpm -ivh /vagrant/rpm/elasticsearch-$elastic_version-x86_64.rpm #创建 ES 集群内部通信加密数字证书，提前清理旧的证书文件和目录 sudo rm -f /vagrant/certs/certs.zip sudo rm -rf /vagrant/certs/es* sudo rm -rf /vagrant/certs/ca sudo rm -rf /vagrant/certs/lk sudo /usr/share/elasticsearch/bin/elasticsearch-certutil cert -in /vagrant/certs/instance.yml -pem -out /vagrant/certs/certs.zip -s #解压缩所有证书备用 sudo /usr/bin/unzip /vagrant/certs/certs.zip -d /vagrant/certs/ #部署节点需要的秘钥 sudo cp /vagrant/certs/ca/ca.crt /etc/elasticsearch/ sudo cp /vagrant/certs/es1/* /etc/elasticsearch/ #更新 ES 默认的配置文件 sudo cp /vagrant/es1.yml /etc/elasticsearch/elasticsearch.yml #配置和启动 ES 系统服务 sudo systemctl daemon-reload sudo systemctl enable elasticsearch.service sudo systemctl start elasticsearch.service sudo systemctl status elasticsearch #初始化 ES 服务器内建用户的密码，这些密码需要在控制台上复制保存备用 sudo /usr/share/elasticsearch/bin/elasticsearch-setup-passwords auto -b #成功顺利的完成了安装 echo Provisioning script works good! echo Please access Elasticsearch https://192.168.50.11:9200 说明：你也可以参考以上脚本手工执行，如果是非 Vagrant 环境，请注意替换各个命令中相关文件的路径。第二个和第三个节点的安装脚本稍有不同，详情见代码库。\nElasticsearch 配置文件 下面是第一个 Elasticsearch 节点的参考配置文件， es1.yml ：\n# ---------------------------------- Cluster ----------------------------------- #设定集群名称 cluster.name: elk4devops # ------------------------------------ Node ------------------------------------ #设定节点名称，此处使用的是 hostname node.name: es1 # ----------------------------------- Paths ------------------------------------ #设定 es 服务器数据目录 path.data: /var/lib/elasticsearch #设定 es 服务器日志目录 path.logs: /var/log/elasticsearch # ---------------------------------- Network ----------------------------------- #设定此节点加入网络的名称，这里使用的是 FQDN network.host: es1.zenlab.local # --------------------------------- Discovery ---------------------------------- #设定初始的 master 节点为 es1 cluster.initial_master_nodes: [\u0026quot;es1\u0026quot;] discovery.seed_hosts: [\u0026quot;es1.zenlab.local\u0026quot;] # ------------------------------- TLS and Cert --------------------------------- #启用用户名和密码认证 xpack.security.enabled: true #启用 ES 集群内加密传输 xpack.security.transport.ssl.enabled: true xpack.security.transport.ssl.certificate_authorities: ca.crt xpack.security.transport.ssl.key: ${node.name}.key xpack.security.transport.ssl.certificate: ${node.name}.crt #启用 ES 集群客户端访问加密 xpack.security.http.ssl.enabled: true xpack.security.http.ssl.certificate_authorities: ca.crt xpack.security.http.ssl.key: ${node.name}.key xpack.security.http.ssl.certificate: ${node.name}.crt # For Elastic Agent xpack.security.authc.api_key.enabled: true #启用监控数据收集 xpack.monitoring.collection.enabled: true # ------------------------------- App Search --------------------------------- #提前为 App Search 做好准备 action.auto_create_index: \u0026quot;.app-search-*-logs-*,-.app-search-*,+*\u0026quot; 说明：第二个和第三个节点的配置文件稍有不同，详情见代码库。\n总结 在三节点集群的搭建过程中，最好建议启用各种安全和加密选项，用配置安装脚本最小化工作量；这样一步到位的安全性，可以为后续增加其他 Elastic Stack 的产品组件打下良好的基础，ES 集群的配置尽量完善，尽量覆盖后期的其他各种潜在需求，减少未来配置变更的工作量，让后续的测试越来越轻松。\n",
    "ref": "/blog/elasticsearch-3-nodes-cluster-setup/"
  },{
    "title": "DevOps Coach 周刊 #5",
    "date": "",
    "description": "推荐 DevOps 教练学习的全球新闻，文章，宕机事件和流行工具",
    "body": "宕机  上一周新发的宕机事故。 近期全球重大宕机事故的分析总结、事后回顾。   May your queries flow and your pagers stay silent. \u0026ndash;Dave, Betsy, Niall, Stephen, and Ken\n Equinix 重大电力故障让数据中心客户大发雷霆  关于 Equinix ：Equinix 是全球领先的数据运营商，目前在美洲、亚太、欧洲及中东 14 个国家（地区）的 31 个市场运营着 94 个国际业务交换。 消息来源 CBR https://www.cbronline.com/news/equinix-outage   教练点评：数据中心 UPS 的单点故障并不稀奇，但是这次 Equinix 的事故堪称史诗级事故。\n \u0026ldquo;经历如此严重的停电，显然是不可接受的\u0026rdquo;\n北京时间 8 月 19 日 8 点 10 分更新：最后的电路似乎已经在 8 月 18 日晚间约 22 点 20 分恢复；在停电开始后约 18 小时。\n数据中心巨头 Equinix 表示，在其位于伦敦码头区的 IBX LD8 数据中心遭遇长时间停电后，它已经为所有客户恢复了机架\u0026ndash;该问题使数百名客户（包括几家 ISP）的服务从北京时间凌晨 4:30 开始离线；使许多人对缓慢的电力恢复深感沮丧。\n\u0026ldquo;Equinix 工程师已将问题的根本原因诊断为 UPS（不间断电源）系统故障，我们正在与客户合作，以尽量减少影响。该公司在北京时间 8 月 18 日 12:04 的首次公开声明中表示：\u0026ldquo;我们对由此造成的任何不便感到遗憾。(ISP Giganet 负责人 Matthew Skipsey 早些时候将 Equinix 缺乏沟通描述为 \u0026ldquo;糟糕透顶\u0026rdquo;)。\n多名客户指出，该问题是 Galaxy UPS 系统(由施耐德销售)中的输出静态开关出现故障。该开关将关键负载连接到 UPS 的条件电源或旁路电源的原始电源。停电时间的长短表明，LD8 的 A+B 交流电源是来自同一个 UPS。期望其直流供应商确保弹性和依赖单一数据中心的 ISP 正在吸取惨痛教训。\n伦敦互联网交易所 LINX 同时表示，约有 150 名 LINX 会员直接受到此次事件的影响。(到 13:42，LINX 的所有设备都恢复了。该组织有 900 多个 ASN 从 80 多个不同的国家连接）。)\n受影响的一个客户是 ISP Giganet。它告诉客户。\u0026ldquo;我们仍在等待我们的网络架恢复供电 继 Equinix 和他们的承包商在早期故障后将电源迁移到新的基础设施上之后。\n\u0026ldquo;可悲的是，仍然没有估计的修复时间，这是最令人沮丧的。他们已向我们保证，他们将在可能的情况下提供这一信息。Equinix 不断被追问最新情况。正如您所了解的那样，这是一个 P1 问题，影响着许多 100 多家其他运营商/ISP\u0026ndash;所以它被赋予了最大的优先级。\u0026rdquo;\n据了解，英国电信也是受影响的公司之一。数据中心的访问控制系统已经被中断，一个客户，马修-斯基普西说，\u0026ldquo;所以一切[是]通过双向无线电手动运行，然后通过其他地方打电话。疯狂的时代。这是一个 MBORC 的地狱。\u0026rdquo;\nEquinix 表示，它允许客户 \u0026ldquo;更灵活地访问 LD8\u0026rdquo;，因为它争分夺秒地解决这个问题，\u0026ldquo;在我们的 COVID-19 限制内工作\u0026rdquo;。\nGiganet 补充道：\u0026ldquo;我们已经在凌晨 4.23 时左右失去了我们 2 个 Equinix LD8 机架中的 1 个机架的两个 A+B 馈线。此前，根据 Equinix 的报告，UPS 出现故障，然后触发了数据中心的火警。我们失去电源的机架上安装着我们的核心 Juniper MX 路由器和 Cisco LNS。瞻博网络 MX 路由器是我们的核心设备，LD8 中的一切功能都需要它，包括终止一些专线连接以及为我们的 vDC 平台提供连接。我们所有的设备电源都是由数据中心提供的\u0026rsquo;多样化\u0026rsquo;A+B 电源双馈\u0026ndash;但是经过这次事件，我们怀疑是缺乏弹性，在事件解决后一定会提出来，因为经历如此严重的断电显然是不可接受的。\u0026rdquo;\nGoogle 公司的云平台和 G Stuit 系列事故  来源官方 https://status.cloud.google.com/incident/zall/20008#20008005 Google Cloud Infrastructure Components Incident #20008 GCP 多个产品发生故障：App Engine, Cloud Storage 和 Cloud Logging G Suit 多个模块和功能：Gmail, Drive, Docs/Editor, Chat, Meet, Keep, Voice, Jamboard, Admin Console 事故时间：August 19, 2020, from 20:55 to 03:30 诊断：AppEngine 的部署会报错，访问 GCS 桶时的高延迟，以及 Cloud Logging 中的日志条目丢失。G Suit 多种产品报错和无法使用。 详细的事故总结报告https://static.googleusercontent.com/media/www.google.com/zh-CN//appsstatus/ir/bd9m3vkqwpvkk4j.pdf 根本原因  许多 Google 服务使用一个通用的、内部的、分布式的系统来存储不可变的、非结构化的数据，也就是二进制大对象，或者说 blob。这个 blob 存储系统包含一个与 Google 内部客户端服务对接的前端，一个处理元数据操作的中层，以及一个用于存储数据的后端。blobs 本身。当客户端向前端提出请求时，元数据操作被转发到元数据服务，元数据服务与存储服务进行通信。 来自另一个 Google 服务的流量增加开始使元数据服务超载，导致任务变得不健康，请求的延迟增加。这种延迟促使这些操作的过度重试，导致资源耗尽。自动化系统试图启动新的元数据任务。然而，其中许多任务立即被其收到的流量所淹没，而这些任务也被淹没。由于资源枯竭，分配到的资源不足。这一问题因以下原因而更加严重： 策略用于取消和重试失败的请求，这对流量造成了倍增效应。 与其他产品相比，谷歌云存储受到的影响较小。虽然谷歌云存储是建立在 同一个 blob 存储系统，GCS 的元数据层大多与受影响的元数据层隔离。谷歌内部元数据服务。对于 \u0026ldquo;美国\u0026rdquo;，GCS 元数据隔离的迁移正在进行中。多区域，而所有其他迁移工作已经完成。因此，对全球通信系统客户的影响是 减少，这种影响仅限于 \u0026ldquo;美国 \u0026ldquo;多区域。     教练点评：从事发时刻到 Google 工程师收到告警的时刻（20：58）之间只有短短的 3 分钟，在一个小时内受影响的各个 GCP 服务就开始了并行的调查和补救措施。在 23：00 定位到 blob 存储是根因故障，并实施配置变更，消除了大多数的内部错误。这正是 SRE 中所讨论的重大事故应急流程的有效执行，能快速有效的恢复服务。可以看出 Google 团队在事故响应方面的训练有素。\n Spotify  来源官方 Twitter 账号： https://twitter.com/SpotifyStatus/status/1296064517504409600 这好像是由于 TLS 证书过期导致的。 其它媒体报道： https://www.teiss.co.uk/spotify-outage-expired-tls-cert/ 据报道，周三发生了影响音乐流媒体服务 Spotify 的长达一小时的大规模中断，原因是该公司未能在 TLS 证书到期前更新。 不过，Cloudflare 的网络工程师 Louis Poinsignon 提供了 Spotify 系统内部到底发生了什么事情的线索。据他介绍，该公司显然没有及时更新 TLS 证书，证书过期导致中断。在 TLS 证书更新后，Spotify 的服务很快就恢复了在线。   教练点评：Spotify 的特有的团队工作开发模式一直是一种学习的榜样，很难想象他们的服务会在这样简单的问题上翻船。\n 新闻 DevOps 大会/峰会 中国 DevOps 社区流水线大赛 \u0026ndash; Pipeline Craft Championship\n 8 月 18 日开始为期两个月，免费活动 报名：https://wj.qq.com/s2/6852880/c181 活动官网：https://Pipeline.devopsmeetup.com  GitLab 的大会 \u0026ndash; Commit: You belong here\n 8 月 26 日 线上免费峰会 https://about.gitlab.com/events/commit/  推荐你感兴趣的大会和峰会，发邮件到：martin@devopscoach.org\nGrafana Labs 喜提 B 轮 5000 万美元融资  来源官方：https://grafana.com/about/press/2020-08-17-series-b-announcement/ 8 月 27 日宣布 Grafana Labs 还宣布了 Grafana 加速器计划（GAP），以培养在更广泛的 Grafana 生态系统中进行创新的早期公司和副业项目。GAP 将提供免费的 Grafana Cloud 和 Grafana Enterprise 订阅、现金补助、股权融资以及进入 Grafana Labs 核心开发者的内部通道。   教练点评：这个 CNCF 的热门项目终于迈向了商业化的第一步，随着企业订阅模式的形成，且看后续的创新开发和社区经营是否也能一浪高过一浪。\n 文章   《 Ops 工作的未来 》\n  一篇关于运维角色变化的好文章。对于那些想知道现代运维是什么样子的人来说，有一些很好的提示，包括供应商管理、外包基础设施和理解社会技术系统的重要性。\n  https://acloudguru.com/blog/engineering/the-future-of-ops-jobs\n  《 NAT 是如何工作的 》\n  对于任何想要更好地了解这个网络领域的人来说，这是一本很好的 NAT 网络介绍。好的图和例子，还有很多细节。\n  https://tailscale.com/blog/how-nat-traversal-works/\n  《 如何打造给董事会看的软件开发 KPI 报表 》\n  度量标准有很多不同的用途，包括向组织高层报告。这篇文章探讨了用于董事会对话的工程 KPI。\n  https://codeclimate.com/blog/engineering-kpis-board-deck/\n  《 马丁富乐老师：单链接通道 》\n  有没有想过确保服务之间的消息保持有序，并为任何丢失的消息建立重试机制？这篇文章描述了一个具体的模式，但也是一组关于分布式计算模式的文章的一部分，值得探讨。\n  https://martinfowler.com/articles/patterns-of-distributed-systems/single-socket-channel.html\n  《 提升事故回顾质量的套路 》\n  事故回顾越来越常见，但往往很难做好。这段视频和详细的文字记录有各种改进流程的技巧。\n  https://www.blameless.com/blog/improving-postmortems-paul-osman\n  《 应用日志开发的最佳实践 》\n  即使你不是用 Java 编写应用程序，掌握一些关于日志工作的知识通常也是有用的，因为你可能最终会至少运行一些 Java 应用程序。这些帖子提供了一个坚实的基础。\n  https://sematext.com/blog/java-logging/\n  https://sematext.com/blog/java-logging-best-practices/\n  工具  标签对于大规模管理 AWS 资源至关重要。Awstaghelper 提供了一个命令行工具，可以轻松地在广泛的 AWS 资源中向 CSV 文件或从 CSV 文件中添加和管理标签。 https://github.com/mpostument/awstaghelper   GitOps 工具包是一套可组合的 API 和专门的工具，可用于在 Kubernetes 之上构建一个持续交付平台。它们应该可以为 Flux 的 v2 提供基础，但也可以用来构建其他有趣的高级工具，采用同样的控制循环方法。 https://toolkit.fluxcd.io/   Kip 是一个虚拟 Kubelet 提供商，它允许 Kubernetes 集群透明地将 pods 发射到自己的云实例上。如果你需要额外的工作负载隔离，这很方便。 https://github.com/elotl/kip  学习资源 这里推荐一些值得关注和学习的免费视频学习资料。\n 教练点评：B 站里的相关视频是不可忽视的学习资源。善加利用，就可以加速获取知识的进度。\n 波波老师的系列课程\n https://space.bilibili.com/518029478/video 包括 k8s 和微服务等 DevOps 技术  【SpringBoot 项目实战】 2020 最新在线教育 spring boot 分布式项目实战\n 系统后端接口部分，使用目前流行的 SpringBoot+SpringCloud 进行微服务架构，使用 Feign、Gateway、Hystrix，以及阿里巴巴的 Nacos 等组件搭建了项目的基础环境。项目中还使用 MyBatisPlus 进行持久层的操作，使用了 OAuth2+JWT 实现了分布式的访问，项目中整合了 SpringSecurity 进行了权限控制。除此之外，项目中使用了阿里巴巴的 EasyExcel 实现对 Excel 的读写操作，使用了 Redis 进行首页数据的缓存，使用 Git 进行代码的版本控制 https://www.bilibili.com/video/BV1y7411y7am 播放量： 10w+  2019 谷粒商城微服务 SpringBoot,Dubbo,MySql 高级,Redis 秒杀,ElasticSearch,ActiveMQ,SSO 单点登\n https://www.bilibili.com/video/BV1B4411V7cA 2019 谷粒商城微服务 SpringBoot, zookeep 注册中心, Dubbo, MySql 高级, ElasticSearch, ActiveMQ, 通用 mapper, 解决秒杀, SSO 单点登录, OAuth2 协议三方登录, 第三方支付接口对接, Redis lua 脚本, Redis 秒杀, Redis 分布式锁, 集群搭建, 分布式, sku,spu 表结构介绍, 等等技术结合使用~~~~~~~~~~~ 播放量： 10w+  Git+GitHub 教程\n https://www.bilibili.com/video/BV1pW411A7a5 Git 是先进的分布式版本控制系统，而 Github 是常用的 Git 代码托管中心。 本套教程内容丰富、详实，囊括：Git 安装过程、本地库基本操作、远程基本操作、基于分支的 Gitflow 工作流、跨团队协作的 Forking 工作流、Eclipse 中的 Git 版本控制以及 Git 对 Eclipse 特定文件忽略的配置方法。还通过展示 Git 内部版本管理机制，让你了解 到 Git 高效操作的底层逻辑。教程的最后完整演示了 Gitlab 服务器的搭建过程。 播放量： 21w+  GitLab 与 GitFlow 的简单使用\n https://www.bilibili.com/video/BV1Wb411e7ec 播放量： 1w+  ",
    "ref": "/blog/devopscoach-weekly-5/"
  },{
    "title": "DevOps Coach 周刊 #4",
    "date": "",
    "description": "推荐 DevOps 教练学习的全球新闻，文章，宕机事件和流行工具",
    "body": "宕机  上一周新发的宕机事故。 近期全球重大宕机事故的分析总结、事后回顾。   May your queries flow and your pagers stay silent. \u0026ndash;Dave, Betsy, Niall, Stephen, and Kent\n 新闻 项目发布速递  Azure Functions 的 PowerShell 7 支持现在是 GA，如果在 PowerShell 中编写无服务器函数对你有吸引力。 Go 1.15 - 流行的编程语言。 AWS Glue 2.0 - AWS 上的 ETL 作业服务。 Node 14.8.0 - 服务器端 JavaScript 运行时。  DevOps 大会/峰会 中国 DevOps 社区流水线大赛 \u0026ndash; Pipeline Craft Championship\n 8 月 18 日开始为期两个月，免费活动 报名：https://wj.qq.com/s2/6852880/c181 活动官网：https://Pipeline.devopsmeetup.com  提交大议信息发邮件到：martin@devopscoach.org\n文章 编写 Kubernetes Operators 的 7 个最佳实践。SRE 的观点\n Manuel Dewald，红帽公司 https://www.openshift.com/blog/7-best-practices-for-writing-kubernetes-operators-an-sre-perspective  DevNation 技术讲座：每个用户都应该知道的 10 个很棒的 Kubernetes 工具\n Alex Soto 和 Burr Sutter，红帽公司。 https://www.twitch.tv/videos/709079582?t=00h01m01s  变化的世界, 变化的 Mozilla (但裁员 250 名员工) 非常悲伤的消息从 Mozilla, 火狐的创造者, 本周，他们已- 经裁掉了一个明显的数量的员工，他们的商业需求驱动.\n https://blog.mozilla.org/blog/2020/08/11/changing-world-changing-mozilla/  用 Prometheus 和 Grafana 进行系统监控。\n 监控超级饲料。分布式系统的历史和挑战。 https://flightaware.engineering/systems-monitoring-with-prometheus-grafana/  在 Git 中想做的事情以及如何做这些事情？\n 一些一般的 GIT 技巧 https://stu2b50.dev/posts/things-you-wante9665  公布 Kubernetes 的 Pulumi 开源新项目\n 宣布新功能，推进 Pulumi 的 Kubernetes 支持部署自动化、云原生生态系统集成和 Pulumi 的简单采用。 https://www.pulumi.com/blog/new-kubernetes-superpowers/  Mirantis 收购了 Kubernetes 的 IDE\u0026ndash;Lens - TechCrunch\n 最近收购了 Docker 企业业务的公司 Mirantis 今天宣布收购了 Lens。 https://techcrunch.com/2020/08/13/mirantis-acquires-lens-an-ide-for-kubernetes/  MySQL 性能调优\n 技巧、脚本和工具 https://haydenjames.io/mysql-performance-tuning-tips-scripts-tools/  \u0026ldquo;第一天 \u0026ldquo;云原生组织\n 在这里，我提出了一个云原生架构，以促进任何组织内的创新和实验的动态文化。 https://medium.com/lambda-lego/day-one-cloud-native-organisations-250b4e181a8d  从单体架构到微服务。架构和数据管理\n 在本文中，我们分析了从单体架构到微服务架构的转变，深入探讨了微服务通信类型，并以一个零售应用为例，研究了服务之间通信的最佳实践。 https://epsagon.com/development/monolithic-to-microservices-architecture-data-management/  工具   https://github.com/mingrammer/diagrams\n  云系统架构原型设计的 \u0026ldquo;图表即代码\u0026rdquo;（Diagram as Code）\n  https://github.com/linkedin/shiv\n  shiv 是一个命令行实用程序，用于构建完全自包含的 Python zipapps，就像 PEP 441 中概述的那样，但包含了所有的依赖关系。\n  https://github.com/hazelcast/hazelcast-jet\n  开源的分布式流和批处理技术\n  https://github.com/abe-winter/automigrate\n  使用 git 版本的 SQL 模式+自动迁移它们。\n  https://github.com/soraxas/shsh\n  一个多线程管理器，用于管理 shell 脚本、函数、独立的二进制文件、tab-completions 等。\n  https://github.com/dutchcoders/cloudman\n  管理 ec2 实例的文本用户界面。\n  https://github.com/diego3g/rocketredis\n  一个漂亮的 Redis GUI\n  ",
    "ref": "/blog/devopscoach-weekly-4/"
  },{
    "title": "DevOps Coach 周刊 #3",
    "date": "",
    "description": "推荐 DevOps 教练学习的全球新闻，文章，宕机事件和流行工具",
    "body": "宕机  上一周新发的宕机事故。 近期全球重大宕机事故的分析总结、事后回顾。  上周新发宕机事故  Discord 这个值得注意的是，它涉及到谷歌云平台中所谓的 \u0026ldquo;吵闹邻居 \u0026ldquo;情况。https://discord.statuspage.io/incidents/bnv0wbddzz2x Slack 更新缓存基础架构的坑。从2020年7月23日晚上9:00 PDT到2020年8月1日下午5:17 PDT，客户在使用各种API端点时可能会出现滞后或故障。我们于7月29日开始调查这一问题，并将这些问题追溯到最近对我们的缓存基础设施进行的一项变更，旨在增加该基础设施的容量。一个不可预见的副作用导致一小部分API请求需要更长的时间来处理并最终超时。我们在8月1日恢复了这一更改，所有受影响的客户的问题都得到了解决。8月6日, 6:49 AM GMT+8 https://status.slack.com//2020-07/7d32ad54b0703c47 **佳能 ** 遭遇勒索软件攻击，Maze宣称对此事负责 来源： https://www.zdnet.com/article/canon-suffers-ransomware-attack-maze-claims-responsibility/ Steam 服务器目前已经瘫痪 https://gamerant.com/steam-servers-down-8-05/ Fastly 著名 CDN 服务器最近又出性能事故了， 影响范围，Edge Cloud Services (Fastly API, 快速配置应用, TLS 制备) https://status.fastly.com/incidents/d6ljy97shb0p  关于 Quay.io 宕机事故回顾  来源官网： https://www.openshift.com/blog/about-the-quay.io-outage-post-mortem 时间线：5 月 19 日第一次宕机，28 日第二次宕机，这些事故影响了大多数 quay.io 服务的用户。 Red Hat SRE 团队对本次事件的经验总结：  关于谁和什么人在使用你的服务，你永远都不可能有足够的参考数据。 由于Quay \u0026ldquo;一直是正常工作\u0026rdquo;，我们从来不需要花太多时间分析我们的流量模式，处理负载的行为。这创造了一种虚假的安全感，即服务将无限期地扩展。 当服务出现故障时，恢复是你的首要任务。 由于Quay在第一次中断期间不断出现数据库死锁的情况，我们的标准流程并没有明确的实现服务恢复的预期目标。这就导致我们花了更多的时间进行分析和收集数据，希望找到根本原因，而不是把所有的精力都放在让客户恢复运行上。 要了解你的每一个服务功能的影响。 App Registry很少被我们的客户使用，所以它不是我们团队的主要优先事项。当你的产品中有很少使用的功能时，bug就不会被提交，开发人员也不会再看代码。我们很容易认为这不会给团队带来任何负担\u0026ndash;直到它突然成为重大事件的一部分。    关于 Heroku 事故 #2090 的后续分析  概述：此次事件涉及Heroku的基础设施提供商（大概是AWS）的DNS故障。这次事故的坑是 DNS。 来源官网：https://status.heroku.com/incidents/2090 重要看点：为了给DNS查询提供内部IP地址，我们的服务提供商运行自己的内部DNS服务。这些DNS服务是确保在同一地区运行的基础设施之间建立最快连接的根本。当这些 DNS 服务不可用时，服务之间无法建立新的内部连接。与应用程序或数据服务的外部连接不会受到影响。在此次事件中，我们在一个地区的基础设施子集上经历了这些DNS服务的间歇性故障，包括我们运维的Heroku大部分内部服务的地方。 经验总结：我们正在审查我们如何应对服务提供商的DNS故障或降级，以确保我们能够尽快发现并解决任何未来的问题。  LinkedIn 最近的 Hadoop 事故总结：理论 vs. 实战  概述：LinkedIn的这起事件影响了多个内部客户，他们对耐用性和延迟的要求各不相同，使得恢复变得复杂。 来源官网：https://engineering.linkedin.com/blog/2020/learnings-from-a-recent-hadoop-incident 学习制度化：一场大型事件结束后，总会有一些心得体会。以下是我们正在跟进的几条。  为Hadoop基础设施建立一个强大和更全面的主机生命周期管理。 建立更好地理解我们在负载下各数据中心的网络行为，并确保按需修改网络路由的自动化方式。 目前，我们正在Azure上构建下一代基础设施，包括Hadoop协议栈。就中期而言，我们将有一个额外的集群，该集群建立在一个完全不同的技术栈上，这应该会进一步帮助我们实现冗余。 调查其他架构的可行性，作为我们Azure迁移的一部分。例如，我们可以将数据摄取一次，然后将相同的数据复制到 D/R Cluster中，并通过数据布局和查询规划优化来吃掉延迟成本。我们正在采用Apache Iceberg作为我们的表格式。有了Iceberg，我们应该可以更好地对受影响的文件进行针对性的恢复。在我们当前架构的临时，我们已经建立了几个工具，让我们能够辅助恢复（例如，恢复除损坏数据以外的所有数据，更容易从另一个集群恢复大文件等），并围绕它建立了运行本，以便于访问。 努力审计我们的流程，以确保它们有定义良好的灾难恢复协议。 增加我们的灾难演练的频率，此外，还要审查灾难演练中流程的表现与他们所述的恢复策略的评分卡。 继续研究我们的工具，围绕着理解世系，因为事实证明它在识别流和数据的依赖性方面非常有用。这也将提供理解生态系统端到端的连接图的能力\u0026ndash;这在灾难恢复等大型协调事件中是非常宝贵的。 一些流量所有者在他们的应用工作流本身中增强了弹性。例如，对延迟敏感的应用，产生关键业务小时和每日指标的应用，正在应用逻辑本身中进行明确的数据呆滞性与弹性的权衡。 专注于提高我们预测数据恢复的数据可用性SLA的能力，以便在这种性质的事件再次发生时有能力快速发布。我们的内部数据消费者可以使用这些SLA，并在恢复协议的决策选择方面做出明智的决定。    GitHub可用性报告 \u0026ndash; 2020年7月  概述：相信很多人都经历了 GitHub 7 月13 日的事故。该事故持续了4 小时 25 分钟。以下报告包括对涉及Kubernetes pods和DNS服务受损的事件的描述。 来源官网：https://github.blog/2020-08-05-github-availability-report-july-2020/ 要点回顾：  事件的起因是我们的生产型 Kubernetes Pods 开始被标记为不可用。这在我们的集群中层出不穷，导致容量减少，最终导致我们的服务瘫痪。对Pods的调查显示，Pod中的一个容器超过了其定义的内存限制并被终止。尽管该容器不需要处理生产流量，但Kubernetes的性质要求所有容器都是健康的，Pod才能被标记为可用。 一般情况下，当一个Pod运行到这种故障模式时，集群会在一分钟左右恢复。在这种情况下，Pod中的容器被配置为ImagePullPolicy为Always，它指示Kubernetes每次都要获取新的容器镜像。然而，由于之前完成了一次例行的DNS维护操作，我们的集群无法成功到达我们的注册表，导致Pods无法启动。当为了缓解而触发了重新部署时，这个问题的影响就增加了，我们看到这个故障开始在我们的生产集群中传播。直到我们使用缓存的DNS记录重新启动进程，我们才得以成功获取容器镜像，重新部署，并恢复我们的服务。   后续事项：展望未来，我们已经确定了本季度要解决的一些领域。  加强监控，确保Pod重启不会再基于这种相同的模式而失败 尽量减少我们对镜像仓库的依赖。 在DNS变更期间扩大验证范围 重新评估所有现有的Kubernetes部署策略    新闻 项目发布速递  Nano 5.0 — The popular simple Unix text editor. Julia 1.5 — High performance, dynamically typed language. Mastodon 3.2 — Federated social app. Django 3.1 — Python-based Web application framework. Alacritty 0.5 — Simplicity-focused terminal emulator. Terraform 0.13 General Availability  DevOps 大会/峰会 KubeCon + CloudNativeCon 欧洲 2020\n 8 月 17 – 20， 免费 报名： https://events.linuxfoundation.org/kubecon-cloudnativecon-europe/  Commit 峰会\n 8 月 26 ~ 27， GitLab 免费 报名：https://about.gitlab.com/events/commit/  DevOps Fusion\n 8 月 26 日， 免费 报名：https://swisstestingday.ch/en/  DevOpsCon 伦敦 2020\n 8 月 31 日 ~ 9 月 3 日，收费 报名： https://devopscon.io/  提交大议信息发邮件到：martin@devopscoach.org\n文章 麦肯锡：《十种 \u0026ldquo;反模式\u0026rdquo;，让技术转型脱轨。》\n 大型组织转型项目的反模式清单。在选择技术、技术管理、路线图等方面都有很好的建议。 https://www.mckinsey.com/business-functions/mckinsey-digital/our-insights/ten-antipatterns-that-are-derailing-technology-transformations  AWS：《为运维可视化构建仪表板》\n 一篇关于仪表盘设计的好文章，有很多道理、提示、技巧和例子。 https://aws.amazon.com/builders-library/building-dashboards-for-operational-visibility/  LearnK8s：《验证Kubernetes YAML的最佳实践和策略》\n 看看对验证和测试Kubernetes配置文件有用的几个工具。有用的对比表和每个不同工具的例子。 https://learnk8s.io/validating-kubernetes-yaml  推荐 Arrested DevOps 这个网站，它是帮助你实现理解、开发良好实践、运营你的团队和组织的播客，以获得最大的DevOps妙用。\n 关于Service Mesh和SMI规范的所有事情的讨论。 https://www.arresteddevops.com/service-mesh/  Dev.to：《使用Conftest、Regula和OPA保护你的Terraform管道安全》\n 关于使用Conftest和Regula帮助编写安全的Terraform代码和测试作为CI流程的一部分的帖子。 https://dev.to/prince_of_pasta/securing-your-terraform-pipelines-with-conftest-regula-and-opa-4hkh  无罪网：《事件回顾从小白到大师》\n Under Armour（！）的首席SRE对他们如何进行SRE有很多有趣的事情可以分享。我喜欢他们对事件回顾的方法，即从1:1采访相关人员开始。保罗-奥斯曼\u0026ndash;Under Armour（无罪峰会）。 https://www.blameless.com/blog/improving-postmortems-paul-osman  medium.com 《主要的DevOps挑战以及如何应对这些挑战？》\n DevOps通过提供高效的解决方案，帮助加快交付速度，鼓励团队之间的协作，并促进敏捷环境，推动组织走向更美好的未来。 https://medium.com/faun/major-devops-challenges-and-how-to-address-them-3b4d7b6ee50b  工具   Open Service Mesh是一个新的轻量级、可扩展的、用于动态微服务环境的服务网状结构。它提供了开箱即用的可观察性功能，并使用SMI进行配置。\n  https://openservicemesh.io/\n  https://github.com/openservicemesh/osm\n  Sysbox是一个新的容器运行时，它可以让你更容易地在容器中运行低级软件，比如Systemd、Docker和Kubernetes。由于可插拔的运行时功能，你也可以用Docker运行它。\n  https://github.com/nestybox/sysbox\n  我们开始看到应用框架和开发者工具为在Kubernetes等平台上运行提供高级抽象。Tye是一个有趣的.NET工具，它可以简化在云原生平台上运行.NET应用程序。\n  https://github.com/dotnet/tye\n  Turandot允许在Kubernetes中使用TOSCA。TOSCA提供了一种高级服务描述，旨在实现底层基础设施之间的可移植性和互操作性。\n  https://turandot.puccini.cloud/\n  Copper是一个Kubernetes的配置文件验证器。它支持使用内置的Javascript DSL编写定制测试。\n  https://github.com/cloud66-oss/copper\n  ",
    "ref": "/blog/devopscoach-weekly-3/"
  },{
    "title": "腾讯云下部署 Elastic Stack 各种 Beat 的最佳实践",
    "date": "",
    "description": "如何安全、有弹性和可扩展的使用 Beat 摄入数据",
    "body": "概述 使用 Elastic Stack 的各种 Beats 模块可以彻底的终结在服务器上手工捞日志查指标的扭曲实践。利用腾讯云提供的 Elasticsearch 服务，可以轻松搞定大规模云环境的运维。本文一次性的帮你梳理清楚了，必备的基础操作，确保你能用 Elastic Stack 安全、稳定和扩展的持续监控你的生产环境。\n创建 ES 集群 登录腾讯云服务控制台，查询并进入 Elasticsearc 服务，点击新建按钮，创建 Elasticsearch 集群。如下图所示。\n集群配置说明：\n 北京区 7.5.1 - 白金版 单可用区 冷热模式  本实例其它参数保持默认，可以根据实际业务需求修改这些参数。\n点击下一步后，设置 Elasticsearch 集群的超级用户名和密码。\n在几分钟之后这个集群就成功创建了。查看下面这些基础的配置。\n 启用 Kibana 内网地址： http://es-ot7wei87.internal.kibana.tencentelasticsearch.com:5601 用于 Bests 的 Setup 命令 启用 Kibana 公网地址： https://es-ot7wei87.kibana.tencentelasticsearch.com:5601 用户Elastic Stack 的初始化配置，如创建角色和调整索引生命周期策略等。  这样我们就有了一个安全、可扩展和性能足够的 ES 后台服务。\n创建 Beats 写入角色和用户 登录 Kibana ，点击角色和用户管理，创建用于 Beast 配置文件的‘只写’权限用户。\n 创建 beats-writer 角色 创建 beats-writer 用户，该用户只赋予beats-writer角色，自定义一个安全的复杂密码。  Beats-write 角色设置如下图所示：\n这个用户会用到后面的所有 Beats 配置文件中，用最小化权限用户极大的降低了数据泄露的风险。\nBeats 初始化配置 登录准备好的一个 Linux 服务器，在这台机器上做 Beats 相关的初始化工作；也就是要执行一些列的 setup 命令；这些命令的作用是：\n 在 ES 后台加载索引模板，以及索引的 ILM 策略。 加载 Kibana 相关的对象和可视化仪表板。  注意这是一次性的工作，在一个虚拟机上，只需要成功执行一次。\nSSH 登录到准备的 Linux 服务器上，首先需要安装相关 beats 的 rpm 安装包，安装命令在这里忽略，否则无法执行这些命令。 安装好 filebeat 和 metricbeat 的rpm 包后， 执行下面参考命令。\nfilebeat setup -e \\  -E output.logstash.enabled=false \\  -E output.elasticsearch.hosts=[\u0026#39;192.168.0.43:9200\u0026#39;] \\  -E output.elasticsearch.username=elastic \\  -E output.elasticsearch.password=YourPassWord \\  -E setup.kibana.host=es-ot7wei87.internal.kibana.tencentelasticsearch.com:5601 metricbeat setup -e \\  -E output.elasticsearch.hosts=[\u0026#39;192.168.0.43:9200\u0026#39;] \\  -E output.elasticsearch.username=elastic \\  -E output.elasticsearch.password=YourPassWord \\  -E setup.kibana.host=es-ot7wei87.internal.kibana.tencentelasticsearch.com:5601 运行以上命令的时候 Beats 处于默认安装的状态，这些命令行参数是必要的查收，有了这些参数 beats 会忽略默认的配置文件。\n以上命令根据需求，如果需要使用到其它的 Beats，请使用相关的 setup 命令。其中的 es 和 kibana 相关信息需求参考上一步创建的 es 集群信息。\n以上所有命令成功之后，登录 Kibana 界面，点击 Dashboard 菜单，这里应该已经加载了很多仪表板。目前为止 Elastic Stack 后台就初始化成功了。\n在节点上正式部署 Beats 参考和修改安装脚本，一键式安装和配置 Beats\ngit clone https://github.com/martinliu/elastic-stack-lab.git cd tencent sh add-agent.sh 成功执行完以上脚本后，相关的 beats 服务应是正常运行的状态。执行完这个命令之后，在 Linux 服务器上使用检查服务是否正常运行 sudo systemctl status filebeat ；使用这个命令应该可以看到filebeat 服务都是正常运行的。\n这个脚本所使用的配置文件中的要点：\n 删除了所有和数据摄入无关的配置（例如 es 和 kibana 的配置和初始化等） 加入了最小化的必要的最佳实践参数集合 建议根据需求增加 beats 相关的模块 根据需求加入必要的 Beat 配置参数  实例配置文件如。\nfilebeat.yml\n#=========================== Filebeat inputs ============================= filebeat.inputs: - type: log enabled: false paths: - /var/log/*.log #============================= Filebeat modules =============================== filebeat.config.modules: path: ${path.config}/modules.d/*.yml reload.enabled: true reload.period: 60s #-------------------------- Elasticsearch output ------------------------------ output.elasticsearch: hosts: [\u0026quot;${INT_ES_SRV}\u0026quot;] password: ${BEATS_WRITER_PW} username: ${BEATS_WRITER_USERNAME} #================================ Processors ===================================== processors: - add_host_metadata: netinfo.enabled: true cache.ttl: 5m - add_cloud_metadata: ~ - add_docker_metadata: ~ - add_kubernetes_metadata: ~ - add_fields: target: '' fields: service.name: 'Joint Lab' service.id: 'es-qq' #==================== Best Practice Configuration ========================== setup.ilm.check_exists: false logging.level: error queue.spool: ~ monitoring: enabled: true metricbeat.yml\n# =========================== Modules configuration ============================ metricbeat.config.modules: path: ${path.config}/modules.d/*.yml reload.enabled: true reload.period: 10s #-------------------------- Elasticsearch output ------------------------------ output.elasticsearch: hosts: [\u0026quot;${INT_ES_SRV}\u0026quot;] password: ${BEATS_WRITER_PW} username: ${BEATS_WRITER_USERNAME} #================================ Processors ===================================== processors: - add_host_metadata: netinfo.enabled: true cache.ttl: 5m - add_cloud_metadata: ~ - add_docker_metadata: ~ - add_kubernetes_metadata: ~ - add_fields: target: '' fields: service.name: 'Joint Lab' service.id: 'es-qq' #==================== Best Practice Configuration ========================== setup.ilm.check_exists: false logging.level: error queue.spool: ~ monitoring: enabled: true 以上配置文件使用了这些通用最佳实践配置参数。\n 使用 ECS 扩展字段，丰富上下文含义 启用 beats 端点监控 用 keystore 隐藏所有敏感信息  #禁用索引 ilm 策略检查，避免无用动作 setup.ilm.check_exists: false #把Beats自身的日志记录调到最低级别降低 logging.level: error #开启本地默认的端点缓存行为 queue.spool: ~ #启用端点的监控 monitoring: enabled: true 排错方法 filebeat setup 不成功 在任何 beats 首次做 setup 命令的时候，它可能是会在分钟级别成功结束。如果发生失败或者卡顿的情况，可以等一下，等更长时间看看。不成功的话，需要反复执行，排查 es 和 kibana 服务是否能正常工作。知道陈功了，才能进行下一步的安装工作。\n配置文件错误导致的服务不能启动 由于上面的定制化配置文件也可能出现错误，特别是在首次部署这个配置文件的时候，可以先把日志级别 error 哪一行注释掉，把启动服务那两行也注释掉。\n然后在命令行执行 filebeat -e 查看整个 feilebeat 的启动过程，这个命令会读取定制化的配置文件，然后开始连接后台 es 服务，然后进入正常数据传送的状态。这个过程中如果有任何配置错误，也可以直观的看到相关信息，直到调整到正常的状态。\n以上过程的调整好了以后，一定要通过 git 版本管理起来，然后可以放心的在其它节点上执行 beast 的一键式部署工作。\n总结 以上是在 Beats 部署相关基础最佳实践，也就是说在生产环境中 ES 后台和 beats 的搭配，以及本文所涉及的内容都是基线配置。建议根据自己的需求做更多的调优，这里使用 shell 脚本的方式部署 beats 和相关的配置，shell 脚本适合用于演示原理，建议替换成你所熟悉的自动化运维工具，例如 ansible 等工具。从而保证更大规模的自动化部署和维护。\n本相关的配置文件和脚本位于：https://github.com/martinliu/elastic-stack-lab.git\n",
    "ref": "/blog/beats-implement-on-qcloud/"
  },{
    "title": "DevOps Coach 周刊 #2",
    "date": "",
    "description": "推荐 DevOps 教练学习的全球新闻，文章，宕机事件和流行工具",
    "body": "宕机 上周全球重大宕机事故清单。\nFacebook  具英媒体报道：7月 28 日 12：20pm， Facebook, Instagram 和 WhatsApp 这三款用户的一半以上的用户，无法加载出页面，无法正常使用服务。 Facebook 官方还没有关于这次事故的回应。实际上整个欧洲大陆，特别是葡萄牙和西班牙的故障更要严重一些。原因不明。 影响范围：London, Birmingham 和 Manchester. 来源： https://metro.co.uk/2020/07/28/facebook-instagram-whatsapp-13048914/  fastly - 知名 CDN 服务商  官方声明：Fastly的网络具有内置冗余和自动故障转移路由，以确保最佳性能和正常运行时间。但当网络问题出现时，我们认为我们的客户应该得到清晰、透明的沟通，这样他们才能保持对我们的服务和团队的信任。当我们重新分配流量、升级硬件或在极少数情况下我们的网络不提供流量时，我们会在这里发布通知。如果您遇到问题而没有看到张贴的通知，请发送电子邮件至 support@fastly.com 寻求帮助。 影响范围：North America (Ashburn (BWI), Ashburn (DCA), Ashburn (IAD), Ashburn (WDC), Atlanta (FTY), Atlanta (PDK), Dallas (DAL), Dallas (DFW), Jacksonville (JAX)). 来源：https://status.fastly.com/history  Heroku  官方声明：JUL 28, 2020 09:15 UTC Heroku 平台的很大的部分都遭受到可用性故障。然后开始和他们的服务提供商一起解决问题。一个多小时后平台恢复了正常。 来源：https://status.heroku.com/incidents/2090  新闻 DevOps实践的采用与组织拥抱数字化转型齐头并进。这两个短语都有被过度使用的风险，但这些帖子讨论了一些有用的心理模型，以帮助聚焦对话。\n https://aws.amazon.com/blogs/enterprise-strategy/mental-models-for-digital-transformation/ https://aws.amazon.com/blogs/enterprise-strategy/mental-models-to-clarify-the-goals-for-of-digital-transformation-part-2/  开发者平台的哪些属性会导致采用？下面的文章是专门关于大规模边缘平台的，但对于任何为开发者构建各种平台的人来说，包括在内部平台团队中这样做的人来说，都是很好的阅读。\n https://blog.cloudflare.com/cloudflare-workers-serverless-week/  当第一次接受DevOps实践和云服务时，在大型组织中通常会建立一个卓越中心。在采取这种方法时，需要避免一些陷阱，下面的文章将讨论这些陷阱。\n https://www.contino.io/insights/cloud-centre-of-excellence-2020  最近的DevSecCon在线会议的视频都可以看到，其中涵盖了一系列有趣的主题，包括基础设施作为代码安全、持续审计合规、供应链攻击等。\n https://www.mydevsecops.io/post/devseccon24  关于无服务器架构和单体应用之间的权衡，主要集中在较小规模的应用上，是一个不错的讨论。\n https://dev.to/iamcherta/my-monolith-doesn-t-fit-in-your-serverless-311o  一篇关于linux内核新特性的深度技术文章，这些特性应该会让非特权容器更受欢迎。对seccomp的细节也做了很好的介绍。\n https://people.kernel.org/brauner/the-seccomp-notifier-new-frontiers-in-unprivileged-container-development  基于角色的访问控制在保护Kubernetes的安全方面发挥着重要作用。这个方便的网站将文章、工具和官方文档收集在一起。\n https://rbac.dev/  对于任何使用Serverless技术的人来说，这是一项有趣的调查，来自该领域的众多公司。我期待着结果公布时的到来。\n https://codingsans.typeform.com/to/mPinnC  文章 LaunchDarkly从基于 Polling 的架构开始，最终迁移到向客户推送变化量（Streaming）。Dawn Parzych\u0026ndash;LaunchDarkly。\n https://launchdarkly.com/blog/launchdarklys-evolution-from-polling-to-streaming/  一个更简单的分布式跟踪的替代方案，用于故障排除。 简要概述了分布式追踪的一些问题，以及涉及人工智能的另一种方式的建议。 Larry Lancaster - Zebrium\n https://www.zebrium.com/blog/virtual-tracing-a-simpler-alternative-to-distributed-tracing-for-troubleshooting  谷歌云 对 Classroom 的故障总结报告 2020-07-07 这是Google在7月7日对其Google Classroom 事件的事后报告。\n https://static.googleusercontent.com/media/www.google.com/en//appsstatus/ir/u5sinmib27yly4i.pdf  面向领域的微服务架构介绍 长期以来，Uber一直是微服务的倡导者。现在，凭借几年的经验，他们分享了他们所学到的经验，以及如何处理一些陷阱。Adam Gluck - Uber\n https://eng.uber.com/microservice-architecture/  通过远程事件响应使PagerDuty始终保持开启状态。 本文开篇就从PagerDuty的角度对Cloudflare中断的情况进行了有趣的描述。Dave Bresci - PagerDuty\n https://www.pagerduty.com/blog/remote-incident-response/  安全是设计出来的？ 这篇文章反映了两种不同的安全理念。\n 工程设计应确保系统的安全。 单纯的设计不能保证系统的安全 Lorin Hochstein https://surfingcomplexity.blog/2020/07/28/safe-by-design/  我们能做的就是发现问题 你不能用可用性指标来告知你的系统是否足够可靠，因为它们只能在你出现问题时告诉你。 Lorin Hochstein\n https://surfingcomplexity.blog/2020/07/28/all-we-can-do-is-find-problems/  工具推荐 管理 K8s 命令行工具的工具，所有命令行工具一站式搞定，一键式安装很多 k8s 集群基础。\n https://github.com/alexellis/arkade/  一个在文件系统之上的文件系统。\n https://github.com/carlosgaldino/gotenksfs  一个 Cloud-Native API Gateway\n https://github.com/apache/apisix  一个简单而全面的容器漏洞扫描器，适用于CI。\n https://github.com/aquasecurity/trivy  ",
    "ref": "/blog/devopscoach-weekly-2/"
  },{
    "title": "APM 分布式追踪为何这么难？",
    "date": "",
    "description": "分布式追踪系统实施三部曲追踪数据生成、收集和使用",
    "body": "用跟踪的方式调试计算机程序的调用堆栈的实践其实由来已久，这种方法可能仅次于用 print 输出各种信息。在云原生的时代里，我们还会遭遇工具过剩的情况，工具之间的相生相克加剧了实施分布式追踪的难度。\n总的来说有三个基础难点：\n 生成追踪数据难。对已有应用系统的代码库进行埋点处理的挑战巨大，你的应用程序系统的模式可能也不符合埋点的模式需求。 采集存储追踪数据难。捕获和管理大量追踪数据包，即照顾到查询和使用的需求，又要设定成本合理的数据存储策略，处理数据收集能力的扩缩容。 从数据中获益难。如何理解和使用数据产生可执行行动，如何用它优化微服务的遥测，怎么将它的利益扩展到各个相关团队。  分布式追踪系统的实施结果是落地一条能深度洞察目标系统的工具。让人们能轻松的理解局部和整体的状态，特别是在请求堆栈中的任何局部服务出现故障时，可以最快速的定位故障根源。\n上图是用追踪数据生成的服务地图。\n上图是一次用户请求的全部细节，还可以一键式的跳转到相应的日志或者指标。\n以上三个难点覆盖了部署实施分布式追踪系统的核心领域。\n 埋点 OpenTelemetry是目前受到广泛支持的埋点框架，对棕地应用和绿地应用进行埋点处理的挑战是不同的，需要遵循不同的额最佳实践。 部署 在理解了目标追踪应用系统的运行时状态后，最好使用一种弹性的方式收集和存储追踪数据。满足分析数据量需求的同时平衡存储成本。 收益 将其与日志和指标工具关联起来，定义和监控重要有意义的监控点，用于优化系统性能基线，并最小化 MTTR。  在云计算、Kubernetes、容器化大行其道的今天，分布式追踪的实施是不是正处在进退维谷的尴尬境地呢？其实并非如此，特别是监控运维挑战越高的应用，其实越需要需要使用分布式追踪 APM 工具。分布式追踪对云原生的容器化微服务应用尤为适用。APM 对单纯使用日志和指标的场景具有极大的补充和提高作用，而且它是可观测性策略的关键组成部分。\n总的来说分布式追踪工具可以通过追踪的方式展现请求在系统中的流动状态。流行的开源埋点框架使之与应用的编程语言、运行时环境无关，可以适配与所有类型的应用和服务。有些 APM 工具可以支持运行时埋点（或称为运行框架埋点），在不改变代码的情况下采集追踪数据。APM 的实施虽然有一定难度，但是当开始实施埋点处理，收集追踪数据以后，相关的价值和收益也就会慢慢显现出来了。\n参考：\n https://opentelemetry.io/ https://www.elastic.co/cn/apm  ",
    "ref": "/blog/apm-why-it-so-hard/"
  },{
    "title": "应用开发 DBA 技巧集锦",
    "date": "",
    "description": "无废话数据库开发技巧集合",
    "body": "前言 DBA 可能是经常被其它团队依赖的一种角色、团队，因此他们也会有着很长的等待队列，也经常是事故救火中的英雄和常客。DevOps 强调用跨角色的学习和培训来解决这种依赖，也就是 DevOps 工作三步法的第三步，学习与持续改进。 本文写给所有的应用开发者，希望大家能多学习一些 DBA 知识，减少对专家 DBA 的依赖，加速你们的业务的交付，消除由于等待而造成的浪费。\n本文转载自：https://hakibenita.com/sql-tricks-application-dba\n以下是正文原文：\n当我开始我的开发生涯时，我的第一份工作是DBA。那时，在AWS RDS、Azure、Google Cloud和其余云服务之前，有两种类型的DBA。\n基础设施 DBA 负责建立数据库配置存储，并负责备份和复制。设置好数据库后，基础架构DBA会时不时地冒出来做一些 \u0026ldquo;实例调整\u0026rdquo;，比如调整缓存的大小。\n应用 DBA 从基础架构DBA那里得到了一个干净的数据库，并负责模式设计：创建表、索引、约束和调优SQL。应用DBA也是实现ETL流程和数据迁移的人。在使用存储过程的团队中，应用DBA也会维护这些存储过程。\n应用DBA通常是开发团队的一部分。他们会拥有深厚的领域知识，所以通常他们只会在一两个项目上工作。基础架构DBA通常是某个IT团队的一部分，他们会同时在多个项目上工作。\n我是一名应用DBA 我从来没有任何欲望去摆弄备份或调整存储（我相信这很迷人！）。直到今天，我都喜欢说自己是一个懂得开发应用的DBA，而不是一个懂得数据库的开发者。\n在本文中，我将分享我一路走来收集到的一些关于数据库开发的非浅显技巧。\nBe that guy\u0026hellip;\nImage by CommitStrip\n只更新需要更新的内容 UPDATE是一个相对昂贵的操作。为了加快UPDATE命令的速度，最好确保只更新需要更新的内容。\n以这个查询为例，它对电子邮件列进行了标准化处理。\ndb=# UPDATE users SET email = lower(email); UPDATE 1010000 Time: 1583.935 ms (00:01.584) 看起来很无辜吧，查询更新了1010,000个用户的邮箱。但是，真的需要更新所有的行吗？\ndb=# UPDATE users SET email = lower(email) db-# WHERE email != lower(email); UPDATE 10000 Time: 299.470 ms 只需要更新10000行。通过减少受影响的行数，执行时间从1.5秒降到了不到300ms。更新的行数少了，也节省了后期的数据库维护工作。\n这种类型的大更新在数据迁移脚本中非常常见。所以下次写迁移脚本时，一定要只更新需要更新的内容。\n在批量加载过程中禁用约束和索引。 约束是关系型数据库的重要组成部分：它们能保持数据的一致性和可靠性。不过它们的好处是有代价的，在加载或更新大量行时最明显。\n为了演示，为一个存储设置一个小模式。\nDROP TABLE IF EXISTS product CASCADE; CREATE TABLE product ( id serial PRIMARY KEY, name TEXT NOT NULL, price INT NOT NULL ); INSERT INTO product (name, price) SELECT random()::text, (random() * 1000)::int FROM generate_series(0, 10000); DROP TABLE IF EXISTS customer CASCADE; CREATE TABLE customer ( id serial PRIMARY KEY, name TEXT NOT NULL ); INSERT INTO customer (name) SELECT random()::text FROM generate_series(0, 100000); DROP TABLE IF EXISTS sale; CREATE TABLE sale ( id serial PRIMARY KEY, created timestamptz NOT NULL, product_id int NOT NULL, customer_id int NOT NULL ); 模式定义了不同类型的约束，如 \u0026ldquo;非空 \u0026ldquo;和唯一约束。\n要设置一个基线，首先要向销售表添加外键，然后将一些数据加载到表中:\ndb=# ALTER TABLE sale ADD CONSTRAINT sale_product_fk db-# FOREIGN KEY (product_id) REFERENCES product(id); ALTER TABLE Time: 18.413 ms db=# ALTER TABLE sale ADD CONSTRAINT sale_customer_fk db-# FOREIGN KEY (customer_id) REFERENCES customer(id); ALTER TABLE Time: 5.464 ms db=# CREATE INDEX sale_created_ix ON sale(created); CREATE INDEX Time: 12.605 ms db=# INSERT INTO SALE (created, product_id, customer_id) db-# SELECT db-# now() - interval \u0026#39;1 hour\u0026#39; * random() * 1000, db-# (random() * 10000)::int + 1, db-# (random() * 100000)::int + 1 db-# FROM generate_series(1, 1000000); INSERT 0 1000000 Time: 15410.234 ms (00:15.410) 定义约束和索引后，将100万行加载到表中，耗时约15.4s。\n接下来，尝试先将数据加载到表中，然后才添加约束和索引。\ndb=# INSERT INTO SALE (created, product_id, customer_id) db-# SELECT db-# now() - interval \u0026#39;1 hour\u0026#39; * random() * 1000, db-# (random() * 10000)::int + 1, db-# (random() * 100000)::int + 1 db-# FROM generate_series(1, 1000000); INSERT 0 1000000 Time: 2277.824 ms (00:02.278) db=# ALTER TABLE sale ADD CONSTRAINT sale_product_fk db-# FOREIGN KEY (product_id) REFERENCES product(id); ALTER TABLE Time: 169.193 ms db=# ALTER TABLE sale ADD CONSTRAINT sale_customer_fk db-# FOREIGN KEY (customer_id) REFERENCES customer(id); ALTER TABLE Time: 185.633 ms db=# CREATE INDEX sale_created_ix ON sale(created); CREATE INDEX Time: 484.244 ms 将数据加载到没有索引和约束的表中，速度快了很多，2.27s，而之前是15.4s。在数据加载到表中后创建索引和约束花了一点时间，但总体上整个过程快了很多，3.1s，而之前是15.4s。\n遗憾的是，对于索引，PostgreSQL并没有提供一个简单的方法，除了放弃和重新创建索引。在其他数据库中，如Oracle，你可以禁用和启用索引，而不必重新创建索引。\n中间数据中使用 UNLOGGED 的表 当你修改PostgreSQL中的数据时，修改的内容会被写入提前写日志（WAL）。WAL用于维护完整性，在恢复期间快速推进数据库，并维护复制。\n写入WAL是经常需要的，但在某些情况下，你可能愿意放弃它的一些用途来使事情变得更快。一个例子是中间表。\n中间表是一次性的表，它存储了用于实现某些过程的临时数据。例如，ETL过程中一个非常常见的模式是将数据从CSV文件加载到中间表，清理数据，然后加载到目标表。在这种用例中，中间表是一次性的，在备份或复制中没有用处。\n在灾难发生时不需要恢复的中间表，以及在副本中不需要的中间表，可以设置为 UNLOGGED。\nCREATE UNLOGGED TABLE staging_table ( /* table definition */ ); **注意：**在使用UNLOGGED之前，请务必了解其全部含义。\n使用 WITH 和 RETURNING 实施完成的流程 假设你有一个用户表，你发现表中有一些重复的内容。\n表的设置：\nCREATE TABLE users ( id SERIAL PRIMARY KEY, email TEXT UNIQUE ); CREATE TABLE orders ( id SERIAL PRIMARY KEY, user_id INT, CONSTRAINT orders_user_fk FOREIGN KEY (user_id) REFERENCES USERS(id) ); INSERT INTO users (email) VALUES (\u0026#39;foo@bar.baz\u0026#39;), (\u0026#39;me@hakibenita.com\u0026#39;), (\u0026#39;ME@hakibenita.com\u0026#39;); INSERT INTO orders (user_id) VALUES (1), (1), (2), (3), (3); 表的内容：\ndb=# SELECT u.id, u.email, o.id as order_id FROM orders o JOIN users u ON o.user_id = u.id; id | email | order_id ----+-------------------+----------  1 | foo@bar.baz | 1 1 | foo@bar.baz | 2 2 | me@hakibenita.com | 3 3 | ME@hakibenita.com | 4 3 | ME@hakibenita.com | 5 用户haki benita注册了两次，一次是用邮箱ME@hakibenita.com，另一次是用me@hakibenita.com。由于我们在将邮件插入表中时没有将其规范化，现在我们必须处理重复的问题。\n为了合并重复的用户，我们要。\n 通过小写的电子邮件来识别重复的用户。 更新订单以引用其中一个重复的用户。 从用户表中删除重复的用户  整合重复用户的一种方法是使用中间表。\ndb=# CREATE UNLOGGED TABLE duplicate_users AS db-# SELECT db-# lower(email) AS normalized_email, db-# min(id) AS convert_to_user, db-# array_remove(ARRAY_AGG(id), min(id)) as convert_from_users db-# FROM db-# users db-# GROUP BY db-# normalized_email db-# HAVING db-# count(*) \u0026gt; 1; CREATE TABLE db=# SELECT * FROM duplicate_users; normalized_email | convert_to_user | convert_from_users -------------------+-----------------+--------------------  me@hakibenita.com | 2 | {3} 中间表持有重复用户的映射。对于每一个使用相同的标准化电子邮件地址出现不止一次的用户，我们定义最小ID的用户作为我们将所有重复用户转换为的用户。其他用户被保存在一个数组列中，这些用户的所有引用都将被更新。\n利用中间表，我们更新订单表中重复用户的引用。\ndb=# UPDATE db-# orders o db-# SET db-# user_id = du.convert_to_user db-# FROM db-# duplicate_users du db-# WHERE db-# o.user_id = ANY(du.convert_from_users); UPDATE 2 Now that there are no more references, we can safely delete the duplicate users from the users table: db=# DELETE FROM db-# users db-# WHERE db-# id IN ( db(# SELECT unnest(convert_from_users) db(# FROM duplicate_users db(# ); DELETE 1 请注意，我们使用了函数 unnest 来 \u0026ldquo;转置 \u0026ldquo;数组，即把每个数组元素变成一行。\n这就是结果：\ndb=# SELECT u.id, u.email, o.id as order_id db-# FROM orders o JOIN users u ON o.user_id = u.id; id | email | order_id ----+-------------------+----------  1 | foo@bar.baz | 1 1 | foo@bar.baz | 2 2 | me@hakibenita.com | 3 2 | me@hakibenita.com | 4 2 | me@hakibenita.com | 5 很好，用户3(ME@hakibenita.com)的所有出现都转换为用户2(me@hakibenita.com)。\n我们还可以验证重复的用户是否从用户表中被删除。\ndb=# SELECT * FROM users; id | email ----+-------------------  1 | foo@bar.baz 2 | me@hakibenita.com 现在我们可以摆脱中间表了。\ndb=# DROP TABLE duplicate_users; DROP TABLE 这个很好，但是非常长，需要清理! 有没有更好的方法？\n使用通用表表达式(CTE) 使用常见的表表达式，也就是所谓的WITH子句，我们只需要一条SQL语句就可以执行整个过程。\nWITH duplicate_users AS ( SELECT min(id) AS convert_to_user, array_remove(ARRAY_AGG(id), min(id)) as convert_from_users FROM users GROUP BY lower(email) HAVING count(*) \u0026gt; 1 ), update_orders_of_duplicate_users AS ( UPDATE orders o SET user_id = du.convert_to_user FROM duplicate_users du WHERE o.user_id = ANY(du.convert_from_users) ) DELETE FROM users WHERE id IN ( SELECT unnest(convert_from_users) FROM duplicate_users ); 我们不创建中间表，而是创建一个通用的表表达式，并多次重复使用。\n从 CTE 返回结果 在WITH子句中执行DML的一个很好的特性是，你可以使用RETURNING关键字来返回数据。例如，让我们报告更新和删除的行数：\nWITH duplicate_users AS ( SELECT min(id) AS convert_to_user, array_remove(ARRAY_AGG(id), min(id)) as convert_from_users FROM users GROUP BY lower(email) HAVING count(*) \u0026gt; 1 ), update_orders_of_duplicate_users AS ( UPDATE orders o SET user_id = du.convert_to_user FROM duplicate_users du WHERE o.user_id = ANY(du.convert_from_users) RETURNING o.id ), delete_duplicate_user AS ( DELETE FROM users WHERE id IN ( SELECT unnest(convert_from_users) FROM duplicate_users ) RETURNING id ) SELECT (SELECT count(*) FROM update_orders_of_duplicate_users) AS orders_updated, (SELECT count(*) FROM delete_duplicate_user) AS users_deleted ; 这个结果是:\norders_updated | users_deleted ----------------+---------------  2 | 1 这种方法的主要吸引力在于，整个过程是在一条命令中执行的，所以不需要管理一个事务，也不需要担心在过程失败时清理中间表。\n**注意：**Reddit上的一位读者给我指出了在普通表表达式中执行DML的一个可能无法预测的行为。\n WITH中的子语句相互之间以及与主查询同时执行。因此，当在WITH中使用数据修改语句时，指定的更新实际发生的顺序是不可预测的。\n 这意味着你不能依赖独立子语句的执行顺序。看来，当子语句之间存在依赖关系时，比如在上面的例子中，你可以依靠依赖的子语句在被使用之前执行。\n避免在选择性低的列上使用索引。 假设你有一个注册流程，用户用电子邮件地址注册。为了激活帐户，他们必须验证他们的电子邮件。你的表可以是这样的。\ndb=# CREATE TABLE users ( db-# id serial, db-# username text, db-# activated boolean db-#); CREATE TABLE 你的大部分用户都是好公民，他们用有效的邮箱注册，并立即激活账号。让我们用用户数据来填充表格，其中大概有90%的用户被激活。\ndb=# INSERT INTO users (username, activated) db-# SELECT db-# md5(random()::text) AS username, db-# random() \u0026lt; 0.9 AS activated db-# FROM db-# generate_series(1, 1000000); INSERT 0 1000000 db=# SELECT activated, count(*) FROM users GROUP BY activated; activated | count -----------+--------  f | 102567 t | 897433 db=# VACUUM ANALYZE users; VACUUM 要查询已激活和未激活的用户，你可能会想在列激活上创建一个索引。\ndb=# CREATE INDEX users_activated_ix ON users(activated); CREATE INDEX 当你试图查询未激活的用户时，数据库正在使用索引。\ndb=# EXPLAIN SELECT * FROM users WHERE NOT activated; QUERY PLAN --------------------------------------------------------------------------------------  Bitmap Heap Scan on users (cost=1923.32..11282.99 rows=102567 width=38) Filter: (NOT activated) -\u0026gt; Bitmap Index Scan on users_activated_ix (cost=0.00..1897.68 rows=102567 width=0) Index Cond: (activated = false) 数据库估计，过滤后会有102567个，这大概是表的10%。这与我们填充的数据是一致的，所以数据库对数据的感觉很好。\n但是，当你尝试查询激活用户时，你发现数据库决定不使用索引。\ndb=# EXPLAIN SELECT * FROM users WHERE activated; QUERY PLAN ---------------------------------------------------------------  Seq Scan on users (cost=0.00..18334.00 rows=897433 width=38) Filter: activated 很多开发人员在数据库没有使用索引的时候，往往会感到困惑。解释为什么索引并不总是最好的选择的一种方法是：如果你必须读取整个表，你会使用索引吗？\n答案可能是否定的，因为你为什么要这样做？从磁盘上读取是很昂贵的，你希望尽可能少地读取。例如，如果一个表是10MB，索引是1MB，要读取整个表，你就必须从磁盘上读取10MB。如果要使用索引来读取表，你就必须从磁盘上读取11MB。这是很浪费的。\n有了这样的理解，我们来看看PostgreSQL对表的收集统计。\ndb=# SELECT attname, n_distinct, most_common_vals, most_common_freqs db-# FROM pg_stats db-# WHERE tablename = \u0026#39;users\u0026#39; AND attname=\u0026#39;activated\u0026#39;; ------------------+------------------------ attname | activated n_distinct | 2 most_common_vals | {t,f} most_common_freqs | {0.89743334,0.10256667} 当PostgreSQL分析该表时，发现激活的列有两个不同的值。most_common_vals列中的值t对应的是most_common_freqs列中的频率0.89743334，值f对应的是频率0.10256667。也就是说，经过分析，数据库估计表中89.74%是激活用户，其余10.26%是未激活用户。\n通过这些统计，PostgreSQL决定，如果希望90%的行满足条件，最好扫描整个表。过了这个阈值，数据库可能会决定使用或不使用索引，这取决于很多因素，没有一个经验法则可以使用。\n使用部分索引 在上一节中，我们在布尔值列上创建了一个索引，其中90%的值为真（激活用户）。当我们试图查询活跃用户时，数据库没有使用该索引。然而，当我们查询未激活的用户时，数据库却使用了该索引。\n这就引出了下一个问题\u0026hellip;\u0026hellip;如果数据库不打算使用索引来过滤活跃用户，那么我们为什么要首先使用索引呢？\n在回答这个问题之前，我们先来看看激活列上的完整索引有多大重量。\ndb=# \\di+ users_activated_ix Schema | Name | Type | Owner | Table | Size --------+--------------------+-------+-------+-------+------  public | users_activated_ix | index | haki | users | 21 MB 索引是21MB。仅供参考，用户表是65MB。这意味着索引的重量约为表的32%。我们也知道~90%的索引可能不会被使用。\n在PostgreSQL中，有一种方法可以只在表的一部分创建索引，使用所谓的部分索引。\ndb=# CREATE INDEX users_unactivated_partial_ix ON users(id) db-# WHERE not activated; CREATE INDEX 使用WHERE子句，我们限制了索引所索引的行。首先让我们确认一下它是否有效。\ndb=# EXPLAIN SELECT * FROM users WHERE not activated; QUERY PLAN ------------------------------------------------------------------------------------------------  Index Scan using users_unactivated_partial_ix on users (cost=0.29..3493.60 rows=102567 width=38) 令人惊奇的是，数据库很聪明，它明白我们在查询中使用的谓词可以通过部分索引来满足。\n使用部分索引还有一个好处。\ndb=# \\di+ users_unactivated_partial_ix List of relations Schema | Name | Type | Owner | Table | Size --------+------------------------------+-------+-------+-------+---------  public | users_unactivated_partial_ix | index | haki | users | 2216 kB 部分索引仅重2.2MB。列上的全索引重达21MB。部分索引的大小正好是全索引的10%，这与表中非活跃用户的比例相匹配。\n始终加载排序过的数据 这是我在代码评审中评论最多的事情之一。它不像其他提示那样直观，它对性能的影响很大。\n比如说你有一个大的销售事实表。\ndb=# CREATE TABLE sale_fact (id serial, username text, sold_at date); CREATE TABLE Every night, during some ETL process, you load data into the table: db=# INSERT INTO sale_fact (username, sold_at) db-# SELECT db-# md5(random()::text) AS username, db-# \u0026#39;2020-01-01\u0026#39;::date + (interval \u0026#39;1 day\u0026#39;) * round(random() * 365 * 2) AS sold_at db-# FROM db-# generate_series(1, 100000); INSERT 0 100000 db=# VACUUM ANALYZE sale_fact; VACUUM 为了伪造一个加载过程，我们使用了随机数据。我们插入了10万行随机的用户名，销售日期从2020-01-01到未来两年。\n该表主要用于制作汇总销售报表。大多数报表都是通过日期来过滤，得到特定时期的销售情况。为了加快范围扫描，你可以在sold_at上创建一个索引。\ndb=# CREATE INDEX sale_fact_sold_at_ix ON sale_fact(sold_at); CREATE INDEX 让我们看看一个查询的执行计划，以获取2020年6月的所有销售。\ndb=# EXPLAIN (ANALYZE) db-# SELECT * db-# FROM sale_fact db-# WHERE sold_at BETWEEN \u0026#39;2020-07-01\u0026#39; AND \u0026#39;2020-07-31\u0026#39;; QUERY PLAN -----------------------------------------------------------------------------------------------  Bitmap Heap Scan on sale_fact (cost=108.30..1107.69 rows=4293 width=41) Recheck Cond: ((sold_at \u0026gt;= \u0026#39;2020-07-01\u0026#39;::date) AND (sold_at \u0026lt;= \u0026#39;2020-07-31\u0026#39;::date)) Heap Blocks: exact=927 -\u0026gt; Bitmap Index Scan on sale_fact_sold_at_ix (cost=0.00..107.22 rows=4293 width=0) Index Cond: ((sold_at \u0026gt;= \u0026#39;2020-07-01\u0026#39;::date) AND (sold_at \u0026lt;= \u0026#39;2020-07-31\u0026#39;::date)) Planning Time: 0.191 ms Execution Time: 5.906 ms 在执行了几次查询预热缓存后，时间稳定在约6ms。\nBitmap Scan 从执行计划来看，我们可以看到数据库使用了位图扫描。位图扫描的工作分为两个阶段。\n 位图索引扫描。浏览整个索引sale_fact_sold_at_ix 并映射所有包含相关记录的表页。 位图堆扫描：读取包含相关行的页面。读取包含相关行的页面，并在这些页面中找到满足条件的行。  页面可以包含多条记录。第一步使用索引来查找页面。第二步检查这些页面里面的行，因此执行计划中的 \u0026ldquo;Recheck Cond \u0026ldquo;操作。\n这时，很多DBA和开发人员都会收工，继续进行下一个查询。BUT，有一个方法可以让这个查询变得更好。\nIndex Scan 为了让事情变得更好，我们会在加载数据的方式上做一个小小的改变。\ndb=# TRUNCATE sale_fact; TRUNCATE TABLE db=# INSERT INTO sale_fact (username, sold_at) db-# SELECT db-# md5(random()::text) AS username, db-# \u0026#39;2020-01-01\u0026#39;::date + (interval \u0026#39;1 day\u0026#39;) * round(random() * 365 * 2) AS sold_at db-# FROM db-# generate_series(1, 100000) db-# ORDER BY sold_at; INSERT 0 100000 db=# VACUUM ANALYZE sale_fact; VACUUM 这次，我们加载的数据是按sold_at排序的。\n让我们看看现在完全相同的查询的执行计划是什么样子的。\ndb=# EXPLAIN (ANALYZE) db-# SELECT * db-# FROM sale_fact db-# WHERE sold_at BETWEEN \u0026#39;2020-07-01\u0026#39; AND \u0026#39;2020-07-31\u0026#39;; QUERY PLAN ---------------------------------------------------------------------------------------------  Index Scan using sale_fact_sold_at_ix on sale_fact (cost=0.29..184.73 rows=4272 width=41) Index Cond: ((sold_at \u0026gt;= \u0026#39;2020-07-01\u0026#39;::date) AND (sold_at \u0026lt;= \u0026#39;2020-07-31\u0026#39;::date)) Planning Time: 0.145 ms Execution Time: 2.294 ms 在运行了几次查询后，我们得到了一个稳定在2.3ms的轮回时间。与之前的查询耗时约6ms相比，我们得到了约60%的稳定节省。\n还有一点我们可以马上看到，这次数据库没有使用位图扫描，而是使用了 \u0026ldquo;常规 \u0026ldquo;索引扫描。为什么会这样呢？\nCorrelation 当数据库在分析一张表时，它会收集各种统计数据。其中一个统计是相关性。\n 物理行排序和逻辑列值排序之间的统计相关性。这个范围从-1到+1。当该值接近-1或+1时，由于减少了对磁盘的随机访问，估计对该列进行索引扫描会比接近零时更便宜。\n 正如官方文档所解释的那样，相关性衡量了特定列值在磁盘上的 \u0026ldquo;排序 \u0026ldquo;程度。\n当相关性为1，或接近1时，意味着表中的页在磁盘上的存储顺序与表中的行大致相同。这其实是很常见的。例如，自动递增的ID通常会有接近1的相关性。跟踪行创建时间的日期和时间戳列通常也会有接近于1的相关性。\n当相关性为-1时，表的页面相对于列的排序顺序是相反的。\n当相关性接近0时，意味着列中的值与表的页面存储方式没有相关性或相关性很小。\n回到我们的sale_fact表，当我们将数据加载到表中时，没有先进行排序，这些就是相关性。\ndb=# SELECT tablename, attname, correlation db-# FROM pg_stats db=# WHERE tablename = \u0026#39;sale_fact\u0026#39;; tablename | attname | correlation -----------+----------+--------------  sale | id | 1 sale | username | -0.005344716 sale | sold_at | -0.011389783 自动生成的列id的相关性为1，sold_at列的相关性很低：连续的值分散在整个表中。\n当我们将排序数据加载到表中时，这些是数据库计算出的相关性。\ntablename | attname | correlation -----------+----------+----------------  sale_fact | id | 1 sale_fact | username | -0.00041992788 sale_fact | sold_at | 1 现在sold_at的相关性为1。\n那么为什么数据库在相关性较低的时候使用位图扫描，而在相关性接近1的时候使用索引扫描呢？\n 当相关性为1时，数据库估计请求范围内的行很可能在连续的页面中。在这种情况下，索引扫描很可能读取很少的页面。 当相关性接近0时，数据库估计请求范围内的行很可能分散在整个表中。在这种情况下，使用位图扫描来映射存在行的表页是有意义的，只有这样才能获取行并应用条件。   下次将数据加载到表中时，请考虑如何查询数据，并确保以用于范围扫描的索引能够受益的方式进行排序。\nCLUSTER Command 另一种按特定索引对磁盘上的表进行 \u0026ldquo;排序 \u0026ldquo;的方法是使用CLUSTER命令。\n例如：\ndb=# TRUNCATE sale_fact; TRUNCATE TABLE -- Insert rows without sorting db=# INSERT INTO sale_fact (username, sold_at) db-# SELECT db-# md5(random()::text) AS username, db-# \u0026#39;2020-01-01\u0026#39;::date + (interval \u0026#39;1 day\u0026#39;) * round(random() * 365 * 2) AS sold_at db-# FROM db-# generate_series(1, 100000) INSERT 0 100000 db=# ANALYZE sale_fact; ANALYZE db=# SELECT tablename, attname, correlation db-# FROM pg_stats db-# WHERE tablename = \u0026#39;sale_fact\u0026#39;; tablename | attname | correlation -----------+-----------+----------------  sale_fact | sold_at | -5.9702674e-05 sale_fact | id | 1 sale_fact | username | 0.010033822 我们按照随机顺序向表中加载数据，结果sold_at的相关性接近于零。\n为了按sold_at对表进行 \u0026ldquo;重新排列\u0026rdquo;，我们使用CLUSTER命令，根据索引sale_fact_sold_at_ix对磁盘上的表进行排序。\ndb=# CLUSTER sale_fact USING sale_fact_sold_at_ix; CLUSTER db=# ANALYZE sale_fact; ANALYZE db=# SELECT tablename, attname, correlation db-# FROM pg_stats db-# WHERE tablename = \u0026#39;sale_fact\u0026#39;; tablename | attname | correlation -----------+----------+--------------  sale_fact | sold_at | 1 sale_fact | id | -0.002239401 sale_fact | username | 0.013389298 表格聚类后，我们可以看到sold_at的相关性为1。\n关于CLUSTER命令需要注意的一些事情。\n 通过特定列对表进行聚类可能会影响其他列的相关性。例如，请看我们将表按sold_at聚类后，列id的相关性。 CLUSTER是一个重度、阻塞的操作，所以请确保不要在活表上执行。  基于这两个原因，最好是将数据分类插入，不要依赖CLUSTER。\n使用 BRIN 索引高相关性的列 说到索引，大多数开发人员会想到B-Tree索引。但是，PostgreSQL提供了其他类型的索引，比如BRIN。\n BRIN是为处理非常大的表而设计的，在这些表中，某些列与它们在表中的物理位置有一些自然的关联。\n BRIN是Block Range Index的缩写。根据文档，BRIN索引对于相关性高的列效果最好。正如我们在前面的章节中已经看到的，一些字段如自动递增的ID和时间戳与表的物理结构有天然的相关性，因此它们是BRIN索引的良好候选。\n在某些情况下，与类似的B-Tree索引相比，BRIN索引在大小和性能上可以提供更好的 \u0026ldquo;性价比\u0026rdquo;。\nBRIN索引的工作原理是将值的范围保持在表内相邻的若干页内。假设我们在一列中有这些值，每个值都是单表页。\n1, 2, 3, 4, 5, 6, 7, 8, 9\nBRIN索引在表中相邻页的范围内工作。如果相邻页数设置为3，索引将把表格分为以下范围：\n[1,2,3], [4,5,6], [7,8,9]\n对于每个范围，BRIN指数保持最小值和最大值。\n[1–3], [4–6], [7–9]\n利用上面的索引，尝试搜索数值5。\n [1–3] - Definitely not here [4–6] - Might be here [7–9] - Definitely not here  利用BRIN索引，我们设法将搜索范围限制在4-6块。\n让我们再举一个例子，这次列中的值会有一个接近于零的相关性，这意味着它们没有被排序。\n[2,9,5], [1,4,7], [3,8,6]\n将3个相邻的块进行索引，会产生以下范围。\n[2–9], [1–7], [3–8]\n让我们试着搜索一下数值5。\n[2–9] - 可能在这 [1–7] - 可能在这 [3–8] - 可能在这\n在这种情况下，索引根本没有限制搜索，因此它是没有用的。\n理解 pages_per_range 相邻页面的数量由参数pages_per_range决定。每个范围的页数会影响BRIN索引的大小和精度。\n大的pages_per_range会产生一个小而不准确的索引。 小的pages_per_range会产生更大更准确的索引。 默认的页面_per_range为128页。\n为了演示，让我们在2个相邻页面的范围上创建一个BRIN索引，并搜索值5。\n [1–2] - 肯定不在这 [3–4] - 肯定不在这 [5–6] - 可能在这 [7–8] - 肯定不在这 [9] - 肯定不在这  使用每个范围为2页的索引，我们能够将搜索限制在第5和第6块。当范围为3页时，索引将搜索范围限制在4、5和6块。\n两个索引之间的另一个区别是，当范围是3页时，我们只需要保留3个范围。当范围为2时，我们必须保留5个范围，所以索引更大。\n创建 BRIN 索引\n使用之前的sales_fact，让我们在sold_at列上创建一个BRIN索引。\ndb=# CREATE INDEX sale_fact_sold_at_bix ON sale_fact db-# USING BRIN(sold_at) WITH (pages_per_range = 128); CREATE INDEX 这就创建了一个BRIN索引，默认的页面_per_range = 128。\n让我们尝试查询销售日期的范围。\ndb=# EXPLAIN (ANALYZE) db-# SELECT * db-# FROM sale_fact db-# WHERE sold_at BETWEEN \u0026#39;2020-07-01\u0026#39; AND \u0026#39;2020-07-31\u0026#39;; QUERY PLAN --------------------------------------------------------------------------------------------  Bitmap Heap Scan on sale_fact (cost=13.11..1135.61 rows=4319 width=41) Recheck Cond: ((sold_at \u0026gt;= \u0026#39;2020-07-01\u0026#39;::date) AND (sold_at \u0026lt;= \u0026#39;2020-07-31\u0026#39;::date)) Rows Removed by Index Recheck: 23130 Heap Blocks: lossy=256 -\u0026gt; Bitmap Index Scan on sale_fact_sold_at_bix (cost=0.00..12.03 rows=12500 width=0) Index Cond: ((sold_at \u0026gt;= \u0026#39;2020-07-01\u0026#39;::date) AND (sold_at \u0026lt;= \u0026#39;2020-07-31\u0026#39;::date)) Execution Time: 8.877 ms 数据库使用我们的BRIN索引得到了一系列的销售日期，但这不是有趣的部分\u0026hellip;\u0026hellip;。\n优化 pages_per_range\n根据执行计划，数据库从使用索引找到的页面中删除了23130条记录。这可能表明我们为索引设置的范围对于这个特定的查询来说太大。让我们尝试创建一个每个范围内页数较少的索引。\ndb=# CREATE INDEX sale_fact_sold_at_bix64 ON sale_fact db-# USING BRIN(sold_at) WITH (pages_per_range = 64); CREATE INDEX db=# EXPLAIN (ANALYZE) db- SELECT * db- FROM sale_fact db- WHERE sold_at BETWEEN \u0026#39;2020-07-01\u0026#39; AND \u0026#39;2020-07-31\u0026#39;; QUERY PLAN ---------------------------------------------------------------------------------------------  Bitmap Heap Scan on sale_fact (cost=13.10..1048.10 rows=4319 width=41) Recheck Cond: ((sold_at \u0026gt;= \u0026#39;2020-07-01\u0026#39;::date) AND (sold_at \u0026lt;= \u0026#39;2020-07-31\u0026#39;::date)) Rows Removed by Index Recheck: 9434 Heap Blocks: lossy=128 -\u0026gt; Bitmap Index Scan on sale_fact_sold_at_bix64 (cost=0.00..12.02 rows=6667 width=0) Index Cond: ((sold_at \u0026gt;= \u0026#39;2020-07-01\u0026#39;::date) AND (sold_at \u0026lt;= \u0026#39;2020-07-31\u0026#39;::date)) Execution Time: 5.491 ms 在每个范围为64页的情况下，数据库从使用索引找到的页面中删除的记录较少，只删除了9,434条，而当范围为128页时，删除了23,130条。这意味着数据库需要做更少的IO，查询速度也稍快，约5.5ms，而不是约8.9ms。\n用不同的pages_per_range值测试索引，产生了以下结果。\nPAGES_PER_RANGE\tROWS_REMOVED_BY_INDEX_RECHECK 128\t23,130 64\t9,434 8\t874 4\t446 2\t446 我们可以看到，当我们减少pages_per_range时，索引更加准确，并且从使用索引找到的页面中删除的行数更少。\n注意，我们针对一个非常特殊的查询进行了优化。这对于演示目的来说是可以的，但在实际生活中，最好使用满足大多数查询需求的值。\n评估指数大小\nBRIN索引的另一大卖点是其大小。在前面的章节中，我们在sold_at字段上创建了一个B-Tree索引。该索引的大小是2224kB。page_per_range=128的BRIN索引的大小只有48kb。这比B-Tree索引小了46倍。\nSchema | Name | Type | Owner | Table | Size --------+-----------------------+-------+-------+-----------+-------  public | sale_fact_sold_at_bix | index | haki | sale_fact | 48 kB public | sale_fact_sold_at_ix | index | haki | sale_fact | 2224 kB BRIN索引的大小也会受到pages_per_range的影响。例如，page_per_range=2的BRIN索引重56kb，仅比48kb稍大。\n让索引 \u0026ldquo;不可见\u0026rdquo; PostgreSQL有一个很好的功能，叫做事务性DDL。在使用Oracle多年后，我已经习惯了诸如CREATE、DROP和ALTER等结束事务的DDL命令。然而，在PostgreSQL中，你可以在事务中执行DDL命令，而且只有当事务提交时，更改才会生效。\n正如我最近发现的那样，使用事务性DDL，你可以使索引不可见! 当你想看看一个执行计划在没有一些索引的情况下是什么样子的时候，这就很方便了。\n例如，在上一节的sale_fact表中，我们在sold_at上创建了一个索引。获取7月份销售额的执行计划是这样的。\ndb=# EXPLAIN db-# SELECT * db-# FROM sale_fact db-# WHERE sold_at BETWEEN \u0026#39;2020-07-01\u0026#39; AND \u0026#39;2020-07-31\u0026#39;; QUERY PLAN --------------------------------------------------------------------------------------------  Index Scan using sale_fact_sold_at_ix on sale_fact (cost=0.42..182.80 rows=4319 width=41) Index Cond: ((sold_at \u0026gt;= \u0026#39;2020-07-01\u0026#39;::date) AND (sold_at \u0026lt;= \u0026#39;2020-07-31\u0026#39;::date))P 为了看看如果索引sale_fact_sold_at_ix不存在，执行计划会是什么，我们可以在一个事务里面放弃索引，然后立即回滚。\ndb=# BEGIN; BEGIN db=# DROP INDEX sale_fact_sold_at_ix; DROP INDEX db=# EXPLAIN db-# SELECT * db-# FROM sale_fact db-# WHERE sold_at BETWEEN \u0026#39;2020-07-01\u0026#39; AND \u0026#39;2020-07-31\u0026#39;; QUERY PLAN ---------------------------------------------------------------------------------  Seq Scan on sale_fact (cost=0.00..2435.00 rows=4319 width=41) Filter: ((sold_at \u0026gt;= \u0026#39;2020-07-01\u0026#39;::date) AND (sold_at \u0026lt;= \u0026#39;2020-07-31\u0026#39;::date)) db=# ROLLBACK; ROLLBACK 我们首先使用BEGIN开始一个事务。然后我们放弃索引并生成一个执行计划。注意，现在执行计划使用了全表扫描，就像索引不存在一样。此时事务仍在进行中，所以还没有丢弃索引。为了在不丢弃索引的情况下完成事务，我们使用ROLLBACK命令回滚事务。\n现在，确保索引仍然存在。\ndb=# \\di+ sale_fact_sold_at_ix List of relations Schema | Name | Type | Owner | Table | Size --------+----------------------+-------+-------+-----------+---------  public | sale_fact_sold_at_ix | index | haki | sale_fact | 2224 kB 其他不支持事务性DDL的数据库提供了其他方法来实现同样的目标。例如，Oracle让你将一个索引标记为不可见，这将导致优化器忽略它。\n注意：在事务内部丢弃索引会在事务处于活动状态时锁定表的并发选择、插入、更新和删除。请在测试环境中谨慎使用，并避免在生产数据库中使用。\n不要在圆周时间安排长期运行的流程。 众所周知，当一只股票的价格达到一个漂亮的整数，如10元、100元、1000元时，就会发生奇怪的事情，这是投资者都知道的事实。正如下面的文章所解释的。\n [\u0026hellip; \u0026hellip;]资产的价格可能会有一个困难的时间 超过一个整数，如50元或100元/股。大多数没有经验的交易者倾向于在价格处于整数时买入或卖出资产，因为他们更有可能觉得一只股票在这种水平上的价值相当高。\n 开发商在这个意义上与投资者并没有什么不同。当他们需要安排一个长期运行的过程时，他们通常会把时间安排在一个整点。\n这种在圆周时间安排任务的倾向，会在这些时间内造成一些异常的负载。所以，如果你需要安排一些长期运行的进程，如果你在其他时间安排，你有更好的机会找到一个系统在休息。\n另一个好主意是给任务的日程安排应用一个随机的延迟，这样它就不会每次都在同一时间运行。这样，即使另一个任务安排在同一时间运行，也不会有大问题。如果你使用systemd定时器单元来安排任务，你可以使用RandomizedDelaySec选项来实现。\n结束语 本文涵盖了我自己经验中的一些琐碎和非琐碎的技巧。其中有些技巧很容易实现，有些则需要更深入地了解数据库的工作原理。数据库是大多数现代系统的支柱，所以花一些时间来了解它们的工作原理对任何开发人员来说都是一项很好的投资!\n",
    "ref": "/blog/sql-tricks-application-dba-chinese/"
  },{
    "title": "DevOps Coach 周刊 #1",
    "date": "",
    "description": "DevOps 教练需要学习的全球新闻，文章，宕机事件和流行工具",
    "body": "新闻 又到了一年一度的时间。定期的Puppet Devops状态调查已经开始。今年的重点是变革管理、持续交付和自服务平台之间的关系。 https://polls.onresearch.net/xsurvey/20JT028/20JT028T1/Survey.aspx?ckie=true\n文档和设计在构建强大的系统中起着至关重要的作用。这篇文章探讨了为什么设计文档是有用的，以及它们应该包含什么样的内容。 https://www.industrialempathy.com/posts/design-docs-at-google/\n一份关于公共Terraform代码安全状况的新报告。对于任何使用Terraform配置服务的人来说，一些有用的数据和一些好的提示。 https://bridgecrew.io/blog/state-of-open-source-terraform-security-report-2020/\n看看如何使用 Azure Pipelines 自动验证 sysmon 配置。 https://medium.com/falconforce/using-azure-pipelines-to-validate-my-sysmon-configuration-48315dba7571\n这是一个很好的大规模迁移低级组件的故事，在这个案例中是一个应用服务器。金丝雀的推出、上游贡献、性能和其他有趣的话题。 https://about.gitlab.com/blog/2020/07/08/migrating-to-puma-on-gitlab/\n拥抱云原生技术和工作方式会带来挑战，本帖记录了其中一些挑战，包括安全、缺乏专业知识、发布周期缓慢等。 https://www.cloudops.com/2020/07/top-7-challenges-to-becoming-cloud-native/\n文章 “How could they be so stupid?” 上周知名Twitter 账号入侵事件出现了更多细节，导致一些人说出了上面这句话。这里有一个看法，如何看待这不是 \u0026ldquo;愚蠢 \u0026ldquo;的问题。Lorin Hochstein https://surfingcomplexity.blog/2020/07/20/how-could-they-be-so-stupid/\nData Consistency Checks 你的数据库中的数据应该是一致的\u0026hellip;\u0026hellip;但话说回来，事故不应该发生，对吗？Slack接受在他们的规模下，数据经常会出问题，他们有框架和一套工具来处理它。Paul Hammond and Samantha Stoller — Slack https://slack.engineering/data-consistency-checks-e73261318f96\nObstacles to Learning from Incidents 我从这篇文章中学到了很多东西。我最喜欢的障碍是 \u0026ldquo;通过差异化来拉开距离\u0026rdquo;，比如 \u0026ldquo;我们绝对不会以这种方式应对事件\u0026rdquo;。Thai Wood — Learning from Incidents https://www.learningfromincidents.io/blog/obstacles-to-learning-from-incidents\nYou don’t need SRE. What you need is SRE. […] SRE，也就是谷歌定义的SRE，对于大多数组织来说并不适用。Sanjeev Sharma https://sdarchitect.blog/2020/02/20/you-dont-need-sre-what-you-need-is-sre/\nQuestionable Advice: “What’s the critical path?” 专家建议，当你试图弄清楚你的关键路径是什么（以及为什么你想知道它是什么）时，应该问什么问题。Charity Majors https://charity.wtf/2020/07/24/questionable-advice-whats-the-critical-path/\nThinking About Your Humans With J. Paul Reed 这个播客集有点像J.Paul Reed和Tim Heckman在https://srefromhome.com/的联合演讲的预览。我喜欢他们把这场传染病大流行称为长达数月的事件，并指出如果你总是在事件中，那么你永远不会在事件中。Julie Gunderson and Mandi Walls — Page it to the Limit https://www.pageittothelimit.com/thinking-about-your-humans/\nRebuilding messaging: How we bootstrapped our platform 我喜欢一个好的双写故事。以下是LinkedIn如何过渡到新的消息存储机制。 Pradhan Cadabam and Jingxuan (Rex) Zhang — LinkedIn https://engineering.linkedin.com/blog/2020/bootstrapping-our-new-messaging-platform\nUsing Automation and SLOs to Create Margin in your Systems 在系统中留有余地，使其具有适应能力，并利用SLO(同情地)来推动优先事项的确定。 https://thechief.io/c/blameless/using-automation-and-slos-create-margin-your-systems/\nHow to Classify Incidents 如何对事件进行分类 什么是事件分类？为什么要对事件进行分类？事件严重性与优先级，以及如何创建事件类别？ https://thechief.io/c/blameless/how-classify-incidents/\n宕机 上周全球重大宕机事故清单。\n Garmin 作为佳明手表和 app 的用户，我体验到了这场 24+小时的服务中断  https://spectrumlocalnews.com/nys/rochester/ap-online/2020/07/24/garmin-fitness-tracking-service-goes-down-frustrating-users   Snapchat 打不开 app，黑屏，无法使用摄像头相关功能  https://screenrant.com/snapchat-down-app-slow-response-messages-not-sent-issues/   Tweetdeck Twitter 客户的工具服务发生故障。  https://www.independent.co.uk/life-style/gadgets-and-tech/news/tweetdeck-down-twitter-not-working-loading-a9633636.html   GGPoker 在 World Series of Poker (WSOP) 世界扑克大赛赛事期间发生一些列问题.  https://portswigger.net/daily-swig/online-poker-operator-hit-by-ddos-attack-on-opening-day-of-wsop-event   Fastly (control plane) Full disclosure: Fastly is my employer.  https://status.fastly.com/incidents/7q2psqf255wl   Squarespace 这一周非常痛苦，在July 21 事故后发生的相关事件： * July 21 https://status.squarespace.com/incidents/hh3p432jcq03 * July 22 (包含事件详细分析) https://status.squarespace.com/incidents/3cgg1171wyvz * July 24 https://status.squarespace.com/incidents/x63nssl9kzvm * July 24 https://status.squarespace.com/incidents/v6ql728f1f4d Google Cloud Platform 几个谷歌云平台组件受到影响，包括 7 层负载均衡器。  https://status.cloud.google.com/incident/zall/20006    工具 https://github.com/flant/shell-operator Shell-operator是一个在Kubernetes集群中运行事件驱动脚本的工具。\nhttps://github.com/Fizzadar/pyinfra pyinfra在大规模的基础架构中实现了超快的自动化。它可以用于临时命令执行、服务部署、配置管理等。 #python #配置管理\nhttps://github.com/alerta/alerta Alerta 监测系统\nhttps://github.com/GoogleCloudPlatform/terraformer CLI工具可以从现有的基础设施中生成terraform文件（反向Terraform）。 #基础设施即代码\nhttps://github.com/visenger/awesome-mlops MLOps的精选参考资料清单。 #github\nhttps://github.com/cycloidio/inframap 读取你的tfstate或HCL，为每个提供者生成一个特定的图表，只显示最重要/相关的资源。 #terraform\nhttps://github.com/Hack-with-Github/Awesome-Hacking 一个为黑客、Pentesters和安全研究人员提供的各种令人敬畏的列表的集合。 #github #安全\nhttps://github.com/box/kube-iptables-tailer kube-iptables-tailer做的正是你所期望的。它将底层的iptables数据暴露给kubectl，方便发现服务在Kubernetes中互相通信的尝试和失败。\nhttps://github.com/Stono/kconmon Kconmon是一个Kubernetes连通性监控工具，它可以运行频繁的测试（tcp、udp和dns），并公开Prometheus指标，这些指标富含节点名称，以及位置信息（如区域），使您能够关联可用性区域或节点之间的问题。\n",
    "ref": "/blog/devopscoach-weekly-1/"
  },{
    "title": "Skaffold 让 K8s 开发者更加酸爽",
    "date": "",
    "description": "Skaffold是本地 Kubernetes 开发者的又一个利器",
    "body": "今天介绍一个本地 Kubernetes 开发的利器 Skaffold。 这是我偶然间发现的一个工具，询问了一下周围的人，居然还没有人用过。测试之后，确实有一种不吐不快的感觉。\n简介 Skaffold Google 开发的一个开源项目。是一个非常轻量的命令行工具，就是一个可执行文件。它的主页上是这样的介绍它的。\n 轻量：Skaffold只是一个客户端工具。由于集群上不需要任何的相关组件，您的集群没有任何开销或维护负担。 运行在任何地方：Skaffold是与世界分享你的项目的最简单的方法：\u0026ldquo;git clone\u0026rdquo;，然后 \u0026ldquo;skaffold run\u0026rdquo;。此外，你还可以使用配置文件、本地用户配置、环境变量和标志来轻松地集成不同环境的差异。 功能丰富：Skaffold拥有许多Kubernetes原生开发的基本功能，包括基于策略的打镜像标签、资源端口转发和日志、文件同步等。 优化你的开发：Skaffold使内部循环紧密，高度优化，让您在开发的同时得到即时反馈。  客户评价 \u0026ldquo;我们的客户很喜欢[Kubernetes]，但一直给我们反馈说在Kubernetes上开发很麻烦。Skaffold一针见血地解决了这个问题。以前需要几分钟才能部署的docker镜像或配置的更改，现在只需要几秒钟。Skaffold的插件架构使我们能够部署到Helm或Kustomize，并使用各种docker构建插件，如Kaniko。Skaffold用一个精简的工具取代了我们定制的实用程序和脚本集合，并且易于使用。\u0026rdquo; Warren Strange，ForgeRock的工程总监。\n\u0026ldquo;当我们评估我们可以使用Kubernetes的工作流程时，Skaffold脱颖而出，成为我们在开发和部署中都想要的工具。它为我们提供了一个跨应用程序的通用入口点，我们也可以为CI/CD重用。现在，我们所有的Kubernetes应用的CI/CD管道在构建和部署时都使用Skaffold。\u0026rdquo; Taylor Barrella，Quora的软件工程师\n\u0026ldquo;Skaffold是一个了不起的工具，它为我们简化了开发和交付。Skaffold通过覆盖两个维度，击中了我们的甜蜜点。第一，从本地开发、集成测试到交付的整个开发周期。第二，Skaffold让我们能够在Linux、OSX和Windows上独立开发，不需要特定的平台逻辑。\u0026rdquo; Martin Höfling，TNG技术咨询有限公司首席顾问\n推荐首次测试流程 前置条件，你的开发用工作电脑上已经安装了它需要调用的 kubectl 和 docker 命令，kubectl 需要有至少一个可用的配置，这个配置可以指向任一一个你有权限部署的 Kubernetes 集群。\n我在 macOS 上，直接运行 ‌brew install skaffold 即可，其它系统参考：https://skaffold.dev/docs/install/\n克隆 Skaffold 的代码库到本地，获取必要的测试应用代码。\n‌git clone https://github.com/GoogleContainerTools/skaffold\n进入代码库中的‘hello world’示例应用。\n执行：‌cd skaffold/examples/getting-started\n执行 ‌skaffold dev ，你会看到 Skaffold 进入了这个项目的构建和运行的状态，执行结果是持续的输出 ”[getting-started] Hello world!“\n现在 Skaffold 就进入了 /getting-started 的监视状态。观察任何代码文件的修改存盘动作，每次代码的变更会触发 Skaffold 流水线的执行，skaffold.yaml 文件中描述了本地流水线中的相关动作：\n 使用 Dockerfile 从源头构建Docker镜像。 用Docker镜像的内容的sha256哈希值来打上标签。 更新 Kubernetes manifest k8s-pod.yaml，以使用上一步构建的镜像。 使用 kubectl apply -f 部署 Kubernetes manifest。 从已部署的应用程序取回日志在本地控制台显示。  现在用代码编辑器打开这个项目唯一的程序文件 main.go ，修改其中的 Hello World 为其它你想到的词，保存后，观察构建的过程。\n推荐微服务测试 参考以下视频，测试 Skaffold 代码库中的 microservice 项目。\nSkaffold 流水线阶段 Skaffold 主要会用到五个阶段。\n其所有阶段如下：\n Init ：\tgenerate a starting point for Skaffold configuration Build ：build images with different builders Tag ：\ttag images based on different policies Test\t：test images with structure tests Deploy\t：deploy with kubectl, kustomize or helm File Sync ：\tsync changed files directly to containers Log ： Tailing\ttail logs from workloads Port Forwarding\t：forward ports from services and arbitrary resources to localhost Cleanup ：\tcleanup manifests and images  当你启动Skaffold时，它就会收集你项目中的源代码，并使用你所选择的工具构建工件；工件一旦成功构建，就会根据你的需要进行标记，并推送到你指定的仓库中。在工作流程的最后，Skaffold还帮助你将工件部署到你的Kubernetes集群中，同样使用你喜欢的工具。\nSkaffold允许你跳过各个阶段。例如，如果你在本地使用Minikube运行Kubernetes，Skaffold不会将工件推送到远程仓库。\n每个阶段的详情见：https://skaffold.dev/docs/pipeline-stages/\n架构设计 Skaffold 秉承着插件化的设计思想。\n以上架构内置了对下来工具的支持：\n Build  Dockerfile locally, in-cluster with kaniko or on cloud using Google Cloud Build Jib Maven and Jib Gradle locally or on cloud using Google Cloud Build Bazel locally Cloud Native Buildpacks locally or on cloud using Google Cloud Build Custom script locally or in-cluster   Test  container-structure-test   Tag   Git tagger Sha256 tagger Env Template tagger DateTime tagger   Deploy   Kubernetes Command-Line Interface (kubectl) Helm kustomize  总结 Skaffold 确实让基于 Kubernetes 的开发者的本地工作环境更加优化和整洁了。希望本文对你的工作有所帮助。\n",
    "ref": "/blog/skaffold-make-local-k8s-dev-easy/"
  },{
    "title": "Beats 摄入数据的最佳实践",
    "date": "",
    "description": "使 Elastic Stack 安全、能适应和可扩展的实战配置",
    "body": "本文概要：配置 ES 3 节点全加密，Kibana 的 SSL 加密配置，Beats 的高可靠性加密传输，用 RBAC 怎样把权限控制到最小，在配置文件中消除明文密码，这些你都做到了么？如何保证安全、能适应和可扩展的配置 Elastic Stack 技术栈，让我们从 Bests 的角度开始讲解。\n前言 本文使用的软版本：\n Elastic Stack 7.8.0 macOS 10.15.5 Vagrant 2.2.9 VirtualBox 6.0 CentOS 8.0  下面的配置和测试过程基于以下 Vagrantfile ，你可以在其它任何同等的环境中测试下面的所有配置。\n# -*- mode: ruby -*- # vi: set ft=ruby : # Every Vagrant development environment requires a box. You can search for # boxes at https://atlas.hashicorp.com/search. BOX_IMAGE = \u0026quot;bento/centos-8\u0026quot; ES_COUNT = 3 NODE_COUNT = 4 Vagrant.configure(\u0026quot;2\u0026quot;) do |config| #设置所有 guest 使用相同的静态 dns 解析 /etc/hosts config.vm.provision :hosts, :sync_hosts =\u0026gt; true #用 vagrant 默认密钥对 ssh 登录 config.ssh.insert_key = false # 用于部署 Elasticsearch 服务器的集群 (1..ES_COUNT).each do |i| config.vm.define \u0026quot;es#{i}\u0026quot; do |es_config| es_config.vm.box = BOX_IMAGE es_config.vm.hostname = \u0026quot;es#{i}.zenlab.local\u0026quot; es_config.vm.network :private_network, ip: \u0026quot;192.168.50.#{i + 10}\u0026quot; es_config.vm.provision :hosts, :sync_hosts =\u0026gt; true es_config.vm.provider :virtualbox do |vb| vb.memory = 2048 vb.cpus = 1 end es_config.vm.provision :shell, path: 'pre-install-ES.sh' end end # 用于部署 Kibana、Logstash 、APM Server、Heatbeat 和 Packetbeat config.vm.define \u0026quot;lk\u0026quot; do |lk_config| lk_config.vm.box = BOX_IMAGE lk_config.vm.hostname = \u0026quot;lk.zenlab.local\u0026quot; lk_config.vm.network :private_network, ip: \u0026quot;192.168.50.20\u0026quot; lk_config.vm.network 'forwarded_port', guest: 5601, host: 5601 lk_config.vm.provision :hosts, :sync_hosts =\u0026gt; true lk_config.vm.provider :virtualbox do |vb| vb.memory = 1024 vb.cpus = 1 end #logstash_config.vm.provision :shell, path: 'pre-install-ES.sh' end # 两个被管理节点，用于部署监控应用和各种 Beats 代理 (1..NODE_COUNT).each do |i| config.vm.define \u0026quot;node#{i}\u0026quot; do |node_config| node_config.vm.box = BOX_IMAGE node_config.vm.hostname = \u0026quot;node#{i}.zenlab.local\u0026quot; node_config.vm.network :private_network, ip: \u0026quot;192.168.50.#{i + 20}\u0026quot; node_config.vm.provider :virtualbox do |vb| vb.memory = 1024 vb.cpus = 1 end node_config.vm.provision :shell, path: 'pre-install-beats.sh' end end # Install avahi on all machines config.vm.provision \u0026quot;shell\u0026quot;, inline: \u0026lt;\u0026lt;-SHELL sh -c \u0026quot;echo 'Welcome to Elastic Stack!'\u0026quot; SHELL end 注：下文中所有路径中的 /vagrant/ 目录是本 vagrant 测试环境中，所有虚拟机的共享目录，是所有节点上配置文件的原路径。如果你使用的不是 vagrant 环境，你需要在下面的测试中适当的替换。\n三节点 Elasticsearch 服务器集群 在每个节点上使用下面的初始化脚本，部署 Elasticsearch 服务器。\n使用vagrant up es1 es2 es3命令创建并启动 ES 服务器三个节点。\n# pre-install-ES.sh elastic_version='7.8.0' echo \u0026quot;Provisioning a Elasticsearch \u0026quot;$elastic_version\u0026quot; Server...\u0026quot; sudo date \u0026gt; /etc/vagrant_provisioned_at sudo swapoff -a sudo sysctl -w vm.max_map_count=262144 sudo sysctl -p sudo sh -c \u0026quot;echo 'elasticsearch - nofile 65535' \u0026gt;\u0026gt; /etc/security/limits.conf\u0026quot; sudo sh -c \u0026quot;echo '**** -- -- -- -- -- -- -- -- ****' \u0026gt; /etc/motd\u0026quot; sudo sh -c \u0026quot;echo '**** Welcome to Elastic Stack Labs' \u0026gt;\u0026gt; /etc/motd\u0026quot; sudo sh -c \u0026quot;echo '**** -- -- -- -- -- -- -- -- ****' \u0026gt;\u0026gt; /etc/motd\u0026quot; sudo sh -c \u0026quot;echo '*' \u0026gt;\u0026gt; /etc/motd\u0026quot; sudo rpm -ivh /vagrant/rpm/elasticsearch-$elastic_version-x86_64.rpm 上面的脚本简单的初始化了几个操作系统参数，然后完成了 rpm 包的安装。非vagrant 环境的需要手工上传 rpm 安装文件，和运行以上的命令。\n配置首个 ES 服务器节点 登录 es1 节点vagrant ssh es1 ；\n创建用于节点间传输所需要的数字证书和秘钥文件，下面是所使用的种子文件。\n# instance.yml instances: - name: 'es1' ip: ['192.168.50.11'] dns: [ 'es1.zenlab.local' ] - name: \u0026quot;es2\u0026quot; ip: ['192.168.50.12'] dns: [ 'es2.zenlab.local' ] - name: 'es3' ip: ['192.168.50.13'] dns: [ 'es3.zenlab.local' ] - name: 'lk' ip: ['192.168.50.20'] dns: [ 'lk.zenlab.local' ] 用  elasticsearch-certutil 创建证书文件包。\nsudo /usr/share/elasticsearch/bin/elasticsearch-certutil cert --ca --pem --in /vagrant/certs/instance.yml --out /vagrant/certs/certs.zip 将得到的 zip 文件解压缩在适当的目录里备用。\n重要步骤：在 Elasticsearch 的配置文件目录中放置必要的数字证书文件。\nsudo mkdir /etc/elasticsearch/certs sudo cp /vagrant/certs/ca/ca.crt /etc/elasticsearch/certs sudo cp /vagrant/certs/es1/* /etc/elasticsearch/certs sudo ls /etc/elasticsearch/certs 在 certs 目录中有三个文件：\n ca.crt CA 根证书 es1.crt 服务器证书 es1.key 私钥文件  CA 根证书是在所有节点上发起对 ES 服务的 HTTPS 服务所需要的客户端证书。 es1.crt 和 es1.key 这样的必要对需要在所有 ES 节点上部署，用于 ES 节点间的 transport 协议加密传输，每个 ES 节点都是用自己的密钥对文件。\n在 ES1 的主配置文件中打开安全选项和其它必要配置，示例配置文件如下。\n# elasticsearch.yml # ---------------------------------- Cluster ----------------------------------- cluster.name: elk4devops # ------------------------------------ Node ------------------------------------ node.name: es1 # ----------------------------------- Paths ------------------------------------ path.data: /var/lib/elasticsearch path.logs: /var/log/elasticsearch # ---------------------------------- Network ----------------------------------- network.host: es1.zenlab.local # --------------------------------- Discovery ---------------------------------- cluster.initial_master_nodes: [\u0026quot;es1\u0026quot;] discovery.seed_hosts: [ \u0026quot;es1.zenlab.local\u0026quot; ] # ------------------------------- TLS and Cert --------------------------------- xpack.security.enabled: true #外部服务加密配置 xpack.security.http.ssl.enabled: true xpack.security.http.ssl.key: certs/es1.key xpack.security.http.ssl.certificate: certs/es1.crt xpack.security.http.ssl.certificate_authorities: certs/ca.crt #集群内通讯加密配置 xpack.security.transport.ssl.enabled: true xpack.security.transport.ssl.key: certs/es1.key xpack.security.transport.ssl.certificate: certs/es1.crt xpack.security.transport.ssl.certificate_authorities: certs/ca.crt xpack.monitoring.collection.enabled: true # ------------------------------- App Search --------------------------------- action.auto_create_index: \u0026quot;.app-search-*-logs-*,-.app-search-*,+*\u0026quot; 使用以上配置文件覆盖Elasticsearch 默认的配置文件，首次启动第一个 ES 节点的服务。\nsudo cp /vagrant/elasticsearch.yml /etc/elasticsearch/elasticsearch.yml sudo systemctl daemon-reload sudo systemctl start elasticsearch 用下面的命令查看启动日志，直到 elasticsearch 服务正常启动。\nsudo tail -f /var/log/elasticsearch/elk4devops.log 用下面的命令初始化 Elasticsearch 系统内置账号为随机复杂密码。\nsudo /usr/share/elasticsearch/bin/elasticsearch-setup-passwords auto -u \u0026quot;https://es1.zenlab.local:9200\u0026quot; -b Changed password for user apm_system PASSWORD apm_system = irpVThXpbFDrdq2rBQUC Changed password for user kibana_system PASSWORD kibana_system = CxGNlkqQMbcp6u6XuCbk Changed password for user kibana PASSWORD kibana = CxGNlkqQMbcp6u6XuCbk Changed password for user logstash_system PASSWORD logstash_system = EOUiCyQQ97IHwUJs8Eum Changed password for user beats_system PASSWORD beats_system = EF8OdPmcpy1bUCgFVQ90 Changed password for user remote_monitoring_user PASSWORD remote_monitoring_user = 3ZRBVo5Omu33McoOKgwE Changed password for user elastic PASSWORD elastic = ZSzN2idoU6hFa4f0ulPP 将上面随机生成的密码保存在安全的地方备用，这些内置的超级用户权限大，一旦遗失了密码，可能会造成重大的数据泄露。\n用上面创建的账户测试第一个 ES 节点是否可以通过 https 正常访问，这里也测试 ca 公钥的可用性。\ncurl --cacert /vagrant/certs/ca/ca.crt -u elastic 'https://es1.zenlab.local:9200/_cat/nodes?v' 在 es1 服务器的命令行运行以上命令，输入 elastic 的密码。应该可以看到正常的输出。/vagrant/certs/ca/ca.crt 这个路径替换成你的环境中的相关 ca 证书文件路径。\n配置第二个和第三个 ES 服务器节点 剩下的两个节点在加入集群之前都已经通过初始化脚本安装完了 rpm 安装包。剩下的就是逐个节点的部署之前生产的证书文件和修改后的 elasticsearc.yml 主配置文件。在本文档参考的环境中使用如下命令。\n登录 es 2  vagrant ssh es2\n配置 es2 的证书和秘钥文件，下面的复制原路径需要替换成你所使用的实际路径。\nsudo mkdir /etc/elasticsearch/certs sudo cp /vagrant/certs/ca/ca.crt /etc/elasticsearch/certs sudo cp /vagrant/certs/es2/* /etc/elasticsearch/certs sudo ls /etc/elasticsearch/certs 部署 es2 的配置文件，然后启动这个节点的 Elasticsearch 服务。\nsudo cp /vagrant/elasticsearch2.yml /etc/elasticsearch/elasticsearch.yml sudo systemctl daemon-reload sudo systemctl start elasticsearch elasticsearch2.yml  文件的内容如下。\n# ---------------------------------- Cluster ----------------------------------- cluster.name: elk4devops # ------------------------------------ Node ------------------------------------ node.name: es2 # ----------------------------------- Paths ------------------------------------ path.data: /var/lib/elasticsearch path.logs: /var/log/elasticsearch # ---------------------------------- Network ----------------------------------- network.host: es2.zenlab.local # --------------------------------- Discovery ---------------------------------- cluster.initial_master_nodes: [\u0026#34;es1\u0026#34;] discovery.seed_hosts: [ \u0026#34;es1.zenlab.local\u0026#34; ] # ------------------------------- TLS and Cert --------------------------------- xpack.security.enabled: true xpack.security.http.ssl.enabled: true xpack.security.http.ssl.key: certs/es2.key xpack.security.http.ssl.certificate: certs/es2.crt xpack.security.http.ssl.certificate_authorities: certs/ca.crt xpack.security.transport.ssl.enabled: true xpack.security.transport.ssl.key: certs/es2.key xpack.security.transport.ssl.certificate: certs/es2.crt xpack.security.transport.ssl.certificate_authorities: certs/ca.crt xpack.monitoring.collection.enabled: true # ------------------------------- App Search --------------------------------- action.auto_create_index: \u0026#34;.app-search-*-logs-*,-.app-search-*,+*\u0026#34; 在 es2 的命令用下面的命令查看是否该节点正常加入了集群。\ncurl --cacert /vagrant/certs/ca/ca.crt -u elastic \u0026#39;https://es1.zenlab.local:9200/_cat/nodes?v\u0026#39; Enter host password for user \u0026#39;elastic\u0026#39;: ip heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name 192.168.50.11 37 94 0 0.00 0.05 0.06 dilmrt * es1 192.168.50.12 17 96 9 0.49 0.20 0.07 dilmrt - es2 注意上面 ca.crt 文件的路径，要输入的是 elasstic 用户的密码。 正常情况下两个节点都会出现在结果清单中。\n用相似的命令初始化和启动 es3 节点的服务。es3 的主配置文件样例如下。\n# ---------------------------------- Cluster ----------------------------------- cluster.name: elk4devops # ------------------------------------ Node ------------------------------------ node.name: es3 # ----------------------------------- Paths ------------------------------------ path.data: /var/lib/elasticsearch path.logs: /var/log/elasticsearch # ---------------------------------- Network ----------------------------------- network.host: es3.zenlab.local # --------------------------------- Discovery ---------------------------------- cluster.initial_master_nodes: [\u0026#34;es1\u0026#34;] discovery.seed_hosts: [ \u0026#34;es1.zenlab.local\u0026#34; ] # ------------------------------- TLS and Cert --------------------------------- xpack.security.enabled: true xpack.security.http.ssl.enabled: true xpack.security.http.ssl.key: certs/es3.key xpack.security.http.ssl.certificate: certs/es3.crt xpack.security.http.ssl.certificate_authorities: certs/ca.crt xpack.security.transport.ssl.enabled: true xpack.security.transport.ssl.key: certs/es3.key xpack.security.transport.ssl.certificate: certs/es3.crt xpack.security.transport.ssl.certificate_authorities: certs/ca.crt xpack.monitoring.collection.enabled: true # ------------------------------- App Search --------------------------------- action.auto_create_index: \u0026#34;.app-search-*-logs-*,-.app-search-*,+*\u0026#34; 最终集群的测试状态如下：\n[vagrant@es1 ~]$ curl --cacert /vagrant/certs/ca/ca.crt -u elastic \u0026#39;https://es1.zenlab.local:9200/_cat/nodes?v\u0026#39; Enter host password for user \u0026#39;elastic\u0026#39;: ip heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name 192.168.50.11 20 96 6 0.18 0.09 0.03 dilmrt * es1 192.168.50.13 50 96 2 0.02 0.07 0.03 dilmrt - es3 192.168.50.12 25 96 1 0.00 0.02 0.00 dilmrt - es2 配置 Kibana 服务器 服务是必要的的管理界面，是数据搜索、可视化的重要工具。在 Elasticsearch 服务打开了外部 https 加密访问的情况下，Kibana 服务器的安装和配置也需要做如下调整。\nKibana 的 rpm 安装这里省略。下面直接进入相关的主要配置步骤。\n复制用于链接 ES 集群的证书\nsudo mkdir /etc/kibana/certs sudo cp /vagrant/certs/ca/ca.crt /etc/kibana/certs sudo cp /vagrant/certs/lk/* /etc/kibana/certs sudo ls /etc/kibana/certs 修改默认的 kibana.yml 配置文件，然后覆盖默认的配置文件后启动 kibana 服务。\nsudo cp /vagrant/kibna.yml /etc/kibana/kibana.yml sudo cat /etc/kibana/kibana.yml sudo systemctl start kibana 监控 kibana 的启动日志，直到它正常启动。\nsudo tail -f /var/log/messages 启动后，使用浏览器访问 https://lk.zenlab.lcoal:5601  Kibana 服务，使用 elastic 用户的密码登录，确保 Kibana 正常启动。\n配置权限 Beats 账号 在使用 Beats 采集监控数据的时候，Beats 的配置文件中需要配置一个后台 Elasticsearch 服务访问账号，安全起见需求需要将这个账号配置为只写权限。配置步骤如下。\n在 Kibana 的用户管理中创建名为 beats-writer 的角色，如下图所示。\n以上这个角色拥有 filebeat 和 Metricbeat 两个索引的访问权限，这里是为了评估用户角色管理的工作量，否则可以每个索引单独设置一套必要权限的角色和用户，从而实现更安全的防护。\n然后创建名为 beats-writer 的用户，设置一个密码，将它赋予 beats-writer 的角色（上面创建的）。\n这样它就可以用于所有 Beats 节点的配置了。\n初始化首个 Beats 节点 在 vagrant 测试环境中启动第一个用于测试 Beats 的节点。\nvagrant up node1\n这里使用了初始脚本安装相关的 rpm 安装包。\n#!/bin/bash # author: Martin Liu # url:martinliu.cn elastic_version='7.8.0' echo \u0026quot;Installing a Filebeat \u0026quot;$elastic_version\u0026quot; agent...\u0026quot; sudo rpm -ivh /vagrant/rpm/filebeat-$elastic_version-x86_64.rpm sudo systemctl enable filebeat.service sudo rpm -ivh /vagrant/rpm/metricbeat-$elastic_version-x86_64.rpm sudo systemctl enable metricbeat.service sudo rpm -ivh /vagrant/rpm/auditbeat-$elastic_version-x86_64.rpm sudo systemctl enable auditbeat.service 登录该节点进行 Beats 的初始化配置。目前 Elasticsearch 集群还是空白的，还没有初始化任何 Beats 相关的索引、可视化和仪表板。这个初始化工作是通过，每种 Beats 的 setup 命令完成的。这个 setup 命令只需要在一个节点上成功执行一次即可，其它节点的配置文件中，连 setup 命令相关的配置都不需要。\n这里使用的 filebeat.yml 参考文件如下：\n#=========================== Filebeat inputs ============================= filebeat.inputs: - type: log enabled: false paths: - /var/log/*.log #============================= Filebeat modules =============================== filebeat.config.modules: path: ${path.config}/modules.d/*.yml reload.enabled: true reload.period: 5s #==================== Elasticsearch template setting ========================== setup.template.settings: index.number_of_shards: 1 index.codec: best_compression #============================== Kibana ===================================== setup.kibana: host: \u0026quot;https://lk.zenlab.local:5601\u0026quot; #-------------------------- Elasticsearch output ------------------------------ output.elasticsearch: hosts: [\u0026quot;es1.zenlab.local:9200\u0026quot;] username: \u0026quot;elastic\u0026quot; password: \u0026quot;1l1lqVMMWMbLI6DCH0dQ\u0026quot; protocol: https #================================ Processors ===================================== processors: - add_host_metadata: netinfo.enabled: true cache.ttl: 5m geo: name: bj-dc-01 location: 35.5528, 116.2360 continent_name: Asia country_iso_code: CN region_name: Beijing region_iso_code: CN-BJ city_name: Beijing - add_cloud_metadata: ~ - add_docker_metadata: ~ - add_kubernetes_metadata: ~ 目前的计划是配置 Beats 直接访问 Elasticsearch 后台服务，不通过 Logstash 中转。以后增加这个参考配置。\n在执行 filebeat setup 命令之前，还需要在 Beats 节点上部署上面生成的 ca 公钥文件。参考命令如下。\nsudo update-ca-trust enable sudo cp /vagrant/certs/ca/ca.crt /etc/pki/ca-trust/source/anchors/ sudo update-ca-trust extract 这里把 ca.crt 公钥文件部署到了 CentOS 操作系统的的可信 CA 发放机构的目录中，其它操作系统中的这个证书路径可能不同，需要做替换，包括以上的证书更新命令也可能需要调整。\n经过以上的配置之后，用之前的 curl 命令测试一下是否这个证书生效了。\n[vagrant@es1 ~]$ curl -u elastic \u0026#39;https://es1.zenlab.local:9200/_cat/nodes?v\u0026#39; Enter host password for user \u0026#39;elastic\u0026#39;: ip heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name 192.168.50.11 20 96 6 0.18 0.09 0.03 dilmrt * es1 192.168.50.13 50 96 2 0.02 0.07 0.03 dilmrt - es3 192.168.50.12 25 96 1 0.00 0.02 0.00 dilmrt - es2 这次在参数中故意省略了 ca 证书文件路径，如果 curl 可以正常访问，那么 Beats 程序也可以，而且不需要在 Beats 配置文件中生命公钥的路径，更有利于在以后切换到另外一套 CA 秘钥后，配置文件的更新工作。\n这里省略 Beats 配置文件的展示，参考一下命令做初始化前的准备。\nsudo cp -f /vagrant/filebeat.yml /etc/filebeat/filebeat.yml sudo cp -f /vagrant/metricbeat.yml /etc/metricbeat/metricbeat.yml sudo filebeat modules enable system 为了测试的方便起见，在 filebeat.yml 和 metricbeat.yml 文件中使用了超级用户 elastic ，如果这个动作伴随着 Elastic Stack 的版本升级需要经常发生，此处需要配置一个 Beats setup 用的专用角色和账户，从而避免多次使用超级用户。\n下面运行 setup 命令：\nfilebeat setup metricbeat setup 这两个命令正常运行后，在 Kibana 里会增加增加相关的索引、pipeline、可视化和仪表板等对象。\n使用下面的命令测试 filebeat 和 metricbeat 是否能正常的采集数据并传输到后台。\nfilebeat -e metricbeat -e 如果报错的话，将 level 在配置文件中设置为 debug，方便调试。调试成功之后，应该在 Kibana 的界面中，可以看到 node1 节点，点击后能看到实时更新过来的日志和监控指标。\n在新的节点上部署 Beats 在新的需要部署 Beats 的节点上，可以使用下面的脚本配置和部署。\nadd-agent.sh\n#!/bin/bash # author: Martin Liu # url:martinliu.cn elastic_version='7.8.0' b_user='beats-writer' b_pwd='DevOps1234' echo \u0026quot;############## Installing a Beats \u0026quot;$elastic_version\u0026quot; agent...\u0026quot; sudo rpm -ivh /vagrant/rpm/filebeat-$elastic_version-x86_64.rpm sudo systemctl enable filebeat.service sudo filebeat modules enable system sudo rpm -ivh /vagrant/rpm/metricbeat-$elastic_version-x86_64.rpm sudo systemctl enable metricbeat.service echo \u0026quot;################### Setup Public CA...\u0026quot; sudo update-ca-trust enable sudo cp /vagrant/certs/ca/ca.crt /etc/pki/ca-trust/source/anchors/ sudo update-ca-trust extract echo \u0026quot;################### Update Beats configuration files ...\u0026quot; sudo cp -f /vagrant/filebeat-v1.yml /etc/filebeat/filebeat.yml sudo cp -f /vagrant/metricbeat-v1.yml /etc/metricbeat/metricbeat.yml echo \u0026quot;################### Setup Keystor for Beats ...\u0026quot; echo $b_user | sudo filebeat keystore add BEATS_WRITER_USERNAME --stdin --force echo $b_pwd | sudo filebeat keystore add BEATS_WRITER_PW --stdin --force echo $b_user | sudo metricbeat keystore add BEATS_WRITER_USERNAME --stdin --force echo $b_pwd | sudo metricbeat keystore add BEATS_WRITER_PW --stdin --force echo \u0026quot;################### Start Beats services ...\u0026quot; sudo systemctl start metricbeat.service sudo systemctl start filebeat.service 简单说明以上脚本的功能：\n 用 rpm 安装包安装所需要的 Beats，filebeat 开启 system 模块。 在目标操作系统里部署必须的 ca 证书到默认路径中，并启用。从而省略在所有 beats 文件中生命公钥文件的路径。 覆盖更新默认的 Beats 配置文件。 创建并初始化 Beats 配置文件中所需要的 beats-writer 用户名和密码。从而消除消除所有明文密码。以上脚本只需要在节点上更新的时候才允许，允许后删除，从而不会留下任何明文密码和账户信息。Beats 的任何模块配置中，如果需要配置任何密码账户也需要如法炮制，从而保证基本的安全性。 启动 Beats 服务  以上脚本所使用的配置文件文件如下。\nfilebeat-v1.yml\nfilebeat.inputs: - type: log enabled: false paths: - /var/log/*.log #============================= Filebeat modules =============================== filebeat.config.modules: path: ${path.config}/modules.d/*.yml reload.enabled: true reload.period: 60s #-------------------------- Elasticsearch output ------------------------------ output.elasticsearch: hosts: [\u0026quot;es1.zenlab.local:9200\u0026quot;,\u0026quot;es2.zenlab.local:9200\u0026quot;,\u0026quot;es3.zenlab.local:9200\u0026quot;] password: ${BEATS_WRITER_PW} username: ${BEATS_WRITER_USERNAME} protocol: https #================================ Processors ===================================== processors: - add_host_metadata: netinfo.enabled: true cache.ttl: 5m geo: name: bj-dc-01 location: 35.5528, 116.2360 continent_name: Asia country_iso_code: CN region_name: Beijing region_iso_code: CN-BJ city_name: Beijing - add_cloud_metadata: ~ - add_docker_metadata: ~ - add_kubernetes_metadata: ~ - add_fields: target: '' fields: service.name: 'Elastic Cloud' service.id: 'ec-ww' #==================== Best Practice Configuration ========================== setup.ilm.check_exists: false logging.level: error queue.spool: ~ metricbeat.yml\n# =========================== Modules configuration ============================ metricbeat.config.modules: path: ${path.config}/modules.d/*.yml reload.enabled: true reload.period: 120s #-------------------------- Elasticsearch output ------------------------------ output.elasticsearch: hosts: [\u0026quot;es1.zenlab.local:9200\u0026quot;,\u0026quot;es2.zenlab.local:9200\u0026quot;,\u0026quot;es3.zenlab.local:9200\u0026quot;] password: ${BEATS_WRITER_PW} username: ${BEATS_WRITER_USERNAME} protocol: https #================================ Processors ===================================== processors: - add_host_metadata: netinfo.enabled: true cache.ttl: 5m geo: name: bj-dc-01 location: 35.5528, 116.2360 continent_name: Asia country_iso_code: CN region_name: Beijing region_iso_code: CN-BJ city_name: Beijing - add_cloud_metadata: ~ - add_docker_metadata: ~ - add_kubernetes_metadata: ~ - add_fields: target: '' fields: service.name: 'Elastic Cloud' service.id: 'ec-ww' #==================== Best Practice Configuration ========================== setup.ilm.check_exists: false logging.level: error queue.spool: ~ 解释一下相关的重要配置。\n netinfo.enabled: true 收集所有网卡的配置信息，覆盖多块网卡的情况 geo: 地理位置信息对以后基于位置的查询打下基础，这对于监控和信息安全都非常重要。为以后基于 host 的上下文关联打下基础，方便在 apm、log、metric、heartbeat 和机器学习的界面中相互跳转。 add_fields: 在 fields 下面维护 ECS 数据定义中的必要的有意义的数据，在网上查询 ECS 的数据定义，这些字段可以优化以后的搜索逻辑。 最后一段是其它必要的最佳实践设置 output.elasticsearch : 这里使用了三个 ES 节点的链接地址，这里应该使用至少 2 个 Elasticsearch 集群中的 ingest 节点。  总结 本文没有展开说明和配置的地方包括：对 Best 节点的工作状态的监控；对索引生命周期规则的调优（用尽磁盘），冷热数据的自动化迁移规则。\n完成的配置包括：\n 配置 ES 3 节点集群内部的 TLS 加密传输，对外的 HTTPS 加密协议服务 Kibana 基于证书的 SSL 加密配置 Beats 的高可靠性后台传输数据，TLS加密传输数据 用基于角色的访问控制，创建了只写权限的 beats-writer 角色和用户。 用 beats 的 keystore 将配置文件中的明文密码消除。  ",
    "ref": "/blog/build-security-in-elastic-stack/"
  },{
    "title": "徘徊在 3 种 DevOps 平台服务之间难以抉择（上）",
    "date": "",
    "description": "GitLab, Jira Cloud 和 CODING 的使用对比（上部）",
    "body": "中国 DevOps 社区在最近两年期间得到了长足的发展，从最初的单一官网站点，发展到现在的社区官网、社区峰会官网、社区论坛、社区微信公众号和社区服务号等多种对外公众界面。在这些网站平台之后的是 20 多位社区志愿者们的辛勤工作和贡献。\n社区官网最初是在 GitHub 上通过 Github-page 的免费空间发布的，在购买了收费的 Hugo 模板之后；网站的代码有了转为私有仓库的需求，因此CODING就从 GitHub 迁移到了 GitLab；当时 Github 还没有免费不限数量的私有仓库，而且 Github 也不能免费实现 20+ 社区代码贡献者的组队维护多个项目。GitLab 总的来说能满足目前的所有社区开发和协作需求：这些需求包括无限私有仓库，足够数量的代码协作人员，免费的 CI 构建和发布功能。GitLab 平台也可以实现 GitLab-page 的静态网站托管服务，但是，如果代码仓库设置为通过 page 实现静态网站发布的情况，需要整个代码库设置为对外公开访问，而这与代码库本身依然需要保持私密矛盾。因此社区的小伙伴也无奈的在 GitLab 上维护代码，然后将 hugo 构建后的结果再发布到 Github-page 的项目去。\n根据以上社区网站代码库迁移的经历，下面总结一下中国 DevOps 社区在网站开发维护和配套 CI/CD 方面的总体需求：\n 实现多人（20+志愿者）私有和共有代码仓库的协作，相关工作包括社区网站内容维护和新功能开发，社区书籍和技术白皮书协作翻译等。 实现 OKR 风格的社区网站开发相关工作管理，季度目标制定，任务跟踪等。 实现 Scrum 风格的软件项目计划、分配和跟踪；统一规划开发和运维相关的所有任务；与季度 OKR 相关联。 实现自动化的 CI、CD 流水线。 自动化和快速的部署软件项目工件（Artifacts）到腾讯云服务器（和其它相关服务），包括静态网页到 Nginx 服务器的发布，到云存储的发布，目前也可能即将会用到 K8s 服务/Serverless 服务的发布。  基于目前社区的相关工作需求，我们在三个平台之间进行了综合的对比和评测：GitLab（免费版）、Jira Cloud（免费版） 和 CODING - 高级版（腾讯云 DevOps 平台服务）。总的来说我们需要一种能满足以上所有需求的、集成化的 DevOps 工具 SaaS 平台服务。\n在开始 DevOps 平台选项之前，值得再次研究一下上面这幅图。重申一下，这幅图表达了两个意思：\n DevOps 是持续不断的循环，并不是单向的多少次重复的流程。理想情况下一次循环对应着敏捷开发的一个迭代，每个迭代 done 的定义并不是编码完成就结束了，还包括后面的测试和运维的所有工作，应该管理到从开发到上线过程中的所有工作。本次迭代的结果可以作为下一个迭代的输入之一。 DevOps 工具平台需要支持的每一次循环中包括的阶段有：计划、构建、持续集成、部署、运维、持续反馈（监控）；如果某个阶段无法直接实现，用其他独立工具实现也不是不可以，例如持续监控阶段（但是监控的状态必须实时透明的反馈给DevOps循环中的所有人）。  下面我们分阶段的描述以上三个 DevOps 工具平台的实际结果，每个阶段中会提出不同的功能需求点，然后横向比对三个工具的优缺点。声明这里是基于中国 DevOps 社区的实际需求做出的工具平台的需求使用体验调研，这些调研结果决定了最后平台选择的决定。\n计划 - Plan OKR 管理 ： \u0026ndash; 传统的社区项目规划往往是技术导向，或者比较就事论事的安排某些开发和维护工作。而中国 DevOps 社区更希望能应用高于项目本身一个层级的 OKR 概念来统筹所有项目的工作。需要用一个顶级目标对应多个KR，每个 KR 能关联到不同项目中的各种工作，也需要能跟踪孤立的 KR。\n GitLab ：在 Gitlab 官方文档和网上并没有查到的 OKR 的实现方式。 Jira Cloud：默认云服务没有 OKR 的功能，不过可以通过两种方式实现：安装第三方 App，使用 Structure 功能扩展实现。实际测试了一个名为 OKR for Jira （by Digital Toucan）的 App；能满足需求。在 OKR 关联界面中可以关联项目 issue，在 issue 的界面里也可以关联 KR；实现双向关联和跟踪。 CODING：在团队管理页面的‘团队目标’功能里有内置的 OKR 管理功能。功能性完全满足社区需求。可以在一个平面的可折叠页面中管理大量的 OKR 条目。O 的完成进度可以根据 KR 的进展自动计算，KR 的完成度可以手工拖到，也可以根据所连接的项目状态自动计算，所有条目的排序可以自由拖动。操作简洁方便。在项目工作的界面里不能关联到 OKR。  下图是 OKR for Jira 免费 app 的截图： 下面是 CODING 中管理 OKR 的界面截图。 项目规划/协同 ： \u0026ndash; 社区网站相关工作需要在每一个项目的执行过程中实现需求分析、工作分解、工作分配和进度追踪等功能。并不需要实现高级的企业产品路线图和Eprics的管理，由于并不开发复杂的商业产品，至少目前工作的复杂度没有这个需求。\n GitLab：项目管理功能齐全，而且包含可定制的看板功能（Scum board / Kanban board），里程碑和 Todos 也是比较特色的功能。具备Issue 状态和代码PR 自动化的关联。 Jira Cloud：默认项目管理丰富，Issue 的默认查看视图有多种方式支持各种看板。Issue 的查看、编辑和相关操作非常符合开发者视角的思路，可以从 Issue 上一键式的创建分支，并且看到分支代码提交、构建和部署的各种状态。 CODING：支持项目中的 Backlog 规划，管理迭代、Epric、需求、任务和缺陷。它可以很方便的定制每一种工作的状态和工作流，特别符合国人默认流程定制的需求。支持项目中的模块管理。操作比较简洁直观可用。一个项目中可以容纳和管理多个代码库。  下面是 CODING 中管理项目协同中的任务管理，虽然没有看板展示的模式，不过用拖拽的方式可以方便的对 Backlog 中的工作条目做迭代规划，点击每个工作条目都可以对其进行编辑修改。\n构建 - Build 代码托管 ： 社区需要使用 Git 代码仓库管理各种网站和应用的代码开发，包括markdown 格式的网站内容更新，主要是用基于主干的开发，或者部分功能分支的方式。\n GitLab：功能强大和丰富的代码仓库管理，支持丰富的合并请求（MR）策略。 Jira Cloud：通过 bitbucket 实现代码仓库管理。从源码到提交、分支、PR 等等都可以关联和跳转。 CODING：虽然不是老牌的 Git 仓库工具，它可以支持 git 和 SVN 仓库。能满足代码的提交、分支、合并请求、版本、对比等功能。功能完全满足需求。  云端开发工具 ： 如果开发者在不能访问自己的工作电脑的情况下，还是需要可以访问到一个功能齐全的线上代码编辑环境。确保社区参与者能够容易的参与相关开发工作。\n GitLab：代码库中的每个文件都可以通过 Web IDE 功能打开，能实现代码的语法检查、提交变化提示、Markdonwn 编辑/预览等功能。具备一定的可用性。 Jira Cloud：在 bitbucket 中选取文件点击编辑后，能进入一个基本的文本文件编辑模式。无其他高级功能，很难胜任稍微复杂一些的程序代码变更。 CODING：代码库中的代码文件可以支持在线的编辑，具有一定的语法加亮和变更对比功能，能提供基础的线上开发能力。同时还提供了全功能的线上 IDE 环境 https://cloudstudio.net/，这个功能很类似于一个线上版本的 vs code，它可以拉取 git 仓库地址，并在与之的多种语言环境中开展代码开发工作。  代码检查 ： 在尽可能的提供代码质量扫码、评估和反馈会对每个社区开发者的工作质量提供帮助，需要帮助社区小伙伴们开发出高质量和安全的社区网站代码。\n GitLab：可以集成第三方的代码扫码服务，在 CI 的过程中调用第三方服务实现。 Jira Cloud：同上。 CODING：内置了一套简洁的代码扫描功能，可以针对不同的开发语言定制各种代码扫描方案，实现代码检查、质量评估、路径过滤等功能。扫描结果可以生成在总体概览视图报表和任务管理清单。  下图是一个代码扫描方案编辑示例。 私有制品库/镜像仓库 ： 随着后期复杂社区项目的开发，以及容器化和微服务化的趋势。需要使用轻量的解决方案予以满足。\n GitLab：为每个项目提供包管理（支持通用、Conan、Maven，NPM、NuGet、PyPi）和 Docker 镜像仓库。满足在一个内的制品管理。 Jira Cloud：需要集成第三方的服务实现。 CODING：为每个项目提供了各种类型的制品仓库，包括：Generic、Docker, Maven, NPM, PyPi, Helm, Composer, NuGet, Conan。可以设置项目内、团队内和公开的访问范围权限。  编译构建 ： 需要提供自动化的编译构建能力，通过自动化的 CI 流水线给开发者快速的反馈，提供友好的 DevOps 流水线构建和修订界面。平台提供免费的构建算力，能够按需要自行接入构建节点和 K8S 环境。\n GitLab：提供基于 gitlab-ci.yml 文件的 Pipeline as Code 的流水线管理模式。无流水线的图形编辑界面。可以通过部署 Runner 的方式扩展构建环境到外部的服务器上，或者 k8s 的环境中。 Jira Cloud：在 Bitbucket 中提供基于 bitbucket-pipelines.yml 文件的 Pipeline as Code 的流水线管理模式。无流水线的图形编辑界面。这个流水线的后台应该是一个共享的基于 Bamboo 的SaaS 服务，还没有发现扩展这个部署环境的方法。 CODING：提供基于 Jenkins 的 CI 服务。也就是说 CODING 服务用套娃的方式包装了 Jenkins 服务，通过共享的构建服务提供基础的构建算力，如果需要的话也可以和 GitLab 一样扩展到外部的构建服务器或者 K8s 服务集群。这里 CODING 还提供了 构建服务到腾讯云的相关服务的集成。因此它能提供 Jenkins+ 的服务能力，对于 Jenkins 服务的构建能力这里就不在赘述。由于 Jenkins 流水线技术比较普及。社区的同学用了半天的时间实现了社区官网构建发布流水线的调试。将基于 Hugo 的网站构建结果用 ssh 命令的方式发布到腾讯云里的 Nginx 服务器的目录中。  下图是在图形流水线编辑器中对标准模板的调试，这里简单的实现了构建和打包的过程，在部署的步骤里，通过远程 ssh 的命令实现了对网站发布包到腾讯云虚拟机的部署。 总结 以上是中国 DevOps 社区对 DevOps 工具平台服务的选型测试过程的一部分总结，这里仅仅从社区的实际工作需求出发，通过试用对比的方式探索了几种平台。总的来说腾讯的 CODING 平台使用体验要好于其它两个服务。具体说有以下几个方面：\n CODING 的页面访问速度非常快，由于是相对比较年轻的产品，目前它比起 Jira 和 GitLab 还处于婴儿期；因此这种够用就好的阶段也降低了对复杂高级产品的认知难度。通过 git 命令下载和提交代码的速度非常快。 OKR 的管理功能具备够用的可用性。 流水线功能同支持图形的流水线编辑和自控制的 Jenkins 文件。如果已经具备了一定的 Jenkins 能力，你就能快速上手开始构建和部署项目了。这个界面整合良好的套娃服务其实还具备了一定的可迁移性。 与腾讯云服务的良好互访问性。如果已经使用了腾讯云的服务，那么 CODING 的部署流水线将对其非常友好，易于衔接已有资源。  后续还将按需测试和对比 DevOps 循环中的其它阶段。如果你也感兴趣参与中国 DevOps 社区的相关志愿者开发工作，请随时和我联系。也希望对此感兴趣的小伙伴能报名参与我们的这种主题评测活动。\n",
    "ref": "/blog/a-comparison-of-devops-tools-p1/"
  },{
    "title": "入门 Elastic Workplace Search",
    "date": "",
    "description": "领导再也不用担心，我找不到工作需要的文档了",
    "body": "简介 Elastic Workplace Search 提供了一个统一的搜索体验，从而便于任何人在任何时间找到所需的文档信息。为企业搭建了一个横跨所有工作内容、所有团队和真相的统一搜索参考平台。\n这个搜索平台能够对接各种数据源，并且实现文档内容级别的索引，目前所支持的数据源包括：OneDrive、SharePoint、ServiceNow、Box、Dropbox、Github、Github Enterprise、Google Drive、JIRA、Confluence、Salesforce、Zendesk 等。\n它具有以下特点：\n 配置部署简单，缩短了系统上线和等待时间。不像是传统的消耗数个月甚至一年都无法完成的搜索项目，这个解决方案可以让企业在几天或几周内就能投入使用。 个性化定制的搜索体验。通过 Elasticsearch 所提供的搜索能力，管理员可以控制企业、团队级别的数据源，个体用户可以控制自己的私有数据源，所有级别上都可以调整相关度权重，从而提高搜索结果的准确性和实用性 提供各种自然语言的和关键字的搜索。系统提供了强大的语言分析和关键字检测能力，用户可以使用任意关键字和搜索开关轻松的搜索到所需的信息。 具备丰富的开箱即用功能：无须开发即可实现用户管理、数据源管理、基于用户和组的数据源可见性设置、数据源对不同用户和组的权重等功能。  系统安装配置 本文的假设，文中所使用的安装包和需要部署的配置文件都在 /vagrant 这个目录下面。下面的所有命令中都假设从这个目录里选用和复制。配置文件见代码库：https://github.com/martinliu/elastic-labs\n本文所使用的安装测试环境是：\n CentOS Server 8 JDK 11 Elasticsearch 7.6.1 Kibana 7.6.1 Elastic Workplace Search 7.6.1  下面使用 vagrant up 一键式拉起基础测试环境的说明，请参考之前的文章。本测试所使用的基础 ES 安装脚本如下。\necho I am provisioning a Elasticsearch Server... date \u0026gt; /etc/vagrant_provisioned_at sudo swapoff -a sudo sysctl -w vm.max_map_count=262144 sysctl -p sudo sh -c \u0026quot;echo 'elasticsearch - nofile 65535' \u0026gt;\u0026gt; /etc/security/limits.conf\u0026quot; sudo sh -c \u0026quot;echo '**** -- -- -- -- -- -- -- -- ****' \u0026gt; /etc/motd\u0026quot; sudo sh -c \u0026quot;echo '**** Welcome to Elastic Stack Labs' \u0026gt;\u0026gt; /etc/motd\u0026quot; sudo sh -c \u0026quot;echo '**** -- -- -- -- -- -- -- -- ****' \u0026gt;\u0026gt; /etc/motd\u0026quot; sudo sh -c \u0026quot;echo '*' \u0026gt;\u0026gt; /etc/motd\u0026quot; sudo rpm -ivh /vagrant/rpm/elasticsearch-7.6.1-x86_64.rpm sudo /usr/share/elasticsearch/bin/elasticsearch-certutil cert -out /etc/elasticsearch/elastic-certificates.p12 -pass \u0026quot;\u0026quot; sudo chmod 660 /etc/elasticsearch/elastic-certificates.p12 sudo cp /vagrant/elasticsearch/elasticsearch.yml /etc/elasticsearch/elasticsearch.yml sudo systemctl daemon-reload sudo systemctl start elasticsearch.service sudo systemctl status elasticsearch sudo /usr/share/elasticsearch/bin/elasticsearch-setup-passwords auto -b echo Provisioning script works good! echo Please go to http://192.168.50.10:9200/ using above passwords 这段脚本配合 vagrant 的 provision 功能使用，它本来就是一段 shell 脚本，可以可以独立执行，它的输出结果如下。\n使用 vagrant up 命令拉起了测试虚拟机之后，在屏幕的输出信息中复制出 elastic 用户的密码。\n master1: Changed password for user apm_system master1: PASSWORD apm_system = XAZnaek3wm0GxN3OHwhP master1: Changed password for user kibana master1: PASSWORD kibana = sUg8OaYqh4f55GzoYApk master1: Changed password for user logstash_system master1: PASSWORD logstash_system = RLthIQOH3aOFLVKqaTMu master1: Changed password for user beats_system master1: PASSWORD beats_system = 73yH90G3hvrzYgVDnG3y master1: Changed password for user remote_monitoring_user master1: PASSWORD remote_monitoring_user = Sk9J77H9QFPsOZtVQJld master1: Changed password for user elastic master1: PASSWORD elastic = OeR3gADZ1Fw1cgc90pwE 本示例使用了 elasticsearc-native 的用户认证模式。 为了方便起见，安装了 Kibana 7.6.1 ，过程此处忽略；在 Kibana 的用户管理中创建如下用户：\n sales1 、 sales2 dev1 、 dev2  示例如下图所示。\n这些是测试用户，用于 Elastic Workplace Search 的测试中。\n安装 Elastic Enterprise Search Elastic Enterprise Search 需要 JDK 8 或者 JDK 11， 本实例安装了 Oracle JDK 11。\nsudo rpm -ivh /vagrant/rpm/jdk-11.0.6_linux-x64_bin.rpm\n复制 Enterprise Search 的安装包到 /opt 目录下，解压缩这个安装包。\nsudo cp /vagrant/rpm/enterprise-search-7.6.0.tar.gz.tar /opt sudo cd /opt sudo tar zxvf /opt/enterprise-search-7.6.0.tar.gz.tar 在 Enterprise Search 的配置文件中加入 elastic 用户的密码等配置信息。并且将配置文件部署到测试服务器中。本实例的配置文件 enterprise-search.yml 内容如下。\nelasticsearch.username: elastic elasticsearch.password: eZhp0h2ZTPKchlxxwwex elasticsearch.host: http://192.168.50.10:9200 allow_es_settings_modification: true ent_search.auth.source: elasticsearch-native ent_search.external_url: http://192.168.50.10:3002 ent_search.listen_host: 0.0.0.0 ent_search.listen_port: 3002 将以上目标配置文件复制到 Elastic Workplace Search 的配置文件目录中，覆盖默认配置文件。\nsudo cp /vagrant/enterprise-search/enterprise-search.yml /opt/enterprise-search-7.6.0/config/enterprise-search.yml 启动 Enterprise Search 服务器，并且设置默认的管理员密码。\nsudo ENT_SEARCH_DEFAULT_PASSWORD=martin1demo /opt/enterprise-search-7.6.0/bin/enterprise-search 在启动的过程中，关注一下的屏幕输出信息，则表示一切正常。\n*** Default user credentials have been setup. These are only printed once, so please ensure they are recorded. *** username: enterprise_search password: martin1demo No secret management encryption keys were provided. Your secrets will be stored unencrypted. You can use the following generated encryption key in your config file to store new encrypted secrets: secret_management.encryption_keys: [911f804cd11f7bc2dd338743ea1752b0b7cd2589cc80060159ed94a918bc09d3] 等待服务器启动正常后，参考相关文档。完成 Github、Jira 和 Confluence 等数据源的配置。\n配置数据源 见介绍文档 https://www.elastic.co/guide/en/workplace-search/current/workplace-search-content-sources.html\n Confluence Cloud Confluence Server Dropbox GitHub Google Drive Jira Cloud Jira Server OneDrive Salesforce ServiceNow SharePoint Online Zendesk  除了默认支持以上数据源外，还可以使用 Custom API 实现自己的数据源接入。数据源的类型分：\n 组织级：可以分配给个人和用户组 私有级：用户个体接入某个数据源，而仅供自己使用  GitHub 数据源对接 首先你需要属于 GitHub 的一个组织，或者多个组织，然后在某个组织，或者几个组织做为一个数据源，对接到 Elastic Workplace Search 中。具体的配置步骤如下.\n在 GitHub 中找到需要搜索的组织，每个 repo 的 issue 和 pr 都是全文搜索的目标。 在 GitHub 的账户中创建一个 OAuth App，图中 1、2、3、4 信息点需要和你的测试环境匹配。复制出 client ID 和 Client Secret 备用。\n在 Elastic Workplace Search 的数据源配置页面创建 GitHub 数据源。填入上一步的两个 ID。 保存以上配置后，在这一步点击 Connect GitHub。 在这一步选择需要搜索的组织，勾选后，点击完成连接配置。 正常连接成功后，就可以看到这个组织里所有 repo 中的 issue 和 pr 了。 Atlassion 数据源对接 支持对 Confluence 和 Jira 两款产品的云服务和本地部署的搜索。配置的过程非常简单， 如果你有多套独立的 Confluence 和 Jira 环境，那么就可以给每个需要搜索的环境配置一个数据源，并且按照需要将对它们的统一搜索配置到一个统一的搜索平台之内。\n配置文档见： https://www.elastic.co/guide/en/workplace-search/current/workplace-search-confluence-cloud-connector.html 和其它。下面是一个配置成功的 Jira 云服务的结果。\n如果所示，每套 Atlassion 环境的产品都可以仅仅通过配置接入这个搜索平台。Jira 中索引的内容类型如下：\n Task 子任务 长篇故事 Project Other  配置完成以后，默认的同步周期是 2 小时做一次增量索引。下图是用户对 Jira 和 Confluence 的两个本地部署服务器联合统一搜索的效果。管理员可设置任何一个人和用户组能搜索那些数据源，每个数据源在搜索结果中的权重排位。从而实现对任何一个用户组定制化搜索结果的作用。\n用户配置示例 本文的目标是给两个用户组的人分配不同的数据源权重，从而得到各异的搜索结果排名。下面是一些建议的思路和配置过程。\n这里把仅有的两个数据源设置成了组织级别的可搜索，也就是他可以进入任何一个合法用户的搜索清单中。加入是特定团队所使用的数据源，在这里需要关闭搜索开关。 本文使用的 Elasticsearc 原生用户的认证，示例中将用户名为 sales* 开头的的用户名分配到 Elastic Workplace Search 的 “销售\u0026amp;市场” 组中。 示例中将用户名为 dev* 开头的的用户名分配到 Elastic Workplace Search 的 “产品开发和运维” 组中。这里只是示例，你可以用任何已知用户与搜索用户组的对应，从而满足你的使用场景。 在组织级别的组属性设置中，先设置默认用户的数据源权重，这里使用默认的 1，也就是不区分两个数据源的权重，使用相同权重。 下面是对 “销售\u0026amp;市场” 组的数据源权重设置，这里假设这个组的人员可能更会搜索 Jira 中的关于项目开发、问题解决进展这类的信息，不会太关注工程师实际解决的代码相关的问题。因此将 Jira 中的权重从 1 增加到 5 ，从而在相同关键字中，提升 Jira 中搜索结果的整体排名。 同理为 “产品开发\u0026amp;运维” 团队设置 GitHub 的高权重。 最后在这个安全的选项设置中，开启了搜索用户可以自主添加数据源的情况，也就是说这部分是个性化的数据源，可能是自己所使用的网盘，或者个人的 GitHub 组织等等，都可以！用户可以将对自己有帮助的，需要搜索的数据源都自助式的添加上，从而提高自己的工作效率。 搜索效果确认 下面是用户 sales1 搜索 ealsticsearch 关键字的结果示意图。\n在上图中，搜索用户可以点击右侧的数据源图标，点选其中的一个数据源作为搜索范围，可以点击 All Time 时间设置条件，筛选出目标时段的文档等。还可以在搜索框中使用类似 ppt 等文件类型搜索条件。 搜索结果是故意设置的，这是 Jira 中的一个 pdf 附件，pdf 的原文也可以搜索，而且对于 销售\u0026amp;市场 用户组来说， Jira 的权重大于 GitHub 很多，因此即使 Github 中有四个匹配的结果，也就将其排了在了最下面。\n下图是 dev1 用户（属于产品开发\u0026amp;运维组）的登录后界面。这里显示了建议的搜索快捷短语 pull requests form last week ，页面上的搜索结果是按照数据源中最更新的文档靠前的规则排列的。 下面这个用户搜索可关键词 app search，从这个结果中可以看出，即使是在 GitHub 中的一半匹配（并无完整的 app search 这个词组出现在任何文档里）搜索结果的排名都比 Jira 中的完全命中的排名高。 测试总结 到目前为止，本文展示了一部分 Elastic Workplace Search 的基础功能。以及一些假象的搜索和配置场景，相信对此感兴趣的读者参考本文，也可以在 1 天之内完全实现以上所有的测试场景，从而为正确评估这个产品打下一个基础。\n如果，想进一步集成自己的资料库的话，可以参考自定义 API 的相关文档，开发自定义的数据源。这就是一个功能齐全的搜索平台，它可以非常方便的集成任何公司的环境中，并且实现集中统一搜索平台的效果。\nDevOps核心能力建设 如果你也是 DevOps 的实践者，如果你看过我之前写的关于 DevOps 状态调查报告和能力成长模型的相关文章，你可能对下图也有印象。\n这是 DORA 出的最新版本的 DevOps 能力成长模型，在 2019 年的DevOps 能力调查中，增加了对生产力工具的调查，该模型中所关注的三种生产力能力工具包括：\n 各种有用易用的工具 互联网搜索 内网搜索  在这个部分有两项生产力影响因素能力是关于搜索的。在我国的很多工作环境中，特别是开发相关的工作，无 Internet 环境的纯内网是很普遍的。而内网上的 Atlassian 相关产品，微软相关产品又是最多用的；不同业务部门或者团队拥有自建的 Jira 或者 Confulence 服务器；在团队协作的时候，或者在执行跨部门的项目的时候，项目资料的统一搜索就成了问题。类似的需求和现象不胜枚举，希望本文介绍的 Elastic Workplace Search 统一搜索平台可以成为你的帮手，为你填补 DevOps 能力成长模型中关于 内网搜索 的这一项空白。当然，这个平台所支持的外网 SaaS 服务也是很多的，可以综合使用。\n",
    "ref": "/blog/getting-start-elastic-workplace-search/"
  },{
    "title": "随心所欲的为应用无痛添加搜索功能",
    "date": "",
    "description": "",
    "body": "开发搜索功能从此再也不用犯愁了，有了 App Search ，为应用增加搜索功能一下子变得简单了很多。本文描述了如何轻松上手这套搜索平台的所有步骤。\n什么是 App Search? 这是一套强大的 API 和开发者工具集，以构建功能强大的面向用户的搜索应用为目标。相关详细介绍见 https://www.elastic.co/cn/app-search\n丰富的开箱即用功能:\n 为相关性搜索应用场景而优化 拼写错误容忍 相关度调整 支持第三方 API 客户端，且具备强大的 API 独立的 API 日志和搜索分析 自动化扩展\u0026amp;运维支持 Search UI library  环境准备 测试环境现需要一台 Elasticsearch 服务器，或者和下面等同的环境。\n本文的环境描述如下：\n macOS 10.15.4 vagrant 2.2.7 virtualbox 6.0.15 虚拟机模板 bento/centos-8 elasticsearch 7.6.1 app-search 7.6.1 jdk-11.06  本文的测试环境基于 Vagrant + VirtualBox 的组合环境搭建而成，基础安装工作可以一键完成。\n主要脚本 Vagrantfile、pre-install-ES.sh 请参考此代码库：\nhttps://github.com/martinliu/elastic-labs/tree/master/app-search\n开启并登陆这套安装环境的命令如下。\nvagrant up vagrant ssh 在以上命令的启动信息里找到如下的 elastic 用户密码部分备用。\nmaster1: Changed password for user elastic master1: PASSWORD elastic = eczHJ7NPrsO1B1BRA8SS 安装 App Search 浏览 App Search 的安装文档： https://swiftype.com/documentation/app-search/self-managed/installation\n安装 App Search 所需的 JDK 8 或者 11 ，本文安装的是 Oracle 的 JDK 11。本文假设所有的安装文件和已经编辑好的配置文件都放在了 /vagrant 目录下。\nsudo rpm -ivh /vagrant/rpm/jdk-11.0.6_linux-x64_bin.rpm\n安装 App Search 服务器。\nsudo rpm -ivh /vagrant/rpm/app-search-7.6.1.rpm \n浏览 App Search 服务器默认的配置文件，了解有哪些可用选项。\nsudo more /usr/share/app-search/config/app-search.yml \n将 Elasticsearch 服务器安装时产生的随机密码更新到 app-search.yml 文件中，并且定制它的内容如下：\nallow_es_settings_modification: true elasticsearch.host: http://192.168.50.10:9200 elasticsearch.username: elastic elasticsearch.password: eczHJ7NPrsO1B1BRA8SS app_search.external_url: http://192.168.50.10:3002 app_search.listen_host: 192.168.50.10 app_search.listen_port: 3002 log_directory: /var/log/app-search filebeat_log_directory: /var/log/app-search 将更新好的 app-search.yml 更新到它默认的路径中。\nsudo cp /vagrant/appsearch/app-search.yml /usr/share/app-search/config/app-search.yml\n启动 App Search 服务器。\nsudo /usr/share/app-search/bin/app-search\n在启动日志中，找到如下的默认用户名和密码。\n######################################################### *** Default user credentials have been setup. These are only printed once, so please ensure they are recorded. *** username: app_search password: vjqmjhv2s5rzixjc ######################################################### 在服务器初始化启动完毕之后，用上面的用户名和密码，在浏览器中登录 App Search 服务器 http://192.168.50.10:3002\n到此为止，App Search 服务器的安装就完成了。它其实是一个基于 Elasticsearch 的搜索服务平台。\n它的特点是帮助开发者随心所欲的为已有的或者正在开发的项目增加功能强大的搜索功能，而且将搜索功能的实施成本降低到无痛点的程度。App Search 可以覆盖的使用场景如下：\n SaaS / web 应用 复杂的电商应用 客户支持服务站点 Geo 地理搜索 公司官网 内部的搜索 还有更多其他  创建名为 games 的搜索引擎 在首页的创建引擎的输入框中输入 games， 语言选择默认选项，点击创建。浏览新创建的引擎，点击左下角的菜单 Credentials，复制 privite-key 备用。\n找到这个搜索引擎的 API 调用网址备用。 http://192.168.50.10:3002/api/as/v1/\n通过 API 索引数据文档 需要通过 App Search 提供的 API 索引一份具有 4000+ 条数据的 json 文件。数据文件见代码库中的 video-games.json 。本文使用 Ruby 编写了一个上传脚本，见 upload.rb ，该脚本使用了名为 elastic-app-search 的客户端库。你可以使用其他编程语音，实现待接入系统和 App Search 服务器的对接，并与之保持同步，保持待搜索数据的更新。\n# `gem install elastic-app-search progress_bar` require 'elastic-app-search' require 'json' require 'progress_bar' API_ENDPOINT = 'http://192.168.50.10:3002/api/as//v1/' API_KEY = 'private-jdhcmi1yhy8wjxo6upb4qki3' ENGINE_NAME = 'games' client = Elastic::AppSearch::Client.new(:api_key =\u0026gt; API_KEY, :api_endpoint =\u0026gt; API_ENDPOINT) file = File.read('./video-games.json') data = JSON.parse(file) bar = ProgressBar.new(data.count / 100) data.each_slice(100) do |slice| client.index_documents(ENGINE_NAME, slice) bar.increment! end 以上脚本中的 API_ENDPOINT 和 API_KEY 需要更新，与当前测试系统匹配。这个脚本的运行效果如下：\n➜ app-search git:(master) ✗ ruby upload.rb [##########################################################################] [40/40] [100.00%] [00:54] [00:00] [ 0.73/s] 索引之后，在搜引擎的 Documents 页面，浏览索引后的数据，用 Query Tester 进行一些搜索，了解这些数据的内容，注意观察当前搜索的结果和排序。\n修订 Schema 开发者可以按照需要随时修改 Schema，实际上这是一个 Schema 的平台。 Schema 的修改后，数据即可生效，在这个过程中前端用户的搜索体验不会受到任何影响。\n修改三个字段的定义，并增加 language 字段，点击右上角的 Update Type 按钮生效。\n按需进行搜索设置 创建同义词 为 Pokemon 创建同义词 Pikachu，如下图所示。\n调整搜索字段的权重 为 globa_sales 增加 Functional Boost 1。 为 Name 增加 weight 3 ，点击右上角的 Save 保存。在这个过程中观察右侧的搜结果的动态变化，还可以做其他字段的修改，知道搜素结果满意为止。\n创建 curations 故意将某条搜索结果置顶，这有可能因为，这款游戏目前是热评游戏，是畅销爆款，是高利率商品，是广告商品，或者其他业务原因。可以给某个关键字，置顶一条或者多条搜索结果。下面将 pokemon 的 pokemon-ranger-ds-2006 这款产品置顶。点击右上角的 Query Tester 测试一下效果。\n创建用户端搜索界面 Reference UI 是提供给用户使用的搜索界面，它可以是只有一个输入框，也可以是比较复杂的条件查询。如下所示。\n调整之后点击 Create Preview 按钮，进入搜素界面的确认页面，尝试使用所设定的搜索功能。满意后点击右上角的 Download ZIP Package 按钮下载这个界面的所有代码。\n在本地解压缩这份搜索代码，并进行调试。\n在命令行，进入这个目录，先执行 npm install 命令，然后执行npm start命令。\nCompiled successfully! You can now view app-search-reference-ui-react in the browser. Local: http://localhost:3000/ On Your Network: http://192.168.1.6:3000/ Note that the development build is not optimized. To create a production build, use npm run build. 在弹出的网页中，在本地测试这个搜索界面的可用性。最后运行 npm run build 命令，\n➜ games-react-demo-ui git:(master) ✗ npm run build \u0026gt; app-search-reference-ui-react@1.2.0 build /Users/martin/code/elastic-labs/app-search/games-react-demo-ui \u0026gt; npm-run-all build-css build-js \u0026gt; app-search-reference-ui-react@1.2.0 build-css /Users/martin/code/elastic-labs/app-search/games-react-demo-ui \u0026gt; node-sass-chokidar src/ -o src/ No input files were found. \u0026gt; app-search-reference-ui-react@1.2.0 build-js /Users/martin/code/elastic-labs/app-search/games-react-demo-ui \u0026gt; node ./scripts/build-no-chunks.js Creating an optimized production build... Browserslist: caniuse-lite is outdated. Please run next command `npm update` Browserslist: caniuse-lite is outdated. Please run next command `npm update` Compiled successfully. File sizes after gzip: 109.1 KB build/static/js/main.2f745bc0.js 3.64 KB build/static/css/main.e43852a4.css The project was built assuming it is hosted at the server root. You can control this with the homepage field in your package.json. For example, add this to build it for GitHub Pages: \u0026quot;homepage\u0026quot; : \u0026quot;http://myname.github.io/myapp\u0026quot;, The build folder is ready to be deployed. You may serve it with a static server: npm install -g serve serve -s build Find out more about deployment here: https://bit.ly/CRA-deploy 最后将构建结果部署到一个目标的先安装的 Nginx 服务器上。\nsudo yum install -y nginx sudo mv -f build/* /usr/share/nginx/html 在浏览器中访问 Nginx 服务器 http://192.168.50.10/index.html 观察最终的实现效果。 总结 使用 App Search 搜索平台，开发者可以快速的开发出一套定制化的搜索系统，轻松的实现后台搜索业务逻辑的调整，并轻松的将用户搜索界面测试后部署上线。\n",
    "ref": "/blog/getting-start-elastic-app-search/"
  },{
    "title": "使用 Elastic Stack 监控 Covid-19 疫情发展",
    "date": "",
    "description": "",
    "body": "代号为 COVID-19 的新型冠状病毒肺炎在全球肆虐着，剧情翻转的非常快，目前欧美已经成为了全球的重灾区。 本文介绍如何使用 Elastic Stack，实现对国内外疫情发展态势的分析。介绍一种简单易行的数据分析流程。说不定你也可以得出独到的高价值洞察。\n本文使用的 Elastic Stack 版本和环境如下：\n Vagrant 的基础镜像 bento/centos-8 Elasticsearch 7.6.1 Kibana 7.6.1 Logstash 7.6.1  关于使用 Vagrant 环境搭建 Elastic Stack 的方法，见我之前的文章。本文的数据分析处理流程图如下所示。\n分析和展示丁香园数据 本文的目标分析数据源是 https://ncov.dxy.cn/ncovh5/view/pneumonia 这个也是我们最近一直在关注的关于中国的疫情公布平台。\n丁香园网页的数据被香港大学的 Isaac Lin 同学，通过他所开发的网络爬虫抓取加工后，用 API 的形式和 csv 数据文件的形式提供了出来，他的爬虫程序和结果数据给很多目前分析疫情的人带来了很大的帮助，有不少人去他的 blog 和 github 上点赞和评论的。\n https://github.com/BlankerL/DXY-COVID-19-Data/tree/master/csv https://lab.isaaclin.cn/nCoV/  你可以用 Python 程序调用Lin 同学的 API 然后在将处理后的结果写入 ES，这样的脚本可以参考 Rockybean 的这个 https://www.yuque.com/elastictalk/blog/et25?from=timeline。也可以用下面的命令将Github 的 csv 文件下载到本地，在做手工的数据分析，这样也等于是对林同学的数据内容和定义进行一次深入的探索，这也将更有益于你理解数据，方面后面使用 Kibana 做数据分析。\n在本机使用 git 做数据下载和同步的命令如下。\ngit clone https://github.com/BlankerL/DXY-COVID-19-Data.git cd DXY-COVID-19-Data/ git pull 你也可以用用git pull命令在日后做数据更新，并进行后续的跟踪分析。\n同步到本地的数据也可以使用 Logstash 或者是 Filebeat 持续的同步到 ES 中，这样就可以在 Kibana 上看到每日的实时更新结果。\n导入数据并初始化索引 本文选择了最简单直接的方式，使用 Kibana 自带的数据导入功能，手工导入丁香园的 csv 时序数据文件 csv/DXYArea.csv。 如下图所示。\n这个工具是机器学习的周边工具 数据可视化器 ，它对这份数据做了初步的分析和识别，点击导入，然后在下面点击 Advancd ，进入高级设置，如下图所示：\n 可以在 index name 中可以输入dxy-area-m5 作为本次新建的索引名称。 然后删除默认的 Mapping 定义，输入下面的重新重定义的数据结构。  { \u0026quot;@timestamp\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;date\u0026quot; }, \u0026quot;continentEnglishName\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot; }, \u0026quot;continentName\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot; }, \u0026quot;countryEnglishName\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot; }, \u0026quot;countryName\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot; }, \u0026quot;provinceEnglishName\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot; }, \u0026quot;provinceName\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot; }, \u0026quot;province_confirmedCount\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;integer\u0026quot; }, \u0026quot;province_curedCount\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;integer\u0026quot; }, \u0026quot;province_deadCount\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;integer\u0026quot; }, \u0026quot;province_suspectedCount\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;integer\u0026quot; }, \u0026quot;province_zipCode\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;integer\u0026quot; }, \u0026quot;cityEnglishName\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot; }, \u0026quot;cityName\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot; }, \u0026quot;city_confirmedCount\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;integer\u0026quot; }, \u0026quot;city_curedCount\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;integer\u0026quot; }, \u0026quot;city_deadCount\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;integer\u0026quot; }, \u0026quot;city_suspectedCount\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;integer\u0026quot; }, \u0026quot;city_zipCode\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;integer\u0026quot; }, \u0026quot;level\u0026quot;:{ \u0026quot;type\u0026quot;: \u0026quot;keyword\u0026quot; }, \u0026quot;location\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;geo_point\u0026quot; }, \u0026quot;is_china\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;boolean\u0026quot; }, \u0026quot;updateTime\u0026quot;: { \u0026quot;type\u0026quot;: \u0026quot;date\u0026quot;, \u0026quot;format\u0026quot;: \u0026quot;yyyy-MM-dd HH:mm:ss\u0026quot; } } 对以上 Mapping 的简要说明：\n 增加了字段 level, is_china 和 Location，你也可以加入你所需要的其它待用字段，所有新增无值字段都需要后期进行初始化。 level 定义了数据记录的级别为：国家、港澳台和省级。 is_china 定义了国内外数据标识 在导入后，本文使用的字段的批量初始化/维护是调用 /_update_by_query 方法，也可以是使用 ingest pipline 的方式，或者其它 Elastic Stack 中的其它替代功能。  如上图所示的数据导入成功之后，点击 View index in Discovery， 我们可以使用 Kibana 的 Discovery 功能来对所导入的数据进行分析和确认，特别是一些关键字段的数值。观察这些数据的格式和内容的含义是什么。使用 filter 功能了解数据的内容和特征。建议使用下面的 filter 和组合探索一下【也可以使用 kql 语言做查询，如果用 kql 做查询的话，也可以很方便的将这些查询条件进行复用】。\n countryName:中国 NOT countryName:中国 countryName:中国 / provinceName:中国 countryName:中国 / NOT provinceName:中国 / cityName exists countryName:中国 / NOT provinceName:中国 / NOT cityName exists countryName:中国 / cityName: 境外输入  以上的 / 是多个 filter 叠加的含义，可以大概的猜测出下面的结论。\n 中国国内数据 国外数据 中国省级统计数据 中国各省的各个城市的统计数据 中国的港澳台数据 中国海关所监控到的境外输入数据  为了后面使用省的名称做地图分析，这里需要查看数据中各个省英文名称，以广西为例，设置查询条件：provinceEnglishName\tGuangxi\n现在来浏览 Elastic Map 地图服务所引用的中国各省的中英文名称和代码，查看 https://maps.elastic.co/#file/china_provinces ；\n可以发现现所导入的数据和 Elastic 地图服务的官方数据不一致。\n下图是用 Excel 分析对比的结果，建议使用 Python、logstash 或者其它工具在导入的过程中对这个字段做预处理和校准。\n本文下面描述了 Dev Tool 中运行相关的数据优化和及校准脚本。\n#维护is_china字段 POST dxy-area-m5/_update_by_query { \u0026quot;script\u0026quot;:{ \u0026quot;lang\u0026quot;: \u0026quot;painless\u0026quot;, \u0026quot;source\u0026quot;: \u0026quot;\u0026quot;\u0026quot; if (ctx._source.countryEnglishName == \u0026quot;China\u0026quot;) { ctx._source.is_china = true; } else { ctx._source.is_china = false; } \u0026quot;\u0026quot;\u0026quot; } } #维护 level 字段，对于中国的数据来说，如果省的名字是中国这就是国家级的统计数据 POST dxy-area-m5/_update_by_query { \u0026quot;script\u0026quot;:{ \u0026quot;lang\u0026quot;: \u0026quot;painless\u0026quot;, \u0026quot;source\u0026quot;: \u0026quot;\u0026quot;\u0026quot; if(ctx._source.provinceName == ctx._source.countryName){ ctx._source.level = \u0026quot;country\u0026quot; } else { if (ctx._source.cityName == null) { ctx._source.level = \u0026quot;cn-hmt\u0026quot; } else { ctx._source.level = \u0026quot;province\u0026quot; } } \u0026quot;\u0026quot;\u0026quot; } } #更新省的名字为国际代码 POST dxy-area-m5/_update_by_query { \u0026quot;script\u0026quot;:{ \u0026quot;lang\u0026quot;: \u0026quot;painless\u0026quot;, \u0026quot;source\u0026quot;: \u0026quot;\u0026quot;\u0026quot; if (ctx._source.provinceEnglishName == \u0026quot;Guangxi\u0026quot;) { ctx._source.provinceEnglishName = \u0026quot;Guangxi Zhuang Autonomous Region\u0026quot;; } if (ctx._source.provinceEnglishName == \u0026quot;Hong Kong\u0026quot;) { ctx._source.provinceEnglishName = \u0026quot;HongKong\u0026quot;; } if (ctx._source.provinceEnglishName == \u0026quot;Macao\u0026quot;) { ctx._source.provinceEnglishName = \u0026quot;Macau\u0026quot;; } if (ctx._source.provinceEnglishName == \u0026quot;Neimenggu\u0026quot;) { ctx._source.provinceEnglishName = \u0026quot;Inner Mongolia\u0026quot;; } if (ctx._source.provinceEnglishName == \u0026quot;Ningxia\u0026quot;) { ctx._source.provinceEnglishName = \u0026quot;Ningxia Hui Autonomous Region\u0026quot;; } if (ctx._source.provinceEnglishName == \u0026quot;Taiwan\u0026quot;) { ctx._source.provinceEnglishName = \u0026quot;Taiwan Province\u0026quot;; ctx._source.provinceName = \u0026quot;台湾省 (中华人民共和国)\u0026quot;; } if (ctx._source.provinceEnglishName == \u0026quot;Xizang\u0026quot;) { ctx._source.provinceEnglishName = \u0026quot;Tibet\u0026quot;; } if (ctx._source.cityName == \u0026quot;境外输入人员\u0026quot;) { ctx._source.cityName = \u0026quot;境外输入\u0026quot;; } \u0026quot;\u0026quot;\u0026quot; } } 注意：以上的三个 POST 方法调用的对象是 dxy-area-m5  ，这个索引的名字需要和你上面导入数据创建的索引一致。由于是手工初次处理这些数据，建议再次运行以上的一系列搜索过滤条件，确认这些目标字段和数据得到了正确的处理。\n可视化和展示数据 在分析数据就绪了以后，下面介绍一组通过 Kibana 进行数据可视化分析展示的思路和方法。\n💻 从 Discovery 界面中直接调用可视化视图创建 在 Discovery 的查询界面里，点击左侧 fields 清单中的 provinceName，或者其它想进行可视化分析的字段，点击后即可查看其中一部分的数值分布情况，点击下面的 Visualize 按钮。就可以进入可视化编辑模式。\n进入这个 field 的默认可视化配置模式，选择 Y 轴的指标为 province_confirmedCount 的最大值，然后在上方增加 is_china:true 和 level:province 过滤条件后，就可以得到下面的结果。\n还可以对 Buckets 里面 X 轴的值进行调整，使用省的名字。 这样基本上得出了确诊数省排名的结果。或者你还可以调整出其它的分析结论。在分析结束后，点击左上角的 Save ，将分析组合保存下来用于后期的仪表板的制作。\n💻 使用 Visualization 的 lens 功能探索数据 点击 New Visualization，选择左上角的 Lens 图标。在 CHANGE INDEX PATTERN 中选择目标的索引如：dxy-area-m5。 拖拽几个字段进入中间的显示区：continentName countryName province_confirmedCount 这些字段，也可以尝试将这些字段拖入右侧的 X 轴或者 Y 轴。\n拖入不同的位置，图形下方的建议可视化展示风格会随之变化，Lens 功能在预判和猜测你可能会用到的展示和分析组合。感受这些建议图形所提供的数据分析的线索。\n同样的，你也可以在上面使用过滤器和时间段选择功能，这些数据筛选条件发生变化之后，可视化的图形数据也会随之变化。\n使用 TSVB 时序数据可视化构造器 这个控件的功能稍微复杂一些，用下图说明它的用法。\n如上图所示，现在 Panel Options 里面设置需要使用的数据索引，以及其他参数。\n然后在 Data 中选择需要显示的数据指标，如上图中选择了全国累计确诊和累计治愈，两个指标。将他们放在一起更能回答这样一个问题：是否治愈的速度是足够的，如果治愈速度跟得上的话，说明医疗资源是足够用的，如果这两条线之间的落差比较大就危险了。\n上方的 TSVB 图形显示了所有数值和格式调整后的预览效果。可以无限的修订知道满意为止。这个控件天然支持指标数值、排行榜、速度表、Markdown 文本和数据表。可以切换到不同的视角看它的展示效果。\n使用地图展示省级累计数据 我们可以使用已经导入的数据在地图上显示省级的累计确诊和治愈人数。过程是这样的：\n 点击 Kibana 左侧的 Maps 图标，创建一个新的地图。 创建图层，选择 EMS Boundaries ，选择这个图层所使用的基础地图为 China Provinces 点击 Add layer 按钮 在图层配置里输入图层名称缩放级别，透明度的设置 设置 Tooltip fields 的设置中增加 name(zh) ,中文的省名称 设置 Term Joins 的规则，点击 Join 关键字，设置索引中的数据和地图的关联。如下图所示，这就是我们为什么要把导入数据中的省英文名称与 EMS 的定义数据对齐了。   点击 and use metrics 设置在每个省上显示的数据。如下图所示。   最后设置 Layer Style， 将 Fill color 填色设置为 By Value， 选择省累计确诊，下面的颜色可以选择白色到深红的过度。 最后点击 Save \u0026amp; close 按钮。  这里的技术点在于：Elastic 地图中的基础数据（地理名称代码）必须和目标索引中的相关字段能够匹配上（join）上，然后才能将索引中的实际做聚合运算的字段根据地理名称进行处理，例如根据数值的大小，将各个省填充成不同的颜色，用 tooltips 显示这个省的数据信息。\n创建 Dashboard 仪表板 上面所设计的所有的图示和地图都是创建 Dashboard 的素材，等做了一些素材之后就可以做仪表板了。这个过程就是在空白的仪表板上逐渐加入合适的图表，然后不断调整图表布局的过程，然后呈现出一个阶段性的效果。如下图所示。\n世卫组织数据的处理和展示 浏览世卫组织的数据 https://github.com/CSSEGISandData/COVID-19\n基于以上数据可以制作一个如下的仪表板：\n这个仪表板中的地图是亮点，建议仔细学习研究一下。 这个仪表板的来源是一篇国外的文章： https://www.siscale.com/importing-covid-19-data-into-elasticsearch/\n我在一个小时左右，根据经验顺利的在我的实验环境里顺利生成了这个成果。下面是根据这篇文章怎么样使用 logstash 导入 Github 中世卫组织发布的数据，并持续与之保持同步。这里是他们的代码：https://github.com/siscale/covid-19-elk\n下面描述如何使用这份代码。首先你需要有一个安装好的切正常运行的 Elasticsearch 7.6.1 服务器，一个可以正常使用的 Kibana 7.6.1 服务器。在此基础之上，安装 logstash 服务器，修改并放好 logstash 的配置文件。 在 Kibana 的 Dev Tool 中导入索引的 Mapping。启动 logstash 服务器，等待和确认数据的传入。导入 Kibana 的相关对象。浏览查看和确认 siscale （国外一家 Elastic 的合作伙伴公司） 的作品。理解每个可视化展示控件的设计细节。\n你可以参考下面的安装步骤和注意事项。\n 登录 Kibana，进入 Dev Tool 中，将文件 index-template-mapping.json 中的内容复制进去并点击执行按钮。 安装 Logstash 7.6.1  yum install java-11-openjdk-11.0.6.10-0.el8_1.x86_64 rpm -ivh logstash-7.6.1.rpm  将配置文件中的 /etc/logstash/covid-19-hashes.json 修改为 /usr/share/logstash/covid-19-hashes.json 然后把它们复制到 logstash 的配置目录中  cp logstash-github-covid-19-daily-reports-template.conf logstash-github-covid-19-time-series-template.conf /etc/logstash/conf.d/  确保你的虚拟机（测试环境和 github 以及其他的国外基本正常的情况下）网络正常的情况下，启动 logstash 服务并且关注该服务的日志信息  sudo systemctl start logstash sudo tail -f /var/log/logstash/logstash-plain.log PS:在日志中可以看到 logstash 完全正常的启动成功，或者看到报错，这时候就需要停止 logstash 服务，并进行调整。直到服务彻底运行成功不报错。\n在 logstash 服务正常运行的情况下，世卫组织的数据是会被正常的导入到 ES 中的，你可以在 Discovery 中查看如下的查询结果。那么恭喜你，你已经和世卫组织的数据保持实时同步了。\n最后是导入该项目的仪表板对象。操作步骤参考：登录 kibana， 进入管理， 点击 Kibana 下面的 saved objeces ； 点击 import 按钮。选择 kibana-7.6.1-covid-19-dashboard.ndjson ，然后即可浏览名为 COVID 19 的仪表板了。导入后在 Kibana 的仪表板清单中选择查看名为 “COCID 19” 的仪表板。预祝你能看到和我相同的结果，建议仔细查看他们的地图设计，做的是非常的细致，如下图所示，它是三个图层叠加的显示效果。\n总结 最后希望你通过本文已经成功的展示出了以上的预期结果。下面简单总结一下相关知识点。\n 对陌生数据集的首次探索可以是手动导入 csv 文件的手动过程 在导入的过程中需要做适当的 field mapping 的调整，和扩展，让后期的查询和数据分析更加清晰 对导入后的数据，充分利用 Discovery 的查询和分析能力，确定好数据校准和调优的更新策略 充分利用 ES 的批量查询修改API，可以轻松快捷的实现数据修订。 地图的使用重点在地理信息代码和数据索引中的实际 field 的 join，因此需要特别设计和维护 join 的字段，确保他们的精确性。 仪表板的制作和设计依赖于各种图标的设计  Elastic Stack 在本案例中得到了充分而综合的运用。从 E 到 L 到 K 一个都不能少。建议大家能平衡掌握这个技术栈的各种技术能力，补足不太擅长的部分。\n本文参考的网址如下：\n https://gisanddata.maps.arcgis.com/apps/opsdashboard/index.html#/bda7594740fd40299423467b48e9ecf6 http://covid.surge.sh/ https://informationisbeautiful.net/visualizations/covid-19-coronavirus-infographic-datapack/ https://ncov.dxy.cn/ncovh5/view/pneumonia https://github.com/CSSEGISandData/COVID-19 https://lab.isaaclin.cn/nCoV/ https://github.com/siscale/covid-19-elk https://www.mapbox.cn/coronavirusmap/#3.35/28.47/109.74 https://ncov.deepeye.tech/ https://www.siscale.com/importing-covid-19-data-into-elasticsearch/  ",
    "ref": "/blog/%E4%BD%BF%E7%94%A8-elastic-stack-%E7%9B%91%E6%8E%A7-covid-19-%E7%96%AB%E6%83%85%E5%8F%91%E5%B1%95/"
  },{
    "title": "如何在墙内正常导入 Vagrant 虚拟机模板",
    "date": "",
    "description": "在墙内如何正常下载所需要的 Vagrant 的虚拟机模板文件",
    "body": "当你满心欢喜的安装完了 vagrant 之后，在你第一次 vagrant up 命令的时候，是下载超时么？你的内心是什么感受？想放弃了么？\n其实你只需要找到国内的 box 文件镜像服务器，或者下载地址，然后手工下载对应的 Box 文件（操作系统镜像文件），并导入即可，本文将帮你铲除这只官方镜像文件下载失败的拦路虎。\nVagrant 的优势：\n 虚拟机对于系统级开发和测试工作具有不可替代的作用 手工安装的虚拟机非常  准备工作 我的测试环境如下，如果你的测试环境和我的不同，但是本操作方法和过程也同样的适用于相似的环境。\n环境描述：\n macOS catalina version 10.15.3 vagrant 2.2.4 Virtuabox 6.0.15r135660  如果你也百度了’ vagrant box 国内镜像‘的话，结果会使你很失望，清华大学等站点只是缓存了个别的镜像文件，并没有其它版本特别全面的网站，更没有完整的镜像。如果你知道其它国内的镜像站点请告诉我，我会增加到本文。\nUbuntu 的可以浏览这两个目标下载网址。\nhttps://mirrors.tuna.tsinghua.edu.cn/ubuntu-cloud-images/vagrant/\n然后用vagrant 下面的命令就可以将 box 下载并且添加到本地。\n ubuntu 18.04 LTS:  vagrant box add https://mirrors.tuna.tsinghua.edu.cn/ubuntu-cloud-images/bionic/current/bionic-server-cloudimg-amd64-vagrant.box \u0026ndash;name ubuntu18\n ubunt 16.04 LTS：  vagrant box add https://mirrors.tuna.tsinghua.edu.cn/ubuntu-cloud-images/xenial/current/xenial-server-cloudimg-amd64-vagrant.box \u0026ndash;name ubuntu16\n ubuntu14：  vagrant box add https://mirrors.tuna.tsinghua.edu.cn/ubuntu-cloud-images/vagrant/trusty/current/trusty-server-cloudimg-amd64-vagrant-disk1.box \u0026ndash;name ubuntu14\n对于 CentOS 而言，它的官网整理的比较好，提供了各种格式的下载，可能需要科学上网才能访问到 Centos 的下载网址。\nhttp://cloud.centos.org/centos/7/vagrant/ http://cloud.centos.org/centos/8/vagrant/\n实战建议：你并不需要下载过多的 box 操作系统镜像文件，够用即可。建议将最近有可能使用到的 Box 文件用断点续传的多线程下载工具下载到本机磁盘备用。我下载了一些，关注的微信号‘ MyDevOps ’ 回复 box1 即可获得百度网盘下载地址，这个共享目录中有本文中所提到的所有 Box 文件。\n导入 Box 文件 用 vagrant box add 命令将本地下载好的 box 文件导入到 vagrant 的主目录中，macOS 下是在~/.vagrant/ 目录里。\n使用vagrant box list名先查看本地已有的 box 清单，下面的执行结果如下。\n➜ ~ vagrant box list Puppetlabs Ubuntu 12.04.2 x86_64, VBox 4.2.10, No Puppet or Chef (virtualbox, 0) bento/centos-7.1 (virtualbox, 2.2.2) bento/centos-7.2 (virtualbox, 2.3.1) bento/centos-8 (virtualbox, 202002.04.0) bento/ubuntu-16.04 (virtualbox, 0) coreos-alpha (virtualbox, 1451.2.0) geerlingguy/centos6 (virtualbox, 0) geerlingguy/centos7 (virtualbox, 0) geerlingguy/ubuntu1604 (virtualbox, 0) ubuntu/trusty64 (virtualbox, 20161207.0.0) ubuntu/trusty64 (virtualbox, 20170307.0.0) ubuntu/wily64 (virtualbox, 20160715.0.0) ubuntu/xenial64 (virtualbox, 20161214.0.1) ubuntu/xenial64 (virtualbox, 20170307.0.1) ➜ ~ 使用vagrant box add导入，并确认。 参考下面的执行过程\n➜ ~ vagrant box add ~/Downloads/box/bionic-server-cloudimg-amd64-vagrant.box --name ubuntu/bionic ==\u0026gt; box: Box file was not detected as metadata. Adding it directly... ==\u0026gt; box: Adding box 'ubuntu/bionic' (v0) for provider: box: Unpacking necessary files from: file:///Users/martin/Downloads/box/bionic-server-cloudimg-amd64-vagrant.box ==\u0026gt; box: Successfully added box 'ubuntu/bionic' (v0) for 'virtualbox'! ➜ ~ vagrant box list Puppetlabs Ubuntu 12.04.2 x86_64, VBox 4.2.10, No Puppet or Chef (virtualbox, 0) bento/centos-7.1 (virtualbox, 2.2.2) bento/centos-7.2 (virtualbox, 2.3.1) bento/centos-8 (virtualbox, 202002.04.0) bento/ubuntu-16.04 (virtualbox, 0) coreos-alpha (virtualbox, 1451.2.0) geerlingguy/centos6 (virtualbox, 0) geerlingguy/centos7 (virtualbox, 0) geerlingguy/ubuntu1604 (virtualbox, 0) ubuntu/bionic (virtualbox, 0) ubuntu/trusty64 (virtualbox, 20161207.0.0) ubuntu/trusty64 (virtualbox, 20170307.0.0) ubuntu/wily64 (virtualbox, 20160715.0.0) ubuntu/xenial64 (virtualbox, 20161214.0.1) ubuntu/xenial64 (virtualbox, 20170307.0.1) ➜ ~ 校验所导入的 Box 创建一个测试目录，并执行vagrant init ubuntu/bionic ，然后使用 vagrant up 测试。\n➜ test pwd /Users/martin/code/test ➜ test vagrant init ubuntu/bionic A `Vagrantfile` has been placed in this directory. You are now ready to `vagrant up` your first virtual environment! Please read the comments in the Vagrantfile as well as documentation on `vagrantup.com` for more information on using Vagrant. test 目录下面现在生成了一个默认的 Vagrantfile 文件，查看这个默认的 Vagrantfile 配置文件。这是一个很好的学习资料。\n➜ test cat Vagrantfile # -*- mode: ruby -*- # vi: set ft=ruby : # All Vagrant configuration is done below. The \u0026quot;2\u0026quot; in Vagrant.configure # configures the configuration version (we support older styles for # backwards compatibility). Please don't change it unless you know what # you're doing. Vagrant.configure(\u0026quot;2\u0026quot;) do |config| # The most common configuration options are documented and commented below. # For a complete reference, please see the online documentation at # https://docs.vagrantup.com. # Every Vagrant development environment requires a box. You can search for # boxes at https://vagrantcloud.com/search. config.vm.box = \u0026quot;ubuntu/bionic\u0026quot; # Disable automatic box update checking. If you disable this, then # boxes will only be checked for updates when the user runs # `vagrant box outdated`. This is not recommended. # config.vm.box_check_update = false # Create a forwarded port mapping which allows access to a specific port # within the machine from a port on the host machine. In the example below, # accessing \u0026quot;localhost:8080\u0026quot; will access port 80 on the guest machine. # NOTE: This will enable public access to the opened port # config.vm.network \u0026quot;forwarded_port\u0026quot;, guest: 80, host: 8080 # Create a forwarded port mapping which allows access to a specific port # within the machine from a port on the host machine and only allow access # via 127.0.0.1 to disable public access # config.vm.network \u0026quot;forwarded_port\u0026quot;, guest: 80, host: 8080, host_ip: \u0026quot;127.0.0.1\u0026quot; # Create a private network, which allows host-only access to the machine # using a specific IP. # config.vm.network \u0026quot;private_network\u0026quot;, ip: \u0026quot;192.168.33.10\u0026quot; # Create a public network, which generally matched to bridged network. # Bridged networks make the machine appear as another physical device on # your network. # config.vm.network \u0026quot;public_network\u0026quot; # Share an additional folder to the guest VM. The first argument is # the path on the host to the actual folder. The second argument is # the path on the guest to mount the folder. And the optional third # argument is a set of non-required options. # config.vm.synced_folder \u0026quot;../data\u0026quot;, \u0026quot;/vagrant_data\u0026quot; # Provider-specific configuration so you can fine-tune various # backing providers for Vagrant. These expose provider-specific options. # Example for VirtualBox: # # config.vm.provider \u0026quot;virtualbox\u0026quot; do |vb| # # Display the VirtualBox GUI when booting the machine # vb.gui = true # # # Customize the amount of memory on the VM: # vb.memory = \u0026quot;1024\u0026quot; # end # # View the documentation for the provider you are using for more # information on available options. # Enable provisioning with a shell script. Additional provisioners such as # Puppet, Chef, Ansible, Salt, and Docker are also available. Please see the # documentation for more information about their specific syntax and use. # config.vm.provision \u0026quot;shell\u0026quot;, inline: \u0026lt;\u0026lt;-SHELL # apt-get update # apt-get install -y apache2 # SHELL end 现在可以踏实的运行 vagrant up 了，Ubuntu 的 Box 文件导入通常没有什么问题。默认配置的 Ubuntu 版本 bionic 的 vm 现在就正常启动了。\n➜ test vagrant up Bringing machine 'default' up with 'virtualbox' provider... ==\u0026gt; default: Importing base box 'ubuntu/bionic'... ==\u0026gt; default: Matching MAC address for NAT networking... ==\u0026gt; default: Setting the name of the VM: test_default_1585496539631_90780 ==\u0026gt; default: Clearing any previously set network interfaces... ==\u0026gt; default: Preparing network interfaces based on configuration... default: Adapter 1: nat ==\u0026gt; default: Forwarding ports... default: 22 (guest) =\u0026gt; 2222 (host) (adapter 1) ==\u0026gt; default: Running 'pre-boot' VM customizations... ==\u0026gt; default: Booting VM... ==\u0026gt; default: Waiting for machine to boot. This may take a few minutes... default: SSH address: 127.0.0.1:2222 default: SSH username: vagrant default: SSH auth method: private key default: Warning: Connection reset. Retrying... default: default: Vagrant insecure key detected. Vagrant will automatically replace default: this with a newly generated keypair for better security. default: default: Inserting generated public key within guest... default: Removing insecure key from the guest if it's present... default: Key inserted! Disconnecting and reconnecting using new SSH key... ==\u0026gt; default: Machine booted and ready! ==\u0026gt; default: Checking for guest additions in VM... default: The guest additions on this VM do not match the installed version of default: VirtualBox! In most cases this is fine, but in rare cases it can default: prevent things such as shared folders from working properly. If you see default: shared folder errors, please make sure the guest additions within the default: virtual machine match the version of VirtualBox you have installed on default: your host and reload your VM. default: default: Guest Additions Version: 5.2.34 default: VirtualBox Version: 6.0 ==\u0026gt; default: Mounting shared folders... default: /vagrant =\u0026gt; /Users/martin/code/test 现在 ssh 登录到这个崭新的 vm 。\n➜ test vagrant ssh Welcome to Ubuntu 18.04.4 LTS (GNU/Linux 4.15.0-91-generic x86_64) * Documentation: https://help.ubuntu.com * Management: https://landscape.canonical.com * Support: https://ubuntu.com/advantage System information as of Sun Mar 29 15:42:53 UTC 2020 System load: 1.25 Processes: 99 Usage of /: 10.1% of 9.63GB Users logged in: 0 Memory usage: 12% IP address for enp0s3: 10.0.2.15 Swap usage: 0% 0 packages can be updated. 0 updates are security updates. vagrant@ubuntu-bionic:~$ top 导入 CentOS 7 可能遇到的问题 CentOS 7 和 8 的相关版本在我的测试环境中都出现了导入正常 vagrant up 异常的问题，通常网络搜索错误代码后，就可以解决了，如果有任何问题，欢迎到我的微信公众后台留言。\n总结 Vagrant 的功能性和必要性是非常高的，特别是对于天朝的码农而言，就更加重要了。它是 DevOps 工具链上的知名工具，而它的使用率和广泛性却不高。后续还会出这方面的系列内容，讲解更多关于 Vagrant 的优化和功能。\n2io\n",
    "ref": "/blog/download-import-vagrant-box/"
  },{
    "title": "最简化 Elasticsearch & Kibana & Filebeat 安装说明",
    "date": "",
    "description": "这可能是最简洁的 Elastic Stack搭建说明，立刻开启你的日志集中式管控",
    "body": "本文描述如何搭建一套具备用户名和密码安全认证的 Elastic Stack 系统，并开始使用 Filebeat 的基础模块实现分布式的日志收集。\n 安装单节点 Elasticsearch 服务器，启用用户名和密码安全认证，并创建 TLS 数字证书备用 安装 Kibana 服务器，并配置与 Elasticsearch 服务的连接 安装和配置 Filebeat 代理程序，并配置 system 和 auditd 模块 使用 Kibana 监控 Filebeat 所采集的系统日志，并监控系统的状态  为了使你也获得与我一致的安装和测试体验，请先下载并浏览相本文所使用的代码库：https://github.com/martinliu/elastic-labs\n试验环境概述和启动 本文所使用相关软件以及版本。\n macOS Catalina version 10.15.3 Vagrant 2.2.4 VirtalBox 6.0 操作系统镜像: bento/centos-8 (virtualbox, 202002.04.0) Elastic Stack 安装包（RPM）  Elasticsearch 7.6.1 Kibana 7.6.1 Filebeat 7.6.1   使用 Vagrant 的目录共享功能，分享安装包到测试机的 /vagrant/rpm 目录下  注意事项：\n 你也可以使用任何一台 CentOS 8 虚拟机或者云主机，则后续的安装命令和 rpm 安装包的路径需要有所变化。 Vagrant 文件中定义的虚拟机配置为 4 GB 内存，建议你的操作系统最低为 8GB 内存，推荐 16GB 或者更高， 本文也适用于 Linux 或 Windows 操作系统的 Vagrant 测试环境，需要提前下载并且准备好 bento/centos-8 的基础操作系统镜像。  启动测试环境。\nvagrant up vagrant status 安装 Elasticsearch 服务器 SSH 登录测试虚拟机。\nvagrant ssh\n执行 RPM 安装命令，安装 elasticsearch 服务器。\ncd /vagrant/rpm sudo rpm -ivh ./elasticsearch-7.6.1-x86_64.rpm sudo systemctl daemon-reload sudo systemctl enable elasticsearch.service sudo systemctl start elasticsearch.service sudo systemctl status elasticsearch.service 测试 Elasticsearch 服务是否功能正常 【 Dry run 】\ncurl localhost:9200\n期待的输出类似下面。\n{ \u0026quot;name\u0026quot; : \u0026quot;elk-master\u0026quot;, \u0026quot;cluster_name\u0026quot; : \u0026quot;elasticsearch\u0026quot;, \u0026quot;cluster_uuid\u0026quot; : \u0026quot;X4V2Yvc-SJ6ccjWbXQ5OmQ\u0026quot;, \u0026quot;version\u0026quot; : { \u0026quot;number\u0026quot; : \u0026quot;7.6.1\u0026quot;, \u0026quot;build_flavor\u0026quot; : \u0026quot;default\u0026quot;, \u0026quot;build_type\u0026quot; : \u0026quot;rpm\u0026quot;, \u0026quot;build_hash\u0026quot; : \u0026quot;aa751e09be0a5072e8570670309b1f12348f023b\u0026quot;, \u0026quot;build_date\u0026quot; : \u0026quot;2020-02-29T00:15:25.529771Z\u0026quot;, \u0026quot;build_snapshot\u0026quot; : false, \u0026quot;lucene_version\u0026quot; : \u0026quot;8.4.0\u0026quot;, \u0026quot;minimum_wire_compatibility_version\u0026quot; : \u0026quot;6.8.0\u0026quot;, \u0026quot;minimum_index_compatibility_version\u0026quot; : \u0026quot;6.0.0-beta1\u0026quot; }, \u0026quot;tagline\u0026quot; : \u0026quot;You Know, for Search\u0026quot; } 浏览和学习 Elasticsearch 默认的配置文件。\nsudo cat /etc/elasticsearch/elasticsearch.yml\n使用 Elasticsearch 的精简版目标测试配置文件。\nsudo cp /vagrant/elasticsearch/elasticsearch.yml /etc/elasticsearch/elasticsearch.yml sudo systemctl restart elasticsearch.service sudo systemctl status elasticsearch.service 手工查看 Elasticsearch 服务器的日志，并确认服务启动正常。\nsudo tail -f /var/log/elasticsearch/my-elk.log\nCtl + c 终止以上日志查看，再次测试 Elasticsearch 服务。\ncurl localhost:9200\n替换为 IP 地址测试。\ncurl http://192.168.50.10:9200/\n配置 Elasticsearch 服务的 TLS 数字证书和身份验证 停止 Elasticsearch 服务。\nsudo systemctl stop elasticsearch.service\n创建 TLS 数字证书 cd /usr/share/elasticsearch sudo bin/elasticsearch-certutil cert -out /etc/elasticsearch/elastic-certificates.p12 -pass \u0026quot;\u0026quot; sudo chmod 660 /etc/elasticsearch/elastic-certificates.p12 更新 Elasticsearch 配置文件 手工打开 Elasticsearch 配置文件。\nsudo vi /etc/elasticsearch/elasticsearch.yml\n在配置文件的末端增加下面的配置段落。\n# ------------------------------- TLS and Cert --------------------------------- xpack.security.enabled: true xpack.security.transport.ssl.enabled: true xpack.security.transport.ssl.verification_mode: certificate xpack.security.transport.ssl.keystore.path: elastic-certificates.p12 xpack.security.transport.ssl.truststore.path: elastic-certificates.p12 重新启动配置 Elasticsearch 服务。\nsudo systemctl restart elasticsearch.service sudo systemctl status elasticsearch.service 确认服务已经正常启动。\nsudo tail -f /var/log/elasticsearch/my-elk.log\n创建 Elasticsearch 服务的用户密码 运行 Elasticsearch 的密码配置工具，为各种内置用户生成随机的密码。\nsudo cd /usr/share/elasticsearch sudo bin/elasticsearch-setup-passwords auto 将生成的密码信息妥善保存备用。\nChanged password for user apm_system PASSWORD apm_system = AHyg5HzJRZg8Fiva0buW Changed password for user kibana PASSWORD kibana = Kt72IXkiarlGr7do02Yp Changed password for user logstash_system PASSWORD logstash_system = Q9nnlOdf6V9kyPbbhqN7 Changed password for user beats_system PASSWORD beats_system = bLNrZDggPKRSKc35EG32 Changed password for user remote_monitoring_user PASSWORD remote_monitoring_user = o1pi2yTDnhrKBGcS6xqP Changed password for user elastic PASSWORD elastic = RO11xymgXTCD16ivTP33 在浏览器中访问http://192.168.50.10:9200/ ，测试并确认上面的 elastic 用户的密码。\n安装和配置 Kibana 服务器 执行 Kibana 安装命令\ncd /vagrant/rpm/ sudo rpm -ivh kibana-7.6.1-x86_64.rpm 查看并学习 Kibana 默认配置文件\nsudo cat /etc/kibana/kibana.yml\n更新默认配置文件，准备好 elastic 用户的密码，将其更新到 Kibana 配置文件中。\nsudo cp /vagrant/kibana/kibna.yml /etc/kibana/kibana.yml sudo systemctl start kibana.service sudo systemctl status kibana.service 查看重启的服务是否工作正常。\nsudo tail -f /var/log/messages\n在浏览器里测试登录 Kibana http://192.168.50.10:5601 ，使用 elastic 的用户名和密码。\n安装 filebeat 并配置 2 个模块 执行 Filebeat 安装包。\ncd /vagrant/rpm sudo rpm -ivh ./filebeat-7.6.1-x86_64.rpm 查看默认的 Filebeat 配置文件。\nsudo cat /etc/filebeat/filebeat.yml\n更新默认配置文件，准备好 elastic 用户的密码，将其更新到 Kibana 配置文件中。\nsudo cp /vagrant/filebeat/filebeat.yml /etc/filebeat/filebeat.yml\n查看 Filebeat 的默认日志监控模块。\nsudo filebeat modules list\n启用 Filebeat 的 System 和 Auditd 模块，监控系统日志和基础的操作系统安全信息。\nsudo filebeat modules enable system auditd\n查看 Filebeat 监控模块的配置文件。\nsudo cd /etc/filebeat sudo ls -l modules.d/ 建议查看以上启用的 System 和 Auditd 模块的配置文件。\n运行 Filebeat 在后台的初始化命令，在后台创建 Filebeat 所需要的索引 filebeat-* ，并导入所有模块相关的 Dashboard 等 Kibana 日志可视化分析工具。\nsudo filebeat setup\n在浏览器中登录 http://192.168.50.10:5601 Kibana 后，点击左侧的 Dashboard 图标，查看所有刚才导入的内容，搜索并打开 System 关键字的 Dasboard。\n在启动日志收集代理 Filebeat 服务前，运行一下命令测试 Filebeat 配置文件的正确性。\nsudo filebeat test config\n启动 Filebeat 服务，开始对这台操作系统的日志进行监控。\nsudo systemctl start filebeat sudo systemctl status filebeat 建议的测试  点击左侧的 Dicovery 图标，选中 Filebeat-* 索引，打开并一条日志数据，并查看所有字段；用 KQL 进行全文搜索。 点击左侧的 Dashboard 图标，搜索 system 关键字，查看一个仪表板的日志展示；搜索 audit 关键字，并查打开一个仪表板，在命令行中尝试 ssh localhost，多尝试几次，刷新 Audit 仪表板，观察数据是否发生了变化。 点击左侧的 Logs 图标，用鼠标上下滚动日志信息流， 点击右上角的开始 Live Stream 查看模式，观察日志信息流的自动滚动效果，在 KQL 搜素框中输入 tags : demo-service ，体验它的搜索建议功能，在 Highlight 中输入 http://192.168.50.10:5601/app/infra ，观察日志信息流显示的变化。 点击左侧的 SIEM 图标，看看这里都有什么内容。  后续  用启用 Filebeat 的 Elasticsearch, Kibana 日志监控模块 安装 Apache, MySQL 等软件，并开启 Filebeat 的日志监控模块  参考文档： https://www.elastic.co/guide/en/elasticsearch/reference/current/setting-system-settings.html\n",
    "ref": "/blog/install-es-kibana-filebeat/"
  },{
    "title": "SLA、SLO 和 SLI 还是傻傻分不清么？",
    "date": "",
    "description": "SLA、SLI 和 SLO 是 SRE 工程实践里非常核心的概念，但是大家在同时提到这些概念的时候，经常容易混淆。",
    "body": "SLA、SLI 和 SLO 是 SRE 工程实践里非常核心的概念，但是大家在同时提到这些概念的时候，经常容易混淆。\n长篇大论的文章反而容易使人更加疑惑，还不如画一张示意图说明一下，帮助大家一次性彻底梳理清楚这些不可以含糊不清的核心概念。说明一下，下图假设所讨论的 SLA 个数为 1，使用了软件工程中 ER 图的表达方式，但也有所变化。\n一图讲清 SLA、SLO、SLI\n本文不讲 why，只是帮助大家梳理清楚这些概念在以上人机系统中的相互关系。虽然不想做名词解释。但是为了方便起见，整理一个术语清单。\n SLA = Service Level Agreement = 服务质量/水平协议 SLO = Service Level Objective = 服务质量/水平目标 SLI = Services Level Indicator = 服务质量/水平指标  下面用人、事、物的逻辑进行阐释。\n人和事 用从上到下，从左到右的顺序。\n客户 - 每 1 个客户在使用产品服务时，都显性或隐性的基于某 1 个 SLA，SLA 和客户之间是一种 1 对 1 的文档关系，这份协议文档就显性或者隐性的存在于系统中。客户使用 1 种，或者 n 种连接方式访问产品服务的 1 个或者 n 个应用系统。\n销售 - SLA 本身是所销售产品服务的一部分，它规定了承诺给客户的产品功用和质量。基于 SLA，客户可以选择用付费或者免费的方式使用产品。1 个/份 SLA 的销售工作可以由 1 到 n 位销售完成。销售和客户都幻想着几乎完美的 SLA，这样代表企业利益的销售，以及产品的客户就都可以达到双赢的局面，皆大欢喜。\n产品 - 通过与销售的间接互动，或者直接的客户调研，产品经理能够确定应用系统所应该具有的功能和发展方向。\nSRE - SRE 和产品共同制定了每个 SLA 相关应用系统的 SLO，SLO 定量的定义了每 1 个应用系统所应该具备的服务质量，1 个应用系统的 SLO 被该产品服务的 SLO 文档定义，在该文档中 SLO 被映射到 1 个或者 n 个 SLI，每个 SLI 都需要用监控工具持续采集数据，通常它们的数值单位各不相同。所有 SLO 都是用百分比数值形式表达的，例如：99.99% 的成功率，90％ 的请求延迟 \u0026lt; 400 毫秒等。SRE 和产品经理/专家还应该共同关注运行应用系统的基础设施层，确保基础设施的可用性和容量足以满足目标数量的用户访问，而且还要考虑和设计底层资源的容灾和跨区多活等复杂场景。\n开发/运维 - 重要但暂不做讨论。\n事 用从下往上的顺序。\nIaaS 云服务 - 也可以是其它类型的可以供应用系统运行的环境。这里存在着 1 到 n 种子服务。它和上层的 n 个应用系统通常是 n 对 n 的关系。\n应用系统 - 1 个到 n 个应用系统构成了 1 个产品服务（内含SLA），在和客户的互动中实现着产品服务的业务价值。\n文档 - 以网页或者纸张的形式向用户描述了某个应用服务所提供的服务内容和质量信息。向用户提供这个文档并不是强制、显性和必须的。\n结束 请根据以上解释，结合你的实际工作场景，想象并描绘一下 SLA 、SLO 和 SLI 在你周围的人事物中关系网。在SRE 的工作实践中，定义 SLO，并梳理 SLI，将量化以后的目标和说明文档化，并让各个干系人认同并签署，是一项基础的起步工作。\n本文参考了 Google 出品的两本SRE 书籍，这两本书的英文版在 Google 的官网可以免费在线阅读。SRE Workbook 的简体中文版会在2020 年中出版。\n",
    "ref": "/blog/sre-sla-slo-sli/"
  },{
    "title": "怎样使用两个DevOps研究模型？",
    "date": "",
    "description": "死磕2019年加速度全球DevOps状态调查报告系列，深度解读第二篇。",
    "body": "本文要覆盖的章节是《 How to use the research models》 这一章。双模型在今年的报告中首次出现了，它们是效能模型和生产力模型。为什么会存在两个模型？有什么区别？有什么相似之处？最重要的问题是，你怎么用它们来指导你的DevOps工作？\n本文的阅读建议：\n 下载我整理的最新版的《DevOps能力成长模型》，含双模型分解图。 阅读和参考前5年的DevOps状态调查报告，了解今年这份报告的历史和发展历程。以前的文章中有下载链接/二维码。 阅读2019年的调查问卷的中文版，感谢中国DevOps社区翻译团队对英文原版问卷的翻译工作，如果你都不知道这些调查结果是通过什么问卷调查得出的，那真的是很可惜。如果你想用这套问卷工具在企业内部做调研，请使用前文中的免费调查服务申请流程。样例问卷的访问地址：https://www.wjx.cn/jq/43837840.aspx 在Google的网站上做极简版DevOps行业基础测试，它是6年行业调查结果数据库的首次对外开放。  模型是怎么诞生的？ 首先，我们需要了解一下这份持续了6年的报告是谁主导并开发的？这是一个怎样的团队？从DORA公司网站的这个页面上，可以看到团队人员介绍。https://devops-research.com/about.html 如下所示。\n不做其它任何解读和评论，只想请大家关注一下分析报告的主持者的title : Dr Nicole Forsgren, CEO and Chief Scientist ; 翻译一下 Nicole Forsgren 博士，CEO和首席科学家。她是一个长期的IT行业从业人员，最早专注于DevOps的行业调研员。她持有管理信息系统的博士学位和会计硕士学位。从社交媒体上可以看出她和行业大咖Jez Humber和Gene Kim都是好朋友。\n其次，如果你也回顾了所有往届的DevOps状态调查报告，我们应该能体会到这场历时6年行业调研的基本逻辑和脉络。在第一年就已经提出了四大黄金度量指标，并且以此为主线；每年反复验证状态，以及其他相关影响因素。使用了穷举的逻辑，每年根据行业的发展动态，根据和其它业内大咖的讨论，适当的加入新的调查点。当然每个调查的能力点也是需要每年反复确认和验证，调查点之间的逻辑关系也越来越明显，经过二次研究之后就形成了DevOps能力成长模型。\n最后，DevOps能力成长模型诞生于《Accelerate:The Science of Lean Software and DevOps: Building and Scaling High Performing Technology Organizations 》这本书。 https://www.amazon.com/Accelerate-Software-Performing-Technology-Organizations/dp/1942788339\n在这本书里分模块（局部）的介绍了DevOps能力模型的影响逻辑关系，从转型型领导力一直推导出模型的最右侧：组织效能和非商业效能。这个模型应该就是历届DevOps状态调查研究背后的理论基础，当然它也应该是慢慢发展和完善出来的，起码数字转型这个话题是2018年才出现的热点。模型的数值计算算法，见近两年报告的附录部分。这个模型在本书中是从各个不同的局部关系逐渐介绍的。如下图所示：\nAccelerate全书的逻辑不仅在于介绍各种DevOp实践、技术、文化、领导力等等相关因素有哪些，更重要的是揭示出这些影响因素（能力点）之间的关联关系。在书的最后展示了DevOps能力成长模型的全图，如下图所示：\nAccelerate这本书也提供了这幅图的电子版下载链接：https://devops-research.com/assets/transformation_practices.pdf\n这是一份非常棒的学习资料，如果你还没有买本书的话，也可以下载学习这份精华资料。这份文档的总标题是：”调研总体策划“，除了模型之外该文档还提供了一张全面复杂的表格，表格的名字：”高效能团队，管理、领导力行为和实践调查表，由Steve Bell，Karen Whitley Bell“；如果你想对自己的组织进行全面的调研的话，这也是一份优秀的调研方案。调研的矩阵如下：\n 纵向：文化、组织结构、直接学习和对齐价值、部署策略、通过分析提高流动性和训练有素的问题解决、工作方式节奏化\u0026amp;日常化 横向：团队实践、管理实践、领导力实践。  我很有幸2017年在北京DevOpsDays大会上参加Jez先生的培训，并获赠了Jez先生的签名版《Accelerate》纸版书，其实在这以前我已经购买了Kindle的电子版和Audible的有声书版。我反复研读了这本书的各种版本，再次强烈推荐所有DevOps相关的管理者一定要学习这本书。\n以书中的模型为基础，2018年的DevOps状态报告里以又进一步做了各种扩展，如果你读过去年的报告，你可以看到如下的各种局部的扩展。\n大家注意看2018年的这个局部模型图的标题”精益和敏捷实践“，这里也包含敏捷开发实践。我在反复琢磨这个模型之后，用Twitter私信问过Nicole博士。我问他为何没有专项调查过敏捷开发实践？模型上为何不给敏捷开发一个位置？她的回复是，我们之前已经调研过了，而且模型上也提到了。可能在全球的软件开发工程水平看，有可能Nicole博士团队认为敏捷开发应该是比较基础的软件开发实践，据我个人了解国外高水平公司要么都已经规范照做了，要么也有像Google这样的高水平公司确实也不显性的宣传自己是敏捷开发，甚至吐槽敏捷的。\n2018年对模型的扩展力度还是很大的，提出了很多新的调查项；为了能看到方便的看到一个DevOps能力模型的全景视图，我使用OmniGraffle软件基于《Accelerate》书中的模型，扩充绘制了如下的模型图：\n这幅图向我们完整的揭示了到2018年以来的所有DevOps调研点，有些点是经过多年反复验证的，有些是2018年新引入的。这幅图花了我几天时间，在这个过程中也反复的推敲了其中的逻辑关系。这幅图仅代表我个人的观点，不代表DORA和《Accelerate》书籍的任何观点；需要声明的是：我绘制的DevOps能力成长模型并非我的个人著作，引用了DORA和《Accelerate》的著作，但我力求精确无误的表达整个模型。再次声明，这个模型图非官方出品，是我的个人研究。\n研究模型的研究逻辑是穷举法，是从左到右的推导和影响关系。最新发布的2019年DevOps状态调查报告显示了新的变化，这触发了对以上模型的更新。本文将提供最新版高清大图的下载。\n为何两个模型？ 为何2019年会分化出两个模型，简单的讲：穷举的范围越来越大了，生产力作为一个新的全局共享目标进入了调查问卷的范围。我们之前社区的小伙伴已经将2019年的近100道调查题问题翻译成中文了，敬请参阅参考DevOps状态调研问卷。在翻译完那些题目后，我并没有意识到今年可能会新增出这样一个全局共享目标的调研对象，真的以为：这个效能模型（组织效能和非商业效能）会一条道走到最后。\n效能模型 对效能模型的更新变化如下图所示：\n生产力模型 新增的生产力模型令我感到相当意外，它的结构如下所示：\n总之，还无法预测明年的调研范围会有怎样的更新。可以确认的是行业DevOps的能力模型是在动态变化的，想跟上世界级的水平还必须不断刷新自己的能力组合。否则你的同行的对手可能早就一骑绝尘而去了。DevOps能力发展不是一个有限游戏（例如刷黄金5级），是每年都和整个行业一起发展的无限游戏。\n如何使用模型？ 2019年的报告中给出了模型的使用和阅读方法的官方解释，见2019年报告英文原版的27页。本文对其的解读如下。\n使用模型指导转型 识别你将要改善的能力点。模型中的每个被箭头所指向的方块被称之为构造，构造有单级构造，也有二级构造（如精益产品开发、软件开发实践），历年来的报告中已经为你展示和所有DevOps能力点，你现在需要做的是从中选择出你需要改进的候选能力点。\n开展加速度的组织转型需要一个前提条件，一个扎实的基础作为起点。报告中并没有解释这个条件，你需要自己理解。聚焦在转型所急需的那些候选能力点上，在多个候选能力点里选择出亟需改进的”约束点“「此处参考TOC限制理论，相关书籍《目标》」。想想：那些能力的不足造成了最大的延期？「记住这里说的是最大值，这需要一个量化的跨组织的分析调研」什么最让你头痛？什么是最大的问题？经过以上的引导问题的提示，从清单中选出3~5个候选优化发展的能力项，安排出专项人力和财力资源，先重拳出击改善第一波能力点。不要担心你还有其他的很多问题；现阶段不妨聚焦在那个最大的问题上；这样你才能将瓶颈（约束点）各个击破，发掘这个其他的协同功效，避免不必要的工作。这个部分基本上是经典TOC理论的应用，关于这个理论在DevOps实施中的详细使用方法描述，请参考《DevOps实践指南》的第二章 2.5 持续识别和改善约束点。\n以上DevOps转型工作还有其他的产出。那些追求SDO组织效能的组织还会得到这些收益，降低职业透支（996icu）和部署的痛，提高安全水平。附加的好处还包括，它能提高生产力，提高了生产力就可以获得工作生活平衡且降低职业透支。\n怎样阅读模型？ 报告使用了结构方程模型 （Structural equation modeling https://en.wikipedia.org/wiki/Structural_equation_modeling） ，来作为一种预测模型，用它测试各个构造之间的关系。模型中的每个方块就是一个调研度量的点，就是一个构造。剪头表示了构造之间的关系。一个大的包含多个构造的方框称之为二级构造。淡蓝色的构造表示一个控制变量，它用点线连接。\n在报告原文中，将第31页和57页的模型称之为全模型，见报告的27页的原文：”See pages 31 and 57 for full models.“；而在我的系列文章中，则将下图称之为全模型。\n以上阅读方法同样的适用于上图。总之请仔细理解了左下角的图例，正确的阅读和理解模型。不管你是将DevOps实践的实施视为组织转型也好，把它当做项目做也罢；当你识别你的目标的时候，都可以参考这个模型。\n两个研究模型的重叠 由于SDO效能和生产力在很多方面本来就是相关的。它们的产出都是使用各种优秀的方法创造和交付各种技术，从而为组织和个人交付价值。那些优化软件交付的支持工作也将使生产力受益，这也是理所当然的。虽然他们的某些诱因是相同的，它们看起来很相似，但是他们度量的产出确实不同的，报告团队也是组织了独立的分析调研。总之，SDO效能和生产力是两个不同的调研模型。\n重叠模型的妙用 当你在应用SDO效能模型的时候，可以在消减职业透支方面做出聪明点的投资，更高的生产力也同样能降低职业透支。因此这个应该是向各种组织和技术团队大力提倡的做法，由于工作需求是持续增长的。工作是没完没了的，这个项目完了，还有下一个项目。而我们需要注意，我们也要关注生活和工作的平衡，而降低职业透支。\n心理安全性文化也能对SDO效能、组织效能和生产力作出贡献。研究结果表明了创造和发展健康的文化对组织和个人都有好处。\n投资在代码可维护性、松耦合架构和监控方面，也能同时帮助SDO效能、生产力（它们是通过消减技术债间接的影响到生产力的）。好的工具和系统也非常值得关注。\n总结 通过本文我相信你已经可以正确的理解2019年状态报告中的模型了，模型包括SDO效能模型和生产力模型。包括我绘制的全模型。希望DORA官方能后续推出官方版模型全图。\n 模型的意义在于：DevOps能力点是整个软件开发和交付行业都应该关注的，在投资DevOps实践的时候，需要能聚焦到组织各自不同的急需改进的能力约束点组合上。通过模型最右侧的组织级统一共享目标来度量和验证DevOps的实践是否实际有效。\n TOC是一个值得关注的问题解决套路，参考其它的相关文章和其它各种书籍。\n请关注DevOps教练的公众号，在后台输入2019，下载本文中各种模型的高清大图。\n ",
    "ref": "/blog/2019-state-devops-report-insight-2/"
  },{
    "title": "如何做横向行业的DevOps表现基准测试？",
    "date": "",
    "description": "死磕2019年加速度全球DevOps状态调查报告系列，深度解读第一篇。",
    "body": "长期关注我的blog和微信公众号（DevOps教练）的朋友可以发现，我今年从这个调查问卷开始，陆续发布了一些列文章。如果给这些文章一个文集标题的话，那么应该是：死磕2019年加速度全球DevOps状态调查报告系列。 为了帮助大家充分利用这份优秀的行业报告，我会用一些列文章，分章节的解读这份长达80多页的报告。上一篇文章如果你已经解读了该报告的核心重要发现和看点。本文要覆盖的章节是 How do we compare 这一章。\n本文的阅读建议：\n 先阅读和参考前5年的DevOps状态调查报告，了解今年这份报告的历史和发展历程。以前的文章中有下载链接/二维码。 阅读2019年的调查问卷的中文版，感谢中国DevOps社区翻译团队对英文原版问卷的翻译工作，如果你都不知道这些调查结果是通过什么问卷调查得出的，那真的是很可惜。如果你想用这套问卷工具在企业内部做调研，请使用前文中的免费调查服务申请流程。样例问卷的访问地址：https://www.wjx.cn/jq/43837840.aspx 在Google的网站上做极简版DevOps行业基础测试，它是6年行业调查结果数据库的首次对外开放。  WHY DEVOPS？ 这是一个可以持续反复问自己的问题，首先让我们澄清一件事情：为什么要做DevOps？\n是否是为了提高研发效能？是否是为了提高生产力？是否是为了提高效率？这些答案可能都对，也可都不对。对于一个组织而言：如果IT对它的使命和目标至关重要的情况下，组织对IT会产生强依赖关系，DevOps才对该组织才有意义。历年来的DevOps状态调查告诉我们：DevOps对于那些以IT为命脉的组织而言直观重要，对所有从事软件交付的组织广泛有效。\n从DevOps能力成长模型中可以看出，图中的诸多能力项都正向贡献/预测到最右侧的两个组织级别目标，他们是：组织效能和非商业效能（商业和非商业目标），它们是：\n 盈利能力 （商业） 生产力 市场份额 （商业） 客户数量 （商业） 产品或服务的数量 （商业） 运营效率 客户满意度 （商业） 提供的产品或服务的质量 （商业） 实现组织或使命目标  如果你的某项/某几项DevOps实践能够直接贡献到以上的商业目标，或者说能持续的创造客户价值，即商业价值；那么你的DevOps就是成功的。反之，如果你仅仅期望研发效能、生产力、效率能够就等同于创造出了很多的客户价值，那是一种幻觉；这就像是：你经过了很多预赛和体能的准备，而在冠军争夺赛中，你依然名落孙山，当你的组织的绩效远远低于预期的商业目标的时候，你的各种XXX效率都是无用的。\n四大黄金度量指标 6年来的DevOps状态调查报告（我只关注DORA主导和执行的这个）已经在用量化的方式，帮助我们作出了精英表现者的画像，当然还有其它的落后者。可以明确的一点是：强者从四个维度上同时都表现强劲。（去年已经打破了常见的一个误区：过度的保守主义导致在组织四个指标之中做折中选择，常见的是牺牲吞吐量指标，确保稳定性，可是后果往往是相反的。）\n先来回顾和梳理所谓的四大黄金度量指标的分类：\n 吞吐量\u0026ndash;部署频率：对于您工作的主要应用程序或服务，您的组织在生产环境进行代码部署或向最终用户做发布的频率。调查这个指标的问题见2019年加速度DevOps状态调查问卷中的第二部分的第二题。 吞吐量\u0026ndash;前置时间：对于您工作的主要应用程序或服务，从代码提交到在生产中成功运行的过程需要的时间。调查这个指标的问题见2019年加速度DevOps状态调查问卷中的第二部分的第一题。 稳定性\u0026ndash;服务恢复时间：对于您工作的主要应用程序或服务，当服务中断或出现影响用户Bug时（如：计划外中断、服务受损），恢复服务通常需要的时间。调查这个指标的问题见2019年加速度DevOps状态调查问卷中的第二部分的第四题。 稳定性\u0026ndash;变更失败率：对于您所工作的主要应用程序或服务，对于生产变更，或向最终用户发版的变更，百分之多少会导致服务质量下降（如：服务受损或服务中断），并需要进行后续的修复工作（需要热补丁、回滚，前向修复，打补丁修复）。调查这个指标的问题见2019年加速度DevOps状态调查问卷中的第二部分的第五题。  上面的四个指标是DevOps状态调查报告使用cluster算法做受众分类的主要依据，这个类聚分析的结果就是那张四大DevOps等级的泡泡图。\n在这个泡泡图中，我们可以看到有多少比例的受访者处于精英、高效、中等和低效的阵营。复述一下今年的一个重大发现：精英表现者已经从去年的高效能表现者集团中脱颖而出，他们在指标的绝对值和总体数量上都增长迅敏，增长率高达将近3倍。【DevOps教练点评：回顾一下这份报告的标题中加入的加速度的关键字，一旦某个组织的实施方法得当，一个持续优化的组织的整体效能就可能做上火箭，加速度的飞离地球。而加速度不足的企业则处于持续跌回地面的窘境。】\n这四大黄金度量指标的采集方法就是调查问卷中那些四个问题。对所有实践DevOps的组织而言，我们需要的是持续实施和优化追踪这些度量指标的方法和系统，确保能实时查看这四个指标的状态是最完美的。可是目前几乎还没有什么企业能够做到，手工分别统计上报，定期公布到全体IT部门也是非常可取的做法。总之，没有度量就不存在管理，就无从系统性的改进。\n我在行业里的表现如何？ 这是我写作本文想要回答的核心问题。如果你能够度量自己的四个黄金指标了，也能够随时拿出一组确切的数据，我们就能做行业基准测试比较了。\n这可能是Google收编DORA团队所买到的最有价值的一部分资产，历年来的DevOps调查问卷参与者的问卷答案数据库。Google今年将这个数据库向公众开放了，网址在 https://beta.devops-research.com/performance.html (这个网址应该不用科学上网，会出现证书错误提示，请忽略继续访问该页面)。在你回答了下面的五个问题后，就可以获得一份自己的行业基准测试报告。\n最后一个问题是，从13个行业中选择出一个最合适的所在行业。\n下图是你在整个所有行业里的横向对比。\n下图是你在所在行业里的横向对比。\n下图是四个黄金指标在四个表现级别/集团上的度量；表明你每个指标处于哪个等级。\n经过以上的最简版DevOps表现状态基准测试以后，你就看到了你在所有行业中和所在行业中的横向比较。当然，我们也能预测一下自己处于那个阵营和等级。然而，这并不是你的DevOps旅程的剧终情节。\n所有DevOps的实践者一旦上路以后，都是一条不归路的感觉，我们可以定期的关注我们的基准测试结果，并观察自己在动态变化的行业基线中的位置，而更重要的是：找到每个现阶段的改进空间，并且持续突破自己DevOps的能力瓶颈和极限。持续的无限制的加速度发展所有DevOps能力点才是这个DevOps旅程的终极意义。\n关于服务运维效能 服务效能指标是在去年的效能报告中新引进的，而在去年和今年的调查问卷和结果报告中并没有直接的关于这项指标的采集数据和结果。\n从上图中我们可以直接的理解一下，左侧的四大黄金指标都关乎于软件开发部门，而这个指标关乎于服务运维部门。去年并没有给出关于可用性指标的度量方法，今年也没有在调查问卷中做直接/显性的问题设置。只是在今年2019年的报告中做了进一步的解释，说这个可用性指标的实施方法论是SRE套路。我正在翻译SRE Workbook，这本书比起之前翻译的DevOps Handbook，更具有实操性。我们拭目以待，明年的状态调查问卷是如何对可用性设问和调查分析的。关于SRE的基础概念和实施方法，心急的朋友不妨参加中国DevOps社区今年10月在杭州举办的年度大会，我有一个关于SRE的主题分享，让我们一起讨论SRE的落地套路，让用SRE套路使我们的DevOps故事闭环。\n总之我们实践DevOps的时候要全局的关注“软件交付和运维效能”，简称SDO效能（software delivery and operational performance）；有O了才完整的闭环了。\n总结 本文写道这里，我认为你可以无障碍的阅读2019年加速度全球DevOps状态调查报告到第25页了。我们总结一下，你应该能理解吞吐量和稳定性的四大黄金度量指标的定义；持续度量和关注这些指标的正确方法；使用Google所提供的极简版度量工具，找到自己在行业中的定位和所处的效能级别。关注SDO效能的完整性，尝试了解和实践SRE实践，让你的DevOps体验闭环和完整起来。下一期死磕2019年加速度全球DevOps状态调查报告系列将为你呈现更新版本的DevOps能力成长模型，进一步讲解如何应用今年分化出来的两个研究模型：SDO和组织效能模型与生产力模型。\n ",
    "ref": "/blog/2019-state-devops-report-insight-1/"
  },{
    "title": "2019年加速度DevOps状态调查报告-导读",
    "date": "",
    "description": "新鲜出炉的状态调查报告会揭示什么？",
    "body": "凭借六年多的来自全球31,000多名专业人士的数据的研究，2019年加速发展状态报告是同类研究中规模最大、持续时间最长的研究。2019年加速度DevOps状态调查首发，首发的位置在Google Cloud网站上的Blog栏目，发布于产品新闻分类下。\n  文章使用的主标签 DevOps 、SRE。    文章地址：https://cloud.google.com/blog/products/devops-sre/the-2019-accelerate-state-of-devops-elite-performance-productivity-and-scaling  下文为对Google文章原文的翻译和整理。并且加入了我本人的各种判断和见解。\n关于今年的DevOps状态调查报告有什么更新和变化？报告文章中给我们了一句话的概要介绍：今年会对部署工具链、云计算、灾难恢复和工作方式等主题进行深度调查。更详细的情况，详细的参过问卷调查的您自有评判。\n‘DevOps之研究和评估’（DORA）是通过数据驱动的洞察力，帮助组织实现DevOps和高效能组织的先驱，而Google Cloud很高兴地宣布推出2019年加速DevOps报告 。（前期文章介绍过DORA加入Google Cloud的细节） 该报告提供了DevOps行业的全景视图，为各种规模和所有行业的组织提供可操作的指导，从而提高他们的软件交付效能，最终使之成为精英DevOps实践者。\n2019年的新洞见 我们看到：有持续的证据表明了软件的速度、稳定性和可用性有助于提高组织绩效，今年我们能够发现一些关于推动DevOps高绩效表现，以及实践和功能的新洞见。 部分如下所示：\n DevOps已经‘跨越了鸿沟’：各个行业的组织继续地提高着他们的DevOps专业知识，特别是在表现最高那部分人群中。 精英表现者的比例几乎提高了两倍，目前他们占所有组织的20％。 这也得到了其他行业分析师报告的证实。【教练解读：精英表现者实现了从7%到20%的增长。】    精英表现者更有可能使用云计算 ：快速自动扩缩容、成本可见性和可靠性是云计算提供的一些关键优势。更具国家标准与技术研究院（NIST）定义的云计算所具有的五项特征功能，效能最高的DevOps团队比低效能团队在这些方面执行的可能性高24倍，5大特性包括按需的自助服务、广泛的网络访问、资源池，快速弹性和可度量的服务。 【教练解读：你们家使用的云计算是假的。】\n  大多数云计算用户并未充分发挥其潜力 ：只有29％的使用云计算的受访者符合NIST上述的五项标准特征。 这证明了这样一个事实，即声称使用云计算的组织，未必采用了所有必要的云计算特征模式来实现精英水平的业绩，这也有可能会阻碍他们通过云计算获益。 【教练解读：你号称的优势正在阻碍你。】\n  首次呈现出了行业差异性 ：在今年的报告中，零售行业在速度和稳定性方面都展示出了更好的表现。然而，与前几年保持一致的是，根据持续的证据表明，DevOps更好或更差的表现，并没有其行业的差异性。这依然表明：各种类型和规模的组织，包括金融服务、政府和零售等高度监管的行业，也都是可以通过应用DevOps实践来实现高水平的绩效。【教练解读：今年零售业做的很突出，还是你们进来刷榜了？】\n  DevOps走进企业 - 第1部分 ：我们首次发现，根据证据显示大型企业组织（员工人数超过5,000人）的效能低于小型企业（员工人数少少于5,000人）。重量级的流程和控制措施，以及紧耦合的体系架构是导致较低速度，以及相关不稳定性的部分原因。【教练解读：大型组织的坑也更大。】\n  DevOps走进企业 - 第2部分 ：我们的分析显示最高能的DevOps表现者（即高级和精英表现者），专注于通过结构化的解决方案来构建DevOps社区，这些解决方案包括以下四种模式之一：社区建设者、大学、涌现和实验者（Community Builders, University, Emergent, and Experimenters）。【教练解读：需要给它山之石提供存在的土壤。】\n  没有“一刀切”的方法，成功有赖于一致的努力付出 ：在投资于DevOps的各项能力时，特别是在大型组织中，需要同时关注团队级别和组织级别的工作成果。在团队层面上，持续集成、自动化测试和监控等实践的一些工作投入运作良好。组织级能力包括：在多个部门和团队之间，设置系统体系结构或变更审批策略的能力。 该报告分解了这些能力并概述了应该采取的策略，因此您也可以执行相关的DevOps策略，并从中获得最大的效果。【教练解读：单纯的刷某个团队或者项目也是然并卵。】\n  表现较差的组织比高级和精英表现者使用的软件更多 ：维护和支持私有商业软件的成本可能过高，这促使高级和精英表现者使用开源解决方案。 这和以前报告中的结果一致。 事实上， 2018年的加速度 DevOps报告就表明，精英表现者大量使用开源组件、库和平台的可能性是其它组织的 1.75倍。【教练解读：开源软件正在吞噬着整个世界。】\n  你如何改进DevOps？ 今年的报告提供了有助于推动DevOps改进性能和生产力的两种研究模型。\n效能研究模型 着眼于哪些能让你提升组织绩效的结构和抓手，提供相关的云计算、持续交付、灾难恢复测试，明确变更管理和心理安全文化是如何对软件交付绩效产生积极作用的见解。 本次研究还发现重量级的变革流程是不起作用的。\n图片翻译参考：\n 左侧的一列，从上至下：清晰的变更流程、重量级变更流程、灾难恢复测试、代码的可维护性、松耦合的架构、监控、主干开发、自动化部署。 中间的一列，从上至下：心理安全感文化、持续交付、云计算、持续集成、自动化测试。 右侧的一列，从上至下：行业（控制）企业（控制）、工作恢复、透支 图例，从上至下：结构、二级结构、团队或者组织的统一目标、控制变量、正向预测关系、双向影响、负面影响关系、粗体字-今年新的调查结果（左侧1～4，中间1）  生产力研究模型 表明：组织可以通过投资易于易用的工具和信息搜索引擎、心理安全文化，以及消除技术债务的方式来提高工程师的生产力。 提高生产力还有助于提高员工的工作-生活平衡，并降低职业透支（教练注释-996icu）。\n图片翻译参考：\n 左侧的一列，从上至下：实用且易用的工具、内部搜索引擎、外部搜索引擎、代码可维护性。 中间的一列，从上至下：心理安全感文化、生产力、技术债、松耦合的架构、监控。 右侧的一列，从上至下：多年的经验（控制）、SDO效能、软件交付效能、可用性、组织级效能、透支 图例，从上至下：结构、正向预测关系、负面影响关系、团队或者组织的统一目标、控制变量、弱关联性、粗体字-今年新的调查结果（左侧1～4，中间1～2，右侧2）  今年的报告再次确认了连续第六年各种重要发现：首先，可以在不牺牲速度的情况下优化稳定性。 其次，DevOps通过影响商业和非商业目标为​​客户和最终用户提供价值。\n感谢为调查做出贡献的所有人。 我们希望此报告能够帮助各种规模，行业和地区的组织改进。 我们期待听到您对报告的想法和反馈。 您可以通过以下方式了解有关2019年加速状态报告的更多信息。\n相关材料和扩展 报告尝鲜试读 报告封面 关注点：DORA + Google， 新的赞助商的支持。\n报告目录 目录结构很类似，内容大不同。\nDevOps四大核心度量指标 四个级别的表现者在四大度量维度上的比较，以及今年的数据更新。\n精英表现者 他们始终遥遥领先。重点是所有的指标同时都好。\n两大研究模型的分化  效能模型 生产力模型  灾难恢复测试 灾难恢复测试和DevOps强相关。\n心理安全性 文化建设的一个关键组成。\nDevOps转型的策略一览表 你们都用了哪些推广DevOps的策略呢？抱歉并没有刷成熟度这一项。\n下载报告 目前Google的官网上提供了所有DORA的DevOps状态调查报告的下载包括2019年度最新的状态调查报告。为了方便国内DevOp实践者的学习，我将它下载到了百度网盘。请大家需要的按照一下方法下载阅读。\n报告下载方法：\n 扫码下面的二维码，关注DevOps教练的微信公众号 进入DevOps教练的微信公众号的文字输入状态 输入数字 ： 2019 识别自动回复的二维码 下载pdf版本的2019加速度DevOps状态调查报告  使用2019调查问卷服务 前面的文章发布了2019DevOps问卷调查的中文翻译版本，https://martinliu.cn/posts/2019-state-devops-survey-chinese-version/ 这是对原版英文调查问卷的翻译，由中国DevOps社区翻译组完成，现在我们已经将它通过问卷星平台转化成了可以使用的调查服务。\n如果你的企业正在实施DevOps，如果你想了解一下这种称之为DevOps的科学的调查问卷，不妨可以通过下面的流程申请使用这个问卷服务：\n 发邮件到 info@DevOpsChina.org ；邮件标题为 dora 2019 邮件内容请包含：公司名称、使用范围（全公司、团队）、使用其实时间、联系人姓名、联系人手机/微信、调查问卷的套数（题套问卷对应一个网站，可下载一份数据采集结果） 本服务为免费社区服务，在收到邮件后就会尽快为您提供所需要数量的网址，并在约定的结束时间发送调查结果到你的邮箱。  后续 经过了多年对这项行业顶级调查问卷和报告的追逐。今年的报告内容量大，新发现多，而且引入了新的研究模型。我会从内容和模型层面做更多的总结和研究。后续用一系列的文章进行报道。请关注“DevOps教练”微信号的更新文章和本网址的更新。\n ",
    "ref": "/blog/2019-state-devops-survey-report/"
  },{
    "title": "中文版：2019年DevOps状态调查问卷",
    "date": "",
    "description": "看看DevOps度量的科学方法",
    "body": "本文是中文版《2019年加速度DevOps状态调查》问卷。如果你还没有填写该问卷的话，可以在线上填写英文版，点击这个链接 https://bit.ly/2UzLMH2 ，进入问卷调查网站。本文可以作为你的帮助文档。\n 译者团队：刘征、张晔、刘頲、朱婷、王英伟、王虹、李建芳、沈越飞、井建宇、申屠欣欣\n 本文由以上翻译团队经过两周的时间，在业余时间翻译完成，如果对本文有任何改进建议请发邮件到 martin AT DevOpsCoach.org\n发布本文的另外一个原因：作为历时6年，被称之为DevOps界之科学的调查研究，我们可以透过这套问卷，洞察如何用问卷的方式定量的度量DevOps的现状。对于已经实施了多年DevOps企业，本问卷可谓是一道营养丰富的大餐。\n历年来的DevOps状态报告 如果你需要下载学习的话，请点击下面的链接（扫码二维码），这里还有历年来英文版报告全集和部分中文版本。\n 下面是2019年DevOps状态调查问卷的简体中文版译文。\n第一部分 欢迎参加2019年全球DevOps全球行业调查。\n 我们有兴趣了解您的工作方式以及工作环境。  答案并没有对错。  如果您不知道答案，可以选择“我不知道或不适用”，您的作答将被忽略。  非常感谢您花时间帮助我们去探索那些能使技术进步的秘密！\n1. 您的组织主要属于哪个行业？  教育 能源 金融服务 政府 医疗保健和制药 工业与制造业 保险 媒体/娱乐 非盈利 零售/消费品/电子商务 技术 电信 其他。请明确说明： [____]  2. 有多少员工在您的组织里工作？  1-4 5-9 10-19 20-99 100-499 500-1,999 2,000-4,999 5,000-9,999 10,000+ 我不知道  3. 你们的服务器上都部署了哪些操作系统？   Windows 2003 / 2003R2 Windows 2008 / 2008R2 Windows 2012 / 2012R2 Windows 其他 Linux Debian / Ubuntu变种 Linux Enterprise Linux变体（RHEL，Oracle，CentOS） Linux Fedora Linux SUSE Linux Enterprise Server Linux OpenSUSE Linux Arch Linux其他 其他的UNIX FreeBSD / NetBSD / OpenBSD系统 AIX Solaris 其他  4. 在过去一年中，关于下列绩效指标，您的组织实现的程度如何？  您组织的整体表现 您组织的整体盈利能力 主要产品的相对市场份额 客户数量增加  （表现远低于目标 表现低于目标 略低于目标 达到了目标 略高于目标 表现高于目标 表现远高于目标 不适用或我不知道）\n5. 我们也有兴趣了解其他一些目标。 选择指示您的组织在过去一年中如何针对以下目标执行的选项  产品或服务的数量 运营效率 消费者满意度 所提供的产品或服务的质量 实现组织的/使命的目标 通过其它的方面向外部各方证明了贵组织实现预期成果  （表现远低于目标 表现低于目标 略低于目标 达到了目标 略高于目标 表现高于目标 表现远高于目标 不适用或我不知道）\n6. 我们有兴趣了解DevOps或敏捷方法是怎样在您组织的各个团队中传播的。  在这里，我们将描述我们看到过的那些常见的模式，并要求您从中选择出哪些在自己的组织中最常见方式（请选择所有适用的选项）\n  培训中心（有时也称为DOJO） - 让人们暂时脱离正常的工作惯例，以便在一段时间内学习新的工具或技术、实践甚至文化，然后再回到正常的工作环境中，目标（希望？）是：他们会坚持使用新的工作方式，甚至可能推广给其他的人。\n  卓越中心 - 一个所有专业知识都具足，然后为内部各方提供咨询的地方。\n  止步于概念证明 - 进行概念证明（PoC）项目，通常执行团队可以突破组织规范（通常是官方的规则）的羁绊，从而自由的按照所认为的最好的方式构建。然而，在PoC之后，那些付出就停滞不前了。\n  用概念证明当模板 - 也是从小规模的概念证明（PoC）项目（如上所述）开始，然后开始使用这个最初的模式在组织中的其它团队进行复制。\n  用概念证明做种子 - 也是从小规模的概念证明（PoC）开始，然后将PoC知识传播给其他团队。这是通过打散PoC（可以是第一个PoC团队，或是后续/并行的PoC团队）执行团队，并将他们派发到其他团队，去分享他们所学到的知识和实践的方式来完成的。也可以称此为轮岗，那些前PoC团队成员沉浸在其他团队中，发挥着传播新的实践和文化，并兼做导师的职责。他们可能会无限期地留在这个新的群体中，或者只是用足够长的时间来确保，他带来的新的做法是可持续的。\n  实践社区 - 在组织内培养对工具、语言或方法有共同兴趣的团体，以便在他们的彼此之间、团队之间，以及在组织内部分享他们的知识和专业技能。\n  大爆炸式 - 组织进行整体一次性的DevOps方法（当然他们要选择对其下的定义）转型，通常采用自上而下的指令。\n  自下而上或草根方式 - 那些在一线工作的小团队将资源整合在一起，然后在整个组织中，通过非官方的形式分享所取得的成功，并进行推广，而无需任何组织官方的支持或资源。\n  混搭型 - 组织实施过了上述的若干种方法，通常由于无法得到成功所需的资源和重视，只能是半途而废了。\n  第二部分 这部分涉及您的工作及其成果，以及它对您自身的影响。\n1. 在你工作的过程中，你的感受是怎样的？  请评价您对以下陈述的同意或不同意程度。\n 我经常处于高水平的生产力 我经常能够进入一个良好的“流程”，在那里我可以完成复杂、耗时的任务，同时最大限度地减少干扰和中断。 我对我的工作很满意。 我有足够的工具和资源来完成我的工作。 我的工作很好地利用了我的技能和能力。  （强烈反对 不同意 不太同意 既不赞成也不反对 有点同意 同意 非常同意 我不知道/不适用）\n2. 对于您工作的主要应用程序或服务，变更前置时间（即：从代码提交到在生产中成功运行的过程需要的时间）是多长？  超过六个月 一个月到六个月之间 一周到一个月之间 一天到一周之间 不到一天 不到一个小时 我不知道或不适用  3. 对于您工作的主要应用程序或服务，您的组织在生产环境进行代码部署或向最终用户做发布的频率是什么？  每六个月少于一次 每一到六个月一次 每周到每月一次 每天到每周一次 每小时到每天一次 按需（每天都要进行多次部署） 我不知道或不适用  4. 对于您工作的主要应用程序或服务，当服务中断或出现影响用户Bug时（如：计划外中断、服务受损），恢复服务通常需要多长时间？  超过六个月 一个月到六个月之间 一周到一个月之间 一天到一周之间 一天之内 一小时之内 我不知道或不适用  5. 对于您所工作的主要应用程序或服务，对于生产变更，或向最终用户发版的变更，百分之多少会导致服务质量下降（如：服务受损或服务中断），并需要进行后续的修复工作（需要热补丁、回滚，前向修复，打补丁修复）  0％-15％ 16％-30％ 31％-45％ 46％-60％ 61％-75％ 76％-100％ 我不知道或不适用  6. 接下来的问题会询问可靠性，以及您和您的团队如何看待它。  请评价您对以下陈述的同意或不同意程度。 对于您所工作的主要应用程序或服务：\n 定义了明确的可用性目标（如服务级别协议/服务级别目标），这些目标在团队和客户之间达成了清晰的共识。 我知道最近一段时间实际的可用性。 在最近一段时间内，我的团队达到或超过了可用性目标。 当我们未达成可用性目标时，就会进行改进工作，也或将对调整工作的优先级。 如果使用云服务，我的团队就会借助云计算的高可用性（如：使用多个可用区）来提高可靠性。  （强烈反对 不同意 不太同意 既不赞成也不反对 有点同意 同意 非常同意 我不知道/不适用）\n7. 工作的可持续性很重要，而职场透支是一个相关的重要度量指标。您能否回答几个问题，让我们知道您的工作对您有何影响？  请评价您对以下声明的同意或不同意程度：\n 我感觉透支很严重。 我感到筋疲力尽。 我对所从事的工作无语或愤世嫉俗。 我觉得工作效率低下。 我觉得工作应对业余的正常生活产生负面影响。 我能够完成工作并保持良好的整体状态。 我能够有效应对与工作有关的压力。 我可以在业余时间中（即，当我选择不工作时）脱离工作。  （强烈反对 不同意 不太同意 既不赞成也不反对 有点同意 同意 非常同意 我不知道/不适用）\n第三部分 当你回答以下问题的时候，请回想一下你在团队中的经历\n1. 请评价您对以下声明的同意或不同意程度：  如果我对我们的团队犯了错误，也不会有不良影响。 我们团队的成员能够发现问题和提出棘手的问题。 我们团队的成员不会因为差异性而互相拒绝。 对我们的团队而言冒风险是安全的。 想让我们团队的其人提供帮助并不困难。 我们团队中没有人会以任何形式故意破坏我的工作成果。 团队非常重视我独特的技术和才能。 我们的团队能够在出现冲突时解决冲突。 我们团队内部有很高的信任度。  （强烈反对 不同意 不太同意 既不赞成也不反对 有点同意 同意 非常同意 我不知道/不适用）\n2. 当你回答以下问题时，回想你是如何和你的团队合作的 请评价您对以下声明的同意或不同意程度：\n 当我的团队成员之间存在相反的意见时，我们会互相尊重。 我可以依靠我的团队来产出高质量的成果。 我的团队提供了一个可以创新的环境。 我的团队有明确的角色和责任。 我的团队所承担的项目对我来说具有个人和专业意义。 我能够获得有效完成工作所需的必要的信息（例如，战略、新产品、组织变革，我们的优先事项和价值观）。  （强烈反对 不同意 不太同意 既不赞成也不反对 有点同意 同意 非常同意 我不知道/不适用）\n3. 回想一下你的团队是如何工作和组织的 请评价您对以下陈述的同意或不同意程度。\n对于您使用的主要应用程序或服务：\n 为了完成我自己的工作，我不需要与团队外的人沟通和协调。 在我的团队中，我们可以对系统的设计进行大规模更改，而无需为其他团队创建重要的工作。 在我的团队中，我们可以对系统的设计进行大规模更改，而不用依赖于其他团队的大量工作。 我的团队可以根据需要独立部署和发布我们的产品或服务，而不依赖于其依赖的其他服务。 我们可以按需的进行大部分的测试，而无需等待一个集成测试环境。 在我的团队中，我们在正常工作指端中执行部署，停机时间可忽略不计。  （强烈反对 不同意 不太同意 既不赞成也不反对 有点同意 同意 非常同意 我不知道/不适用）\n4. 最后，我们想了解一下您的组织文化。 请评价您对以下声明的同意或不同意程度：\n 我的组织氛围宜人，重视各种不同的观点。 我的组织是一个所有类型的员工（例如，所有性别，种族，文化背景）都能够完全发挥其能力的地方。 当我在组织中发言时，我的意见很受重视。  （强烈反对 不同意 不太同意 既不赞成也不反对 有点同意 同意 非常同意 我不知道/不适用）\n第四部分 这部分关于你所处环境中知识是如何供给和获取的。 让我们换个角度，告诉我们您的日常工作。\n1. 当您工作时，您会在哪里寻找信息？  当我需要相关知识用于解决问题时，我会频繁访问外部信息（如Stack Overflow、百度等）。 当我遇到具有挑战性的问题，需要寻找类似问题的解决方案时，我经常访问外部信息 (如Stack Overflow、百度等)。 当我处理困难的任务时，我经常和可能遇到类似问题的人沟通。 当我需要工作相关主题或问题的知识时，我经常与其他人讨论。 在处理任务时，我经常会参考内部知识库或工具来帮助找到解决方案。 当我处理具有挑战性的问题时，我经常搜索内部工具或代码库以便找到类似问题或示例的解决方案。 当我有疑问或寻找代码示例时，我经常搜索组织的源代码库 当我有疑问或遇到有挑战的问题时，我会搜索内部文档  (强烈反对 不同意 不太同意 既不赞成也不反对 有点同意 同意 非常同意 我不知道/不适用)\n2. 当您遇到问题时，您会定期检查哪些信息来源？请选择所有适用项  内部(组织)知识库、论坛或文档 内部(组织)代码库 Stack Overflow 网站 在线教程和视频 百度、Bing或其它类似的公开搜索引擎 外部(公共)参考文档 当面请教同事 通过电子邮件、文本或聊天工具请教同事 朋友或同行(如微信、网络兴趣组、微博等) 您自己的个人笔记 其它。请填写 以上都不是  (强烈反对 不同意 不太同意 既不赞成也不反对 有点同意 同意 非常同意 我不知道/不适用)\n第五部分 这部分关于你的角色，以及你们团队做变更的特征和模式等。\n1. 现在让我们谈谈您工作时的感受。 无论您的正式职位是什么，让我们谈谈您所做的工作。在您的日常工作中，您负责多少个不同的角色（或工作类型）？请选择所有适用项\n 软件开发 测试 基础设施/运营 数据库管理 信息/应用安全 人员管理 项目或产品管理 文档 需求分析 用户体验 随时待命/事件响应 其它。请列出您执行的其他角色  2. 您每天在这些角色之间切换多少次？  不想回应 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20或以上  3. 您现在正工作在多少个项目或产品上？  不想回应 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20或以上  4. 您通常在一周中工作在多少个项目上？  不想回应 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20或以上  5. 思考下你过去3个月的工作。 请以这些记忆里的工作对以下陈述进行回应。 我遇到过的代码，脚本，配置或系统\u0026hellip;\u0026hellip;\n 包含已知的错误，这些错误不支持新功能开发 没有足够的测试或测试覆盖率 与低下的代码质量或设计有关 取消或放弃项目后尚未进行清理 在我所在的团队中没有人有专业知识能够理解 有不完全或不正确的迁移 使用了过时的技术 文档和/或注释存在缺失、不完整或过时的情况  6. 现在思考在你的组织中的进行变更及相应流程是什么样的。 在我的组织中\u0026hellip;\u0026hellip;\n 在实施或部署之前，必须由外部机构（例如，变更审批委员会，经理等）批准生产变更 我的组织有一个正式的流程来批准在实施或发布之前对应用程序或生产系统进行变更。 我清楚地了解批准实施​​变更的流程 我相信我能够及时通过审批流程来实施变更 对于我通常所做的各类变更，我知道每次从“提交”到“已接受”所需的步骤。 我们依靠同事的同行评审（例如代码审查或结对编程）来管理或批准变更。 我的团队遵循基于风险的政策来批准变更，通过自动化方法推进低风险变更，只有高风险变更才需要人工批准。 所有重大变更必须在实施前由高级经理批准  第6部分 对于此页面上的问题，请思考你为测试生产系统的弹性所做的工作。\n1.以下哪些活动用于测试我们的IT系统/服务的弹性？  未在真实系统上进行沙盘推演 基础设施（包括数据中心）故障转移 应用程序故障转移 模拟破坏类生产的测试系统（包括故障注入、如降级网络链路、关闭路由器等） 模拟破坏生产系统（包括故障注入，如降级网络链路，关闭路由器等） 创建自动化和系统，定期，持续地破坏生产系统 其他。 请明确说明： 以上都不是  2. 你所在的组织多久执行一次中断生产系统的模拟（包括故障注入，例如降级网络链路、关闭路由器等）  从不 仅在初次部署 按周 按月 按年 少于一年一次 不知道或不适用  3. 你所在的组织多久执行一次基础设施（包括数据中心）故障转移以测试弹性？  从不 仅在初次部署 按周 按月 按年 少于一年一次 不知道或不适用  4. 你所在的组织多久执行一次应用程序故障转移以测试弹性？  从不 仅在初次部署 按周 按月 按年 少于一年一次 不知道或不适用  5. 如果我的组织在灾备演习时发现了任何改进的机会，我们会创建行动任务并在下一次演习前修复这些改进项。  非常同意 同意 有点同意 既不赞成也不反对 不太同意 不同意 强烈反对 不适用或我不知道  第七部分 此页将会询问您或您的组织关于云应用的一些问题\n1. 我主要负责的产品或服务在哪运行？（请选择所有适用的选项）  公有云（包含多个公有云） 私有云 混合云（将公有云和私有云/数据中心/本地设施结合在一起） 在数据中心或本地（不是云） 我桌面下的一个小服务器 其他   2.采用多个云提供商的驱动因素是什么？（请最多选择3个）  我们只有一个云提供商, 或者我们没有使用公有云 法律合规性 灾备可用性 对一个供应商缺乏信任 利用每个提供商的独特优势 谈判策略或采购要求 其他  3.请评价您对以下陈述同意或不同意的程度  我主要负责的产品或服务最初是设计在云中运行或基于云设计架构的。 对于我主要负责的产品或服务, 环境配置和部署仅使用存储在版本控制库中的脚本和信息, 无需手动步骤 (审批除外)。  (强烈反对 不同意 不太同意 既不赞成也不反对 有点同意 同意 非常同意 我不知道/不适用)\n4.请评价您使用云服务时对以下陈述的同意或不同意程度。  一旦我有了访问权限, 我就可以根据需要独立地配置和配置产品或服务所需的云资源和功能, 而无需提高票证或需要人工交互。 我主要负责的服务或产品设计为通过网络从各种设备 (如智能手机、平板电脑、笔记本电脑) 访问, 而不需要专有插件或协议。 我的产品或服务所运行的云，服务于多个团队和应用程序, 并根据需要动态分配和重新分配计算和基础架构资源。 我可以根据需求动态地增加或减少可用于主要支持的服务或产品的云资源。 我可以监视或控制我主要支持的服务或产品所使用的云资源的数量和成本。  (强烈反对 不同意 不太同意 既不赞成也不反对 有点同意 同意 非常同意 我不知道/不适用)\n5.换个主题，在您工作的时候，您是怎样看待成本的？  我的团队可以准确地估计操作我们软件的成本。 我的团队可以轻松识别我们运营成本最高的应用程序。 我的团队很少超出我们的成本费用或支出预算。  (强烈反对 不同意 不太同意 既不赞成也不反对 有点同意 同意 非常同意 我不知道/不适用)\n第八部分 关于版本控制系统、分支模型、自动化测试、持续集成、持续交付等一直到生产环境的反馈等等实践。 现在让我们谈谈您和您的团队所做的技术工作。\n1.请介绍一下您和您的团队如何开发软件。我的团队：  我们的组织将所有代码存储在一个单一庞大的版本控制存储库中 组织中所有工程师都可以查看和搜索组织中所有代码 我可以在自己之外的项目中编辑代码，并适时提交 我们将应用程序的所有依赖项源代码（例如软件库）都存储到版本控制存储库中 我们为发行版本创建的所有包，包括依赖项，都是在单个版本控制中创建的，而不是从多个版本或分支中创建的  (强烈反对 不同意 不太同意 既不赞成也不反对 有点同意 同意 非常同意 我不知道/不适用)\n2.我们关注您工作中使用什么代码，请评价您对以下陈述同意或不同意程度  如果需要，我们很容易更改其他团队维护的代码 我很容易在代码库中找到示例 我经常从团队之外的工程师那里收到项目的更新。 我很容易重新使用别人的代码 我很容易对我的项目增加新的依赖项 我很容易移动新的依赖项版本 我的依赖项是稳定的很少破坏我的代码  (强烈反对 不同意 不太同意 既不赞成也不反对 有点同意 同意 非常同意 我不知道/不适用)\n3.我们关注您在工作中遵循的开发实践和模式。  我团队中的所有开发人员至少每天都会将代码推送到trunk / master 应用程序的代码库中不到三个活动分支 我们的应用程序团队从来没有代码锁定期，任何时候没有人可以签入代码或由于合并配置而执行请求。 在合并到master之前，分支和分叉的生命周期非常短（不到一天）。  (强烈反对 不同意 不太同意 既不赞成也不反对 有点同意 同意 非常同意 我不知道/不适用)\n4.下一组问题是关于在工作中提交代码、搭建和部署软件。 对于您使用的主要应用程序或服务：\n 代码提交会自动生成软件 代码提交会运行一系列自动化测试 每天成功地执行自动化的构建和测试 当构建中断时，它通常在十分钟内修复  (强烈反对 不同意 不太同意 既不赞成也不反对 有点同意 同意 非常同意 我不知道/不适用)\n5.许多团队使用自动化测试来优化他们的软件 请评价您对以下陈述的同意或不同意程度 回答这些问题时，请考虑您自己的测试过程：\n 当自动化测试通过时，我确信软件是可发布的 自动测试失败可能表明存在真正的缺陷 开发人员很容易重现和修复验收失败的测试 我们测试必要的数据，以便每一步都能轻松运行自动化测试 我可以在十分钟内从自动测试中得到反馈 我们经常使用之前的测试运行数据来提高自动化测试套件的质量  (强烈反对 不同意 不太同意 既不赞成也不反对 有点同意 同意 非常同意 我不知道/不适用)\n6.请评价您对以下陈述的同意或不同意程度 对于您使用的主要应用程序或服务：\n 我们的软件在整个生命周期中都处于可部署状态 我的团队优先考虑保持软件可部署而不是处理新功能 团队中的任何人都可以获得系统在质量和可部署性方面的快速反馈 当人们得到系统不可部署的反馈时（例如构建或测试失败），他们将优先解决这些问题 我们可以根据需要随时将我们的系统部署到生产或最终用户  (强烈反对 不同意 不太同意 既不赞成也不反对 有点同意 同意 非常同意 我不知道/不适用)\n7. 请结合自己的测试过程回答以下问题：  当通过自动化测试后，我相信软件是可发布的。 自动化测试失败表明存在真正的缺陷。 开发人员很容易重现并修复验收测试发现的缺陷。 我们有必要的测试数据，用于每个步骤中轻松地运行自动化测试。 我可以在10分钟内收到自动化测试反馈。 我们经常使用以前测试运行的数据来提高自动化测试套件的质量。  (强烈反对 不同意 不太同意 既不赞成也不反对 有点同意 同意 非常同意 我不知道/不适用)\n8. 对于您工作的主要应用或服务：  我们的软件始终处于可部署的状态。 在我的团队中，保持软件处于可部署状态的优先级高于实现新需求。 任何团队成员都可以快速反馈系统的质量和可部署性。 团队成员将修复导致系统无法部署的问题（如编译失败、测试失败等）置于最高优先级。 我们可以随时根据需要将系统部署到生产环境或最终用户。  (强烈反对 不同意 不太同意 既不赞成也不反对 有点同意 同意 非常同意 我不知道/不适用)\n9. 对于您工作的主要应用或服务，实现完全自动化部署到生产环境或最终用户的比例是：  0%-15% 16%-30% 31%-45% 46%-60% 61%-75% 76%-100% 我不知道或不适用  10. 对于您工作的主要应用或服务，部署过程需要多长时间才能使软件新版本可供用户使用：  小于1小时 在1小时和1天之间 在1天和3天之间 在3天和1周之间 在1周和1个月之间 大于1个月 我不知道或不适用  11. 您如何监控和了解正在运行的系统：  我的团队有一套技术解决方案用以报告系统的整体健康状况（如系统功能是否正常？系统是否有充足的可用资源等？）。 我的团队有一套技术解决方案用以报告基于用户使用情况的系统状态（如用户是否知道系统已关闭，是否有不良的体验等？）。 我的团队有一套技术解决方案用以监控主要业务和系统参数。 我的团队有工具用于协助我们了解和调试生产环境上的系统。  (强烈反对 不同意 不太同意 既不赞成也不反对 有点同意 同意 非常同意 我不知道/不适用)\n第九部分 这页面询问了一些细节关于您的技术环境和工作\n请选择以下之一\n1. 为了部署我们的软件解决方案，我的团队使用以下CI / CD /测试自动化工具链  主要是内部开发（自研）的，且所有权属于我的组织 混合使用专有工具，开源和商业现成软件 主要是开源和商用现货，高度定制 主要是开源和商用现货，很少定制 主要是商业现成的套装软件 主要是开源的，高度定制 主要是开源的，很少定制 其他 不适用或我不知道  2. 请评价您对以下说法的同意或不同意程度  在我的团队中，与组织中的其他团队相比，我们的CI/CD/自动化测试过程和工具是为我们的需求而定制的  (强烈反对 不同意 不太同意 既不赞成也不反对 有点同意 同意 非常同意 我不知道/不适用)\n3. 请评价您对以下说法的同意或不同意程度。 通过CI / CD工具链部署软件时：  使用CI / CD工具链可以提高我的效率在我的工作中 使用CI / CD工具链在我的工作中提高我的生产力 使用Ci/CD工具链提高了我的工作效率 我发现CI / CD工具链在我的工作中很有用。  (强烈反对 不同意 不太同意 既不赞成也不反对 有点同意 同意 非常同意 我不知道/不适用)\n4. 请评价您对以下说法的同意或不同意程度。 通过CI / CD /测试自动化工具链部署软件时：  我的交互在工具链是清晰易懂的 与工具链交互并不需要我的大量精力 我发现工具链容易使用 我发现容易让工具链做我想要做的事  (强烈反对 不同意 不太同意 既不赞成也不反对 有点同意 同意 非常同意 我不知道/不适用)\n5. 选择最能代表谁负责创建和维护CI / CD /测试自动化工具链及其配置的选项：  我们的团队有完全自治选择和配置自己的CI / CD /自动化测试的工具链。 我们需要使用一个统一工具链，但是我们为构建/测试/部署过程维护自己的脚本，并且在配置方式上有很多自主权。 我们需要使用一个统一工具链具有预配置脚本和构建步骤，测试和部署过程的步骤，我们可以根据需要重构或自定义。 我们需要使用带有预配置脚本和步骤的统一工具链，而我们几乎没有能力重构它 所有构建，测试和部署软件，都由我们建立的统一团队处理 不适用或我不知道  6. 我的工具链包括以下内容（请选择所有适用的选项）  自动化构建 自动化单元测试 自动化验收测试 自动化性能测试 自动安全测试 自动化配置和部署到测试环境 自动化部署到生产 与chatbots / Slack集成 与生产监控和可视化工具集成 以上都不是  第十部分 最后一页！请花几分钟时间告诉我们你自己。 请注意，此数据仅用于研究目的，此调查是匿名的，仅以匿名方式汇总报告。\n1. 你的性别？  男 女 非二元 不想回应  2. 在您的团队中工作的女性比例是多少？ 请输入0到100之间的数字。  女性团队的百分比： [___] 不想回应  3. 您是否认定为少数派群体的成员？  是 没有 不想回应  4. 你认定是残疾人吗？ 包括与视觉，听觉，步行，记忆/集中，自我保健或沟通相关的残疾\n 是 没有 不想回应  5. 哪个最贴切地描述了你的工作角色？  开发或工程师 DevOps或SRE 信息安全 IT运营或基础设施 网络运营 产品管理 用户体验或软件分析 经理 专业服务 质量工程师或QA 发布工程师 销售工程师 销售或营销 我是顾问、教练或培训师 我是C级高管 我是学生 我不属于任何部门 其他 不想回答  6. 你有多少年的经验？  0-2 3-5 6-10 11-15 超过16 不想回应  7. ­­­­­请选择您所在的地理区域：  非洲 亚洲 中美洲 东欧洲 欧洲联盟 中东 北美 大洋洲 南美洲 加勒比  总结 本文是否帮你解答了这样一个疑问：每年的DevOps状态报告中的参考数据是从哪里来的？是通过什么方式采集的？到目前为止，我们还不清楚这些数据是通过什么打分规则和算法处理的。如果你是这方面的专家，请和我们分享以下你的观点。\n",
    "ref": "/blog/2019-state-devops-survey-chinese-version/"
  },{
    "title": "2019年DevOps状态调查问卷开放中",
    "date": "",
    "description": "在问卷中反思自问，仔细作答，并观察自己的相对位置",
    "body": "2019年加速度DevOps状态调查首发，首发的位置在Google Cloud网站上的Blog栏目，发布于产品新闻分类下。\n 文章使用的主标签 DevOps 、SRE。 文章地址：https://cloud.google.com/blog/products/devops-sre/make-your-voice-heard-take-the-2019-accelerate-state-of-devops-survey  关于今年的状态调查有什么更新和变化，文章中只给出了一句话的概况：今年会对部署工具链、云计算、灾难恢复和工作方式等主题进行深度调查。更详细的情况，详细你参与完问卷调查只有自由评判。\n如何参与2019年DevOps状态调查 点击这个链接 https://bit.ly/2UzLMH2 ，进入问卷调查网站。\n从围观到参与是一种积极的态度。与其观望这份行业报告的产生过程，倒不如参与其中。由于今年这个问卷调查是Google发起的，可能会有更多的人会参与。\n精通英文的人应该能在半个小时内完成这个调查。如果英文不好的话，最多也用不了2个小时，以上推测，基于我去年的填写经历。\n我还想发起一个基于这个调查的兴趣小组，请符合以下条件之一的人进微信群交流：\n 正在认证填写这份问卷，想从群里获得必要的帮助，从而可以能正确的作答。 想研究这份文件的题库，大家共同分析DORA设问的目标和结构。 跟进一步的，交流关于DevOps度量方面的话题  关于2018年的DevOps状态报告 有幸去年策划和参与了这份报告的翻译工作。也算是相对其他人更深入的学习和研究了去年的结果。并对它的总结和推论都有非常深刻的印象，也受益匪浅。\n2018年DevOps状态调查报告的中文版本，在2018年DevOpsDays 深圳大会上做了发布，我也在台上和张乐一起向与会者做了简短的分享。如果你需要下载学习的话，请点击下面的链接（扫码二维码），这里还有历年来英文版报告全集和部分中文版本。\n在2018年里Nicole Forsgren博士发布了《Accelerate》这本书，书里算是对这场从2014年开始的，持续对年的行业专项调查研究的一个总结。书中对度量DevOps这个主题做了详解科学的解读，它是那些需要度量DevOps成果的组织的一本很好的参考书。中文版本据说在翻译的过程中，期待它的出版。等不及的话可以去国外买英文电子版，这本书我是读了不下三遍，也做了相关的分享演讲，确实有很多收获。\n分享几个我观察到的小细节：\n DORA在2018年结束了与Puppet公司的合作调查，因此2018年的报告标题中增加了一个单词“加速度”，即：2018 Acclerate State of DevOps Report； 以前的都叫做 xxxx年 State of DevOps Report。 Puppet公司也没有闲着，Puppet和Splunk公司携手也进行了状态调查和分析，也发布了名为《2018 State of DevOps Report》，问卷的问题肯定和以前无法延续和持续的，但是报告的命名保持下来了。我猜这也是为何DORA的报告需要加一个词的原因，  总结一下，由Nicole Forsgren博士主持进行的DevOps状态调查报告的下载站点都在 https://puppet.com/resources/whitepaper ， 在这里依然可以下载到名为 2018 State of DevOps Report 的报告，但是这一个和Nicole博士无关；所有她主持的报告下载地址在她的DORA网站上 https://devops-research.com/research.html 。 在DORA加入了Google Cloud以后，Nicole博士主持的调查问卷名为“ Accelerate State of DevOps Report” ； 相信我们所期待的最终的分析结果的标题应该是“ 2019 Accelerate State of DevOps Report” ； 而Puppet公司应该还是会持续发布名为“2019 State of DevOps Report”的报告。我相信肯定会有很多人在2018年去年就有点晕了，怎么出来两个名字相似，可是内容大相径庭的DevOps状态报告。\nDevOps背后的科学：访谈Nicole Forsgren 最近在Nicole Forsgren正式发布了2019年的DevOps状态调查报告之后，她接受了RealWorldDevOps电台的访问。Nicole Forsgren保持这一贯的爽朗、认真和理性的特点，与电台主播迈克进行了42分钟的畅谈。\n 访谈英文原文：https://www.realworlddevops.com/episodes/the-science-behind-devops-with-dr-nicole-forsgren 在这个页面上还可以收听或者下载这期访谈节目。 英文原文的翻译版本（Google机器翻译，为修订）见下文。 访谈中的几个关键内容（并不是所有观点）：  2014年开始DevOps状态调查分析和报告工作 这项工作前期与Puppet公司合作进行 Nicole和Jez Humble建立了独立的DORA，即DevOps Research \u0026amp; Assessment公司 https://devops-research.com/ 2018年12月DORA被Google收购，Nicole加入Google后，Google将作为DORA的特别调查样本和支持公司，保持DORA持续进行。 Nicole叙述了最有意义的三件事：架构高于技术，云计算很重要，外包是不起作用的。    在这次访谈中，我们也可以听出一点关于这个行业调查的宗旨和调性。紧跟时代发展步伐，每年做一定的突破和更新，保持厂商/工具无关性等等。具体内容详见下面的机器翻译文字。\n访谈笔录 以下为电台网站英文版本的直接机器翻译，未做修订，不保证能够被人正确理解；有疑问的地方请参考英文原文和访谈音频。\n 迈克朱利安：这是真实的世界DevOps播客，我是你的主持人迈克朱利安。我正准备在DevOps世界中遇到最有趣的人。从您喜爱的工具的创作者到精彩会议的组织者，以及出色的公共演讲者的伟大着作的作者，我想向您介绍我能找到的最有趣的人。\n迈克朱利安：啊，崩溃报道。经常被遗忘的一块坚实的监控策略。您是否很难复制您从用户那里听到的错误或难以捉摸的性能问题？你应该看看Raygun。无论你是负责网络应用程序还是移动应用程序，Raygun都可以在几分钟内轻松找到并诊断出问题，而不是你通常做的事情，如果你像我一样，请问最近的人，“嘿，是app适合你？“得到一个空白的凝视，因为嘿，这是星巴克，谁是一个奇怪的人提出有关移动应用程序性能的问题？无论如何，Raygun，我个人感谢他们帮助使这个播客成为可能。您可以访问raygun.com查看今天的免费试用版。\n迈克朱利安：嗨伙计们。我是Mike Julian，你是Real World DevOps Podcast的主持人。本周我的客人是Nicole Forsgren博士。您可能知道她是“加速：精益软件和DevOps的科学”一书的作者，或者可能是年度DevOps状态报告背后的研究员。当然，这不是全部。她也是最近被谷歌收购的DevOps研究和评估的创始人，他是管理信息系统和会计教授，同时也是一名性能工程师和系统管理员。说我很高兴与你交谈，这可能是一种轻描淡写。所以，欢迎来到节目。\nNicole Forsgren：谢谢。很高兴来到这里。我很高兴我们终于联系了。我们试图做多久了？\n迈克朱利安：几个月。我想我已经联系过你了，现在已经是三月了。我在11月份到达了，你说，“嗯，你知道，我还有其他的东西在继续，顺便说一句，我的公司被收购了。”\nNicole Forsgren：那么，那时候，我必须狡猾，对吧？我不得不说，“我有一个真正的大项目。我很抱歉。我们以后可以见面吗？”而且，上帝保佑，你是非常仁慈和善良的，你说，“当然 - ”\n迈克朱利安：谢谢你。\nNicole Forsgren：\u0026hellip;\u0026hellip;“我们以后可以聊聊。”然后我想你在说：“哦，恭喜你的\u0026rsquo;大项目'\u0026lsquo;之后给我发了一条消息。”我说，“谢谢。”\n迈克朱利安：听起来不错。\nNicole Forsgren：我很感激。是啊。然后，你再次伸出手，我说，“哦，我正在做另一个大项目。但是，这一次\u0026hellip;\u0026hellip;”\n迈克朱利安：这不是收购。\nNicole Forsgren：是的，这不是收购。这一次，这是一个正常的大项目，这是今年的DevOps状态报告。我们刚刚启动了调查，所以我非常兴奋，我们再次收集数据。\n迈克朱利安：所以我们可以解决这个问题，你在哪里可以找到DevOps状态报告？\nNicole Forsgren：所有DevOps状态报告都在DORA网站上发布。我们仍然有网站。我们所参与的所有报道，我想说我们从2014年开始，我已经很老了，我已经忘记了。我们完成的所有报告都是托管的。我们会在演出笔记中发布它们。如果你可以拿自己的健怡可乐或咖啡或茶或水，或者你想要波本威士忌。舒服。坐下来，大约需要25分钟。我知道，对，每个人都喜欢，“女孩，25分钟？”\n迈克朱利安：这是一项重大调查。\n妮可福斯格伦：我知道。它是。但这是因为DevOps状态报告是科学的，对吧？我们研究预测，而不仅仅是相关性。但请坐下来，舒服一点，让我知道做你的工作是什么感觉。因为今年我们正在挖掘其他一些东西;生产力，工具链，关于职业倦怠和幸福的额外事情，以及我们如何进入流动，以及真正的样子。还有一些非常棒的事情是，在以非常深思熟虑的方式进行调查之后，已经有很多人已经准备好了。顺便说一下，如果你有的话，我爱你们所有人。与同事分享，与同行分享。\n但是他们已经说过，仅仅通过参加调查，他们已经离开了，甚至在报告出来之前，他们已经走开了有关如何使他们的工作更好的非常有趣的想法和技巧和见解。\n迈克朱利安：是的，想到这一点很疯狂，参加调查的行为实际上改善了我的工作。因为我采取的大多数调查，我已经完成了，我想，“嗯，这有点浪费时间。”感觉就像我只是放弃了一堆东西而没有得到任何东西。\nNicole Forsgren：是的，我认为这种方式起作用的原因是因为我们对问题的处理方式非常谨慎，有时只是采取调查的行为可以帮助你思考你的工作方式。因此，采取某些问题的行为可以帮助人们思考他们正在做的事情。然后，当然，就像我开玩笑说，这是我的生活圈，调查将持续到5月3日，然后我将进入数据分析和报告撰写。我们预计报告本身将在8月中旬左右公布。\n迈克朱利安：嗯，为什么我们不退后几步说\u0026hellip;每个人都喜欢一个好的起源故事。很多年前，我相信你和我在一次LISA会面。您正在与Carolyn Rowland联合举办研讨会 -\nNicole Forsgren：哦，我喜欢Carolyn。\n迈克朱利安：是的，她也很精彩。我应该让她在这里。\n妮可福斯格伦：我的双胞胎。是。绝对。\n迈克朱利安：所以当我第一次见到你时你就是一名教授。我想，你知道教授在LISA上闲逛，并就如何理解商业价值给出了所有这些很好的建议，我认为这绝对令人着迷。教授，在DevOps世界中闲逛，这是怎么发生的？\nNicole Forsgren：哦，天哪。好的，有趣的是，我实际上是从工业开始的。我的第一份工作是在一个主框架上，编写医疗系统，然后编写财务系统。所以我是一名大型机程序员。然后支持我的主框架系统，对吧？这就是Ops中我们这么多人在Ops中开始的原因，有人说，“好吧，有人必须这样做。”对？我还在学校，然后我最终成为DEV，对吗？我在IBM担任软件工程师已有好几年了，然后转向学术界。我得到了博士学位，在那里我开始询问有关如何分析系统的问题，所以我实际上在做NLP，自然语言处理。\n迈克朱利安：很有意思。\nNicole Forsgren：是的，我在做\u0026hellip;\u0026hellip;\n迈克朱利安：是的，这是一个奇怪的切入点。绝对不是我所期望的。\nNicole Forsgren：是的，所以疯狂的事情，我的第一年实际上是欺骗检测。\n迈克朱利安：我打赌这太棒了。\nNicole Forsgren：这真的很有趣，非常有趣。但是我从系统工作中充分利用了我的背景，对吧？因为我们做什么？我们分析日志系统。\n迈克朱利安：对。\n妮可福斯格伦：对吗？我们习惯于以凌乱的格式分析大量数据，很多时候基于文本，超级嘈杂，不能总是信任它，对吧？现在人们都说，“我不相信调查。人们撒谎。”孩子们，我们的系统也是如此。\n迈克朱利安：一直以来。\n妮可福斯格伦：对吗？所以，他们喜欢我的一大堆这项工作。突然间，我随机对系统管理员进行了可用性研究。我们写了结果，把它们还给了IBM，IBM就像是，“你的意思是什么？我们遵循UCD指南，用户中心设计指南。这应该是适用的。”我就像是，“等等，哇哇哇哇哇哇哇哇哇哇哇哇哇哇\n当时，他们为所有用户提供了一套UCD指南。超级先进，高级别的高级系统管理员，他们正在做备份，灾难恢复，一切。那些买过笔记本电脑并且在生命中第一次使用电子邮件的人。\n迈克朱利安：我确信那个过得很好。\n妮可福斯格伦：什么？我想，“就是这样。改变我的论文。”当然，这让我的顾问惊慌失措。他们就像是，“你会去做什么？”所以我开始做什么，当时是DevOps的基础。那是什么，你如何理解和预测信息系统？通过信息系统，技术，自动化，使用和预测，然后是团队，组织层面的个人团队的结果和影响。\n现在，我说了所有这些，那是大词，这是学术用语，基本上是什么是DevOps。我如何理解人们何时使用自动化和流程以及工具和文化，以及我如何知道它汇总起来以产生影响并增加价值？现在我们就像，“哦，那是DevOps。”\n这是2007年末。\n迈克朱利安：哦，哇。所以你和我们在一起很早。\nNicole Forsgren：是的。这是一个非常有趣的平行轨道，因为现在我们回顾过去，我们就像，大约10年前。这与DevOps同时是新生的起源，对吧？所以，我们这么多人在同一时间偶然发现了它。我不知道这是在工业中发生的事情。我一直在偷偷摸摸，我一直这样做，偶然发现LISA，试图连接数据，当然，就像每个好学者一样。拼命想找到数据。\n偶然发现，撞到了一个收集类似东西但使用不同粗糙方法的小组。一个来自一个可爱的小配置管理创业公司的团队叫做Puppet，对吧？开始与他们合作，邀请自己参与该项目。上帝保佑他们，我对他们有如此多的爱和尊重，因为他们基本上让这个随机的，随机的学术撕裂他们的研究并重做它并亲切地告诉我以前从未见过的这两个家伙，在电话中，名叫Jean和Jez，他们做错了什么，他们使用的这个词不是正确的词。 Redid，在2013年末，DevOps状态报告，使其在学术上严谨，然后，持续了几年，对吗？然后突然间，我们在几年后重新编写了一堆东西。\n我离开学术界，离开即将任职的地方，去另一个可爱的小配置管理创业公司Chef，这很有趣，对吗？因此，我正在与Puppet合作，为Chef工作，并继续研究并与组织和公司合作。我离开了学术界，因为我看到这个疯狂的DevOps事情有所作为。但是在学术界，他们还没有完全掌握它。而且我想确保我可以做出更大的改变，因为我在98,99,2000开始在大学的科技工作;我们举起这个疯狂的网络泡沫破灭。\n它不是一场萧条，因为一切都崩溃了，世界就像人们想象的那样结束了，但公司失败了，它对人们的遭遇产生了巨大的影响和影响。他们失去了工作，打破了家庭，他们感到沮丧，影响了他们的生活，有些人正在自杀。而且我非常担心当我们再次击中这一波时会发生什么，我们又开始看到那次击中。那么，如果公司和组织不了解制造技术的智能方法会发生什么，因为你不能只是让人们不顾问题，或者让同样的人陷入困境。当我说同样的人扔我的意思时，七天强行游行。\n当他们让我们这样做时，我在IBM，对吗？他们陷入集体诉讼，你不能这样做。这不是一种生活方式。\n迈克朱利安：是的，我参与其中很多，他们是残酷的。而且它们没有任何有用的结果。\nNicole Forsgren：这只是破碎的心灵和破碎的生命，对吧？所以，有些人喜欢说，你真的关心这个。我只是这个书呆子的学者，他只关心我做的事情。因此，如果我们真的可以，从根本上改变人们制作软件的方式，因为如果它实际上实际上，从根本上改善了他们的生活\u0026hellip;\u0026hellip;让我们这样做。\n然后，感谢上帝，我们发现它确实存在。当然，它很好地为企业提供价值，但这很重要，因为那时它的作用是帮助他们做出更明智的投资，因为这样可以减少倦怠。它让人们更快乐，让他们的生活更美好，我认为这是重要的部分。\n迈克朱利安：所以你发现的是，一家公司实施所有这些更好的持续部署实践，更快的交付时间，更快的价值实现\u0026hellip;\u0026hellip;它使人们的生活更好地完成了工作？\nNicole Forsgren：是的，John Shook也发现了这一点。对？他在精益中做了这项伟大的工作，为了改变\u0026hellip;有些人说，“你如何改变文化？”让我们找到改变文化的方法。有时，改变文化的最佳方式是改变你的工作方式，我相信我们已经看到了自己，对吗？在我们生活的其他方面。改变我们的感受，改变家庭的工作方式，改变我们的关系工作方式。你实际上改变了你的生活经历，或者你生活经历的某些方面。\n因此，如果我们改变我们制作软件的方式，我们将改变我们团队的运作方式，这正在改变文化的方式。换句话说，如果我们可以告诉我们的组织在技术和流程方面做出哪些明智的投资，那么我们也可以改善文化。我们也可以改变人们的生活吧？微软Bing团队发现了这个，对吧？他们希望在持续交付方面进行明智的投资。\n在一年之内，他们看到了工作生涯的分数，我将其从头脑中拉下来，但我想说它从38％上升到75％。那太大了。\n迈克朱利安：这是一个令人难以置信的跳跃。\n妮可福斯格伦：对。这是因为人们能够在工作中离开工作然后回家。你可以去看你的家人，你可以去看电影，你可以去吃饭，你可以有爱好，或者你可以去狂欢看格雷的解剖。你可以做你想做的。\n迈克朱利安：这对我来说最令人难以置信的事情之一是，为了让公司取得成功，他们必须推动员工，让他们通过振铃器。直观地说，这是永远不会正确的。而你实际上有数据表明这是不对的。做这些事实上让每个人都变得更好。业务得到了显着改善，人们的生活得到了极大的改善，而且一切都很棒。\nNicole Forsgren：是的，如果我们想要推动人们，这是不可持续的。如果有的话，我们希望推动人们做他们擅长的事情，我们希望利用自动化来实现自动化擅长的事情。那是什么意思呢？\n我们希望让人们做有创意，创新，新颖的事情。让我们让人们解决问题，让自动化做我们需要的一致性，可靠性，可重复性，可自动性。让我们不要让人敲打锤子并不断进行手动测试。让我们让人们弄清楚如何解决问题，做一两次以确保这是正确的事情，自动化，将其委托给自动化，机器和工具，交付，完成，然后拉人回到循环中进入循环，找出新的东西。\n我认为是Jesse Purcell说：“我想让自己不断自动化。”对？使自己脱离当前的工作，然后找到一份新工作，让自己再次自动化。我们永远不会失业。\nMike Julian：是的，当我第一次开始使用DevOps时，我常常担心这一点，实际上，当我第一次开始自动化时，当时并不是DevOps，它是在大学中自动化Windows桌面部署。这是在21世纪初。我最大的担忧之一是，因为我花了半个星期的时间来做这件事，如果我要自动化，我会花一个小时做这个，剩下的时间我会做什么呢？他们只是要解雇我，因为他们不再需要我了。\n事实证明，不，这根本不是发生的事情。更高的工作价值变得有效，因为我并没有那么专注于辛劳。\nNicole Forsgren：对，那些类型的东西，机器和电脑都做不到。而另一件事，我曾经告诉我的所有朋友，在工作保障方面不考虑这一点，对吧？不要试图将自己描绘成一个别人无法做到的事情，因为那样你就无法被替换，因为这也意味着你永远无法得到晋升。\n如果我们始终确保工作的某些方面可以实现自动化，以便我们有机会获得新工作，那么这只会为创造更多的事物创造更多机会。总会有问题，我们总有一些问题需要解决。我不想被困在做无聊的工作。\n迈克朱利安：是的，上帝知道这是事实。\n妮可福斯格伦：哦，天哪，我知道。我不想被困在做无聊，重复的工作。这简直令人头痛。如果我们能找到，特别是真正具有挑战性的复杂事物，如果我们能找到自动化的方法，相信我，我们永远不会把自己挖到那个洞的底部。那总是存在的。\nMike Julian：所以我想谈谈DevOps状态报告，我想先问一个你之前提到过的问题。你提到这句话，学术严谨。那是什么意思？\nNicole Forsgren：学术严谨包括一些事情，好吗？因此学术严谨的一部分是研究设计。所以这不只是在回答一堆问题\u0026hellip;\u0026hellip;对不起，yolo是我的简写，“你的方法论是有问题的。”\n迈克朱利安：我最近看到很多调查结果出来了。\nNicole Forsgren：是的。所以一个是研究设计。有人说，“妮可，研究设计是什么意思？”那么研究设计是，您要求的问题类型是否与您用于收集数据的方法相匹配？对？这些东西是否匹配？对于某些事情，调查是恰当的。一次，所以一次是横截面，一个时间跨整个行业的调查。有些事情适合。有些事情不适合。\n一个很好的例子，很多人真的希望我在DevOps状态报告中做开放空间和问题。\n迈克朱利安：这是什么意思？喜欢开放式问题？\nNicole Forsgren：不，开放空间。所以很多人对开放式办公空间有很多感觉。我应该在开放的办公空间工作吗？开放办公空间会影响生产力吗？或配对编程\u0026hellip;\u0026hellip;配对编程会影响生产力吗？配对编程会影响质量吗？人们对这些事情有很多感觉。在DevOps状态报告中使用的研究设计类型是一个完全匿名部署的调查，在整个行业中的单个时间点，并不适合回答其中任何一个问题的研究设计。\n迈克朱利安：那是为什么？\nNicole Forsgren：因为您需要做的是拥有更加可控的研究设计。所以我需要知道，例如，你和谁一起工作。我需要知道，所以让我们继续进行同行评审，我需要知道你正在处理的问题类型，代码问题的类型，我现在需要问题的复杂性，我需要知道它花了多长时间，对吧？如果你现在想要提高生产力，对吧？因为我需要了解一定的生产力。我需要知道结果是什么。因此，如果我的结果是生产力，我需要衡量生产力，因为我需要控制困惑，对吧？因为事情比较复杂，我们希望花更长的时间。那些不那么复杂的东西，我希望不会那么久，对吧？\n然后我需要匹配和控制。对？甚至像开放式办公空间这样的东西，对吧？因为如果你在一个开放的办公空间而不是一个开放的办公空间进行同行编程，如果你在办公室里这样做，我需要知道这个人的资历，或者一些资历代理。我现在需要你如何配对，你是否与你的近似经验水平的人配对，如果不是资历经验水平。我需要知道配对编程是如何工作的，我需要知道所涉及的技术，我需要知道你是否偏远，或者你是否真的坐在一起。我需要知道你是否能够同时输入文本，或者是否有人插入而另一个人没有。\n因此，当我进行比较时，我知道比较是什么样的。\n迈克朱利安：这是一个令人难以置信的信息量。我没想到你必须知道这么多才能从中得到一个好的答案。\nNicole Forsgren：这不是我的头脑。是的，因为你问了我一个很好的问题，我吐了一口气。这只是研究设计，然后你继续分析，对吗？当您继续进行分析时，我们需要了解您提出的问题类型。这些类型的问题，我们是否在考虑相关性？我们在看预测吗？我们在考虑因果关系吗？我们提供哪些类型的数据以及适合哪种类型的分析和问题？\n同样，他们需要以正确的方式匹配。某些类型的数据不适用于某些类型的分析或问题。所以你真的需要确保每一个都适合于正确类型的东西。对？某些类型的分析，如机械，调查问题，永远不适合机械分析，对吧？虽然，老实说，没有人会做机械分析。从来没有，顺便说一句，如果有人来找我并说他们正在做机械分析，我会坐下来非常专心地听你的，非常感兴趣，因为我认为没有人在做机械\u0026hellip;\u0026hellip;这不是一个事情。\n迈克朱利安：所以当你分析调查结果时，我们看到的是一个问题，然后是另一个问题，接下来是另一个问题，你知道数百个问题。当您分析这些内容时，您是在一次查看问题，还是在查看多个问题，然后根据您在几个不同问题中看到的内容来解释答案？\nNicole Forsgren：所以当我写完结果时，当我写这份报告时，我正在写出我的分析结果，而我的分析正在考虑一个非常非常仔细的研究设计。现在意味着什么，我的研究设计经过精心构建，以尽量减少误解。它试图尽量减少答案中的漂移。所以，我们这样做的一种方式，这在加速的第二部分中概述，如果有任何想要阅读的统计数据书呆子，我们做的事情称为潜在结构。\n所以，你问过只有几个问题或几个问题。我提到过，我们这样做的一种方式称为潜在构造。如果我想问你关于文化的话，我可以向10个人询问文化，我会得到15个答案。因为文化可能意味着许多不同的事情，对吗？一般来说，当我们在DevOps环境中谈论文化时，我们倾向于得到一些东西\u0026hellip;\u0026hellip;人们会说非常常见的事情，如打破孤岛，拥有良好的信任，拥有新奇，对吧？\n因此，我们所做的是从定义开始，然后我们将提出几个项目，问题，捕获每个维度。所以你可能想要考虑一个涂料维恩图，其中每个问题都被覆盖，然后是所有他们拥有最大或完美覆盖的东西，它们是中心，那个小坚果，这就是构造是什么。这就是文化，即文化所代表的。\n然后每个圈子都是问题。这就是我们在研究设计中所做的。研究设计的一部分。当我进入统计分析模式时，我会考虑所有问题，所有项目，不仅仅是文化，而是我正在考虑的每一件事。因此，在过去的几年里，我已经完成了监视可观察性，我已经完成了CI，我已经完成了自动化测试，我已经完成了版本控制，我已经完成了所有这些工作，并且我将所有这些都扔进了漏斗，对？\n迈克朱利安：我敢肯定，这可能是你庞大的Excel电子表格。\nNicole Forsgren：不，这是SPSS。我使用SPSS但您可以使用几种不同的统计工具。我们做主成分分析。而我们所做的就是它们如何加载？基本上，他们如何组合在一起，我们是否具有收敛有效性？它们会聚合吗？他们只测量他们应该测量的东西吗？我们是否有判别有效性？他们不衡量他们不应该衡量的东西吗？我们有可靠性吗？每个阅读这些问题的人都会以非常相似的方式阅读吗？\n一旦我们掌握了所有这些，并且对所有这些事情进行了几次统计测试，那么我说，“好的，这些项目，通常是三到五项，所有这些项目都是文化，”或“所有这些项目一起是CI，“或”所有这些，正确的这些项目分组，代表了这一点。“好的，现在，现在，我可以开始查看关联，预测或其他内容，然后我会看到报告，现在我只想谈谈文化。\n所以我把它作为一件事情谈论，但实际上是几件事，然后当我谈到文化时，我可以说，“这就是文化是什么”，我可以用这种细微的，多维的方式谈论它，我知道那些维度是什么，因为它由三到五，六到七个问题组成，顺便说一下，如果其中一个问题不合适，因为我从统计分析中知道，我可以抛弃它，我知道为什么。我总是有几件事。如果您只有一个问题或者您只有两个问题，那就是风险。如果其中一个不起作用，哪一个是错误的？你不知道。对？因为，是A还是B？我不知道。\n至少如果我从三开始，一个失败，那么它可能是好的两个。\n迈克朱利安：是的。这里的许多听众已经采取了很多由营销组织进行的调查，除了调查也是由营销人员设计的\u0026hellip;\nNicole Forsgren：他们是由想要特定答案的人设计的。\n迈克朱利安：没错。\nNicole Forsgren：这就是挑战。\n迈克朱利安：是的，然而，为了清楚地说明，DevOps状态报告根本就不是这样。正如你所说，有很多东西都是严格的。\nNicole Forsgren：好的一点是，我们一直是供应商和工具无关的。\n迈克朱利安：你不是在寻找一个非常特别的答案，你想知道实际上是什么。\nNicole Forsgren：我们并不是在寻找产品的答案。那么，在CI的例子中，什么是CI？我不关心工具。我说，如果你正在做CI，如果你正在进行CI，持续集成，以一种预测智能结果的方式，你将拥有这四样东西。其中的力量是，任何人都可以回过头来看待这个评估工具。如果您是经理，领导者或开发人员，您可以说，“我使用的任何工具，世界上的任何工具，我应该寻找这四件事”，或“我自己构建的任何工具，或者如果我正在做CI，我应该有这四件事。“\n如果你是一个供应商，你应该说，“如果我认为我正在建立或销售CI，我最好有这四件事。对吗？这就是伟大的事情，我必须说，上帝保佑我的新团队。他们让我以同样的方式运行它。它仍然是相同的。它仍然是供应商和工具无关，它仍然是能力集中。你寻找的每一件事，无论是自动化或流程，文化或结果，它的供应商和工具不可知，它的能力集中，再次，权力是你可以用它作为一个评估工具。\n我的团队是这样做的吗？我的工具是这样做的吗？我的技术是这样做的吗？我能做到吗？如果我不是，我的弱点是什么？我的约束是什么？因为如果我把我们带回到开头，是什么驱使我和DORA团队，那么我们想要摆脱这一点是什么？我们想让事情变得更好。我们该怎么做？我们可以为人们提供简单的评估标准。而且我并不是说这很容易，因为所有这些都很简单，需要工作。但如果有明确的评估标准，我们就有了可以去的地方。\nMike Julian：因为我知道你喜欢谈论你几年来所做的事情。您提出了哪些最有趣的结果？\nNicole Forsgren：哦，有很多好的。\n迈克朱利安：让我们选择你的前三名。\nNicole Forsgren：好的，我认为我的最爱之一是，我会用俗气的营销方式来做\u0026hellip;\n迈克朱利安：请接受。我们已经做好了准备。\nNicole Forsgren：有一个小创业公司并且不得不假装它作为营销人员一分钟的人，我们将看到我在这方面做了什么。\n架构很重要，而不是技术没有。第一。好的。那是什么意思呢？这意味着，我们发现如果您以正确的方式构建它，您的架构结果会比您的技术堆栈产生更大的影响。所以架构成果，一些关键问题是：我可以测试吗？我可以部署吗？我可以建立没有细粒度的沟通和协调吗？\n迈克朱利安：细粒度意味着什么？\nNicole Forsgren：我是否必须与他人见面并一起工作并征用一些东西，我是否需要开辟一些疯狂的新测试环境，还是必须获得17个不同团队的批准？请注意，我刚刚提到过团队。沟通和协调可能是技术限制，也可能是人的限制。这让人很难回到康威定律。\n迈克朱利安：我最喜欢的法律之一。\n妮可福斯格伦：对吗？这是一个DevOp的事情。但是，这是真的。无论我们的沟通模式如何，我们通常最终会融入我们的技术。现在，我将说这在云和云原生环境中通常更容易实现，但它也可以在Legacy和Mainframe环境中完全实现。我们没有看到前几年布朗菲尔德和格林菲尔德受访者之间存在统计学上的显着差异。\n迈克朱利安：很高兴知道。\nNicole Forsgren：是的，我喜欢那个。那个人很有趣。\n好的，第二个。云很重要，但只有你做得对。\n迈克朱利安：噢，这意味着什么？\nNicole Forsgren：Dun dun duh。所以，这是我最喜欢的统计数据之一。我们发现，如果您正在执行所有五个重要的云特征，那么您成为精英表演者的可能性要高23倍。根据美国国家标准技术研究院（NIST）的说法，我想你可以说你是否正在完成云计算的所有五个基本特征。所以我没有提出这个，这来自NIST，好吗？\n所以它很有趣，因为我们询问了很多人是否在云端。他们就像，当然我们在云端，我们完全在云端，对吗？但只有22％的人正在做五件事。那这五个是什么？所以这五个是按需自助服务。您可以在没有人工干预的情况下配置资源，如果您必须填写一张票并等待一个人办票，这不算数。没有积分。\n另一个是广泛的网络访问。因此，您可以通过任何类型的平台访问您的云端内容;手机，平板电脑，笔记本电脑，工作站。大多数人都非常擅长这一点。另一个是资源池，因此可以根据需要动态分配和重新分配资源。另一个是快速弹性，对，爆裂魔法。我们通常都知道这个。\n现在最后一个是测量服务。所以我们只支付我们使用的费用。因此，最常查看的通常是广泛的网络访问和按需自助服务。\n迈克朱利安：是的，有趣的是，对我来说，那里没有任何东西阻止，比如说，从排位赛开始的内部开放堆栈集群。\nNicole Forsgren：没错，对。所以这可能是私有云。我爱你指出了这一点。之所以如此重要的原因是，它只是归结为执行。它可以完成，另一个挑战是组织，管理人员或董事会经常说你必须去云，所以有人说，“哦，是的，我们要去云端。”但后来有人重新定义了云中的意义。对？所以，你到达那里，有人检查他们的小盒子，把金星放在某人的图表上，他们走开了，他们就像是，“好吧，我们没有看到任何好处。”好吧，是的，因为你没有这样做。\n迈克朱利安：对。是的。\nNicole Forsgren：就像是，“我买了一个健身房会员，我已经完成了。”不，再说一遍，我不是说这很容易，对吧？有一些工作涉及。现在我喜欢的另一件事是，让我们说你不在云端，由于某种原因你必须留在Legacy环境中，你可以看看这五件事你可以尽可能多地实现，你仍然可以实现利益。\n迈克朱利安：对。这不是一个全有或全无的方法。你可以做其中的一些，并从中获得很多好处。\nNicole Forsgren：这几乎就像一个骗子回到了第一，这是建筑问题，技术没有。我怎么能做一个备忘单，看看如何到达那里的一些非常好的技巧？\n迈克朱利安：那你的三号是什么？\nNicole Forsgren：我的第三个可能是，外包不起作用。\n迈克朱利安：是的。\nNicole Forsgren：有些人讨厌我，他们从他们的眼睛射出激光束。所以我们说外包不起作用*。\n迈克朱利安：好的，什么是星号？\nNicole Forsgren：Asterisk，星号将是功能性外包不起作用。\n迈克朱利安：好的，所以说外包我的待命职责，可能不会那么好用。\nNicole Forsgren：拿走所有的DEV，把它运走。全部采用TEST，将其运走。拿走所有OPS，运送它。现在，为什么呢？因为那样，你们所做的一切都是另一套交接，你们创造了另一个孤岛。你还批量完成了大量的工作，而你却让每个人都等待这种情况发生。目标是创造价值而不是让人们等待。如果现在每个人都必须等待所有东西回来，如果你正在做高价值的工作等待低价值的工作，因为它必须回到一起，这通常是它的工作方式，你是骨头。\n现在，功能外包。如果您有一个与您合作并与您协调并以相同的节奏交付的外包合作伙伴，那么这不是功能性外包。那是星号。\n迈克朱利安：好的，有问题。\nNicole Forsgren：另外，如果他们是你的团队的一部分，他们是你公司的一部分，但他们基本上一次消失了三个月。对不起孩子，这是功能外包。我没有任何积分，愿上帝怜悯你的灵魂。这没用。\n迈克朱利安：对。在我看来，你怎么知道你是否处于这种困境中，如果你的团队和你给这些项目的人之间有明显的交接，你就有功能外包。那会是对的吗？\nNicole Forsgren：是的，特别是如果有一个明显的手，然后是一个黑盒子的神秘。\n迈克朱利安：就像，工作是如何完成的？\nNicole Forsgren：第一步，第二步，问号，第三步：获利。\n迈克朱利安：也许吧。所以前两个，这一切都很好，因为我们可以看到从哪里去，但第三个实际上看起来有点困难，因为如果我是一个系统管理员，我完全无法控制这个功能外包。我可能也讨厌它，我可能自己讨厌它，但我对它没有任何控制权。我可以做什么作为系统管理员，或操作员，开发人员，我该如何改善这种情况？\n妮可福斯格伦：所以一些想法可能包括一些事情，看看是否有任何方法可以改善过渡期间的沟通或节奏。对？您可能仍然拥有该外包合作伙伴，因为这就是它的方式。但是，假设您已经以三个月的增量进行了工作，有没有办法将切换增加到每月一次？有没有什么方法可以让我们知道我们知道我们导入的功能，小批量工作，只是增加切换？有什么方法可以将它们整合到我们的节奏中，融入我们的团队吗？\n现在我意识到这里有一些挑战，因为从法律的角度来看，我们不能像我们的团队那样对待他们，因为那时，至少从美国的角度来看，一旦我们像对待员工那样对待他们，那么我们就要对就业税负责以及所有其他合法的东西。但是，如果我们能够将它们整合到我们的工作节奏中，或者更接近我们的工作节奏，那么我们的结果就会得到改善。\n迈克朱利安：好的，很酷。这更有意义。这听起来并不像我担心的那么难。\nNicole Forsgren：所以它可以开始减少节奏的延迟，要求稍微更清楚地了解正在发生的事情，如果它是一个完整的黑盒子，那就是寻找它。\n迈克朱利安：妮可，这绝对是太棒了。非常感谢你加入我。我有两个最后的问题。人们在哪里可以找到这个DevOps状态报告来进行调查？调查在哪里？\nNicole Forsgren：哦，我们已经发布了调查结果。我可以将它包含在演出笔记中吗？\n迈克朱利安：当然。好的，大家，查看链接的节目说明。我的最后一个问题是除了这项调查之外，人们可以在哪里找到更多关于你和你的工作的信息？\nNicole Forsgren：我有几个地方。所以我自己的网站是在nicolefv.com，我总是在Twitter上，通常谈论冰淇淋和健怡可乐，那是@nicolefv。\n迈克朱利安：我确实爱你Twitter推特。这是我的最爱之一。\nNicole Forsgren：是的，每个人都来打个招呼。我的DM是开放的。\n迈克朱利安：我最喜欢你的Twitter提要大概是在你写报告的时候，说：“天哪，我为什么要这样做？”\nNicole Forsgren：是的，我试着把它锁起来，但每隔一段时间就会有什么东西会滑落，比如“哦，我的天哪，一件好事正在发生”，或者“哦，我忘记了这一件事”，或“那么多好事正在发生。“\n迈克朱利安：是的，我记得去年就像，“哦，我的上帝，这太酷了，但我无法告诉你。”\n ",
    "ref": "/blog/2019-state-devops-survey-open/"
  },{
    "title": "2019年关于DevOps的几个预测",
    "date": "",
    "description": "参考了XebiaLabs和其它的几篇文章",
    "body": "本文汇聚了来自3个网站的预测文章，他们分别是XebiaLabs、G20Group和Veritis。在总共22项预测中，个别预测是相同的。DevOps是一个持续进化和发展的过程，同时也受到目前各种新技术的影响。\nXebiaLabs的7个预测 英文原文： https://blog.xebialabs.com/2019/01/10/7-predictions-for-devops-in-2019/\n1. 持续集将成作为流水线的重要代办事项 如果企业希望提高团队用在功能开发上的可用时间，从而加速向生产环境中交付的话，那么在整个DevOps流水线中，引进持续集成CI部分将成为高优先级且重要的事项。监控CI流水线相关的数据、活动和流程的能力将变得非常重要，这样可以使发布流程中的所有人都能看到最新的流程状态，从而减少开发人员花费在无关任务上的时间。 【来自：XebiaLabs产品开发副总裁Andreas Prins】\n2. 价值流映射将被广泛使用 目前，随着软件交付的速度和质量正成为大型企业的巨大竞争优势，越来越多的组织将会探索价值流映射（Value stream mapping）的使用方式，从而确保他们的软件开发是和整体业务价值保持一致的。这种转变将会减少软件发布流水线中的浪费，并创建出更强大的跨职能团队协作。【来自：Lisa Wells，XebiaLabs产品营销副总裁】\n3. 实时挖掘软件交付流水线所产生的数据 在2019年，IT部门通过软件持续不断创造业务价值的压力将会越来越高。因此，组织将用各种方法挖掘在软件交付流程中大量的由机器所生成的数据，而不只是在事后才进行分析，甚至还包括DevOps的可预测性。这样才能够更好地预测软件交付流程和基础架构中所发生的问题，而这些问题可能对应用程序的质量和安全性产生负面影响，可能会使产品上市时间延期。【来自： Lisa Wells，XebiaLabs产品营销副总裁】\n4. 在人和流程中培养责任共但文化 DevOps同时关乎于人、流程和工具。对于任何DevOps实施计划而言，需要将人和流程视为首要的交付价值的因素。在2019年，我们将看到企业会越来越重视培养承担责任的文化，团队在复杂的应用程序交付流水线中共同承担质量和效率的责任。各个团队需要及时了解协作和进度。关键是在项目的进展过程中，及时的与整个公司分享那些取得了成功的措施和及其成果。除了证明他们的努力能够带来重大成果之外，毕竟，也没有什么比这种方式更能激励团队的了。【来自：T.J. Randall，客户成功副总裁，XebiaLabs】\n5. 自服务部署将成为主流 随着自动化部署已经成为企业的标准实践，随着组织逐渐地意识到可以将信息安全和合规性也融入到他们的交付流程中，在2019年，自助服务式部署会成为主流的工作实践。【来自：T.J. Randall，客户成功副总裁，XebiaLabs】\n6. 建立自己的DevOps能力度量组合 随着DevOps的投资增加，管理层将需要更多的投资回报率证据。团队需要建立他们基于全局测量（不仅仅是单个团队或个人）和结果（具有速度和稳定性的软件交付）的组合来测量DevOps（DevOps Intelligence）的能力。【来自：Vincent Lussenburg，DevOps战略总监，XebiaLabs】\n7. DevSecOps融入到DevOps流程中 对信息安全“前置（左移）”的需求将会在DevOps实践中得到更好的理解和更有效的应用。在2018年，“前置（左移）”经常被滥用，被误以为会把软件的安全性责任推给开发人员。在2019年，DevSecOps将成为DevOps的另一个自然的选择，将安全性融入到流程中的每个阶段，并且所有人都对安全性有责任。【来自：Vincent Lussenburg, Director of DevOps Strategy, XebiaLabs】\nG20Group的5个预测 原文：https://www.go2group.com/blog/devops-trends-2019-our-top-five-predictions-for-the-year/\n由于文章比较长，下面是核心观点的概述。\n 使用AI加速/优化的DevOps将开始被逐渐应用。基于AI的预测性可以被用在CI或者CD栋流水线过程中，确保交付流程的有效性。这个趋势将加速应用开发者和数据科学家之间的协作。 容器化应用不在是新鲜事物了。DevOps和多云架构加速了容器相关的技术在大型企业中国的使用。越来越巨大的软件开发和部署规模也进一步提高了容器生产环境集群的规模和复杂性。Kubernets的广泛使用也进一步加速了应用容器化的进程。 Functions-as-a-Service (FaaS) 将会崭露头角。随着越来越多的专业人士在生产环境中广泛的使用容器技术。相信FaaS也会逐渐被应用起来，它也比称之为无服务器计算。这种技术的实现包括：AWS Lambda、Google Cloud Functions, Microsoft Azure Functions, IBM 等。 DevSecOps会变得更加重要。随着企业应用DevOps的范围逐渐扩大化，将安全性和合规性无缝的集成到DevOps转型过程中也得到了广泛的接受。主流的DevOps实践者会把安全性视为代码，安全团队会在DevOps工作流中和各种团队携手打造安全性。 自动化将会依然非常重要。企业越来越意识到在软件开发周中提高响应速度、运维的可恢复性、更快的上市时间的重要性；这需要将软件开发和运维工作通过自动化更好的链接起来。组织在复杂的生态系统中扩大自动化的应用还是有些难度。  来自Veritis的10个预测 原文： https://www.veritis.com/blog/devops-trends-top-10-predictions-for-devops-in-2019/\n",
    "ref": "/blog/predictions-for-devops-in-2019/"
  },{
    "title": "产品管理遇上Devops",
    "date": "",
    "description": "产品管理还是项目管理？在DevOps世代里，向左走还是向右走？",
    "body": "DevOps企业峰会是历史悠久的DevOps主题企业级峰会，近年来在北美的拉斯维加斯和欧洲的伦敦每年各举办一次。 这个大会的官网：https://events.itrevolution.com/ 2019年的会议时间已经发布，感兴趣的可以参加。\nCSG公司连续多年参加DevOps企业峰会，本分享主题是CSG在2018年美国拉斯维加斯的峰会上的主旨演讲之一。本文是对这个演讲的视频回放的整理，该视频已经上传到了腾讯视频。\n\nCSG International公司简介 CSG是一个基于SaaS的客户支持和计费公司。CSG是美国最大的账单打印和呼叫中心公司。帮助他们的合作伙伴公司完成水电费、宽带费、通信费等相关业务的收款工作，并为最终客户提供热线电话支持。\nCSG的技术堆栈范围广泛，从Mainframe主机到Linux开放系统到AWS云服务，CSG认为如果正确的运用DevOps技术的话，技术堆栈并不是阻力和限制。\nCSG的DevOps旅程经历了如下几个阶段。\n2012年 敏捷转型 敏捷转型历经四年，进行了组织结构调整，在这个过程中关注点和亮点如下：\n 应用精益思想消除了各种等待队列 应用康威定律重组重组了团队 重组团队之后形成跨职能团队，将设计团队，开发和测试团队融为一体 实施持续集成技术，落地持续部署流水线作为业务开发的基础设施 实施了测试自动化 实施了共享的遥测数据，这就是今天所热议的可观察性 将作业批量尺寸缩减为以前的一半 成立了多个独立于研发团队的共享的运维团队【注意：运维还没有和研发团队融为一体，共享运维团队管理所有IT环境并和所有产品团队协作】  敏捷转型的效果：\n 发布影响业务的事件数量下降（在固定的时间周期里统计由于发布导致的影响客户服务的事件数量） 变更失败率下降  2012-2015 敏捷转型和DevOps早期 在敏捷转型的持续集成的基础上，CSG实施了持续部署实践，持续部署被视为应用DevOps实践的标志性动作，将所有部署转为为可重复执行的自动化部署。\n上图是运维工程师们在工作时段里进行日间部署的场景，但是平均每天进行15.1个部署，71个面向最终用户的特性发布。在部署期间，运维工程师们在信心满满的打着电动。由于每一个生产环境的部署都已经做过了大量的自动化测试，且在其它环境中至少部署过7遍了。\n2016 反作用力和挣扎期 上图的情形应该很常见，CSG也经历了这个阶段。\n开发团队追逐：\n 交付速度 更好、更快的环境 更好的服务请求工具 憎恨变更请求队列（流程）  运维团队追逐：\n 稳定性！ 高质量代码 更敏捷的工具 憎恨变更请求队列（流程）  开发和运维团队都厌恶的：\n 变更管理流程 发布管理流程 生产环境的运维部门 PMO项目经理  客户想要的是：“更快得到高质量的特性！”\n2016 DevOps团队融合阶段 大家一起反思这个问题：“我们为何不站在同一条战线上，一起追逐相同的目标？”\n设置共同（共享）目标：更快、更稳定和更安全！融为同一个团队，为了更好的服务客户而努力奋斗。\n2016~2018 后DevOps时代 为了化解在的研发和运维之间的依然持续存的矛盾现象，在大家反思之后；进行了再次的团队组织结构调整，消除了所有共享的运维团队，将运维团队的工程师融入了各个研发团队。\nCSG的DevOps转型阶段的重点：\n 运用了不同于双模IT的模型，即”统模IT“，在DevOps实践面前，各种类型的IT架构都一视同仁 转型后的开发团队统一负责产品的构建、测试、运行和服务质量 下放变更管理委员会（CAB）职责到各个开发团队，成立本地化的CAB（详见ITIL的术语表） 建立了群策群力的服务支持响应机制（参考精益思想的安灯拉绳），因此大幅度缩短了MTTR时间 实施了反向布兰特操作，消除大量普遍存在的布兰特（这是一个比喻，详见《凤凰项目》的人物布兰特） 建立整合的Backlog，将开发、测试和运维的工作统筹管理 实施基础设施自动化 将运维问题（目标不一致、反作用力、部门墙）视为工程实践问题：更好的工程实践，更少的苦活累活！  【注意】如上图所示，新增了一个度量指标：Inc/Mo 每月的事件数量（ITIL的术语），这是生产环境中每月发生的事件单的数量，数量的降低说明了生产环境的稳定性的提高。\nCSG在这个阶段中所引入的DevOps实践参考指南书籍是《DevOps Handbook》，中文版封面如下图所示：\nhttps://book.douban.com/subject/30186150/\n在始于2016年的DevOps旅程中，CSG从改善负面指标阶段，步入了追逐正向业务价值目标的阶段。\nCSG通过打敏捷开发、精益思想和DevOps实践的组合拳，实现了稳定性和业务的同步增长。\n 从2012年到2018年业务订阅用户数增长了27%。 生产系统的交易吞吐量（TPS每秒的交易数），增长了433%  产品管理遇上DevOps的主旋律 产品管理和DevOps之间的关系该如何协调和处理，在这个阶段里得到了定义。\n整个集体应该遵从的三大主旋律：\n 将策略连接落实到人，从而改善了产品管理和DevOp的关系，基于相同的业务诉求：实现了更好的价值产出 IT不是是独立于业务之外：管理的应该是产品价值流，而非项目。 运维问题是一个同时于与工程和产品都相关的问题  见上图，寻找划出的重点和关键词。\n出现了新的度量指标：\n Impact minutes ：业务恢复时间 MTRR Release on demand ： 特性按需发布比率 eNPS ：员工对企业的点赞比率  以上数据的度量周期是从2017年至今的，影响这些指标的内因包括：\n 精益领导力组合 产品经理遇上DevOps  产品管理为何要遇上DevOps？ 在CSG工作了19年之久，经历和目睹敏捷和DevOps转型全过程的项目经理，Brian Clark（VP Product management）的简单版答案：“业务成果”。\nCSG的处于一个非常稳定的成熟市场，而且是市场的领导者；上游的电信运营商公司和宽带网络公司的业务都已经很难成长了。\nCSG所在行业的复合年均增长率约等于2%，CSG公司的复合年均增长率是3.92%。他们面临着如何保留高级技术人才的挑战。而在实施了DevOps实践之后，业务成果好转，新增了两个BBS企业客户。雇员的eNPS增长了400%，人员保有率大于95%，目标市场的业务占用率提高了。\n从2015开始产品经理和DevOps团队开始讨论“团队的精益领导力组合”，定义了组织级别的愿景：“将工作可视化，把我们的人员和策略链接在一起，驱动参与度、价值和兴奋度。”\n所谓的精益领导力组合如下图所示：\n主要有三部分组成：\n 组合管理 发布管理 转型赋能  回顾一下CSG过去的三年，主要经历了6里程碑。 1 服务请求管理 从梳理服务目录开始，将100多种IT服务梳理在一个服务目录中，需要这些服务的人通过服务请求并获得服务。以前这些服务工作交付所付出的大量运维性劳动是无法可视化和计量的。通过服务目录的不断完善，以前不可见的运维工作都可以察觉到，并可以计量和统计。\n到2018年为止，统计数据表明：\n 服务目录管理的服务条目数量是 620 个 从服务目录创建并完成的服务请求单数量是 53000+ 个 使用同一个服务目录增加了工作的可视化程度，并且还具有潜在的成长空间 服务目录请求站点的访问量达到了 75000+ 次  服务目录的实施结果是可以被统计的，将这些数据呈现给了领导层团队；领导层随后决定增加了这些方面的投资，从而优化和消除了大量可重复的工作。这个阶段的成果也是非常突出的。举两个简单的例子如下：\n 自动化了一个非常耗时的服务，该项服务每年需要消耗5000+人工时，这几乎是3个专职工程师一年的工作量。 优化了一个通常需要耗时10天才能完成的服务，后来该项服务现可以在请求的当天就得以满足。  随着以上成果的逐渐扩大化，服务请求方和交付方都更加愿意和领导团队接触，并参与到等多的提议和计划中。这些成果足以值得让团队兴奋起来，下图是史诗一号团队在举行团建活动，以此来庆祝第一步的成功。【注：想获取兴奋度就喝起来！】\n2 建立技术和产品组合规划室 - TAM Room 为了让项目执行过程和项目中的工作内容都更加可视化，建立了“技术和产品组合规划室”。在这个房间的墙上设立大型工作看板，将不同类型的工作用不同的颜色表示。这面墙展示了所有团队当前的工作内容，是产品和项目级别管理的全貌，任何事情如果不在这面墙上，团队不会对它耗费一秒钟。\n 蓝色： 安全相关 红色：客户相关 黄色：云计算相关 绿色：技术相关 橙色：项目管理  这些是史诗级别的工作，是经过客户优先级排序的工作。 接下来构建了十六个团队的团队级别看板，团队会把这些实施工作拿走到他们自己的看板上。\n当团队工作在这个看板上之后，团队可以很好的处理计划外工作。如果有什么经理人员向团队提出其它工作的时候，团队可以回答“Yes”；然后请他看看当前的工作状态，说出可能的选项是什么？【注：讨论的结果很可能是，用Yes婉拒了计划外工作，或者请工作提出者交换他的进行中的工作。】\nTAP Room还是每个一个项目周期结束时，大家一起做回顾的场所，房间里提供了汉堡和热狗等午餐，团队成员用午餐会的形式交流各自的收获和想法。\n3 向全员推广，并提升参与度 - 各种坛子 如何将以上的成功经验传播到整个组织里，如何让更多的人参与其中，并提升全员的参与度。CSG创建了各种坛子的想法。\n每个坛子都有各自的负责人和执行周期。如Shark Tank是两周进行一次，如果任何人对产品和技术有谏言建议都会发到这里，负责人会统一收集和用不同的优先级排序。\n Shark Tank 组织战略级别的，由VP们管理 Think Tank 产品组合级别的，由产品经理/负责人管理 DO Tank Scrum团队级别，由团队的负责人管理  上面一行的三个坛子是把组织级别的业务战略直接贯彻和对齐到底（Engineer）方式，当然任何人也可以在各个层面上提出反馈建议，并实现了每个人的参与度的从下而上的反馈回路。\n下面一行的三个坛子和他们的组织架构相关，也分别有各种独立的定义和用法，所有坛子都是两周执行一次回顾和处理。\n4 倡导价值驱动和交付 在这个阶段中，CSG不想仅仅止步于成功经验的传播和反馈，希望让更多人知道能从哪里，获得他们需要的信息和帮助，从而复制那些在组织级别已经取得成功的套路。\nCSG制作了视频短片，用阶段性回顾的方式，总结了他们所谓的参与度、有趣、有价值和有意义等概念，希望人多人能加入到史诗团队中。让人们觉得是和公司息息相关的。\n这个短片用产品周报发布的全公司，根据数据统计显示，有大约500人在发布的当天从头看到尾。使所有人都参与到价值交付中，并感受到激动。\n5 产能洞察管理 - Capacity Insights CSG也和其它所有公司一样，每个团队都很忙，项目经理和交付的工程师团队也存在在感受不一致的情况。如下高压力对话也很常见。\n 你们能做更多工作么？ 不能！ 怎么会啊！ 我们很忙！ 给我一个忙的证据！  产能管理工具（Capacity Insights）的出现缓解了这个问题，首先，CSG把计划内的工作输入到这个工具里，并进行工作量的跟踪和记录。同时还把计划外的工作也纳入这个系统，进行统一的跟踪和记录。这里的数据在项目、产品和团队级别上被透明的分享和沟通，从此团队的高压力对话现象得到了大幅度的缓解，大家更有意愿进行合作了。\n这些数据可以按照各种价值流的维度将耗费的工作时间（计划和实用）统计出来，并按照产品、团队和技术技能等各种维度进行钻去和统计。这样就可以把宝贵的产能合理的使用，实现了好钢用在刀刃上。\n6 生活和工作平衡 CSG不希望工程师团队周末加班，当然一周工作时间超长的情况也很常见，CSG希望他们能过上正常人的生活。领导层关注到这个问题后，开始实施一些措施。建立了产品迭代回顾的画廊，如下图所示。\n在这个画廊上关注着一些数据的状态。\n 31个团队的总工作时间是15000小时 削减了25%的值守加班时间 削减了100%的测试数据配置工作，用自动化的方法削减了相当于3个全职工程师的工作量 用自动化的方式消除了某个业务流程确认环节90%的时间  CSG的成功秘诀是人，这都仰仗于赋能的员工：开放、分享、参与和兴奋。\n产品和项目的PK 对于这个话题的总结如下。\n 部门墙（Queue）有碍于学习进步 基于项目的团队管理有碍于学习进步 基于产品的团队才可以精进成长  CSG公司在2017年以前的工作模式，产品和项目并存。\n开发团队 - 产品工作\n 基于业务需求的史诗 （最左侧的） 基于发布节奏的工作 管理产品代办工作\u0026amp;排序 交付工作完成的解决方案  运维团队 - 项目工作\n 处理临时、非计划的发布工作 被各种会议驱动和中断 接受研发发布过来的解决方案（临时和计划的） 同时处理各种基础设施的IT项目（最右侧的）  当两者的工作节奏交织在一起的时候，就会产生各种冲突。\n出现了各种明显的问题：\n 双向的依赖关系 多个任务工作时间计划相互撞车 缺乏统一的依赖管理和产能规划，这进一步产生了大量进行中工作（WIP） 项目制的工作模式导致研发在迫于发布周期的情况下，交付了质量很低的解决方案  CSG随后进行了基于价值流的产品条线的聚焦，将开发和运维团队的代办工作事项都整合到了统一的单独入口，从而进行统一的管理。\n 单一的工作入口管理可以更好的在统一的时间轴上进行优先级排序管理，并且能够实现所有工作的可视化和排序。 设置不同的发布节奏，从2周到12周不等，还有特性的按需发布 根据完成度、业务需求和耦合程度，不同工作任务选取不同的发布节奏 进行工程上的重构：自动化、架构和运维即服务模式  完全参考和接受了ThoughtWorks技术雷达提出的：应用产品管理的方式到内部平台。\n运维团队的人也将IT工作转为产品交付的方式，指定专人专家管理内部的平台。安全运维被视为工程和产品问题，通过重构的工程方法优化平台。\n基于产品/服务价值流交付的管理方式是多个迭代，往复循环的迭代，而不会是简单的停止于测试完毕的验收发布。\n配置管理、服务请求变更管理、遥测、监控管理、安全、事件问题管理和相应都是产品管理的一部分，这些运行态的工作是产品生命周期中不可或缺的。也不应该被其它孤立的外部团操作。\n因此服务持续性管理也变成为一种内置的持续的动作，而不是这个流程之外的独立事件。\nCSG提倡：运维是工程和产品的问题，在本图中也得到体现，运维工作是产品的运行时管理工作，也是包括在持续的产品开发迭代中，最好有一个统一的持久的团队负责。\nCSG举例说明了”运维是工程和产品的问题“；CSG的业务系统需要处理信用卡信息，因此需要满足PCI的合规需求。在这个业务需求的驱动下，运维团队花费了无数的安全审计时间（20000+小时）去满足合规的标准。在产品驱动的思维下，运维团队和安全专家合作开发了，实现PCI合规的配置管理工具。这些安全管理工具是基于Chef开发的，也在Chef的开发者大会上分享过，而且现在是一个开源的产品，任何人都可以下载使用。\n通过以下的对比发现CSG在这个思维转型了以后所得到的收益。\nCSG在跨价值流的工作可视化管理方面也取得了一定的收益。\n以前各种不同工作分类的工作内容，上图每种颜色的方框就是一个分类，每个分类的工作都有各自不同的跟踪管理系统（工单系统）。在这种情况下如果跨价值流分析相关的工作内容，则非常困难，要依赖大量的手工统计和集成工作。统一的工作可视化无法实现。因此CSG使用Jira来统一管理和跟踪以上各种工作，从而得到准确和实时的视图。\n2019年的目标 CSG的2019年DevOps的发展目标和举措也很值得参考。\n Impact Minutes 服务受影响的时间 ： 4700分钟，实现年同步增长50%；计划实施系统的强壮性工程，落实人的可恢复性 Release on Demond 按需发布 ： 希望最终是消除发布这个环节，或者是高于70%的按需发布比例；计划实施的举措是重构架构、自动化、解耦。 eNPS 员工推荐率 ： 提升这个比例；计划实施的举措有精益领导力组合，链接到每个人，工作生活平衡。  ",
    "ref": "/blog/csg-product-meet-devops/"
  },{
    "title": "博客简介",
    "date": "",
    "description": "我的博客持续分享 DevOps 和 SRE 相关的文章。",
    "body": "http://www.martinliu.cn 是我的个人博客，开始于 2007 年。\nBIO 个人简介 Elastic 公司社区布道师，中国 DevOps 社区核心组织者，《DevOps Handbook》《The Site Reliability Workbook》译者；精通 DevOps/SRE/ITSM 等理论体系和相关实践等落地实现。致力于在全国范围内通过社区来推广 DevOps 的理念、技术和实践。推动开源 Elastic Stack 技术堆栈的应用，包括运维大数据分析平台、云原生服务治理、APM 全链路监控和 AIOps 等使用场景。\n关注我  B 站 - DevOps 教练 https://space.bilibili.com/477542716 DevOps Coach 网站 微信公众号 - DevOps 教练（MyDevOps）  实验室 DevOps 教练实验室  访问地址： https://devopscoach.org 简介：本实验室包含虚拟化、云计算、配置管理、CI、CD 等各种实验。 实验内容：  Vagrant 实验室 Elastic Stack 实验室 Chef 实验室 Ansible 实验室 Jenkins 实验室 Pipeline 流水线实验室    Nutanix 实验室  访问地址：https://nutanix.martinliu.cn 简介：本实验室包含 Nutanix CE 的基础安装，没有 Nutanix 专用服务器的朋友，可以从这一步开始。这里的所有练习步骤都是 Nutanix 软件的基础操作，在企业版软件上也同样适用。 实验内容：  Prism Central 部署和配置 Nutanix Calm 基础功能 Nutanix Calm 中级操作    《DevOps Handbook》- 《DevOps 实践指南》 翻译书籍 《DevOps Handbook》\n京东和亚马逊有售。\n 京东书店：https://item.jd.com/26848921955.html 英文原版-亚马逊书店：http://a.co/95lK7hC  《SRE Workbook》 - 《SRE 工作手册》 《SRE Paradox》 - 《DevOps 悖论》 ",
    "ref": "/about/"
  },{
    "title": "成熟度模型已死",
    "date": "",
    "description": "如果选择了错误的DevOps度量模型，就像货轮的导航罗盘坏了一样。",
    "body": "上一篇文章重要观点回顾：\n 应用DevOps的企业不应该使用成熟度模型度量 应用DevOps的不同企业/部门不会参考某个所谓标准 应用DevOps的不同企业/部门应该参考5大类24项的能力成长模型，来度量其发展进度，在磨练这些能力的过程中，选择符合自身业务需求的，且优先级别高能力先发展。  成熟度模型已死 这个模型在各行各业都可能存在，而且可能是最容易被人接受的模型之一。对于很多新生的领域，如法炮制的套用这个模型合适么？无论合适与否，它还是会出现在DevOps的领域中。为了避免实践者试错，我们不得来分析一下这种模型的特点。\n特征1 它总是阶梯式的，而且从来都是5个等级，人们经常戏称为Golden 5。常见的5级成熟度模型有下列几种。\nCMMI 能力成熟度模型集成\nITIL/ITSM的成熟度模型\nIT与业务融合的成熟度 http://www.cio.com.cn/eyan/1431.html\n德勤网络安全合规成熟度示意图\n持续交付流程成熟度\n如果你百度“成熟度模型”，还可以轻易地找到很多类似模型。客观的讲，这个模型是被广泛应用的神五级。\n这个模型对于任何使用的组织来说都是统一的，不会说对于有些企业是8级的，对于另外一些企业是10级的。\n这种模型的另外一个代名词是“XXX标准”，或者“XX行业标准”。\n特征2 通常对于每个等级上还可以定义出3到7个不同的维度。维度的数量少则3个级别，多字7到10个维度；可以要在每一个级别的不同维度上进行评价。这些维度一旦确定下来，也通常是十年如一日的静止不变。\n只是一种纵横交叉的矩阵的模式，如以上的持续交付流程成熟度、德勤网络安全合规成熟度示意图和IT与业务融合的成熟度都是这样。\n维度和等级往往都是静态的，通常模型发布之后，在很长一段时间里，不会发生改变。\n特征3 这些模型对于不同的组织而言，组织的目标都是一致而单纯的，即“通过/到达”某个级别。请你回忆一下以前的经历。一个软件开发组织经过一年的奋斗，他们通过了CMMI3级认证；第二年的时候，项目组一狠心，一跺脚一次性通过了5级认证。请问他们为什么一定要在第二年通过5级？在第三年里，相比以前，软件开发的质量提高了么？在第四年，有没有可能出现倒退的现象？如果你回答不了这些问题的话，可以尝试请教一个更资深一些的，工作10年以上的朋友或者同事。\n成熟度模型的局限性 根据以上的三个主要特征，这种模型的局限性大概有以下几个方面：\n每一个企业的自身条件、业务环境、资源约束都是不同的。让他们都对标一个统一的静态成熟度模型是不合适的。这就像是目前某些国家的教育体制一样。\nIT行业每天都在发生着巨大的变化，这就是我么经常提到的乌卡时代，今年流行的技术，很快就会过时，明年也将出现新的、未知的技术领域。很多行业的特点就是，在不断反复的被颠覆。而这些成熟度模型通常是永恒不变的。\n成熟度模型通常是在微观上进行考察，对很多考察点做孤立的分析和评测。这样做只能度量到技术、工具或者流程本身的一些方面。而忽视了组织通过它们所获得的总体成果产出。举个例子一个企业在通过了CMMI5级之后，发现收入/利润比以前还下降了；解释CMMI到达顶级的企业，业务收入还退步了，这本来就是一件比较尴尬的事情。\n如果一个集团企业，在所有IT组织/部门中强推某种成熟度模型的话，还有可能出现停滞不前的博弈现象。某些组织可能会宁愿待在中间的某个不成熟等级，并不愿意快速的提升到最高等级。那样的话，他们将失去每年一定数量的，用于提高成熟度等级的资源和预算。从最大化局部利益的角度考虑，最高级的成熟度可能等于最低级的资源支持。\n最后，无论到达了那个等级的成熟度，这种明确而清晰的满足感，滋生出了锚定效应。这其实阻碍了组织持续的探索和尝试未知领域，组织因此学习的知识就会越来越少。甚至于出现能力的下滑和倒退。\n综上所述，在DevOps的领域里，成熟度模型和统一标准已经过时了，它不适合用于DevOps的度量；而且，纵观整个行业，国际上目前还没有那一个适用的DevOps成熟度模型被应用于任何组织。那么还有什么其他DevOps适用的模型？\nDevOps能力成长模型 这个模型是在《Accelerate-加速器》这本书里被提出的。相信大家对Nicole博士联合Puppet Lab发起的DevOps状态调查和年度报告并不陌生。这本书分析了DevOps状态报告四年的历史数据，书里所展示的内容，其实也正好是作者Nicole Forsgren博士对DevOps现状调研的第一个迭代的阶段性成果。\n这本书的目标是解密高效能组织的高明之处，以及背后的原因。从探寻影响组织绩效的因素为起点，经过了四年的不断调研，Nicole博士向我们展示了一个相对比较完整的，各种影响因素的关系网。特别说明的是：下图来自于《加速器》这本书，这个形态是经过4年演进出来的，我们无法猜测2018年Nicole博士究竟怎样地拓展了调研的范围；更无法猜测的是：在2018年的状态报告结果中，这幅图会变成什么样子？\nNicole博士总结出了DevOps能力的5大分类，包含的能力点有24项。\n第一类：持续交付  对生产环境的所有工件进行版本控制 运用自动化部署流程 实施持续集成 运用基于主干的开发方法 实施测试自动化 进行测试数据管理 前置信息安全管理 实施持续交付  第二类：系统架构  应用松耦合的架构设计 授权团队进行架构重构的决策  第三类：产品和流程  收集和实施客户反馈 运用价值流模式可视化工作流 运用小批量的工作模式 培养和赋能团队进行试验  第四类：精益管理和监控  应用轻量变更审批流程 业务决策得到从应用到基础架构的全堆栈支持 前瞻性地监控系统的状况 应用WIP来进行价值流的工作管理 通过可视化来监控团队工作质量和进行沟通  第五类：企业文化  发展并支持生机型企业文化 鼓励和支持学习 支持和辅助团队间的协作 提供工作所需要的资源和工具 支持和落实领导力转型  DevOps能力成长模型的特点 首先，这个模型是基于4年以上的、科学的调查分析而来的。Nicole博士和全球最顶尖的DevOps公司，以及各种业内大咖，历经了多年的协作。其次，此模型是演变出来的，而且一定会持续更新。最后，分析一下这个模型的特点。\n 它目标是适用于能力和起点本来就参差不齐的不同的组织/团队。 它适用于每个团队在能力上优劣各不相同的情况。而且每个团队的业务使命和向下文也不相同。 它使每个团队聚焦在各自不同的能力点上，发展和解决各不相同的约束点/弱点。 以上能力模型来上游调查数据就是一个行业基线（基线也在不断变化中），不同的团队参考每一项能力的行业基线定义各自的下一步的发展目标。  建议的度量套路 可以将DevOps能力成长模型作为企业应用DevOps的一个有效的度量工具。通过持续的度量，现状分析和改进，让DevOps的优化全局价值产出的特性加速企业客户价值的增长。这里简单描述一下建议的套路\n 度量关键产出：这些指标是衡量你的团队软件交付的好坏与否的一个高阶的度量。相关指标有：IT效能、前置时间、部署频率、MTTR、变更失败率、加班程度和部署痛点。 能力驱动的改进：这些能力是你提升关键产出的抓手。由于你提高了一些能力，你在这些能力得到提升的同时，还能更快且可靠的交付软件。 按优先级改进：通过能力模型的评估，你识别出了那些能力约束点/瓶颈，是它们在阻止你达到更高的技术阶段，然后确定那些能力需要先优先发展。  ",
    "ref": "/blog/maturity-is-dead/"
  },{
    "title": "参与2018年DevOps状态调查报告",
    "date": "",
    "description": "",
    "body": "听说这里有一个15分钟就能完成的DevOps调查问卷，有25位参与者或将得到总值为3200美元的亚马逊购物券。一年也就是这一次机会。问卷调查将在10天后就关闭。\n这是DevOps状态报告调查问卷的第七年。在过去的6年里，已经有两万七千多人参与了这项调查。这项调查已经获得了丰硕的成果，主要是帮助你了解在DevOps之旅上当前的进展。今年又扩展了调查的范围，再度加深了对DevOps之旅的调研。\n我已经帮你把问题的套路摸清楚了，其实问题都很清晰直白，很容易和你所在企业的DevOps状态做匹配。填写问卷调查也是一个学习的过程，可以用开放的心态去了解一下，调查报告对DevOps的观察角度都有哪些？\n对其中的部分问题做出了简要的说明，预祝你在参加这项全球性著名调查的过程中，有一个愉快的体验。\n今年的看点 据说DevOps状态调查报告的一个最大的价值就是：在你的组织中，你可以用这些数据展示出DevOps的价值，从而取得管理层的支持，并启动DevOps项目。\n在今年的调查研究工作中，新加入的，对在企业中应用和推广DevOps有深度洞察的专家包括：\n Andi Mann, the chief technology advocate at Splunk and co-author of Visible Ops – Private Cloud and and The Innovative CIO. Michael Stahnke, a director of engineering at Puppet and the author of Pro OpenSSH. Alanna Brown, the director of product marketing at Puppet and creator of the first State of DevOps Report in 2013.  参加这项问卷调查将有25人会得到亚马逊购物券，价值 $100, $200 或 $500 ； 抽奖说明：\n $500 2 人 $200 8 人 $100 15 人  注：规则完整版 https://puppet.com/2018-devops-survey-contest-rules\n参与此项调研报告 每道问题选择了答案之后，会影响到后续所出现的问题，我选择了金融（含保险）行业的DevOps软件工程师的路径。\n这个调查的问题库非常强大，每一个问题的回答都在影响下一个问题的范围。有些问题是情景设定和分析题，会预设一个阶段（有可能是你还未达到的），在这种情况里作出你的判断和选择。\n翻墙之后网页刷新速度会更快一些。\n第一部分  Where do you work? / 你在那个大洲工作？ In which country do you work? / 在那个国家工作？ What is the principal industry of your organization? / 你的组织是什么行业的？ Which of the following best describes your title or role in your company? / 下面的各种头衔/角色那个和你最匹配？ What department do you work in? / 你什么部门工作？ And what team do you work on? / 你在什么团队工作？ Which of the following describes your level of knowledge regarding your organization’s IT operations and software delivery? / 下面那一项最准确地描述了你的组织在IT运维和软件交付方面的知识程度？  第二部分 Many people say that there are four elements of DevOps that work together as enterprises evolve. They are:\n Culture 文化 Automation 自动化 Measurement 度量 Sharing 分享  The next few questions will ask about each of these elements.\n这部分是对企业的CAMS调查的。\n  Where would you say you are at culture-wise, on your DevOps journey so far? / 在你目前的DevOps旅程中，DevOps文化存在于怎样的范围里？\n  Where would you say you are at automation-wise, on your DevOps journey so far? / 在你目前的DevOps旅程中，自动化的程度是怎样的？\n  Where would you say you are at measurement-wise, on your DevOps journey so far? Please select all that apply. / 在你目前的DevOps旅程中，在那些方面实施了度量？- 多选\n  Where would you say you are at sharing-wise, on your DevOps journey so far? / 在你目前的DevOps旅程中，在分享方面是怎么做的？\n  How frequently do each of these practices occur in your organization? / 下列实践在你的组织中发生的频率？从来没用过 ~ 总是在用 5级\n We balance lowering technical debt, with new feature work Configurations are managed by a configuration management tool A cross-functional review is done before implementation of a project Teams use continuous delivery Before starting a project, we establish concrete success criteria We create learning opportunities across teams (e.g., training, internal DevOps workshops, etc.) We expose data and services via APIs Success metrics for projects are visible DevOps initiatives are supported by senior leadership Teams use agile approaches across development and operations Developers are on-call for production issues Teams use continuous integration Source code is made available to other teams Experiences and lessons are shared externally (e.g., meetups / conferences, blog posts, etc.)    How frequently were each of these practices used when you were first starting out with DevOps? / 在你的DevOps刚刚起步的阶段，下列实践的使用频率是怎样的？从来没用过 ~ 总是在用 5级\n Application configurations are in version control Infrastructure teams use version control Automate system configurations (e.g. operating system baselines) System configurations are in version control Automate provisioning (e.g. server, VM, cloud instances, etc.) Application development teams use version control Automate security policy configurations    How frequently were these practices used after you started to see some traction with DevOps? / 在你开始感受到DevOps的优势以后，下列实践的使用频率是怎样的？从来没用过 ~ 总是在用\n We reuse deployment patterns for building applications or services Monitoring and alerting are configurable by the team operating the service We deploy on a single standardized operating system We deploy on a set of standardized operating systems We build on a standardized set of technologies Configurations are managed by a configuration management tool We reuse testing patterns for building applications or services    How frequently were the following used while you were expanding DevOps practices? / 在你推广DevOps实践的过程中，下列实践的使用频率是怎样的？从来没用过 ~ 总是在用 5级\n We have post-incident reviews and share results Security teams are involved in technology design and deployment Teams contribute improvements to tooling provided by other teams We reuse testing patterns for building applications or services Individuals can do their work without manual approval from outside of their team We reuse deployment patterns for building applications or services Monitoring and alerting are configurable by team operating service    How frequently were these practices used while you were optimizing your DevOps practices? / 当你在优化DevOps实践的过程中，下列实践的使用频率是怎样的？从来没用过 ~ 总是在用 5级\n Infrastructure changes are tested before deploying to production Rearchitect applications based on business needs (e.g., reducing operational costs, ease of deployment, etc.) Individuals accomplish changes without significant wait times Monitoring and alerting are configurable by team operating service Teams contribute improvements to tooling provided by other teams Service changes can be made during business hours Incident responses are automated    How frequently were these practices used while you were enabling self-service? / 在你管理自助服务的情况下，下列实践的使用频率是怎样的？从来没用过 ~ 总是在用 5级\n Teams contribute improvements to tooling provided by other teams Resources (e.g., accounts, infrastructure, etc.) made available via self-service Logging configuration is deployed with the application or service Monitoring and alerting are configurable by team operating service App developers deploy testing environments on their own    Which, if any, of the following processes or tools are “self-service” in your DevOps approach? Please select all that apply. / 在你的DevOps计划中，下列哪些流程或者工具会做成自助服务？\n  Which of the following organizational structures have you used in your DevOps journey? / 在你DevOps的旅程中，你曾经用过下列哪些组织结构？\n Cross-functional teams that are responsible for specific services or applications A centralized IT team and multiple application development teams A Site Reliability Engineering (SRE) team A service provider that provides DevOps capabilities (e.g. builds test environments, provides monitoring, etc.) A dedicated DevOps team    Please tell us what kind of development your organization does. / 你的组织开发各种类型软件的比例是多少？5个问题填写百分比，凑够100\n We do custom development for internal users We do custom development for COTS (commercial off-the-shelf software) We manage COTS (commercial off-the-shelf software (e.g., upgrades) We do in-house development of custom applications for external users    If you could move the needle on one metric related to DevOps, what would it be? / 如果让你仅仅选择一个度量DevOps的指标，这个指标是什么？ - 描述题\n  Just a few more questions to help us categorize your answers. / 下列问题帮助我们对你的组织进行分类。\n  What figure best describes your company’s annual revenue in US$ equivalent? / 你们公司的年营业额是多少美元？\n  What is the proportion of genders working on your team? / 你所在的团队男女比例？\n  Please tell us how you identify. / 请问告诉我们你认为自己是什么性别。\n  What is your current annual salary in US dollars? / 你的年薪是多少美元？\n  Do you consider yourself to be part of a visible or invisible minority where you work? / 你认为自己工作是显耀的还是无足轻重（少数派）的？\n  Please tell us of what minority(ies) you consider yourself to be a member. Please select all that apply. / 请告诉我们你的这种无足轻重是指哪方面？-多选\n  Would you like to receive an email with the report link when it is available? / 你是否希望收到这份报告的下载链接？\n  完毕 本文来源：https://puppet.com/blog/introducing-2018-state-devops-survey-new-research-focus\n调查问卷网址：https://polls.onresearch.net/DevOps/blog\n后记 DevOps圈子里的人都知道，这项问卷调查在IT行业里的知名度和权威性。它的目的在于：通过持续的研究DevOps在各个企业中应用的状态特征，定量的收集大量行业基础分析数据，这样所有的企业就有了一个可以参照的基线数据。更重要的是，它还将企业的绩效分成了高中低三个等级；对这些数据，用科学的分析方法，总结出了高绩效企业之所以高明的原因，将这些结论/假设/原因还在逐年推演和求证中。因此它形成了最具说服力的一些列结论。这些结论都展示在了历年来的DevOps状态报告中。\n今年 Nicole Forsgren博士，《Accelerate》一书的主要作者，用此书对多年来的DevOps状态分析做了一个总结。此书一出版就高居亚马逊畅销榜榜首，还被誉为DevOps界的科学。这本书为你展示了历年来的状态分析报告是怎么来的？调查的范围和方向是如何演进的？为什么会得出这样的分析结果？\n调查报告的分析结果是客观而科学的。而这本书向你展示了这些报告数据背后的How和Why。它提出了一个全新的主题“DevOps能力发展模型”；该书的一些结论也是非常具有颠覆性：\n 应用DevOps的企业不应该使用成熟度模型度量 应用DevOps的不同企业/部门不会参考某个共同标准 应用DevOps的不同企业/部门应该参考5大类24项的能力成长模型，来度量其发展进度，在磨练这些能力的过程中，选择符合自身业务需求的，且优先级别高能力先发展。  下图是24项能力的分解表：\n我在这本刚发布的时候购买了电子版。在参加5月份的DevOpsDays大会北京站的深度培训“持续交付”课上，遇到了这个培训老师的Jez Humble先生，他也是本书的合著者之一。意外地获赠了一本他的签名实体书。\n在学习了一段时间以后，我总结和归纳了一些内容：关于对DevOps能力发展模型的详细剖析，对24项DevOps主要发展能力之间的关联关系的解读；这些内容将会在8月份上海的DevOpsDays大会上呈现。\n",
    "ref": "/blog/2018-devops-survey/"
  },{
    "title": "从完美风暴说开去，直到DevOpsDays社区",
    "date": "",
    "description": "各种大会、各种喧嚣，你都看够了么？免费的，收费的，都与你有何相干？哪里是你自己的社区，哪里可以找到同类和导师？",
    "body": "各种大会、各种喧嚣，你都看够了么？免费的，收费的，都与你有何相干？哪里是你自己的社区，哪里可以找到同类和导师？本文是我对社区的一点个人的思考，感兴趣的读一下。\n本文的标题图片是中国DevOpsDays社区志愿者招募的标题图片，这是NASA的一张完美风暴的航拍图片，暂时不欣赏这幅图的完美之处。让我来先讲讲它的出处，这幅图来自于樊登读书会App，源于他最近读到的一本书《谢谢你迟到》。\n我觉得书名和DevOps有些相关性，DevOps在IT行业中的兴起是最近9年的事，说来这是一段不长不短的时间。纵观最近几年的IT行业，这是一个从业人员的幸福感和优越感急剧下降的过程，是敏捷、精益、CMM和ITSM等管理等套路，在逐渐被人质疑的过程，是IT行业内的大厂纷纷走向没落的9年。DevOps并不是从无到有蹦出来的，它的姗姗来迟也并不具有任何的偶然性，相反它是各种管理实践分久必合的必然结果，它是一个各种最佳实践的聚合体，它是从敏捷社区发源，然后逐步融入了各种必要的元素，而且各种元素之间产生了化学反应后的化合物。\n我对社区的认识源于很久以前在大学中对Linux的喜爱，从哪里听说了开源社区这种事物。对开源软件社区的深刻理解是在加入Red Hat公司期间形成的。Red Hat公司创造了一种神奇的开放文化（见CEO Jim出版的Open Orgnazation一书），让曾经在哪里工作过的员工可以将自己的职业生涯清晰的化为：Red Hat阶段和非Red Hat两个阶段（所有其它公司都是和Red Hat迥异的，都是雷同的）。这不是我自己总结的，是今天早晨和一个公司同事聊出来的，我们都曾经在Red Hat工作过，不过在那段时间里我们并不认识。\n在Red Hat的时候，当你加入到某个开源项目的邮件讨论组的时候，你会很自豪的有一等公民的感觉。由于你发现你的同事在各种项目的讨论中频繁出现，他们的日常工作就是在开源社区中修复bug，提交feature。虽然我并不贡献代码，不过还是觉得占了“Red Hat是个活雷锋”的形象的光。Red Hat公司的工程师在开源社区中的贡献，是这种项目的助推剂和催化剂。\n当然也有人觉得Red Hat是商业开源而已，少了早年开源社区的那种乌托邦式的纯粹感，并不是一种无欲无求的奉献。但是时代还是要继续，而且是不断的变迁的。开源软件社区就是这样轻易的颠覆了软件世界的格局，纷纷倒闭和没落的昔日贵族们，他们不都是巨无霸级别的闭源殿堂么？\n开源软件的开放性和分享精神给了我非常大的影响，这加深了我对社区的认识。DevOpsDays社区是不同于开源软件社区的，我对他的感受和理解基于软件开源社区，但隐约感觉到它们是两种社区，应该是不同的类型，但是目前还说不清楚。\n用台风眼作为DevOpsDays社区的比喻是在我听樊登讲《谢谢你迟到》时想到的。听完之后，看了一下App里的此书的图文描述，发现这的确是我所需要的寓意，下面直接转述，不做解释。\n 2.台风眼\n在台风来袭时，位于台风中心的台风眼反而是最安全、最风平浪静的。回到社区，找到自己熟悉的中心，就像是台风中的“台风眼”。\n台风眼也不是固定不动的，它能保持安稳的一大原因就是，它会应时而动。台风持续不断地移动，就像这个时代的脉搏，台风眼也随着它移动，保持自己始终处在有利的位置。\n台风眼就是我们每个人最好的老师。\n 我现在所深度参与的是“DevOpsDays社区”，它的历史可以追溯到 #DevOps 这个词的诞生，它的全球广泛程度可以参考官网 https://DevOpsDays.org ； 这也是我喜爱这个社区的两个原因。\n另外，我觉得DevOps本身对这个时代应该是很有价值的；此时此刻的深夜，我扫了一眼微信朋友圈，还是能看到“深夜、聚众、上线加夜班的团队”在上演着这不断重复的人间悲喜剧，看到他们相互的点赞、加油和鼓励；可是从DevOps的观点出发，我们其实可以冒出这样一句话：“其实还有一条更好的路”。\n虽然，有时候你觉得DevOps无处不在；但是，我个人深刻的意识到，其实IT行业中还有巨大数量的人，他们并不知道DevOps的存在。还有大量的人，个人掌握了DevOps的知识和实践，但是还是无法影响和改变周遭的人。还有大量的团队在迷迷糊糊地实施着DevOps。更有大量的公司在观望着DevOps。\n很显然，DevOps的推广和传播还是不够的，这是我觉得各种DevOps社区都应该意识到的一个事实。我们都有责任传播正确的理念和信息，切勿蹭着这个热点，而有不负责的传播着错误和误导的信息。所有博主、微信号和公司都应该自省。纷繁复杂的DevOps实践之间本来就已经存在着千丝万缕的联系，而它们的落地无不挑战和考验着所有的DevOps实践者们；只有在各自公司的业务场景里，运用科学系统的思维方式，经历相当长一段时间的实验阶段，才可能感知和捕捉到DevOps的好处和优势。在这个过程中，和同行的实践者坐而论道或将是一种很好的学习和提升的方式。而这也是DevOpsDays社区期望能为实践者们提供的。为此DevOpsDays社区需要做如下的工作，才能提供出以上的学习环境：\n 线上线下的分享会 线下的城市聚会 举办区域的大会  这些活动的发生时需要一定数量的人力、物力和财力。如果我们想在国内覆盖更大数量的群体，必然需要更多数量的志愿者。如果没有坚实的志愿者群体，没有志愿者群体的奉献，任何社区可能都是难于发展和存在的。\n总结 本文其实是写给我自己的和整个国内DevOps社区的，仅仅是简单地回顾了一下我个人的社区经历而已。不是想引导任何人来加入我们所发起的这个志愿者群体的。原因很简单：不到24小时，我们收到了近百人的报名申请。这让我们核心组织者措手不及。之前是发愁没有志愿者分担我们的劳动，而现在发愁的是如何与已经报名的人联系起来，我个人也没有管理如此数量志愿者群体的经验。最后希望我们可以快速的度过这个幸福难题；使志愿者们可以自组织地运作起来，让DevOpsDays社区为这个行业传播价值，让它在人和人之间创建有意义的链接。\n参与中国DevOpsDays社区的三种姿势：\n 关注，从中学习所需要的知识；就这样静静的看着挺好。 加入，分担一些志愿者工作，结交新朋友。 分享，为这个社区注入新鲜的知识和经验，社区需要更多这样的人，需要有更多的人可以成长为分享者，分享也是一种更高阶的学习。  中国DevOpsDays社区的官网是： http://ChinaDevOpsDays.org\n.\n",
    "ref": "/blog/perfect-storm-devops-days/"
  },{
    "title": "Kops on Aws",
    "date": "",
    "description": "这也许是最简单直接的Kubernetes安装大法",
    "body": "kops这种方式是我找到的最佳的，最适合于培训课堂需要的安装方式，当然对有类似需求的人有帮助。\nRoute53 DNS配置 kops需要使用DNS服务，用主机名提供k8s的相关服务访问。配置的注意点：\n 域名还是有必要有一个的，没有的话注册一个也不贵，以后用着也方便 建议在aws的Route53里做一个二级域名，例如：k8s.devopscoach.org 这个二级域名最好是能被正常公网解析的，为了便于直接访问集群里的服务 用 dig NS k8s.devopscoach.org 可以能正常解析（Mac上是这个命令）  由于全球的域名同步会需要一些时间，因此可以先做这一步，用到的时候，可能就已经同步好了。\nkops会将所有主机的域名解析都自动化的添加A记录到这里。\n安装工具准备 需要安装的工具包括 kubectl, kops 和 AWS CLI 工具。kops需要调用 AWS CLI来创建所需要的资源。我觉得简单的方法是：在目标的Region里创建一台Amazon AMI的虚拟机，这样AWS CLI就不用装了，而且在云里的话，执行kops的时候，由于有一大堆资源创建更新的api调用，感觉速度比在本机快很多，而且还用担心断网。\n可以启动一台t2.micro规格的Amazon AMI即可，另外需要给这个实例配置如下IAM用户权限，在启动的时候选择合适的IAM Role。\n AmazonEC2FullAccess AmazonRoute53FullAccess AmazonS3FullAccess IAMFullAccess AmazonVPCFullAccess  这台虚拟机启动之后，安装kubectl和kops。\ncurl -LO https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl sudo chmod +x kubectl sudo mv kubectl /usr/local/bin/kubectl wget https://github.com/kubernetes/kops/releases/download/1.8.0/kops-linux-amd64 sudo chmod +x kops-linux-amd64 sudo mv kops-linux-amd64 /usr/local/bin/kops 准备ssh登陆秘钥，用户ssh登录各个ec2实例\n[ec2-user@ip-172-31-27-182 ~]$ ssh-keygen Generating public/private rsa key pair. Enter file in which to save the key (/home/ec2-user/.ssh/id_rsa): Enter passphrase (empty for no passphrase): Enter same passphrase again: Your identification has been saved in /home/ec2-user/.ssh/id_rsa. Your public key has been saved in /home/ec2-user/.ssh/id_rsa.pub. The key fingerprint is: SHA256:oSPZf85vNsC7l9z24umLJs4tQ6qDMCrWfqAVXGYoA34 ec2-user@ip-172-31-27-182 The key's randomart image is: +---[RSA 2048]----+ |o . | |.o . + | | .+E+ . | | .o o . . | | + + S. | | oo . o + | | .+o.. .o.+ o | |oo .... .==.O.+. | |o ... .o .*@+==+.| +----[SHA256]-----+ [ec2-user@ip-172-31-27-182 ~]$ 创建S3 bucket 这是用来存储Kubernetes群集的配置信息的，kops在创建、运行、更新和管理它创建的群集过程中，没个Cluster的信息可以保存在bucket的一个目录中。\n[ec2-user@ip-172-31-27-182 ~]$ aws s3 mb s3://clusters.k8s.devopscoach.org make_bucket: clusters.k8s.devopscoach.org [ec2-user@ip-172-31-27-182 ~]$ export KOPS_STATE_STORE=s3://clusters.k8s.devopscoach.org 创建完成后，将其放入环境变量中待用。\n在集群安装完成之后，bucket里面的文件如下：\n创建Kubernetes Cluster 命令行参数如下：\n kops create cluster //创建集群 \u0026ndash;cloud=aws //使用aws \u0026ndash;zones=ap-northeast-1a //使用这个指定的zone \u0026ndash;name=dev.k8s.devopscoach.org //集群的名字 \u0026ndash;dns-zone=k8s.devopscoach.org //集群所使用的DNS解析区 \u0026ndash;dns public //对公可访问  命令的执行结果如下。\n[ec2-user@ip-172-31-27-182 ~]$ kops create cluster --cloud=aws --zones=ap-northeast-1a --name=dev.k8s.devopscoach.org --dns-zone=k8s.devopscoach.org --dns public I0401 17:05:06.003257 30031 create_cluster.go:971] Using SSH public key: /home/ec2-user/.ssh/id_rsa.pub I0401 17:05:07.132058 30031 subnets.go:184] Assigned CIDR 172.20.32.0/19 to subnet ap-northeast-1a Previewing changes that will be made: ********************************************************************************* A new kops version is available: 1.8.1 Upgrading is recommended More information: https://github.com/kubernetes/kops/blob/master/permalinks/upgrade_kops.md#1.8.1 ********************************************************************************* I0401 17:05:12.605297 30031 executor.go:91] Tasks: 0 done / 73 total; 31 can run I0401 17:05:13.546597 30031 executor.go:91] Tasks: 31 done / 73 total; 24 can run -----此处删除了n个字符------ VPC/dev.k8s.devopscoach.org CIDR 172.20.0.0/16 EnableDNSHostnames true EnableDNSSupport true Shared false Tags {Name: dev.k8s.devopscoach.org, KubernetesCluster: dev.k8s.devopscoach.org, kubernetes.io/cluster/dev.k8s.devopscoach.org: owned} VPCDHCPOptionsAssociation/dev.k8s.devopscoach.org VPC name:dev.k8s.devopscoach.org DHCPOptions name:dev.k8s.devopscoach.org Must specify --yes to apply changes Cluster configuration has been created. Suggestions: * list clusters with: kops get cluster * edit this cluster with: kops edit cluster dev.k8s.devopscoach.org * edit your node instance group: kops edit ig --name=dev.k8s.devopscoach.org nodes * edit your master instance group: kops edit ig --name=dev.k8s.devopscoach.org master-ap-northeast-1a Finally configure your cluster with: kops update cluster dev.k8s.devopscoach.org --yes [ec2-user@ip-172-31-27-182 ~]$ kops命令列出了所有需要建立的资源清单。而真实的开始资源创建，并搭建和配置Kubernetes集群还需要执行，以上输出中提示的最后一条命令: kops update cluster dev.k8s.devopscoach.org --yes\n执行结果如下：\n[ec2-user@ip-172-31-27-182 ~]$ kops update cluster dev.k8s.devopscoach.org --yes ********************************************************************************* A new kops version is available: 1.8.1 Upgrading is recommended More information: https://github.com/kubernetes/kops/blob/master/permalinks/upgrade_kops.md#1.8.1 ********************************************************************************* I0401 17:13:02.482203 30077 executor.go:91] Tasks: 0 done / 73 total; 31 can run I0401 17:13:04.389402 30077 vfs_castore.go:430] Issuing new certificate: \u0026quot;apiserver-aggregator-ca\u0026quot; I0401 17:13:04.628667 30077 vfs_castore.go:430] Issuing new certificate: \u0026quot;ca\u0026quot; I0401 17:13:07.291294 30077 executor.go:91] Tasks: 31 done / 73 total; 24 can run I0401 17:13:09.273293 30077 vfs_castore.go:430] Issuing new certificate: \u0026quot;kubelet-api\u0026quot; I0401 17:13:09.803612 30077 vfs_castore.go:430] Issuing new certificate: \u0026quot;kubelet\u0026quot; I0401 17:13:09.809131 30077 vfs_castore.go:430] Issuing new certificate: \u0026quot;kube-scheduler\u0026quot; I0401 17:13:09.973826 30077 vfs_castore.go:430] Issuing new certificate: \u0026quot;apiserver-proxy-client\u0026quot; I0401 17:13:10.317412 30077 vfs_castore.go:430] Issuing new certificate: \u0026quot;kops\u0026quot; I0401 17:13:10.321177 30077 vfs_castore.go:430] Issuing new certificate: \u0026quot;apiserver-aggregator\u0026quot; I0401 17:13:10.440919 30077 vfs_castore.go:430] Issuing new certificate: \u0026quot;kube-controller-manager\u0026quot; I0401 17:13:10.630182 30077 vfs_castore.go:430] Issuing new certificate: \u0026quot;kubecfg\u0026quot; I0401 17:13:11.020560 30077 vfs_castore.go:430] Issuing new certificate: \u0026quot;master\u0026quot; I0401 17:13:11.040010 30077 vfs_castore.go:430] Issuing new certificate: \u0026quot;kube-proxy\u0026quot; I0401 17:13:12.698208 30077 executor.go:91] Tasks: 55 done / 73 total; 16 can run I0401 17:13:13.609559 30077 launchconfiguration.go:333] waiting for IAM instance profile \u0026quot;nodes.dev.k8s.devopscoach.org\u0026quot; to be ready I0401 17:13:13.656221 30077 launchconfiguration.go:333] waiting for IAM instance profile \u0026quot;masters.dev.k8s.devopscoach.org\u0026quot; to be ready I0401 17:13:24.156701 30077 executor.go:91] Tasks: 71 done / 73 total; 2 can run I0401 17:13:24.864262 30077 executor.go:91] Tasks: 73 done / 73 total; 0 can run I0401 17:13:24.864379 30077 dns.go:153] Pre-creating DNS records I0401 17:13:26.454177 30077 update_cluster.go:248] Exporting kubecfg for cluster kops has set your kubectl context to dev.k8s.devopscoach.org Cluster is starting. It should be ready in a few minutes. Suggestions: * validate cluster: kops validate cluster * list nodes: kubectl get nodes --show-labels * ssh to the master: ssh -i ~/.ssh/id_rsa admin@api.dev.k8s.devopscoach.org The admin user is specific to Debian. If not using Debian please use the appropriate user based on your OS. * read about installing addons: https://github.com/kubernetes/kops/blob/master/docs/addons.md 以上这套组合拳打出去之后，需要等几分钟才能完成Kubernetes集群的部署。\n在以上实例中创建的Ec2实例如下：\n master-ap-northeast-1a.masters.dev.k8s.devopscoach.org //m3.medium nodes.dev.k8s.devopscoach.org //t2.medium nodes.dev.k8s.devopscoach.org //t2.medium  也创建了两个ASG：\n 一个是针对master的扩容规则 另外一个是针对worker node的扩容规则  从扩容规则为空可以看出，它主要是用于定义集群规格的，而非自动化扩容的。\n在安装完成之后，用一下命令确认集群状态如下：\n[ec2-user@ip-172-31-27-182 ~]$ kops validate cluster Using cluster from kubectl context: dev.k8s.devopscoach.org Validating cluster dev.k8s.devopscoach.org INSTANCE GROUPS NAME ROLE MACHINETYPE MIN MAX SUBNETS master-ap-northeast-1a Master m3.medium 1 1 ap-northeast-1a nodes Node t2.medium 2 2 ap-northeast-1a NODE STATUS NAME ROLE READY ip-172-20-38-48.ap-northeast-1.compute.internal master True ip-172-20-45-235.ap-northeast-1.compute.internal node True ip-172-20-63-157.ap-northeast-1.compute.internal node True Your cluster dev.k8s.devopscoach.org is ready [ec2-user@ip-172-31-27-182 ~]$ kubectl get nodes --show-labels NAME STATUS ROLES AGE VERSION LABELS ip-172-20-38-48.ap-northeast-1.compute.internal Ready master 5m v1.8.7 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=m3.medium,beta.kubernetes.io/os=linux,failure-domain.beta.kubernetes.io/region=ap-northeast-1,failure-domain.beta.kubernetes.io/zone=ap-northeast-1a,kops.k8s.io/instancegroup=master-ap-northeast-1a,kubernetes.io/hostname=ip-172-20-38-48.ap-northeast-1.compute.internal,kubernetes.io/role=master,node-role.kubernetes.io/master= ip-172-20-45-235.ap-northeast-1.compute.internal Ready node 4m v1.8.7 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=t2.medium,beta.kubernetes.io/os=linux,failure-domain.beta.kubernetes.io/region=ap-northeast-1,failure-domain.beta.kubernetes.io/zone=ap-northeast-1a,kops.k8s.io/instancegroup=nodes,kubernetes.io/hostname=ip-172-20-45-235.ap-northeast-1.compute.internal,kubernetes.io/role=node,node-role.kubernetes.io/node= ip-172-20-63-157.ap-northeast-1.compute.internal Ready node 4m v1.8.7 beta.kubernetes.io/arch=amd64,beta.kubernetes.io/instance-type=t2.medium,beta.kubernetes.io/os=linux,failure-domain.beta.kubernetes.io/region=ap-northeast-1,failure-domain.beta.kubernetes.io/zone=ap-northeast-1a,kops.k8s.io/instancegroup=nodes,kubernetes.io/hostname=ip-172-20-63-157.ap-northeast-1.compute.internal,kubernetes.io/role=node,node-role.kubernetes.io/node= [ec2-user@ip-172-31-27-182 ~]$ 创建并访问服务 如下所示的创建两副本的nginx部署，部署的命令 sample-nginx。\n[ec2-user@ip-172-31-27-182 ~]$ kubectl run sample-nginx --image=nginx --replicas=2 --port=80 deployment.apps \u0026quot;sample-nginx\u0026quot; created [ec2-user@ip-172-31-27-182 ~]$ kubectl get pods NAME READY STATUS RESTARTS AGE sample-nginx-7588757c8f-jvkjt 1/1 Running 0 5s sample-nginx-7588757c8f-zq8tj 1/1 Running 0 5s [ec2-user@ip-172-31-27-182 ~]$ kubectl get deployments NAME DESIRED CURRENT UP-TO-DATE AVAILABLE AGE sample-nginx 2 2 2 2 13s 然后将这个部署暴露为服务，使用到Kubernetes的命令如下：\n[ec2-user@ip-172-31-27-182 ~]$ kubectl expose deployment sample-nginx --port=80 --type=LoadBalancer service \u0026quot;sample-nginx\u0026quot; exposed [ec2-user@ip-172-31-27-182 ~]$ kubectl get services -o wide NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE SELECTOR kubernetes ClusterIP 100.64.0.1 \u0026lt;none\u0026gt; 443/TCP 10m \u0026lt;none\u0026gt; sample-nginx LoadBalancer 100.64.127.19 ae3a1ca9235d111e890d706038dd676b-392190656.ap-northeast-1.elb.amazonaws.com 80:30363/TCP 25s run=sample-nginx 这条命令 ubectl expose deployment sample-nginx --port=80 --type=LoadBalancer 会创建一个ELB并将，集群里容正在运行的 sample—nginx 服务注册到这个ELB，然后就可以访问浏览到Nginx的默认页面了。\n删除集群 用一条命令就能删除以上所建立的Kubernetes集群。\nkops delete cluster --name=dev.k8s.devopscoach.org --yes ",
    "ref": "/blog/kops-on-aws/"
  },{
    "title": "容器化应用的设计原则",
    "date": "",
    "description": "来自Red Hat咨询团队大牛的最佳实践和经验总结",
    "body": "本文来自于Red Hat咨询顾问Bilgin Ibryam所编写的一篇白皮书，名为《PRINCIPLES OF CONTAINER-BASED APPLICATION DESIGN》。这篇文章在作者的Blog上发表后，作者的twitter被Kubernetes官方twitter转发。白皮书在Red Hat官网的下载地址：https://www.redhat.com/en/resources/cloud-native-container-design-whitepaper 文本是对这篇文章的学习和整理。\n先回顾经典的软件设计原则：\n 保持简单，愚蠢（KISS） 不要重复自己（DRY） 你不会需要它 （YAGNI） 关注点分离（SoC） Single responsibility, Open/closed, Liskov substitution, Interface segregation, Dependency inversion （SOLID）  然后是Red Hat的云原生容器设计原则：\n 唯一关注性原则（SCP） 高度可观测性原则（HOP） 生命周期一致性原则（LCP） 镜像不可变性原则（IIP） 进程可处置性原则（PDP） 自包含性原则（S-CP） 运行时约束性原则（RCP）  很多组织都理解云原生的重要性和必要性，但是并不知道从哪里开始。那么请确保：云原生平台和容器化应用能无缝的运行在一起，并且具备抵御故障的能力，甚至在底层的基础架构出现宕机的时候，也能通过过弹性扩展的方式表现出可靠性。本文描述了容器化应用时需要遵循的基本准则，实施这些原则有助于使之与云原生平台Kubernetes更加适配。\n唯一关注性原则 SINGLE CONCERN PRINCIPLE（SCP） 在许多方面，唯一关注性原则与来自SOLID的SRP是类似的，它建议一个类应该只有一个责任。SRP背后的动机是每个责任是变更的一个轴心，一个类应该有，且也只有一个需要改变的理由。SCP原则中的“关注”一词强调关注是一种更高层次的抽象的责任，而且它更好地将范围描述为一个容器而不是一个类。虽然SRP的主要动机是变化原因的唯一性，而SCP的主要动机是容器镜像重用和可替换性。如果你创建一个解决单个问题的容器，并且以功能完整的方式来实现，不同应用程序中的容器镜像重用的可能性就会更高。\n因此，SCP原则规定每个集容器都应该解决一个问题，并做得很好。 实现这一点，通常比在面向对象的世界中实现SRP更容易，容器通常管理的一个单一的进程，大多数情况下一个进程解决一个问题。\n如果你的容器化微服务需要解决多个问题，它可以使用这样的模式，将多个容器用sidecar和init-containers的模式合并成一个部署单元（pod），这样每个容器仍然是处理单个问题。同样，您可以替换处理同样问题的容器。 例如，将Web服务器容器或队列实现容器，更新为更具可扩展性的容器。\n高度可观测性原则 HIGH OBSERVABILITY PRINCIPLE（HOP） 容器提供了一种统一的方式来打包和运行应用程序，将它们视为一个黑盒子对象。 但任何旨在成为云原生公民的容器都必须提供API支持，要为运行时环境编写接口（API），以观察容器的健康状况和行为。 这是自动化容器更新和生命周期回收的基本先决条件和统一的方式，从而提高系统的弹性和用户体验。\n实际上，您的容器化应用程序必须至少为其提供不同类型的健康检查的API\u0026ndash;活动和就绪等状态。更好的应用程序的行为则必须提供其他手段来观察容器化应用程序的状态。应用程序应该将重要事件记录到标准错误（STDERR）和标准输出（STDOUT）中，从而通过统一的日志聚合工具（诸如Fluentd和Logstash之类的工具）进行分析，并与跟踪和指标收集库相结合，例如OpenTracing，Prometheus等。\n将您的应用程序视为黑盒子，但实施所有必要的API以帮助平台对其进行观测，并以最佳方式管理您的应用程序。\n生命周期一致性原则 LIFE-CYCLE CONFORMANCE PRINCIPLE（LCP） HOP规定了你的容器提供供平台观测的API。 LCP则规定：您的应用程序有办法读取来自平台的事件。 此外，除了获得事件以外，容器还应该对这些事件相应地作出反应。这就是此原则名字由来。这几乎就像在应用程序通过一个“写入API”与平台进行交互。\n来自管理平台的各种事件都是为了帮助您管理您的容器的生命周期的。决定处理哪些事件取决于您的应用程序 以及是否对这些事件做出反应。\n但有些事件比其他事件更重要。例如，任何需要一个干净的关闭进程，这就需要捕获信号：终止（SIGTERM）消息，并尽可能迅速关闭。 这是为了避免通过强制关闭信号：kill（SIGKILL），之后跟随一个SIGTERM。\n还有其他事件，例如PostStart和PreStop，可能对您的应用程序生命周期管理也非常重要。 例如，某些应用程序需要在服务之前进行预热请求和一些需要在关闭干净之前释放资源。\n镜像不可变性原则 IMAGE IMMUTABILITY PRINCIPLE（IIP） IMAGE IMMUTABILITY PRINCIPLE（IIP）容器化的应用程序是不可变更的，镜像一旦完成了构建，预计在不同的环境中运行都不会改变。这意味着在因外部环境的不同，在需要的时候需要使用外部手法处理所依赖的外部配置数据，而不是每个环境修改或者构建不同的容器。而容器应用程序中的任何变更，都应该因此触发构建新的容器映像，并在所有环境中重用它。相同于这个原理的，不可变服务器和不可变基础架构的概念也很受欢迎，并且对于服务器/主机管理也是如此。\n在遵循IIP原则的情况下，应该防止为不同的环境创建相似的容器镜像，要始终坚持为所有环境只配置一个容器映像。 这个原则允许在应用程序更新期间，采用自动回滚和前滚等做法，这是云原生自动化的重要方面。\n进程可处置性原则 PROCESS DISPOSABILITY PRINCIPLE（PDP） 迁移到容器应用程序的主要动机之一是：容器需要尽可能做到临时性，并做好在任何时候被另一个容器实例替换的准备。需要更换容器的原因有很多，比如：健康检查失败、缩容、应用程序将容器迁移到不同的主机，平台资源匮乏或其它的问题。\n这意味着容器化的应用程序必须保持其状态为向外扩展的或分布式和冗余的。这也意味着应用程序应该快速启动和关闭，甚至为彻底的硬件故障做好准备。 实施这一原则的另一个有用的做法是创建小容器。 容器在云原生环境可以自动调度并在不同的主机上启动。较小的容器可以实现更快启动时间，因为在重新启动之前容器镜像需要被物理地复制到主机系统。\n自包含性原则 SELF-CONTAINMENT PRINCIPLE（S-CP） 这个原则规定一个容器应该在构建时包含所有需要的东西。容器的存在应该仅仅依赖于Linux®内核，在并添加相关额外的库，在容器构建时加入它们。除了库之外，它还应该包含语言运行时，应用程序平台（如果需要），以及运行所需的其他依赖关系，等运行容器化应用所需要的诸如此类的东西。\n唯一的例外是：由于不同环境之间差异，并且只能在运行时提供的配置; 例如，通过Kubernetes提供的ConfigMap。\n某些应用程序由多个容器组件组成。 例如，容器化的Web应用程序也可能需要数据库容器。 根据这个原则，并不建议合并两个容器。相反，它建议的是数据库容器只包含运行数据库所需的所有内容，Web应用程序容器只包含运行Web应用程序所需的所有内容，如Web服务器。 在运行时，Web应用程序容器将根据需要依赖于并访问数据库容器。\n运行时约束性原则 RUNTIME CONFINEMENT PRINCIPLE（RCP） S-CP从构建时的角度查看容器，并关注于生成的二进制文件及其内容。但是容器不仅仅是磁盘上一个只有尺寸大小的单一维度的黑盒子。 容器运行时有多个维度，例如内存使用维度，CPU使用维度等资源消耗维度。\n这个RCP原则建议每个容器申报资源需求，并发送信息到平台。它应该分享容器的资源配置文件，从CPU，内存，网络，磁盘的角度声明。这影响到平台如何执行调度，自动扩展，容量 管理以及容器常规的服务级别协议（SLA）等。\n除了向平台声明容器的资源需求之外，还有一点也很重要， 应用被约束在使用所声明的资源需求内。如果应用程序对资源的使用保持在约束的范围内，则当资源匮乏发生时，平台不太可能将其终止和迁移。\n结论 云原生不仅仅是一种最终状态 - 它也是一种工作方式。 本份白皮书描述了一系列容器应用的基本原则，必须遵守才能成为优秀的云原生公民。\n除了这些原则之外，创建良好的容器应用程序还需要熟悉其他容器相关的最佳实践和技术。 尽管上述原则非常根本，适用于大多数用例，下面列出的最佳实践在应用和不应用的时候，则需要判断力。以下是一些与容器相关的更常见的最佳实践：\n 镜像要尽可能的小。 通过清理临时文件，并避免安装不必要的软件包来构建小尺寸镜像。 这减少了容器的尺寸，构建时间和复制容器镜像的网络传输时间。 支持任意用户ID。 避免使用sudo命令或要求特定用户名运行你的容器。 标记重要的端口。 虽然可以在运行时指定端口号，然而使用EXPOSE命令在运行的时候指定，则可以让镜像的使用者更轻松。 为持久数据使用卷。 在容器摧毁之后还需要保存的容器数据的，必须将数据写入一个数据卷。 设置镜像元数据。 以标签和注释形式存在的镜像元数据可以使您的容器镜像更加实用，从而为使用您的容器的开发人员提供了更好的体验。 使主机和镜像同步。 一些容器应用需要容器在某些属性（如时间和机器ID）上与主机同步。  这里是指向各种模式和最佳实践的资源的链接，以帮助您能有效地实现上述目标：\n • https://www.slideshare.net/luebken/container-patterns • https://docs.docker.com/engine/userguide/eng-image/dockerfile_best-practices • http://docs.projectatomic.io/container-best-practices • https://docs.openshift.com/enterprise/3.0/creating_images/guidelines.html • https://www.usenix.org/system/files/conference/hotcloud16/hotcloud16_burns.pdf • https://leanpub.com/k8spatterns/ • https://12factor.net  ",
    "ref": "/blog/cloud-native-container-design/"
  },{
    "title": "7种DevOps工程师必备技能",
    "date": "",
    "description": "7种DevOps工程师必备技能",
    "body": "使用DevOps的目的是改变和改善开发与IT运营之间的关系，倡导两个部门之间更好的沟通与协作。虽然这看起来有些简单，然后，DevOps工程师还需要做更多的工作，才能成功部署代码，并将Dev和Ops两个部分成功地绑定在一起。\n从应付DevOps压力的角度出发，DevOps工程师除了需要日常技能的基础，每个工程师都必须具备多种技能。DevOps工程师除了要对脚本和编码有着强烈的热情之外，还必须具有开放的思想和协作精神，才能成功地执行该过程。\n“DevOps教练”参考一些文献，已经为你设计了一个清单，列出了下面的7种必备技能，公司的DevOps工程师的招聘需求里，应该明确提出下列所有品质。\n1. 灵活性 编码是一个持续的过程，不断变化，总是需要更新。要成为一个成功而有效的DevOps工程师，理想的候选人必须有能力不断地开发新的系统，并将其集成到主干代码中。DevOps工程师必须具有灵活的工作技能并适应不断变化的代码。\n无论是集成、测试、发布还是部署，工程师都必须能够轻松地从一个软件构建领域迁移到另一个领域。例如，持续集成需要具备快速有效地管理变更的技术技能，并且能够在团队中协作，以保证每个人都朝着共同的目标努力。\n2. 安全技能 与许多其他所熟练的领域一样，安全始终是最重要的，尤其是在编码方面。黑客进入系统的一个简单方法是利用漏洞，破坏现有的系统并获取数据。 DevOps带来了更快的代码开发和部署周期，这意味着漏洞也比以前更容易引入代码。因此，工程师必须具备编写安全代码的技能，以保护应用程序免受不期望的攻击，此外还要确保系统针对常见的网络安全漏洞建立防御机制。\nDevOps工程师在受雇时必须具备安全技能，因为软件从部署一开始就内置了安全性(而不是在以后添加)是至关重要。如果从一开始就没有安全措施，那么黑客就有更多的机会通过网络注入破坏性代码。因此，在招聘下一位DevOps工程师时，确保安全性是技能列表中最重要的一项。\n3. 协作 对于一个成功的DevOps工程师来说，不具备八面玲珑的和周围打成一片的能力是不行的——协作实际上是DevOps概念的核心，它将软件开发和软件运维结合在一起。DevOps工程师必须具备团队合作的能力，在DevOps流程中协作提供了更多的跨职能的联动。\n4. 脚本编写技巧 尽管这一点听起来很显然，但任何开发人员都必须具备编写代码的高超技能。无论是JavaScript、Python、Perl还是Ruby，一个成功的开发工程师都必须能够编写代码。\n从编写手动代码到替换手动操作流程(如分配IP地址或DNS代码)，必须团队里必须具有能够编写这些代码的人员，这是完美的候选人应该能够做到的。\n5. 决策 一个优柔寡断的候选人不是你想要的业务开发工程师。一个成功DevOps工程师候选人将有能力自信而迅速地作出决定，即使是在繁忙的环境工作。\n代码不断变化的特性使得必须快速决定如何修复代码中任何不连贯的元素。果断性必须是雇用DevOps工程师时要考虑的一个因素，因为快速决策允许工程师保持快速开发和部署新编码更改的能力。\n6. 基础架构知识 脚本编写只是开发人员应具备的关键技能之一，仅次于云和基础架构的经验。工程师应该对基于数据中心和云基础架构的各种组件的工作方式有一定了解。这包括软件如何联网、并运行在虚拟网络上等要素。\n如果没有理解基础架构的能力，要成为全栈软件开发工程师可能会有些困难。整合基础架构技能将使有效的DevOps工程师能够使用最佳的平台，有效地设计和部署应用程序。还能提出优化建议。\n7. 软技能 如上所述，当一名DevOps工程师不是一个人在工作，所以在这种情况下，任何未来的员工必须具备软技能和技术。在信任的前提下，DevOps文化使所有员工能够与流程进行沟通和理解，在需要的时候作出变化。\n当开发人员有效地相互沟通时，应用程序可以在比某些工作人员不在上下文中的情况里要短得多的时间内交付。以及更快的进入市场，良好的通信将导致更少的错误，从而降低成本并提高代码质量。\n",
    "ref": "/blog/7-skills-devops-engineer/"
  },{
    "title": "2018年必须认识到的6个DevOps趋势",
    "date": "",
    "description": "2018年你必须认识到这6个DevOps趋势",
    "body": "DevOps已经出现了很长时间，我们中的很多人都认为它只是一个时髦词。现在我们知道这并不是一个神话。DevOps已经成为一个IT主流的焦点，并且在过去的几年里一直在重塑着软件世界。专家表示，DevOps将成为主流，2018年DevOps的人气将达到顶峰。\n下面是术语“DevOps”在Google趋势里的现状，以及对2018年预计增长的假设。 谈到统计数据，从2015年到2016年，DevOps的应用企业数增加了约8%，预计2018年这一数字将大幅增长，如上所示。\n你可以阅读RightScale的整个报告。甚至Forrester的报告也明确提到2018年将是DevOps的一年。\n最近发表的关于DevOps的事实和统计数据的文章得到了DevOps爱好者的热烈响应，它只是表明许多技术布道者者对了解更多DevOps并在他们的组织中实施DevOps很感兴趣。\n今天，我们将看到以下事实将塑造DevOps的未来。\n1 将重心从CI流水线移到DevOps装配线 通过CI流水线可以显示应用程序从源代码管理到生产的完整可视化。你可以在一个统一的视图上看到一切。它不仅仅只关于CI，它更多是作为CD (连续交付)的基础；组织正在投入时间和精力来进一步了解自动化其完整的软件开发流程。2018年，第一大DevOps转变将是从单纯的CI流水线转变为DevOps的装配线链接是Shippable关于装配线的描述。\n2 自动化将成为主要关注点 在DevOps中，我们经常谈论自动化。如果可能，对服务器的零接触自动化将是未来的趋势。这并不意味着你必须自动化一切，但如果你必须这样做，那么你应该能够做到。了解DevOps循环的6个C，并确保在这些阶段之间应用自动化是关键，这将是2018年的主要目标。\n3 测试人员需要学会编写代码 在DevOps中，需要测试人员知道如何编写自动化脚本来测试各种情况。如果您是一名测试人员，如果在是否学习编码的问题上进退两难，那么我建议您学习编码。了解不同的DevOps工具和自动化脚本，在当今的软件开发中起着至关重要的作用，这将在2018年占据主导地位。\n如果测试人员不学习自己编写自动化测试脚本，他们将会灭亡。手动测试将在2018年过时，它将占用大量时间。自动化测试不仅可以提高效率，还可以确保功能更快地交付给市场。\n4 微服务体系结构应用的增加 DevOps和微服务最近正是天作之合。微服务是独立的实体，因此不会在出现问题时由于任何依赖关系而中断其他系统。微服务体系结构可帮助公司轻松进行部署和添加新功能。预计公司将转向微服务体系结构，以提高其运行时间和效率。不要因为别人采用了微服务体系结构就跟着他们走，点这个文章：了解自己并理解为什么应该采用微服务体系结构。\n5 预计将有更多的公司选择企业版DevOps工具 目前有许多公司仍然处于建造还是购买的两难境地。但是，我们建议您做您最擅长的事情，并根据您的要求购买工具。这不仅有助于您专注于自己的目标，而且通过完全依赖第三方平台来提高工作效率。许多公司现在都在寻求企业版本，以获得自己的DevOps基础架构，并确保安全性尽可能掌握在最佳人员手中。\n6 KUBERNETES将会大行其道 Kubernetes因其优异的功能性和易用性，从而成为增长最快的容器技术。kubernetes围绕它建立了一个伟大的开源社区。在全球范围内，许多首席信息官和技术人员都采用了Kubernetes，采用比例预计将在2018年进一步提升。\n最近，在KubeCon + CloudberNativeCon北美( 2017年12月6日至8日)之前，云计算基金会进行了一项调查，并分享了容器编排环境正在发生的变化和向Kubernetes的转变。\n来源:容器业务流程环境正在更改。\n以上是将在2018年复现的DevOps的6个趋势。\n",
    "ref": "/blog/6-devops-trends-aware/"
  },{
    "title": "2018值得关注的15个DevOps大会",
    "date": "",
    "description": "",
    "body": "本文向你简要介绍2018年DevOps界的15大最重要的大会活动。DevOps的一个方面就是持续\u0026hellip;\u0026hellip;.参加大会学习！全球范围内看，基本上每个月都至少有一个我们值得重点关注的大会。我们不能奢望都你有机会参加，但是作为DevOps业内人士，如果你不了解这个大会的情况，你就Out了。\n这些大会中有些社偏技术的、有些是注重社交和体验；根据你的业务需求和学习目标，今年走出去参加最高端DevOps盛会的奢望可以有。不提前做功课，怎么能说服领导支持你呢？万一领导批准了呢？\n1. Cloud \u0026amp; DevOps World June 12-14, London\ncloud\u0026amp;DevOps World是techxl 8的一部分，是一系列各种技术会议、网络机会和博览会的一部分。cloud\u0026amp;DevOps World涵盖云创新和管理微服务、DevOps、容器、无服务器体系结构和监管实践。云与云世界的一大亮点是，您可以通过展览的其他部分(如物联网和虚拟现实会议)看到云概念和云概念在发挥作用。\n与会者还可以向观众演示他们的云解决方案，并享受联网、交互式会话和讨论面板。在去年的展会上，有300多家参展商和15000多名与会者参加，使这成为业界最大的展会之一。\n2. DevOps Enterprise Summit (DOES) June 25-26, London\nDevOps企业峰会针对的是参与DevOps革命的主要企业的高级经理。该大会深入探讨了各种重要的主题，一方面涉及技术和架构问题，另一方面涉及领导力挑战。DevOps Enterprise Summit的主题演讲、专题小组讨论、聊天室、社交圈区和展览大厅。\n伦敦活动的讲演者包括来自IBM、Puppet、微软和各行各业的资深人士。DOES是一项每年举办两次的活动，地点在美国和欧洲之间变化。上一次在旧金山举行的展览有1400多人参加。\n3. O’Reilly Velocity Conference June 11-14, San Jose\nVelocity会议是本列表上排名第三的活动，由O’Reilly Media欧莱利媒体公司举办，该公司是一家技术媒体公司，在各种技术领域举办了无数的展览。Velocity会议在讨论站点可靠性工程、基础架构(如代码)、混沌工程、自动化、连续交付、恢复能力和安全性时，吸引了web ops、系统工程师和开发专家。圣何塞展览(今年在不同城市实际上有三个Velocity会议)的演讲者包括来自微软、Netflix、亚马逊和谷歌的代表。\n4. ChefConf May 22-25, Chicago\nChefConf面向开发、自动化和法规遵从性感兴趣的管理员和开发人员。ChefConf关注处理整个应用程序开发和管理生命周期所需的策略和技能。本次活动侧重于实践和经验，以涵盖构建云应用程序、持续法规遵从性和广泛的自动化等活动。去年的ChefConf吸引了大约1，500名与会者，来自Chef和其他重要科技公司的演讲者。\n5. Continuous Lifecycle May 15-18, London\nContinuous Lifecycle每年在伦敦举行，主要集中在开发、容器化、连续交付和敏捷方面。这是一个为期三天的活动，包括会议和研讨会，与会者包括开发负责人、架构师、开发人员、CTO、工程师和工具/基础架构专家。每一个行业都有代表，从高技术的最高水平到制造企业。\n6. DevOps Con May 28-31, Berlin\n你是德国人吗？就算你只能说有点德文，DevOps Con也是值得一游的。它可能被认为是一年中最重要的持续交付会议，在微服务、Docker、云计算和精益业务方面进行了出色的讨论。今年的演讲者包括优步、红帽和西门子的高级职员。DevOps Con演讲者使用德语和英语，让与会者忙于实际的研讨会、会议和主旨演讲。\n7. DevOps Days 今年DevOpsDays在国内举办三场：北京-5月，上海-8月，深圳-11月。\n如果你还不能参加一个DevOps Days会议，那你肯定是住在了月球上。从亚特兰大到苏黎世，DevOps日一年四季都在不断发生，一个月内有多达几十个大会活动，遍布全球。DevOps Days活动关注软件开发和IT基础架构运营，重点关注自动化、测试、安全性和组织文化。\n每场大会的地点都不尽相同，因此如果您有特定的感兴趣区域，请确保您注册了最感兴趣的城市，以便充分利用2018年DevOps的重大活动。DevOps Days甚至鼓励专业人士在大会上组织自己的日程。\n8. DockerCon June 11-15, San Francisco\nDocker大会的演讲者人大多来Docker本身，这并不奇怪。然而，在过去的几年里，来自AWS、Puppet、Cisco和cloudBee的演讲者也逐渐加入。为期三天的会议探讨了分布式、基于容器的应用程序的未来，并提供了一个引人入胜的视角，看看领先公司目前是如何开发Docker平台和容器的。\n与会者将有机会参加技术演示、实验教程和主题演讲。上一届会议有5 000多人出席。\n9. Gartner IT Operations Strategies and Solutions May 15-17, Orlando\n由于Gartner分析师的数量超过了您的能力范围，因此IT运营战略和解决方案展览是向真正了解DevOps行业全局的专家学习的绝佳途径。\n该活动非常适合IT运营管理、云运营和IT服务支持专业人员。今年展会的主题包括IT运营优化、开发与敏捷、云与自动化、新兴IT运营趋势和战略。\n10. IT/Dev Connections Oct 15-18, Dallas\nIT/Dev Connections将自己描述为“反基调”会议。这意味着它集中于实践科目和培训，避免了供应商过多的营销。说到实际，IT/Dev Connections的组织者甚至有一个“出勤证明中心”。\n除了各种讲习班、小组讨论和网络活动外，该会议还值得一提的是其妇女参与技术午餐会。IT/Dev Connections分为五个方面，涉及云和数据中心、数据平台、业务智能、企业协作、管理、移动性、安全性和DevOps的会话超过250个。\n11. Jenkins World September 16-19, San Francisco\nDevOps只是Jenkins World涵盖的主题之一，它还涉及社区、CloudBee和生态系统等不同领域。虽然这一活动更倾向于一个特定的工具集，但它仍然非常受欢迎，2017年的活动约有2，000人参加。过去的讲演者代表了诸如Docker、Red Hat和亚马逊网络服务等公司。\n12. Large Installation System Administration Conference (LISA) October 29–31, Nashville\nLISA会议将自己标榜为“供应商中立”，以便将市场营销保持在最低限度。LISA由美国先进计算系统协会Usenix组织，每年在美国不同的城市举办。本次大会吸引了大量供应商和系统管理员，重点关注关键系统的设计、构建和维护，以及围绕体系结构、文化和工程的实际考虑。讲演者包括戴尔、Netflix、Facebook和fasty等公司的高级代表。\n13. Microsoft Ignite September 24-28, Orlando\n这将是2018年DevOps所有活动的母亲，因为这个大会看起来将超过2017年的人数，将有超过24000人参加。事实上，微软于2014年开始将Ignite作为合并多个会议的一种方式，数字反映了这一点。预计Ignite将非常繁忙，因为它涉及700多个演讲。然而，并不是所有的事情都与微软有关，因为展会包括100多家供应商，他们都是展会和会议演示的一部分。\n14. Monitorama June 4-6, Portland\nMonitorama是另一个特别的大会，它只限于关于软件和基础架构监控工具和技术的主题。它还主办了一次黑客马拉松活动。Monitorama是为数不多的只有一个主题的大会之一，这样与会者就可以专注于一个问题，避免FOMO体验。该大会自2013年以来一直在进行，观众人数限制在600人左右，因此尽早预订是个好主意。\n15. PuppetConf 2018 October 9-11, San Francisco\nPuppet是一种开源配置管理工具，它对DevOps、云管理、下一代基础架构、应用程序交付、安全性、法规遵从性和持续交付的影响非常重要。\nPuppetConf由100多位专家提供了80多个课程，是一个非常棒的学习体验，无论是初学者还是老兵。PuppetConf由IT主管参加，他们希望获得有关DevOps转换、云迁移和持续交付的建议。2017年活动的讲演者包括来自Twitter、Yelp、谷歌、销售人员和Slack的Puppet员工和专业人士。\n后记 本文的清单是15个比较出名的大会，我发起并动态更新的全球DevOps重要大会的日历，访问的地址在这里：https://teamup.com/ks5kh2kcca4w6xva4y\n目前整理的全球大会日程表见下图（持续更新中，请直接查看线上版本）：\n最后一招：参加大会是为了学习先进思想和实践，这些大会是货真价实的真理发源地，在诸位参会学会了以后，回到公司，万一领导还是不理解，不支持怎么办？而且领导也不感冒参加这些大会。那么你可以在公司内部举办类似的大会，可以请外部的和尚来自己的庙里念经。这也是我们中国DevOpsDays核心组织者的一个想法，希望能够提供协助和支持，帮助所有传统企业早上走上上下一心的DevOps转型之旅。\n",
    "ref": "/blog/2018-best-devops-event/"
  },{
    "title": "基础架构的持续集成和应用部署",
    "date": "",
    "description": "在DevOps的场景下如何对基础架构进行持续集成和分层的配置管理，基于统一配置管理工具的应用部署和传统部署有什么不同？",
    "body": "持续集成通常是针对应用而言的，可是基础架构的持续集成应该怎么做？基础架构的持续集成应该属于持续交付/部署的基础。贯串本文的一个问题，或者在阅读本文时，您应该不断地问自己这个问题：我们的应用部署流程是怎样的？\n在回答这个问题之前，我们先来回顾一下，目前几乎所有人正在使用的手工环境和资源交付流程。在源码被编译打包了以后，安装包文件被上传保存到了内部的某个文件服务器上。Ops团队的某个组/人被分配到工单，根据工单描述的需求，它在测试或者生产环境中开始工作：\n 用图形界面进行虚拟机模板的手工克隆工作，或者由于没有相应的权限或者自助服务，不得不给虚拟化管理员发任务单，然后等待回复。 获取用户名和密码手工登录服务器，有些企业还要是等待领导的审批，才能得到密码信封和所需要的访问密码。 根据工单（变更单）里的描述和自己的经验对虚拟机的操作系统进行配置，在这个过程中，Ops往往可能还需和需求方进行不止一次的沟通，确认相关参数。 手工的下载应用安装包，然后分别手工上传到目标的服务器，凭经验和工单信息部署应用，然后测试部署结果，可能是看下页面有没有正常显示，或者服务起没起. 手工测试和确认这些虚拟机的服务和状态，凭经验觉得OK了以后，回复工单，关闭工单。  以上的工作场景，可能是Ops人员很常规的一天，或者是几天内的工作，当然在这个过程中，他们还需要参与一些救火行动；他们在这个过程中也可能会有疑问，也可能会对此工作结果不确定；但是，日常的工作经验告诉他，差不多了，关闭任务单要紧，还有好多项目催活呢！就这样，配置并不精确的虚拟机环境就交给了下游的需求方。\n以上工作过程的问题如下：\n 工作周期长，速度慢。实际上工作周期拖延的越久，工作结果的质量就越差，而并不是我们想想中的慢工出细活。 所有步骤都是纯手工操作，不仅费事费力，而且出错几率高，也几乎不可能无痛的回退。可能有人会说了，我们不需要那么快，我们也不是互联网公司；可是从精益思想的角度看，以上这些工作都属于对业务价值的交付贡献为零的工作；你可能是由于公司给你发着工资，才错误的感觉到，这项工作活动应该有它的价值。 上游传递来的信息可能不全面，不准确，因此Ops很有可能造成错误配置，因此会返工。 传递给下游的虚拟机很可能会在后续的部署过程中，由于应用需求的变化，而需要下游的人员对其重新配置，产生重复的劳动。   手工部署的时间和代价 = 应的数量 X 应用版本数量 X 环境数量\n 对以上工作系统进行优化的原则：如果某一项活动的重复频率越高，那么对它进行优化，所产生的回报也会越明显；这里还要参考限制理论，优化的顺序要正确。\n我们从这个角度出发，就可以来设定基础架构持续集成和应用部署流程的改进目标了：\n 减少总体人工工作时间和代价 提高交付的速度、可靠性和频率 能进行应用部署，能进行数据库Schema的更新 能够实现部署流程的自服务，让任何需要部署应用的人能一键式部署任何版本  到了这里我们就必须将上述手工劳动，变为自动化的过程。因此，基础架构即代码IaC （Infrastructure as code）和相关的配置管理工具就会用到。\n上图是一个典型的持续交付流水线模型，在此我们对它的关注点如下：\n 代码的变更被Jenkins自动化的构建（CI是基础），打包后的安装包被存储在Artifactory里，Artifactory里面还可以存储应用包的其它相关元数据，如测试结果，能否可以用于下一步部署的标签等等。 Jenkins自动化的搭建所需要的环境，调用虚拟化或者公有云资源池的API，制备虚拟机资源，然后调用Chef完成对虚拟机的配置，完成应用包部署所需要的所有层次的配置。 环境配置完成后，应用正常运行了，在相关的测试工具对部署后的环境做验收测试，Chef具有支持测试驱动的相关工具。  基础架构的持续集成 为了实现完整的基础架构持续集成流程，以上持续交付流水线必须具备的能力和概念包括：分层的系统管理、基础架构即代码IaC、配置管理、Chef工具等。下面详细对它们进行描述。\n分层的系统管理 系统管理的层次涉及到OS相关的三个层次。下面自下而上地简单描述一下。\n 制备管理：涉及到虚拟化层，这一层是资源表达层，目前所有主流的虚拟化都支持标准的Rest API，包括VMWare、EC2和Nuanix等。大多数主流配置管理工具都具备用于虚拟机生命周期管理（从生成、到开机、到删除等）的API功能，能按需的获得任何数量、规模、网络和操作系统类型的部署环境。 配置管理：在任何类型的操作系统里自动化的安装和配置软件包，将所有配置参数配置好以后，持续保持这些配置点的状态。对于简单应用，来说按配置参数启动服务即任务完成。 应用编排管理：对于复杂的分布式系统，由于各个自服务之间存在着依赖关系，所有自服务之前需要互通一些配置参数才能实现，应用程序整体的正常运行，配置应用服务器的odbc数据库连接，配置web前端的ldap认证服务器等等。目前微服务所涉及的服务发现和路由，是应用编排必备的配套设施。  不同的DevOps配置管理工具也都力求能覆盖以上三个层次，但是他们所追求的方向，或者想解决的主要问题并不相同。因此各个工具之间功能上有重叠。\n因此在运用这些工具的时候，不仅要追求其卓越的功能，还要能意识到，并有意的在不同层面上做取舍。\n基础架构即代码 IaC这个概念最早是被Chef这类工具提出并实现，它的基本想法就是让Ops人员象开发人员一样的，工作在基础架构的代码上，而不是面对着数十个图形和文字终端界面。使用类似于开发应用程序的方式，开发和管理基础架构环境，因此基础架构能通过API访问和操控是基础，目前所有主流的虚拟化/云计算平台都具备很好的API接口；可惜的是在传统的企业环境中，这些资源池的API功能几乎没有被用到。\n像开发应用代码一样的管理IT基础架构，基础架构的开发和管理也需要遵循与应用开发类似的原则，这些原则包括：\n 一切从源代码开始:并对其进行严格的版本管理，要对基础架构变更，就需要对相应的代码进行变更和测试，最后发布这些代码。从而力求做到服务器的无人登录运维。 模块化设计:不同应用底层所使用的基础架构有着大量的相似之处，模块化的设计不仅意味着标准化，也意味着更少的重复代码。我所用过的Terraform、Chef和Puppet这三种工具，都具有高度的模块化特性。 抽象能力：能够使用不同的模块和参数对任何特征的应用进行建模，用IaC代码进行表达，基础架构的代码开发也就是借助这种抽象能力，将所有管理对象（配置管理项）具体化地描述为应用服务模型。编写出来的基础架构代码，不仅包含了所有对应用配置描述性的语义，而且还是能够被执行的代码，在IaC代码执行之后，你就得到了所期望的虚拟机、应用配置和应用服务。 可测试性：这是一个经常忽略的能力，而在了解之后，你会发现IaC也是编程语言，就是对基础架构进行高级的编程，而且IaC代码本身和它的运行结果都是可以测试的。在执行前对其语义语法测试，在运行以后对其运行结果测试。Chef在这方面表现的尤为突出。  配置管理 我可能是最早的一批进行ITIL配置管理实践，CMDB建设的这批人；我以前和甲方客户有着大量的关于配置管理和CMDB的对话，所经历过的项目也非常煎熬。而在DevOps场景下，感觉以前的经历也是很有意思的，只是我现在说到的CI，在没有特指的情况下，是持续集成的概念，还不是配置项了。\n Process for establishing and maintaining consistency of a product’s performance, functional and physical attributes with its requirements, design and operational information throughout its life。\n 以上是配置管理在维基百科里的定义，它所表达的含义还是值得借鉴的；而如今很多人对DevOps的认识，还有人是建立在DevOps配置管理相关的工具上的。为了纠正这个错误观点，我们经常说：“天文学并不只是关于望远镜的。”\n配置管理工具中有很多是基于主机（OS）的管理工具，包括：CFEngine、Puppet、Chef、Salt和Ansible等。它们都具有基础架构即代码的相关原则和特征。都能实现：定义服务器的目标期望状态的能力，在每一次执行周期里，它们都进行状态检查，汇报当前状态和目标状态的偏差，在必要的时候也可以自动的执行必要的状态修复操作。\nChef这种配置管理工具，使用了Ruby风格的DSL语言，使用者只需要用Chef代码表达”What“即可，而不需要明白”How“；”What“既是对目标配置状态的描述，使用者只需要将需求转换为Chef代码，然后用Chef客户端工具运行它即可。Chef的代码清晰，描述能力强大。在编码的时候遵循DSL规则，如果有必要的话也可以调用Ruby。\nChef是客户端服务器的架构，安装了Chef-client程序的节点可以注册到一个Chef管理服务器里。\nChef的开发人员（IaC编码者），在安装了用于和Chef服务器交互的名为knife的工具，称之为工作站的系统上开发基础架构代码。Chef使用大量内置的DSL资源（例如：package，service，file，directory等操作系统资源分类）对目标节点的配置进行建模，代码可以映射到内部的用来执行这些代码的各种提供者上。\n所能实现的示例代码如下所示，下面是配置Linux操作系统中的Apache服务器。\npackage \u0026#39;httpd\u0026#39; do action :install end service \u0026#39;httpd\u0026#39; do action [ :enable, :start ] end 下面是在Linux操作系统里配置 /a/b/c  目录\ndirectory \u0026#39;/a/b/c\u0026#39; do owner \u0026#39;admin\u0026#39; group \u0026#39;admin\u0026#39; mode \u0026#39;0755\u0026#39; action :create recursive true end 以下面就是 /a/b/c 目录的配置结果状态：\n$ls ‐ld /a/b/c drwxr-­‐xr-­‐x. 5 admin admin 4096 Feb 14 11:22 /a/b/c Chef其它的重要术语：\n recipe ：包含了一个或者对个资源描述定义（Chef预定义了文件、用户、软件包、服务等等资源，可以扩展开发自定义资源类） cookbook ：包含了一个或多个recipe配方 data bag ：包含了一个或多个配置数据点(data bag item)，是JSON格式，一个cookbook食谱可以包含一个或者多个数据袋 run list ：包含了一个或者多个cookbook食谱，可将其部署在被管理的node节点上 role ：一组特定内容的run list运行清单构成了一个角色 environments：同我们现在对环境的定义，并可以一一对应起来  Chef是偏主机配置管理的非常的Iac语言，它具有很丰富的扩展能力和生态系统。它有很好的扩展能力，很强的逻辑性，能够进行深度的表达和锻造。它和Terraform和Ansible都有较大差异。\n部署流程设计 将以上手工处理过程转换为自动化执行的、一键式触发或者自动触发的流程需要关注很多个要点。\n使用Chef部署自开发的应用程序，包括配置所依赖的操作系统配置和软件，以及自身所需的应用配置。可以使用Liquibase进行数据库的schema部署和更新。可以用Jenkins协调和组织所有工序的执行。使用Jenkins管理部署流程的感觉和用它执行CI是类似。\n从简单开始，尽量将一组彼此相关的、版本化的可部署物组织在一起发布，例如在一个发布集合中可以包含：UI、REST服务器、消息服务和数据库。尽量使用一条命令构建，使用一条命令部署。\nCookbook设计类型 Library Cookbook 库食谱 ：这种类型的食谱涵盖了通用的、可重用的逻辑。例如所有配置基线，也可以是安全基线。例如：dns、ntp、主机登录提示、用户和组、禁用服务清单等等。开发扩展的自定义chef资源，用来部署自开发应用。\nApplication Cookbook 应用系统食谱 ：在以上库食谱的基础上，为一个套应用系统开发一个Cookbook食谱，每个应用可是一个recipe配方，recipe配方使用自定义开发的Chef资源。这样就形成了非常轻量的代码库。\nData Bag 数据袋：包含了各种应用配置，例如：服务端口、JAVA_OPTS等等。一个应用系统Cookbook食谱对应一个数据袋，袋子里面包含了该应用在每一套环境里的相关所有配置点。\n上线一个应用的新版本意味着新版本IaC代码的更新和部署，大致的流程是：编辑Chef代码、推送到Chef管理服务器、在节点上运行Chef客户端程序执行部署动作。Chef服务器的版本始终和版本控制库里的Master主干保持一致，这同样意味着环境配置和Master主干代码保持一致。\n用Chef开发自定义应用资源的实例代码如下，这段代码表示了一个Java应用war包的部署。\n基于类似于以上的自定义资源类型，在必要的情况下，还可以对其开发Action（chef资源的操作），可能的操作定义有：\n 从Artifactory服务器下载Java、Tomcat和WAR包。 在标准的路径安装Java和Tomcat。 创建和配置Tomcat容器 在特定的容器里安装WAR包 在主机上开防火墙端口 生成应用属性文件 启动Tomcat容器  Data Bag数据袋的实例代码结构如下：\n\u0026#34;version\u0026#34;: \u0026#34;1.4.9\u0026#34;, \u0026#34;runtime\u0026#34;:{ \u0026#34;my-­app-­ui\u0026#34;:{ \u0026#34;java_opts\u0026#34;: \u0026#34;-­‐Xmx2G -­‐XX:MaxPermSize=1024m\u0026#34; } }, \u0026#34;app_config\u0026#34;:{ \u0026#34;db.url\u0026#34;: \u0026#34;jdbc:postgresql://devdb:5432/myapp\u0026#34;, \u0026#34;svc.foo.url\u0026#34;: \u0026#34;http://devsvc:9000/foo\u0026#34; } 以上是data_bags/my_app/DEV.json的定义，还可以有其它环境的定义data_bags/my_app/TEST.json和data_bags/my_app/PROD.json等。\n人员角色 基础架构的持续集成需要Dev和Ops的相互协作，才能做通，才能全面覆盖应用所需要的技术栈。\n部署人员 更data_bag新数据袋和环境定义文件，触发生产环境部署的动作，调度chef-client客户端的运行，或者推送新版本的Chef代码更新。\n技术负责人 维护应用系统Cookbook食谱。\n框架开发人员 维护库Cookbook食谱，维护框架，持续改进流程。\n以上这三种角色，从上到下是从Ops到Dev的过渡。对于传统IT组织的架构，部署人员是Ops团队的，框架开发人员是Dev团队的。\n这三种角色都凑齐了，才能起到全套应用系统的整体建模和编码，而且每个角色都有负责的部分。技术负责人可能是来自Ops和Dev团队的技术大拿。他们对整体的正确性和完整性负责。\n目前也有Dev团队在其内部招聘运维研发的角色。这三种角色是基础架构即代码的层次结构和人员团队架构的对应，在实际工作中可以灵活应用；一方面覆盖所有技术层次，另外一方面引入所有必要的人员，是团队形成合力。\n如果不是本着将全套应用系统做全量的部署，以上任何角色做自己职责范围内的IaC自动化实践，其实效果是事倍功半的，或者机会只有技术学习和探索的价值。\n构建Cookbook 在开发了各种Cookbook之后，我们就需要对其进行持续测试，因此就需要使用Cookbook的持续构建流程。这个步骤就如同我们对应用程序的代码做CI一样。\n开发人员（程序员不是业务应用开发者的专业名词，这里指IaC开发者，可能来自任何团队）在Workstations工作站上开发Chef的Cookbook代码，将代码提交到GitHub上的Chef代码仓库。\nJenkins的Master服务器会触发CI Job，调用Ruby Slave对Cookbook代码进行集成和测试，然后触发EC2临时实例的创建，将Cookbook在EC2实例中进行测试，使用Artifactory中存储的应用软件包部署应用。如果测试都通过了，就触发Release Job，它将Cookbook代码上传到Chef服务器，供所各种环境中的被管理节点使用。\n上图用EC2作为Chef代码的CI环境，可以替代的方案有Vagrant+虚拟化（Virtual Box或者kvm），或者使用其它虚拟机资源池，如Ovirt KVM、Xen、Nutanix。我实际测试过使用Terraform对接Nutanix资源池，虚拟机创建超级快，几乎是秒得的速度。现有的虚拟化资源池就是最方便的对接对象，需要了解一下API和对接工具即可。\n对于Jenkins构建服务器而言，每一套应用系统对应的Cookbook组/集合的测试和发布都会在同一个构建服务器上发生，一般情况下这个服务器也是这些应用的CI服务器；这个Jenkins服务器也是相关Cookbook的CI作业和发布作业的运行地点。这个服务器上会安装所需要的Ruby gem包，应该能访问到与Chef服务器链接所需要的秘钥；应该可以使用到创建EC2测试节点虚拟机的秘钥，或者说访问其他类型虚拟机资源池的用户名和密码。\nCookbook CI Job Cookbook CI作业的触发条件是：当有新Chef代码被合并的时候。它会进静态代码扫码和测试工作，包括如下内容：\n 使用json和gem的相关工具分析JSON的句法 使用Tailor做Ruby的句法和风格扫描 使用Knife做Chef代码的句法分析 使用Foodctritic做Che代码的句法分析和正确性分析  Chef代码在测试虚拟机里的集成测试是本文的重点，集成测试工具使用Test Kitchen，这个工具有一系列和虚拟化/云环境对接的插件，如 kitchen-ec2插件等。能按需临时的创建用于集成测试的虚拟机，在测试完毕，得出了测试结果之后，就删除本作业所创建的临时虚拟机。\n在集成测试的生命周期过程中也可能创建多个测试虚拟机/EC2实例，这个过程使对应用系统里的所有组件进行仿真的、实际的安装包和服务部署，进行单节点或者多节点的全量应用系统部署。在每个节点上都执行Chef代码，在Chef对应用系统的配置和部署完成之后，在对运行中的应用进行验证测试，测试包括测试相关的服务端口是否能访问，返回结果是否正常等等，Chef是可以进行测试驱动开发的，因此可以写出较细致的测试代码，从而分析本Cookbook集成测试通过与否。在测试结束了以后（最好是10分钟左右或更短），删除所有测试的虚拟机资源。\n应该尽可能的优化这个集成测试，尽量缩短它的执行时间。可以创建专用的EC2-AMI/Nutanix/Kvm/VMWare操作系统镜像，预装所需要的Ruby环境和Chef工具。\n使用Chef Solo（不依赖chef服务器）执行Chef代码的测试，以免将临时节点也添加到了Chef服务器，同时也消除了Chef的客户端和服务器架构之间相互通讯的消耗，这个场景里其实没有使用Chef服务器的必要。使用一个名为CHEFDEV的伪环境来测试代码，而JSON文件里定义的真实环境则被保留用于正式生产环境。在创建EC2虚拟机的时候，给它们打上特定的标签，从而保持一定的可追踪性和环境的可维护性。\nCookbook Release Job 这个作业的运行内容和CI Job基本一致的，而它是靠人为手工触发的，从Chef角度看，可以说：本文上述的所有描述，属于Chef风格的基础架构即代码程序的持续交付。本作业将测试成功的代码在GitHub/GitLab里打上标签，并且上传Cookbook的新版本到正式的Chef生产服务器上。\n可以想象经过多个Cookbook的build job之后，Cookbook的某个版本被发布到了生产环境中，用于环境的配置和应用的部署。本Job作业交付了IaC的开发结果到生产环境中的Chef管理服务器。\n其它IaC的基础架构持续及集成与本文描述的也应该是类似流程。\n应用部署流程 Cookbook的开发和集成完毕了以后，它的结果产物是一些列新版本的Cookbook代码，它们最终上传到Chef服务器。支持生产环境应用部署的Chef服务器与各种环境保持连接，包括测试、预发布和生产等等。\n在发布过程中所使用到的制品是从Artifactory中拉取的。下面简单说下这个架构中的关键点。\nJenkins部署服务器 这是专门用于各种部署工作的Jenkins Master服务器，它和上一个步骤里Cookbook的Build服务器是不同的。它的Slave应该满足这些需求：安装了所需要Ruby环境和gem包。安装了Chef工具，并且具有能更新Chef服务器的秘钥。具有能访问各种虚拟化环境中节点的SSH秘钥。\n部署作业的类型 可以对于每一个应用组（一套应用系统）设置两个部署作业：在开发环境中的，用于开发人员使用的DEV部署作业；另外是运维人员所使用的Non-Dev部署作业。在实践过程中也能发展出其他类型。\n部署人员的工作流程：\n 变更Chef相关代码和配置，包括：编辑应用的data bag配置数据点，有必要的话编辑环境文件，合并代码。 然后在Jenkins部署服务器上执行作业。  通过以上的流程和工具，开发、测试和运维的相关人员，如果需要部署应用了，就可以用一键式的、自助式的部署模式，将任何应用应用系统通过一键式的方式自动化的部署到各种应用环境中。\n这样我们将大量各种角色人员都从事的、没有附加值的应用部署工作，彻底的消灭掉了，节省的时间可以用来做更多有意义的工作，Dev人员有更多时间编码、测试人员不需要等待时间、运维人员也降低的工作压力。\n总结 关于基础架构的持续集成，还有下列值得参考的原则：\n 尽可能的标准化：包括技术、设计和流程等方面；要能够支持环境的规模化扩展，例外是可以的，但是要尽量避免。 所有工具最好有API：避免在某个工具，在工具链上的任何环节的脱节。 使用多种形式的沟通路径：这个实践需要用各种方式进行宣传和推广，包括：全员大会的主题分享、每个团队的启动会议、与开发人员的随时沟通，使用文档进行知识传播和沟通。 保持乐观，尽量发现和找到那些志同道合的早期响应者，让他们和你站在一条战线上。  引用 参考视频 https://www.youtube.com/watch?v=PQ6KTRgAeMU \n参考书籍  ",
    "ref": "/blog/devops-infrastructure-ci-app-deployment/"
  },{
    "title": "DevOps on Nutanix[Beta]",
    "date": "",
    "description": "如何使用超融合平台加速DevOps旅程",
    "body": "Nutanix是什么？中文名字是路坦力，是我目前所在的公司；我负责运营商行业以及与云服务商的合作业务，解决客户在售前、架构和DevOps等方面的问题，我是Nutanix Calm产品的专家。\n之前也发过一些介绍Nutanix和超融合技术的文章，本文会是一篇持续更新的文章，我会把在Nutanix上开展超融合的方法，持续的更新在这里。\n本文上属于Beta版本，会持续更新，欢迎各种类型的反馈信息，发邮件到： martin.liu@nutanix.com\n变更日志：\n 2018-2-26，发表了相关概况介绍性内容  什么是DevOps？  我的定义：DevOps是为了将软件开发、运维和质量保证等部门紧密地协作和集成在一起，而运用的一组成熟的、相互融合在一起的最佳实践。它使人们能准时/及时地生产软件产品或服务，从而满足企业的某个业务目标，开发与运维工作将在一个统一的目标之下协同工作，它是对IT组织内部各个角色之间的相互依存关系的一种新的理解。这个实践集合主要包含了四种最佳实践，如下图所示：\n 注意：上图里Nutanix的定位在持续交付，超融合平台能高速平滑的交付IT服务。\n来自网络的其它定义还有如下。\n 定义2：You cannot buy DevOps and install it. DevOps is not just automation or infrastructure as code. DevOps is people following a process enabled by products to deliver value to end users. \u0026ndash; Donovan Brown, Microsoft DevOps Program Manager\n 以上出自：Donovan\u0026rsquo;s blog post on \u0026ldquo;What is DevOps\u0026rdquo;.\n 定义3：DevOps（Development和Operations的组合词）是一种重视“软件开发人员（Dev）”和“IT运维技术人员（Ops）”之间沟通合作的文化、运动或惯例。透过自动化“软件交付”和“架构变更”的流程，来使得构建、测试、发布软件能够更加地快捷、频繁和可靠。\n 以上出自：维基百科 Wikipedia - DevOps\n什么是HCI-超融合基础架构 我对超融合的定义：将计算、存储和网络这三种资源的至少两种融合在一起的技术就可以称之为超融合技术。Nutanix是将计算和存储融合在了一个系统只能，这里说的系统可以理解一个物理的机箱，并且在这个机箱里搭载了目前业内最通用的KVM虚拟化功能。Nutanix的超融合系统是开箱即用的IaaS平台，可以无节点数限制的水平扩展，能够支持服务器虚拟化、VDI、Oracle RAC等关键性数据库、企业核心业务系统、大数据和私有云等工作负载。在性能和功能上是专门为HCI而打造的。HCI技术正在颠覆着传统的三层架构技术堆栈（指的是：服务器-存储网络-集中存储）。\nNutanix在2018年Gartner融合基础架构分析报告中，Nutanix在领导象限里遥遥领先。\n2018 年 2 月 9 日，北京 ——企业云计算领域的领先企业 Nutanix（纳斯达克：NTNX）今天宣布， Gartner 将 Nutanix 评为 2018 年 Gartner 超融合基础架构（HCI）魔力象限领导者。Nutanix 认为，此次跻身“领导者”象限有力印证了 Nutanix 在其率先开拓的市场上的领导地位，也充分彰显了公司致力于提供下一代企业云操作系统的愿景。\n随着越来越多的企业机构认识到超融合基础架构（HCI）的优势，企业基础设施正在经历根本性的转变。这些企业机构采用了一种新的架构设计，将网络规模技术和消费级设计相融合，实现“隐形基础设施”，从而使 IT 团队能将更多的时间投入到业务应用中。同时，这些企业机构还纷纷采取了能够利用多云基础设施和云服务的 IT 战略。\n\nNutanix 认为，利用其企业云操作系统软件，用户不但能实现公有云的精简性、敏捷性以及部分 IT 消费收益，还能保障企业数据中心的高可控性与安全性。在融合了私有云、公有云和分布式云的统一 IT 操作环境下，Nutanix 企业云操作系统软件提供单点控制来管理任何云的基础设施与应用，从而为云运营商和采用云交付式服务及应用的用户提供统一、高性能、无缝的使用体验。\n关于Nutanix的更多视频，请访问Youku的频道。\n学习Nutanix核心技术 关于Nutanix超融合系统的核心技术特性请访问：Nutanix 圣经，圣经网站上有中文版本pdf下载，最近会有一次中文版的修订请关注。\n试用Nutanix产品 Nutanix提供免费的社区版本，对此感兴趣的人都可以下载和使用。使用这个版本，你能够在几个小时内，搭建起数量为1、3或者4个的物理服务器组成的Nutanix集群。\n关于如何安装和试用Nutanix CE版本的技术文档，访问我的Nutanix实验室文档站点：https://nutanix.martinliu.cn/\n使用Nutanix Calm实现DevOps持续交付 Nutanix是一种开箱即用的高性价比的虚拟化资源池，你可以用最小的时间成本完成大规模资源池的搭建和部署。而现实情况下：所有企业的虚拟化管理员的工作模式还是基于工单的手工VM模板克隆的方式。还没有人能将基于vm的业务系统做到自动化的持续交付。Nutanix Calm就是一项解决这个问题的技术。它是Nutanix超融合系统内置的一个功能，可以一键式的开启这项功能。\nNutanix Calm的主要功能如下所示：\n 应用生命周期管理：利用预定义的应用蓝图，全面地实现了传统型多层应用和流行的分布式服务的自动化运维，包括系统制备、扩缩容和资源释放等操作。应用蓝图将极大地简化了私有云和公有云的应用管理和运维。 应用蓝图管理：将应用系统的所有组成部分（包括相关的虚拟机、配置和可执行程序）融入到了一个可视化的、操作直观的蓝图里，从而简化了企业应用的配置管理和日常运维。应用蓝图提升了基础架构团队的管理效率。IT团队再也不用像以前那样，在应用管理的日常工作上花费大量时间。 Nutanix应用市场：应用蓝图可以在Nutanix 应用市场（Marketplace）里把应用直接发布给最终用户，使产品经理和开发人员能够持续交付产品，快速地供给应用，及时地满足IT服务请求。 应用治理：Calm基于角色的访问控制机制可以限制用户的操作权限。此外，系统会集中地记录所有操作活动和变更，可以实现端到端的可追溯性，这些信息可以提供给安全团队，用来配合相关合规审核工作。 混合云管理：能在混合云的架构里，自动化地制备应用，包括AWS公有云环境，能实现多层应用和分布式应用的弹性扩缩容。Calm能全局统计资源用量，让您对公有云的实际消费成本一目了然，方便您按照业需求和预算做出合理的决策。  Nutanix Calm的蓝图编辑器如下所示。\n在我的Nutanix实验室：文档站点里已经写了一些操作使用的方法和产品截图。如果您已经是Nutanix用户了，请参考和使用这些文档。如果你还不是的话，可以联系Nutanix试用这个产品。\n 后续会持续更新这一部分，会根据DevOps的逻辑将Nutanix Calm的能力全面的展示出来，敬请期待。\n使用Nutanix实现完美的Docker Datacenter体验 CaaS on IaaS的简洁实现方式莫过于在Nutanix超融合平台上部署Docker Datacenter产品。其实Docker Datacenter还是一个很容易使用的Docker平台，易用性非常好，入门级Docker用户建议走这条路试试，毕竟K8s的学习曲线目前还比较陡峭。\n这个组合的免费试用方法：\n 安装部署Nutanix CE（文档见Nutanix实验室） 申请和下载Docker Datacenter的安装包和许可证文件（10个节点免费试用，30天到期了还可以无限次延续） 在Nutanix上创建10个虚拟机用于部署Docker Datacenter 安装部署Docker Datacenter （文档见Nutanix实验室） Enjoy it forever!  如果你使用4台物理服务器安装Nutanix CE，建议的服务器配置：2路20核 Intel XeonCPU，内存256，SSD 512GB一块，SAS HDD 4TB两块；这样形成的群集的总资源量：\n 160个物理CPU核，一个物理核跑两个虚拟机的话，你可以跑320个虚拟机；当然内存够的情况下，你还可以尝试更高的整合比，如1个物理的核带5到10个虚拟机 总存储空间为18TB，使用两副本存数据，你有9TB可用空间，打开去重压缩等功能的话你可以拥有更多的存储空间。 2TB的SSD存储可以让你应付大量的热数据，所有热数据相当于使用了全闪存储一般。 建议这些服务器使用10GB或更高速的以太网，以保证更优雅的性能 不建议这个环境跑生产负载，记住不要把研发环境不算生产负载。 如果需要生产级别的保障，请考虑使用费CE版本的正式Nutanix产品。  使用Nutanix ACS2.0实现完美的K8s体验 此产品预计18年发布，敬请期待。\n",
    "ref": "/blog/devops-on-nutanix/"
  },{
    "title": "Devops Handbook《DevOps实践指南》简介",
    "date": "",
    "description": "DevOps Handbook - DevOps实践指南 这本书将在2018年5月前后出版",
    "body": "企业如何通过DevOps实践提高盈利能力，改善工作文化，实现卓越的生产力目标。如今这些高绩效管理技术比以往的任何时候都要更加重要，由于这对于企业的商业竞争力而言是至关重的，数十年以来，技术组织的领导者们始终在努力地维持这IT系统的敏捷性、可靠性和安全性。然后惨痛的案例依然比比皆是\u0026ndash;不论是healthcare.gov的崩溃，持卡人数据的泄露；还是在云计算环境中大数据的丢失。\n然而，那些运用DevOps原则的高绩效企业（例如Google，Amazon，Facebook，Etsy和Netflix）则每天都可以在生产环境中成百上千次频繁地部署代码。那么DevOps理论、原则和实践到底是何等的殊胜呢？相信所有人在看了本书之后一定会得到答案。\n通过数字看这本书 基础数据 原作者4人 Jene Kim是这本书的主要作者，他在出版了《凤凰项目》之后，开始与其他三位作者编写本书的。Jez Humble是《持续交付》的作者，是持续交付实践和概念的重要发起人。Patrick Debios是DevOpsDays大会的发起人，是他最早在Twiter是用 #DevOps 这个短标签的，是DevOps运动和社区的重要人物。John Willis是DevOps社区早期的推动者之一，曾任Docker公司生态系统发展总监。\n译者4人 在我和人民邮电出版社联系并进行试译之后，组织了翻译小组。王磊和马博文是我这几年结识的DevOps圈内的技术大拿；曾朝京是IT管理领域的资深专家，是我的前同事。王磊的著作有《微服务架构与实践》；马博文翻译的书籍有《DevOps 实践》\n 刘征，Nutanix路坦力资深架构师。Exin首批国内DevOps Master和DevOps Professional认证讲师。持有红帽RHCA认证和AWS高级架构师认证。谙熟企业数据中心的IT服务管理。目前致力于推广DevOps相关的理念和实践，在DevOps社区中积极地参与培训和研讨会等活动，DevOpsDays大会活动在中国的核心组织者。\n  王磊，前ThoughtWorks首席咨询师，EXIN首批国内DevOps Master认证教练。较早倡导和实践微服务的先行者，著有国内首本微服务架构相关书籍《微服务架构与实践》一书。超过10年以上的软件行业经验，对服务化架构、持续交付以及DevOps转型等有丰富的实践经验，同时他也是西安DevOpsMeetup联合发起人，西安GDCR组织者，并译有《Ruby Gems开发实战》一书。\n  马博文, 前ThoughtWorks 高级咨询师，AWS助理架构师。曾从事多年web开发和DevOps，熟悉持续交付，微服务。参与翻译《Scala编程实战》、《DevOps实践》等书，是西安DevOps Meetup活动的发起人。\n  曾朝京，Micro Focus资深解决方案顾问，参加Exin首批国内Devops Master讲师认证培训。长期从事IT运维管理领域咨询工作，曾为能源、金融、航空运输、政府行业中的多个大型企业提供 IT 运维管理规划。目前致力于探索Devops理念在企业IT部门的实践。\n 翻译小组完成翻译，并提交给出版社的日期是2017年12月8日。\n目录提前曝光 本书目前（本文的发布日期）正处于出版社编辑阶段。预计在五月份左右正式出版。下面是本书的目录。\n 序言 前言 导言：展望DevOps新世界 第一部分 三步工作法  第1章 敏捷、持续交付和三步法 第2章 第一步，流动原则 第3章 第二步，反馈原则 第4章 第三步，持续学习与实验原则   第二部分 从何处开始  第5章 选择合适的价值流作为切入点 第6章 理解、可视化和运用价值流 第7章 参考康威定律设计组织结构 第8章 将运维融入日常开发工作   第三部分 第一步：流的技术实践  第9章 为部署流水线奠定基础 第10章 实现快速可靠的自动化测试 第11章 应用和实践持续集成 第12章 自动化和低风险发布 第13章 降低发布风险的架构   第四部分 第二步：反馈的技术实践  第14章 建立能发现并解决问题的遥测系统 第15章 分析遥测数据以更好地预测故障和实现目标 第16章 应用反馈实现安全部署 第17章 将假设驱动的开发和A/B测试融入日常工作 第18章 建立评审和协作流程以提升当前工作的质量   第五部分 第三步：持续学习与实验的技术实践  第19章 将学习融入每天的工作中 第20章 将局部经验转化为全局改进 第21章 预留组织学习和改进的时间   第六部分 集成信息安全、变更管理和合规性的技术实践  第22章 将信息安全融入每个人的日常工作 第23章 保护部署流水线   行动起来 - DevOps手册总结 附录 附加资源  以上目录标题有可能在出版社的编辑过程中会有所调整。不过已经可以看出其主要内容。\n来自出版社-IT Revolution Press (October 6, 2016) IT Revolution Press是 DevOps Handbook 一书的的出版社，位于美国的波特兰市。这本书的简体中文版的书名是《DevOps实践指南》，它是作者继《凤凰项目》之后的一个重大作品，它向你展示了如何将产品经理、开发、质量保证、IT运维和信息安全集成在一起，从而帮助你提升企业的竞争力并赢得市场；如何复制前人那些惊人的DevOps经验成果。\n那么《DevOps实践指南》是否适合你？本书的作者Gene Kim、Jez Humble、Patrick Debois和John Willis为那些希望对IT组织进行转型的人共同编写了此书；特别是为那些想通过DevOps实际进行重大的变革，从而提高生产力、盈利能力并赢得市场的人。这本书涉及DevOps转型的很多方面，是一本从规划到实操的全方位指南，同时它还介绍了DevOps的历史背景，支撑DevOps的各种原则，以及数十个DevOps案例研究。它还提供了各种最佳实践，能有助于组织团结团队一心，使他们实现共同目标，同时获得高层领导支持。\n《DevOps实践指南》深入地研究了DevOps的三个基本原则，现在我们称其为“DevOps工作三步法”，它们是流动、反馈、持续学习与实验”。 《DevOps实践指南》是Gene Kim继《凤凰项目》一书之后编写的，在那本书里也对“三步法”作了概括的描述，后来发展成为本书第一部分的重要内容。\n随着本书循序渐进地揭示DevOps工作三步法，读者将能够清晰的了解到，那些高绩效公司是如何利用这些原则取得成功的。希望任何大型组织也能够复制这些高绩效企业所使用过的成功经验，从而指导他们自己也进行一场成功的DevOps转型。本书用六个部分描述了详实的内容，其中包括：\n 在五年时间里，4位合著者为本书投入了2000多小时的工作时间 40多个DevOps案例研究，包括亚马逊，Etsy，Capital One，Google，Facebook，Intuit，Nationwide保险等等 编写了长达400多页的DevOps实践指南、经验总结和工作指导。 参考和使用来来自25,000多个数据收集点的DevOps相关数据。  《Phoenix项目》（英文版）已经售出35万本，2018年2月进行了第五次印刷。《DevOps实践指南》从DevOps的历史开始讲起，解释了它是怎样从数十年的相关联的知识体系中发展出来的，以及由此应运而生的相关技术、架构和文化实践。在为读者奠定了这些历史基础后，读者就能够深入了解三步工作法的原则了。读者将逐步对当今的DevOps相关理论和原则有更深入的理解。在本书的相关章节里介绍了各种具体原则和模式，以及如何将它们应用在实际的技术价值流中。\n我们很自豪的宣布 DevOps Handbook - 《DevOps实践指南》获得了2016年，年度DevOps最佳图书奖，详见：https://devops.com/the-2016-devops-dozen-winners-announced/\n在亚马逊书网上书店 本书的英文版本在亚马逊有三种格式：Kindle、纸质印刷版和有声书版本。这本书的排名和评价如下，下图的抓取时间是：2018-2-25。\n 在信息管理分类里排名：7 在流程和基础架构里排名：107 在管理书籍里排名：111  有85%的读者给本书了5星的评价。关于这本书在亚马逊的最新状态，请点这里。\n本书的日文版是在2017年6月在日本发布的，详情见日本亚马逊网站。\n本书的使用方式 在上一篇文章《DevOps登山指南》里我分析和介绍了美国金融行业Nationwide保险公司的DevOps案例，原文点这里。这家公司在实施DevOps的过程中将本书做为参考指南，所有DevOps团队通过每周一次的读书会的方式，持续地对照和改进自己的DevOps实践状态。他们总结出来的DevOps项目实施指南如下图所示：\n本图在Nationwide公司内部的使用场景如下：\n 本图将DevOps实施核心团对指导产品开发团队（也可以说是业务团队、服务团队、这样的团队他们有200多个）取得的经验总结在一张纸上，供其它有实施DevOps想法的团队参考。 该登山指南简化了对其它非DevOps团队的教育和指引。 他们将DevOps的实施分成三个阶段，分别用大本营、北坡营地和顶峰作比喻。 这三个阶段里的技术实践都来自于DevOps Handbook，通过他们的筛选和整理，并根据自己的经验做了分阶段的规划。  ",
    "ref": "/blog/devops-handbook/"
  },{
    "title": "DevOps工作三步法：第一步流动原则",
    "date": "",
    "description": "目标是建立从左至右快速的、平滑的、能向客户交付价值的工作流。",
    "body": "本文内容主要来源于《DevOps Handbook》-DevOps实践指南，本文概述的原则是DevOps工作三步法的第一步，它的目标是先建立最底层的基础，即：DevOps技术实践和合理的应用架构；只有这样才能使工作快速而稳定地从开发端流动到运维端；与此同时还能保证不会给生产环境带来混乱，不会中断客户的服务。这就意味着需要降低在生产环境中部署和发布变更的风险。可以通过 持续交付 的技术实践来实现这个目标。\n持续交付基于稳定的自动化部署流水线，团队能够使用自动化测试持续验证代码，确保代码始终处于可部署的状态，开发人员要保证每天都向主干提交代码，以及设计和实现有利于实施低发布风险的环境和软件架构。\n在流动原则的指导下，需要开展的重要的工作内容如下：\n 奠定部署流水线的基础 实现快速、可靠的自动化测试 实现并实践持续集成和持续测试 通过自动化、架构解耦等方式实现低风险发布  以上技术实践能够有效地缩短创建类生产环境的前置时间。同时，持续测试可以为所有团队成员提供快速的反馈，使小型团队能够安全、独立地开发、测试和向生产环境部署代码，从而将生产环境的部署和发布作为日常工作的一部分。\n此外，通过将QA人员和运维人员的任务集成到DevOps实施团队的日常工作中，能够减少救火、困境以及繁琐的重复劳动的发生，使团队成员的工作高效且充满乐趣。这不仅能提升团队的工作质量，还能提高组织的竞争力。\n流动原则相关的详细技术实践请参考请《DevOps实践指南》一书的第三部分，这部分包含第10章到第13章，一共描述了5个技术实践。\n在流动原则里我们强调的而是全局的目标而不是局部的目标，局部目标的例子如下所示：\n 特性开发完成率 测试发现/修复缺陷的比例 运维的可用性指标  我们需要减少价值流中的工作交接的次数，由于当交接次数多到一定程度时，所有人就会彻底的迷失，无法回答工作的上下文联系是什么？也不清楚我们要解决的是什么问题？或者组织的全局目标是什么？\n价值流的应用实例 如果我们选择做DevOps转型的项目是棕地项目，我们就需要对当前的工作，进行细致的值流研讨和分析；需要画出当前的状态。如下图的示例所示（注：这是一个示例，你的棕地项目分析完之后并非如此）。\n为了在实施DevOps的过程中持续的度量和改进，我们需要分析出当前价值流的核心定量指标：\n 总计前置时间 = 求和价值流中每个工作步骤里的LT 【这个指标是DevOps项目的北极星】 总计增值时间 = 求和值流中每个工作步骤里的VA 完成且精确百分比 = 连乘值流中每个工作步骤的%C/A  如果是绿地项目，我们在第一个工作周里，价值流图是没有这些数值的。我们需要每天都在CI/CD流水线工具中采集相关数据，在每个人的日常工作中关注和记录相关数据，在第二周和后续的每一周里度量和分析以上指标，最好用仪表板展示工具，将这些数据实时地显示在所有项目组成员都可以轻松看到的位置。\n对这个价值流进行持续的优化，使它更高效的工作，并不断的进化和改进。如果是棕地项目，那么在分析完以上的机制流之后，可以定制新的进化版的价值流图，并按照新版本的价值流图重新开始项目的执行。如下图的示例所示（注：这是一个示例，你的棕地项目改进优化完之后并非如此）。\n优化和改进日常工作 Goldratt博士的约束理论(TOC) 在实践运用流动原则的技术实践时，可以使用Goldratt博士给出的方法，随时识别并解决价值流中的约束点，这个五步法如下：\n 识别系统的约束点。 决定如何利用这个系统约束点。 基于上述决定，考虑全局工作。 改善系统的约束点。 如果约束点已经突破了，请回到第一步，但要杜绝惯性导致的系统约束。  以上五步法是DevOps实施项目组日常工作的必备流程优化工具。\n常见的4个约束点 传统企业或者团队里最容易发生的约束点有一定的共性，一般可能会按照以下顺序逐个攻克和优化：\n 环境搭建 代码部署 测试的准备和执行 紧密耦合的架构  可以清楚的看到大多数约束点比较偏Ops这一侧，而攻克所有这些约束点需要Dev和Ops一起协作完成。\n常见的9中浪费 在DevOps工作团队里需要尽快能地避免以下浪费现象的发生：\n 半成品 额外/多余工序 额外/多余功能 任务切换 等待 移动 缺陷 非标准或手工操作 填坑侠  以上浪费现象最早是从制造行业的精益管理中总结出来的，这些也是完全可以应用到技术价值流中，IT相关的工作能对每一条有很多痛点清晰的解读，你可以尝试在自己的工作环境中寻找以上所有浪费现象。\nDevOps工作三步工作法 in《凤凰项目》 在本书中，我们阐述了这一基础原理，即所有开发运维模式都来自“三步工作法”，它旨在阐明指导开发运维的流程与实践的价值观与理念。\n**第一工作法 **是关于从开发到IT运维再到客户的整个自左向右的工作流。为了使流量最大化，我们需要小的批量规模和工作间隔，绝不让缺陷流向下游工作中心，并且不断为了整体目标（相对于开发功能完成率、测试发现/修复比率或运维有效性指标等局部目标）进行优化。\n必要的做法包括持续构建、集成以及部署，按需创建环境，严控半成品，以及构建起能够顺利变更的安全系统和组织。\n**第二工作法 **是关于价值流各阶段自右向左的快速持续反馈流，放大其效益以确保防止问题再次发生，或者更快地发现和修复问题。这样，我们就能在所需之处获取或嵌入知识，从源头上保证质量。\n“必要的做法包括：在部署管道中的构建和测试失败时“停止生产线”；日复一日地持续改进日常工作；创建快速的自动化测试套装软件，以确保代码总是处于可部署的状态；在开发和IT运维之间建立共同的目标和共同解决问题的机制；建立普遍的产品遥测技术，让每个人都能知道，代码和环境是否在按照设定的运行，以及是否达到了客户的目标。\n第三工作法 是关于创造公司文化，该文化可带动两种风气的形成：不断尝试，这需要承担风险并从成功和失败中吸取经验教训；理解重复和练习是熟练掌握的前提。”\n“尝试和承担风险让我们能够不懈地改进工作系统，这经常要求我们去做一些与几十年来的做法大不相同的事。一旦出了问题，不断重复的日常操练赋予我们的技能和经验，令我们可以撤回至安全区域并恢复正常运作。\n必要的做法包括营造一种勇于创新、敢于冒险（相对于畏惧或盲目服从命令）以及高信任度（相对于低信任度和命令控制）的文化，把至少20%的开发和IT运维周期划拨给非功能性需求，并且不断鼓励进行改进。”\nFrom: [美] 金（Gene Kim ），[美] 贝尔（Kevin Behr），[美] 斯帕福德（George Spafford）. “凤凰项目一个IT运维的传奇故事.”。\n",
    "ref": "/blog/devops-first-way-flow/"
  },{
    "title": "DevOps登山指南",
    "date": "",
    "description": "DevOps 案例研究 DOES17 San Francisco - DevOps Handbook Experiments in Accelerating Delivery - Nationwide",
    "body": "全美互惠保险公司(Nationwide)美国公司。在2017年6月7日，《财富》2017年美国500强排行榜发布，全美互惠保险公司排名第68位。营业收入40074.1百万美元。\n这家公司是DevOps Handbook（DevOps实践指南）书中的案例研究之一。这是一家DevOps水平较高的企业，是DevOpsDays大会上分享嘉宾的常客，也是各个DevOps工具厂商（New Relic）经常邀请的案例分享嘉宾。他们也经常参加DevOps企业峰会，曾多次做过自己的DevOps应用状况案例分享。\n本文分析和整理了他们在2017年11月旧金山站DevOps企业峰会上他们的演讲，主题为《DevOps Handbook Experiments in Accelerating Delivery - Nationwide》（翻译：使用DevOps Handbook在加速开发交付的过程中的实验）\n本文根据这个演讲的YouTube视频整理而成。视频已经上传到腾讯视频，点这里观看该视频。\n DevOps登山指南手册 我在翻译DevOps Handbook的过程中，感觉书中所描述的这家公司的案例研究，并不像本演讲里所说的这样的精彩。\n而时光已经很快的流转到了将近2018年，他们的DevOps也经过了几年的发展，本文案例向我们展示了一个金融行业（我们往往认为不太容易实施DevOps的行业）企业，在很大的企业规模了，所取得的令人敬佩的成就。\n下面这张图是本文的精华，先给各位呈现出来。他们使用攀登珠穆朗玛峰做为比喻，对DevOps的实施做了生动的诠释。\n本图在Nationwide公司内部的使用场景如下：\n 本图将DevOps实施核心团对指导产品开发团队（也可以说是业务团队、服务团队、这样的团队他们有200多个）取得的经验总结在一张纸上，供其它有实施DevOps想法的团队参考。 该登山指南简化了对其它非DevOps团队的教育和指引。 他们将DevOps的实施分成三个阶段，分别用大本营、北坡营地和顶峰作比喻。 这三个阶段里的技术实践都来自于DevOps Handbook，通过他们的筛选和整理，并根据自己的经验做了分阶段的规划。  为了知其所以然，我们将继续向下发掘，详细了解这个案例分享所讲的主要内容。下面的内容也包含了我对他们的分析和评论，欲了解原始资料，请请参看我上传到腾讯的视频。\n 主题：DevOps Handbook-在加速交付中的各种实验 分享者介绍。\n这个演讲距2018年2月也就是三个月，还算是很新鲜的一个案例。Cindy是DevOps团队中的核心人员之一，她的头衔是Director，角色是夏尔巴人（后面会详细解释这个比喻的含义），为业务产品组提供内部的DevOps咨询和辅导。Jim属于业务条线/BU的Dev这一侧，他是业务部门的解决方案架构师。\nNationwide的核心价值：保护对你最有价值的 公司简介和状况。\n 在很多险种上Nationwide都在业内排名第一名，包括：宠物保险、农场保险、公司寿险等等。 这是一家有90年历史的老店 汽车保险也行业排名第八（后面就是用这个业务为例，来佐证DevOps实施的效果） 不光在财富500强企业排名68，还是财富所评选的前100个最佳的工作企业。   Nationwide IT的规模很大 IT组织的特点和相关数据。\n IT组织庞大，结构复杂，业务条线众多 在选择应用某个DevOps实践的时候，总是要考虑到规模因素，需要评估该实践是否能在200多个业务开发团队的规模上全面地推广和实施 IT人员总数超过5100人，其中程序员和测试人员的数量超过2600人；在电脑世界的IT最佳工作地点的排行帮上位居第51名 该公司有用200多个产品开发团队，他们服务于23个业务部门BU   Nationwide IT的组织结构 典型、复杂和庞大的组织结构\n I\u0026amp;O是基础架构和操作运维团队，该组织不仅运维了所有的IT服务，还服务于所有的业务开发团队。 多个共享服务团队提供企业级的共享服务，包括Scrum测试等传统开发服务，同时也为企业内部的DevOps实践提供技术咨询，他们支持所有类型的企业应用堆栈 业务部门如前所述有23个，有200多个开发团队，Jim服务于金融业务BU 该公司的架构模型近似于典型的Dev、QA和Ops架构；他们的Ops组织也是集中式的；如此复杂的架构带来了DevOps流水线的复杂度方面的挑战，为某个业务BU实施的持续交付流水线会横跨多个BU，有时候甚至需要三个BU的CIO级别领导一起来参与决策，这里也会出现项目投资方和项目决策方不统一的难题。   从哪里开始 应用DevOps的企业环境背景和定位。\n IT组织十年以来追求的战略目标：构建具有全球竞争力的内包式软件开发能力；为此而采用了不同的管理框架和实践，应用和开始的时间点也不同  Agile：敏捷软件开发是10年前就开始的，定位和目标是通过敏捷软件开发交付高质量的软件 DevOps：今年加入了DevOps实践，定位是如何实现速度、效率和降低风险。 Lean IT：定位是确保将IT管理的各种实践（包括以上的敏捷和DevOps）提升和推广到企业级规模。（他们认为在团队级别上任何敏捷和DevOps相关的实践都是很容易实现的，而企业级规模的推广是更高等级的管理，是不容易达到的） CMMI：使用行业规范的软件开发成熟度标准评价和考量自身的软件开发能力，为自身的不断提高提供标准参考。   该公司DevOps实践是最晚开始应用的，其它的三个方面使用的历史比较长了，为了达成一个战略目标，需要4个战术层面实践的支持，这些战术的采用时期和定位不同；4个战术从不同的侧面支持了战略目标的实现。该企业也在Lean IT的论坛上分享和演讲过。   从哪里开始（续） 应用DevOps的时间轨迹和历程，各个时期的关键词。\n 2015-简化：DevOps小屋是入手DevOps实践时，最早使用过的参考框架；他们分析梳理了所有相关的方法论；工具方面专注在部署工具的改进上，所有产品线采用了IBM UrbanCode作为统一的部署工具；可是这个阶段接触的实践还是比较庞杂。 2016-组织：在获得了高层领导的支持以后，他们同时在三个方向出击：软件开发模型、精益IT管理和供应链管理；在三个方面都直接提高和优化了DevOps的速度。 2017-实验：在取得了天时地利人和之后，他们展开了所谓的“双模实验”的实践道路；从业务需求入手（规划了使用了MMP最小化可市场产品的概念），逐渐抛开了纷繁复杂的实践和方法论，他们开始聚焦在了“程序员体验”上，通过各种实验验证DevOps Handbook中描述的实践是如何影响并提升他们的。孵化和实验各种DevOps Handbook书里的实践。 2018-促动：如何把相关的工具推广到200多个开发团队，如何引入Google的SRE模型，将交付流水线作为产品对待，在复杂的组织中，实施跨部门的流水线的挑战依旧不轻。 该公司的DevOps实践道路是一步一个台阶的持续改进过程，经历了三年多时间，每个阶段的关键词代表了他们的成果和挑战。   DevOps团队间的交互模型 【重点】团队组织结构和交互方式。\n 这是实验各种DevOps实践的团队组织模型，开展每项DevOps实践都遵循PDCA的持续改进方法。 所有团队遵循着三个基础原则：1速度，江湖武功唯快不破，这是他们清醒而简单的唯一追求目标，成为检验所有优化改进的唯一验收标准和条件。2实践者之成功，他们做的并不是自顶向下的、政令式的强推，而是让参与DevOps实践的团队自己提出工作想法，自己来决定在哪里尝试改进能提升速度。3范围，从端到端的价值流全局看，既不推崇极左的做法，也不推崇极右的做法，他们将范围限定在，从一张工作卡片进入DevOps产品代办工作（Backlog）开始，直至将它的成果发布到生产环境中。 实施“双模实验”团队的模型，两个团队都提出自己想做的实验想法，双方的工作内容都汇总到一个集中的DevOps产品代办工作队列中，每一项工作/卡片都是一项实验，每一项实验都由两个团队分别完成，A/B团队的做法和实现结果可能不同，这样也自然地应用到了A/B测试的模型。 DevOps Leadership Team团队里是Cindy和Jim所在的团队（应该是一个虚拟团队组织），他们确保所有代办工作都遵循以上的三个基础原则，另外使用系统性思考来确保每种实验如果取得了成功，在推敲是否它能推广并应用到其它的200多个开发团队。 DevOps平台团队辅助和优化双模实验团队的工作，例如双模团队可能都需要自动化变更流程（ITSM的管理范畴）的API，而这些工作就可以踢给平台团队做，平台团队负责设计实现这个API，并且保证它具有企业级规模的能力，然后交付双模团队使用即可。 治理团队是由该公司的各个CIO级别的利益干系人组成的，上文说过某些复杂的DevOps持续交付流水线会跨三个以上的部门，这些BU的大佬会在这个团队中；他们在每个迭代都会出现在双模团队的工作现场，一起现场查看状况，现场解决问题。Jim认为他们亲自临场观察和了解实验工作的效果，远远比将实验成果作出PPT后再给他们去汇报的效果要好。   EPIC史诗 【重点】DevOps团队根据Handbook为基础，提出了所有想实验的工作内容。\n 开发团队从寻找什么拖慢了速度出发，寻找优化和改进工作内容的方法，在渐梳理和过滤以后，发现最后确定要做的工作都可以在Handbook中得到确认。甚至有些人在讨论某个工作条目的时候，能清晰的告诉大家可以参考Handbook书中的章节和页数。 DevOps产品代办工作里的EPIC史诗工作必须是在Handbook书中能够出现和参考到的，如果不是的话，团队可能会对它表示质疑。 这里Cindy简述了自动化测试这项工作的实验，故事是这样的：开发团队自己描述到，当前的Test Bed已经大到不可管理的程度，测试运行的时间太长了，因此不能保持测试的精简和有效性，这样的情况持续了一段时间以后，大家就失去了对自动化测试的信心。而且由于开发和测试人员不在同一个组织/团队里，团队之间必须进行工作交接（部门墙），导致了大量复测试案例的存在。他们的解决方法是，让开发和测试人员结对子，这样就减少了重复测试。当测试套件又变得精简和绿色了以后，大家又开始相信这些自动化测试了，之后大家对自动化测试的文化转变为：将自动化测试案例失败视为零容忍事件（失败的测试会导致全team的人停下来，并在1天内解决）。另外一个故事关于性能测试，性能测试是通过一个位于俄亥俄州的集中式性能测试团队做的，任何开发团队的申请时间是90天（被识别为最长时间的约束点），他们认为这个前置时间是无法接受的。解决方法是，将性测试脚本和运行权限交还给了开发团队，最后90天的性能周期被缩短为了2小时。 DevOps团队和管理层对Handbook书里的实践内容达成了共识和一致，上下一致的参考书中这些业界已经验证过的实践，节省了决策和探索DevOps做法和套路的时间。   开发者/程序员体验：十八般神兵利器，大量的上下文切换 【重点】2017年的实践核心是“开发者/程序员体验”（程序员要“富养”）\n在专注于开发者体验优化的过程中，应用了大量DevOps工具，最后发现如果开发者把它们都用一遍的话，要花好几个小时的时间。为了解决这个问题，他们体验了Rocket.Chat工具，开发者们对此工具提出了一致好评。\n为了让公司领导层支持增加这个工具，他们请领导们到现场亲自视察观看开发人员在使用了Rocket.Chat之后，优化的体验。领导们就这样决策增加的这个工具。\n 开发者/程序员体验：拥抱聊天机器人，减少上下文切换 优化后的开发者工具集如下所示。\n 开发者直接面对的工具精简了很多，他们几乎只需要专注于写代码和处理代码的提交和PR即可。 之前开发者如果需要部署代码，就需要手工的在UrbanCode里点击十几二十次鼠标，才能完成一次部署操作。 在使用了聊天机器人之后，他们只需要对聊天机器人说：deploy；即可   DevOps登山指南 通过这一页纸的手册，为新来的DevOps实践者提供了清晰的指导。\n攀登高山隐喻了这是一个艰难的旅程。\n 北极星 - 前置时间 【重点】各项DevOps工作的唯一参考指标是“前置时间”（指南针）\n选用这个指标的三个原因：\n 这个指标可以在横向的200多个敏捷开发团队里实施；在纵向的组织级、部门级和团队级上，大家都能理解和认可这一指标，都能够掌握前置时间的计算和测量方法。缩短前置时间的目标是清晰的：及时要加快交付速度。 各个开发团队可以自行选择优化前置时间的方法和路径，其实这鼓励了团队的创造性。 对此指标的度量和持续改进，是可以按天实时进行的，同时还要保证实现部署的零宕机时间。   DevOps登山用品：地图和装备 DevOps实践者基础的精神和物质需求。\n 工具和DevOps实践直接相关 每个工具都有其价值和应用场景（例如Rocket.Chat） DevOps Handbook（中文书名：DevOp实践指南）的作用是地图，每个DevOps实践团队都进行至少每周一次的读书俱乐部活动，每次都对书中具体的章节进行团队讨论和学习。   DevOps的支持模型 DevOps支持团队的作用。\n为了满足企业级的支持规模，让水平参差不齐的200多个开发团队都能顺利应用DevOps实践，没有这个支持模型是不可能走远的。\n 夏尔巴人团队的作用是支持和辅导DevOps实践团队，提升团队的思想意识观念和技能，帮助它们构建某些特定领域的工作能力。 参与DevOps实践的开发团队必须自己登上山顶，哪怕是爬也是自己爬上去。绝不勉强，不想进步的团队就不要参与了。 逐渐开展了沉浸式配对的支持模式，让低水平团队的人员在DevOps高水平团队中进行交叉培训，让他们现场看到相同的工作确实可以有不同的、更好的做法。 他们进行每月一次的DevOps道场，在道场里DevOps技术顾问现场指导和帮助前来提高的团队。 将流水线视为产品，流水线的管理确实也是他们的痛点之一。   DevOps成功的那一刻 DevOps对业务有毛用？！\n这个故事是该公司刚开始品尝DevOps成功硕果的那一刻。飓风哈维（是2017年大西洋飓风季中的一个热带气旋。2017年8月25日，登陆美国德克萨斯州沿岸，时速130英里）导致车辆涉水险的申报数量剧增。业务部门的人处理这些车险事件的过程中意识到，他们的业务流程对这个险种的索赔并不友好，于是就来找到了IT部门，提出想要优化这个险种报案和索赔处理。\n这是第一次业务部门找上门来提出的业务需求，IT部门在当天就搞定的经历。业务人员和IT部门的人用了一个小时的时间讨论优化方案，决定去掉索赔流程里40%的多余步骤。IT部门开始设计和实施这个想法，决定需要变更多个应用，他们在当天里，在剩下的7个小时内就完成了这些业务需求的开发和测试，这些业务变更的生产环境部署工作是在工作时段进行的，变更在当天的营业时间结束前就上线了。他们始终以速度为先的实践原则在一年后，在这一天里得到了回报。以前需要至少90天的周期才能完成这样的变更，性能测试会就会占用一半以上的前置时间。而他们觉得这次在整个的设计、实施和部署过程中，其实并没有感到什么压力和风险。\n 后记 本文的价值在于，向你展示一个有参考价值的DevOps案例。它的很多特征和成功之处都值得借鉴和思考。本文的文字主要来源于对视频中的叙述，其中也包含了大量我个人的观点和分析；欢迎读者在观看本案例视频后，与我分享和讨论以上内容。\n",
    "ref": "/blog/devops-climbing-guide/"
  },{
    "title": "2017年底的回顾和展望",
    "date": "",
    "description": "我的2017年，2017年是什么年？18年听说是狗年。",
    "body": "农历年才是中国人意识里的年，狗年不到来，鸡年绝对还没有过完。在这几天里总有一些想要总结和展望的。一年的时间过的犹如白骥过隙一般，愈来愈加明显的感觉到各种岁月的痕迹。此刻所想到的一切只有缓慢和宁静，能否让这个世界缓慢和宁静下来。\n盘点 想想去年这一年都做了什么事？都去过哪些地方？有哪些值得回忆的经历？\n旅行 回顾一下才发现这一年去过不少地方，很多地方是第一次去。\n1-日本（春节） 去年的第一个旅行是在过年期间去日本的东京大阪之旅。首次去日本的总体感觉还是不错的，住的是Airbnb的家庭房间，位置和环境都非常好。游玩了福建狐狸大社、在奈良的东大寺喂小鹿、游玩了大阪的迪士尼，日本好玩好逛的地方真多。\n不过印象最深的还是两件事：1）京都的鸭川河边跑步十公里；2）在大阪的烧肉店和朋友一起和热清酒。\n2-吉隆坡（三月） 这次是出差，公司在吉隆坡开会，顺便带了小孩一起去玩，赶在上小学之前能玩的机会不能放过。在这一周的行程里，不仅游览了市区主要的地方，还去珍拉丁湾的CloudMed故地重游了一下。\n3-普吉岛的泼水节（四月） 去普吉岛开会期间，碰巧赶上了泼水节。除了一头一尾的两天休闲时光之外，其它的三天会议时间，非常消耗精力和体力；完全是三天的黑客马拉松式的比赛式培训。代表中国团队上台做了项目汇报演讲，虽然有些超时，虽然没有拿到第一名，不过整个竞赛的体验还是很不错的。\n4-拉斯维加斯和大峡谷之旅（八月） 这是出差去美国参加公司的年度启动大会。这是一次极致的旅行，在拉斯维加斯的几天会议过程中，和同事一起各种的购物和游览，给我的赌场之旅画上了圆满的句号。而精彩的部分在开完会之后，和同事们一起去大峡谷的游览。\n我们住在大峡谷南缘的威廉姆斯小镇上，来过的人应该都知道这个小镇，对大峡谷南缘的主要景区进行了两进两出的深度游览。希望下次来的时候，可以从东部的羚羊峡谷北上，再次访问我的第一个美国旅行目的地：盐湖城（2006年）。\n5-台北深度一周游（8月） 从美帝回来之后，接着去台北参加了DevOpsDays台北站的大会。趁着开会之余的时间和随行的朋友们一起游览了台北市和附近的不少地方。第一次去宝岛台湾，第一次在国外的城市参加DevOpsDays大会；参加这次大会有两项任务：1）作为国内专家团的邀请人，邀请了多位业内的DevOps大拿同去台北演讲；2）我的专题演讲是在第二天；真是圆满的一次旅行。台北的101大厦、故宫和诚品书店给我留下了深刻的印象。\nDevOps 这一年中除了工作之外，我主要的研究方向是在DevOps上。参加了两次DevOpsDays大会，完成了DevOps Handbook的翻译。\n1-DevOpsDays北京 大会在三月十八日召开，这是在我拿到Exin DevOps Master自由讲师资质以后，所参加的最重要的一个DevOps大会。我也是很积极的参与在这次大会活动里，主持了OpenSpack开放空间环节。这个大会是DevOps社区比较正宗和原生的社区大会，我也是第一次见到了DevOps之父Patric先生。\n在这两天的大会活动中，我们都可以感觉到DevOps社区的火热，由于是DevOpsDays大会的首次来华；它的象征性更大于其它的任何意义。\n通过这次参与首届DevOpsDays大会活动，我感觉找到从技术和社区这两个方面而言，找到了和我匹配最佳的社区。我的工作经历是ITIL相关的IT管理背景的，技术方面接从事最多的是IT管理工具和云计算；而我也是开源技术社区的超级粉丝。\n2-翻译 DevOps Handbook 这是2017年内我投入巨大的一项工作，从来没有想到工作量是如此的惊人，即使是和其它三个朋友一起做；最后回顾一下，觉得工作量还是远远超出了我的想想。\n出版社的线上书稿编辑系统里，有大部分工作时间的统计，经过了不计其数的起早贪黑以后，我的线上系统内工作时间定格在了：278小时44分钟；这份工作让我记忆犹新的是：周末送孩子去上课以后，我在星巴克度过的n多个上午；在交稿前的最后几次令人抓狂的集中修订。出版社审稿通过，编辑开始编辑审稿之后，看着三审作完之后的结果还是觉得分外激动的。\n这本书的中文书名为《DevOps实践指南》，为这本书我建立了一个独立的推广站点：https://handbook.martinliu.cn/，站点里的术语表非常欢迎大家的引用和协作修订。\n3-DevOps培训课 由于这一年中我几乎所有的业余时间和精力都花在Handbook的翻译上，因此接的课很少，甚至于还推掉了不少的课；在翻译完成之后，应该有时间在周末做这方面的培训了。\n培训课对我而言是我进行社区分享的一种形式，觉得很多知识和经验的体会，如果不通过什么渠道分享出来的话，始终会就觉得不尽兴，觉得白学了这些知识。也有可能是开源社区 开放和分享 的毒中的太深了，哈哈！\n展望 虽然在感觉上2017年一晃就过去了，但是盘点之后发现，过得还是极度的充实和饱满的。觉得我的付出和辛苦还是很值得。\n在元旦之后我就确定了今年的总基调：停止开始，开始完成，继往开来，全面开挂。\n我在DevOps方面的经验完全能够利用到公司的产品和工作中，这一点实在是可遇而不可求的。随着公司对Nutanix Calm的重视，基于蓝图的应用全生命周期自动化运维，正渐渐的成为很多项目的需求。为此我也建了一个文档分享站点：https://nutanix.martinliu.cn/；希望在新的一年里继续丰富和优化这些文档。在客户项目和合作伙伴培训的过程中能和更多人碰出DevOps火花。\n在旅行方面，18年可能会去欧洲，还没具体的计划。\n在新领域探索方面，18年已经开始了对区块链的了解和参与。\n在18年里作为中国DevOpsDays大会的核心组织者，希望在5月北京站的大会上，和Handbook的作者一起发布中文版Handbook图书，并在DevOps社区里做更多的分享和贡献。\n",
    "ref": "/blog/post-of-year-2017/"
  },{
    "title": "Container Orchestration Wars",
    "date": "",
    "description": "",
    "body": "容器编排器之战 K8s在2017年底为这场速战速决的站点话上了句号，结果是所有竞争对手都选择了增加对K8s的支持。在各自的编排器框架里内置了K8s。本文是根据Mesosphere公司的大拿Karl KARL ISENBERG在各种大会上分享过多次的一份演讲稿改版的。\nKARL ISENBERG 是谁？ 所在公司?\n Mesosphere（当前） Pivotal  做过的产品?\n DC/OS opensource CloudFoundry BOSH  联络信息：\n github.com/karlkfi twitter.com/karlkfi linkedin.com/in/karlkfi karl.isenberg.us  基础架构的进化 传统的应用架构在逐渐向下面两种架构演变。\n可扩展的单体应用架构 关键词：\n Online 基于互联网 Latency Routed 用户访问基于延迟路由 Multi-Region 多区部署 Load Balanced 负载均衡接入 Multi-Zone 多个Zone Replicated 应用实例多副本 Auto-Scaled 容量自动化收缩 Data Replication 区内数据多副本 Data Synchronization 跨区数据同步  可扩展的微服务架构 上图出处：Wheel of Doom ，来自A Journey into Microservices by Hailo\n应用+裸金属服务器 APPLICATION PROVISIONING ON BARE METAL\n应用+IaaS APPLICATION PROVISIONING ON VIRTUAL INFRASTRUCTURE PLATFORM (IaaS)\n “Ultimately, utility cloud providers have exposed how difficult it is to properly operate data centers — and reminded all of us that the ability to expertly operate infrastructure is what really fuels the consumption of open source infrastructure.” \u0026ndash;Brian Stein (Rackspace VP - 2017)\n 应用+PaaS/aPaaS+IaaS APPLICATION PLATFORM (PaaS / aPaaS) ON INFRASTRUCTURE PLATFORM (IaaS)\n “The goal of Cloud Foundry is to put more of the controls back in the hands of developers so they can self-provision, so there aren’t a lot of roadblocks in their way. But it gives a lot of guardrails.” \u0026ndash; Chip Childers (Cloud Foundry Foundation CTO - 2017)  容器编排器+IaaS CONTAINER ORCHESTRATION ON INFRASTRUCTURE PLATFORM (IaaS)\n “\u0026hellip;traditional “PaaS” roles have now been taken over by containers… The piece that is left for PaaS is the part that was always the most important part of PaaS in the first place, and that’s the opinionated developer experience.” \u0026ndash;Brendan Burns (Kubernetes Cofounder - 2017)\n CaaS+IaaS CONTAINER PLATFORM (CaaS) ON INFRASTRUCTURE PLATFORM (IaaS) CaaS+裸金属服务器 CONTAINER PLATFORM (CaaS) ON BARE METAL\nFaaS+IaaS FUNCTION PLATFORM (FaaS) ON INFRASTRUCTURE PLATFORM (IaaS)\n “If your PaaS can efficiently start instances in 20ms that run for half a second, then call it serverless.” \u0026ndash;Adrian Cockcroft-(AWS VP - 2016)\n FaaS+CaaS FUNCTION PLATFORM (FaaS) ON CONTAINER PLATFORM (CaaS) FaaS+CaaS+IaaS FUNCTION PLATFORM (FaaS) ON CONTAINER PLATFORM (CaaS) ON INFRASTRUCTURE PLATFORM (IaaS)\n平台频谱 - PLATFORM SPECTRUM 从左到右，资源的抽象程度不断提高；最左侧的弹性最高，最右侧的速率最高。 下图是不同类型里的厂商和软件。 容器平台层次 容器编排器的层次如下：  User workloads 用户工作负载 Distributed container management 分布式容器管理 Local container management 本地容器管理 Container agnostic infrastructure 容器无关性基础架构  容器平台的层次如下： CONTAINER PLATFORM\n User workloads 用户工作负载 System management \u0026amp; service enablement 系统管理和服务管理 Distributed container management 分布式容器管理 Local container management 本地容器管理 Container aware infrastructure 容器感知的基础架构 Container agnostic infrastructure 容器无关的基础架构  分布式操作系统的层次如下： 容器平台功能点 CONTAINER PLATFORM CAPABILITIES\n运行态的能力 1 容器\n Resource Isolation Resource Constraints Process Tree Environment Isolation Shell / Exec  2 镜像\n Build Layers Download Cache Publish Prune  3 网络\n Container Bridge Host Virtual Overlay Remote User-defined Port Mapping  4 数据卷\n Ephemeral Host Backup / Restore Copy In / Out Shared  编排器的能力 调度\n Placement Replication/Scaling Readiness Checking Resurrection Rescheduling Rolling Updates Collocation Daemons Cron Jobs  资源管理\n Memory CPU GPU Ephemeral Volumes Remote Persistent Volumes Local Persistent Volumes Ports IPs (per container)  服务管理\n Labels Groups/Namespaces Dependencies Load Balancing (L7) VIPs (L3/L4 LB) DNS DNS Proxy Secrets Config Mgmt  运维方面的能力 管理\n GUI CLI Metrics API Logs API Events API Rolling Upgrades Backups \u0026amp; Restores  MULTI-INFRASTRUCTURE\n Multi-cloud Multi-zone Multi-region Hybrid-cloud Federation  系统服务\n Auto-Scaling Package Management Service Catalog Service Brokers Admin Proxy API Gateway  平台的能力 容器网络\n Overlay Routing Network Address Translation (NAT) Firewalls Access Control Lists Quality of Service  容器存储\n Local Volumes Remote Volumes Block Storage File System Storage Object Storage  平台数据库\n Lock Service Key-Value Database Relational Database Time Series Database  安全\n User Accounts Service Accounts System/User Space E2E Encryption Non-root User Workloads Audit Logging Public Key Infrastructure Certifications  多租户\n User Groups Permissions RBAC ABAC Resource Sharing  FIFO Fair Quotas   Branding Quality of Service  非功能需求\n稳定性\n Performance Responsiveness Efficiency  可用性\n Fault Tolerance Robustness, Reliability, Resilience, Disaster Recovery  灵活性\n Format Support, Interoperability, Extensibility, Container Runtimes  可用度\n Familiarity, Maintainability, Compatibility, Debuggability  可移植性\n Host OS, Cloud, Bare-Metal, Hybrid  安全性\n Encryption Quality, Vulnerability Process, Fast Patching, Backporting  容器平台对比 市场里的主要技术厂商如下。 其它值得考虑的厂商如下。\n下面的能力对比的时间点是 06/2017，这个时候K8s是否能胜出还是个悬念。\n调度 图示说明：\n 绿勾：包含此能力 横杠：New/External/Partial/Experimental  资源管理 服务管理 如何选择 第一阵营：重量级 KUBERNETES\n Huge community Solid API Some assembly required Multitude of vendors/installers  OPENSHIFT\n Application platform based on Kubernetes Always trailing Kubernetes releases No assembly required Open core, enterprise platform  DC/OS\n Runs native applications (non-Docker) Specialized in data services Ambitious scope (on-prem AWS) No assembly required Open core, enterprise platform  DOCKER\n Huge community Fast moving API Integrated orchestration and runtime Recent pivot from runtime to orchestration Open core, enterprise platform  第二阵营：轻量级 EC2 CONTAINER SERVICE (ECS)\n Hosted-only solution Tight integration with AWS services Closed platform  RANCHER CATTLE\n Gateway to Kubernetes, Mesos, and Docker Open platform, enterprise support  NOMAD\n Provisioner with orchestration features Runs native applications (non-Docker) Tight integration with Vault and Consul Some assembly required Open platform, enterprise support  KONTENA\n Simple to set up No assembly required Open core, enterprise platform  Karl个人的考察点？  Which is more important to you: velocity or flexibility? Do you want an opinionated application platform? Do you need to support Big Data initiatives and pipelines? Do you want a hosted solution? Are you willing to build out your own integrations? Do you need on-prem \u0026amp; hybrid capabilities? Do you want to avoid infrastructure lock-in? Are you already invested in a specific infrastructure? Are you already invested in a specific operating system? Do you need **federation and multi-region **support? Do you want multi-tenancy or is multi-instance good enough? How important are seamless automated rolling upgrades? How many nines do your customers need? How important is reverse compatibility \u0026amp; API stability? Do you need to support non-Docker workloads?  ",
    "ref": "/blog/2018-1-container-orchestration-wars/"
  },{
    "title": "Host a Hugo Server on Labtop",
    "date": "",
    "description": "",
    "body": "将笔记本上的Hugo站点分享给局域网里的其他人 我的笔记本上有好几个Hugo做的静态的站点，有自己的个人Blog，有公司产品的培训文档；其中的有些站点内容，有可能是不方便发布到Internet上，有可能是你的观众并没有条件访问Internet，但是使大家同在一个局域网里是一个很现实很方便的做法。那么怎样以最小的代价实现这个需求呢？\n选择Hugo服务器启动参数 为了满足以上需求，在启动Hugo服务器的时候需要增加两个参数，如下所示：\nmartin@bogon:source/martinliu-hugo ‹master*›$ hugo server --bind 192.168.1.107 --baseURL http://192.168.1.107/ Started building sites ... Built site for language en: 0 draft content 0 future content 0 expired content 387 regular pages created 1100 other pages created 0 non-page files copied 668 paginator pages created 509 tags created 37 categories created total in 922 ms Watching for changes in /Users/martin/source/martinliu-hugo/{content,static,themes} Serving pages from memory Web Server is available at http://192.168.1.107:1313/ (bind address 192.168.1.107) Press Ctrl+C to stop 对以上参数的解释：\n \u0026ndash;bind 192.168.1.107 ：这个192的IP地址是笔记本目前局域网（Wifi）的地址，其他人需要和你同在这个局域网里，或者能够访问到这个网段的地址 \u0026ndash;baseURL http://192.168.1.107/ ： 这会覆盖Hugo站点里根目录下配置文件里的baseURL参数，有可能配置文件中这个参数是类似于 http://martinliu.cn/ ，如果不加这个参数的话网站上的相关图片会显示不出来。  配置笔记本电脑的防火墙 以macOS为例，当你启动了这个Hugo服务器的时候，你访问 Security \u0026amp; Privacy 配置的时候，选择 Firewall 标签的时候，会自动弹出一个对话框，询问是否允许 incoming 的网络连接到 hugo 的应用服务。点击允许即可，这样防火墙配置里就多了一条配置，如下图所示：\n总结 Hugo可以很方便的将本地站点分享给局域网里的其它人，只需要在启动的时候加上适当的参数，配置好本机的防火墙策略即可。\n",
    "ref": "/blog/2018-1-host-hugo-server-on-labtop/"
  },{
    "title": "Kubecon 2017演讲稿和视频下载",
    "date": "",
    "description": "",
    "body": "KubeCon 2017演讲稿和视频下载 Kubernetes无疑当下最火热的技术之一，Google公司围绕着它下了更大的一盘棋CNCF。这是在国际寡头IT软件公司的统治局面渐渐退去之后，各种新鲜技术百花齐放了一段时间以后，再通过CNCF的形式又逐渐集中化起来的趋势。KubeCon的人气很旺，演讲分享的人很多。\n最近一次的KubeCon，2017年在奥斯汀站的演讲稿和视频下载的清单已经发布出来了：\nhttps://github.com/cloudyuga/kubecon17\n我在YouTube里听了一部分视频，感觉确实有很多新鲜的工程实践经验的分享。下面分享一个觉得不错的实战案例分享。\nBox公司分享持续交付实战经验 关于这个分享的看点：\n Box公司全面实施Kubernetes的案例，涵盖了所有的环境：Dev、Staging和Prod 遇到的挑战和问题共性强 Jenkins流水线+金丝雀部署+持续交付的组合 解决问题的模式值得借鉴 工具集里开发出来的核心组件已经开业分享在Github上  分享者经典语录：\n 我们是软件工程师，我们不是坐在那按按钮的猴子！\n 以上分享的持续交付方案里kube-applier的源代码分享：\nhttps://github.com/box/kube-applier\nPS：非常敬佩这种开放和分享的工程式文化。很符合开源的精神，爱分享的人，不把东西分享出来的话可能会不爽。\n延伸阅读：\n https://blog.box.com/blog/introducing-kube-applier-declarative-configuration-for-kubernetes/ https://blog.box.com/blog/kubernetes-box-microservices-maximum-velocity/   观看以上演讲视频 \n",
    "ref": "/blog/2018-1-kubecon17/"
  },{
    "title": "用跑步的方式启动2018年",
    "date": "",
    "description": "",
    "body": "用跑步的方式启动2018年 元旦这天早晨送女儿去中国儿童艺术剧院看剧，这正好是我跑步的大好时机。正好是一个大晴天，这样的蓝天岂能辜负。环绕故宫的路线是一根长了很久的草，今天总算可以拔除了。于是我从东华门开始往北，沿着逆时针方向开始跑。下面是这次的跑步路线图。\n跑步路线评价 东华门一侧向北的路上，直到故宫西北角的角楼；刚开始游客和行人还不是很多，但是到了故宫博物院的北门，哪里的游客非常多，需要躲开行人往前跑；在10点以后的时间里，保证你想跑也跑不快，人确实是比较多的，而且正好赶上了元旦这一天。听说有9万人在天安门广场观看了升旗仪式。\n故宫的西侧南长街这条路是很窄的人行道，由于也是有不少游客，我后半程是机动车上和机动车流逆行了一段跑的，虽然有点危险，不过机动车开得都不快，也在明显的躲让这行人，跑后还是感觉还是不建议这么跑。\n到了长安街以后，我想从天安门广场门口跑过，也就是从天安门的西边跑到东边，结果发现其实西边和东边以及广场周边都是设置了安检，如果没有带身份证的话根本就走不过去。在天安门站西的安检门口排了5分钟队以后放弃了。接着过马路到路西想往东跑，结果也比警察截住赶走了。无奈只能继续往南跑，从人民大会堂西路，途径前门大街和正义路，又回到了长安街。还不死心，企图混过东侧的安检抵达天安门城楼下，未果。然后继续沿着南池子大街跑到了起点。\n 如果没有带身份证，根本无法接近天安门城楼下和进入天安门广场以内 如果在节假日里，安检排队的等候时间应该是是10到30分钟以上，根本不适合在跑步的过程中有安检的环节，不是么？ 整个一圈下来，觉得道路上主要是游客居多，如果是跑步圈地，圈名胜地标的想法，还可以跑，不是的话，还是去其它的跑步地点吧  最后 在东华门终点附近，排了两张故宫外侧的图片。\n2018年必须是一个不平凡的一年，我将这一年的基调定义为：停止开始，开始结束，全面开挂！\n",
    "ref": "/blog/2018-1-kickoff/"
  },{
    "title": "2017DevOps企业峰会旧金山站",
    "date": "",
    "description": "在就旧金山顺利举办，规模一次比一次大",
    "body": "DevOps Enterprise Summit由美国的Gene Kim发起并举办的，他是两本流行书籍的作者：《凤凰项目》和《DevOps Handbook》（中文书名《DevOps实践指南》预计于2018年春季出版）。\n大会简介 下面是来自这个大会官网的简单介绍：\n DevOps Enterprise Summit is a conference for the leaders of large, complex organizations implementing DevOps principles and practices. The event programming emphasizes both evolving technical and architectural practices and the methods needed to lead widespread change efforts in large organizations. The goal is to give leaders the tools and practices they need to develop and deploy software faster and to win in the marketplace.\n From:https://events.itrevolution.com/us/\n推荐视频 最近我通过微信公众号分享过关于Seek公司DevOps转型的精彩视频。\n\n演讲稿目录    星期 场次 名称     Monday Electric Cloud Track Rocha, Aloisio, Betting on DevOps- How NetEnt Transforms Online Gaming Delivery.pdf   Monday Electric Cloud Track Wallgren, Andres, Architecting Your App and Your Pipeline for Continuous Delivery - 10 DO\u0026rsquo;s for Successful DevOps.pdf   Monday Electric Cloud Track Mckay, Gary, From Mainframe to Microservices- How Somos Keeps Telcos and Us All Connected.pdf   Monday Electric Cloud Track Pullen, Wesley, DevOps from Grassroots to Mainstream.pdf   Monday Electric Cloud Track Esser, John, DevOps Transformation 2.0- From Ancestry.com to AdvancedMD - applying strategies for leading DevOps innovation.pdf   Monday Breakout Session Comtois, Pauly, Bringing DevOps to Product.pdf   Monday Breakout Session Raia, Alice, Overcoming 75 years of inertia in healthcare; a Top-down + bottoms-up DevOps Transformation.pdf   Monday Breakout Session Perret, Jennifer, Guckenheimer, Sam, The Skype Journey to 1ES and Cloud.pdf   Monday Breakout Session Grafmeyer, Jim, Payne, Cindy, DevOps Handbook Experiments in Accelerating Delivery.pdf   Monday Breakout Session Hering, Micro, What got you here, wont get you there - A story of transformations.pdf   Monday Breakout Session Dominica DeGrandis - DeGrandis_Nov 12.2017.pdf   Monday Breakout Session Olivier, Dawie, Agile:Dawie ruined my life.pdf   Monday Breakout Session Thrasher, Paula, Scaling DevOps Talent in a Large Enterprise.pdf   Monday Breakout Session Daththreya, Gnani, Shunmugasundaram, Sathiya, Continuous Chaos in DevOps.pdf   Monday Breakout Session Hockaday, Kurt, Turning the Battleship A Principled Approach to Driving Change in DoD IT.pdf   Monday General Session Mayner, Steve, Transformational Leadership and DevOps - Beyond the Research.pdf   Monday General Session Johnson, Suzette, Yeman, Robin, What Legacy government organizations need to advance the state of DevOps.pdf   Monday General Session Nassello, Scott, Using DevOps to build your learning organization.pdf   Monday General Session Morrison, Erica, Prugh, Scott, More Culture, More Engineering, Less Duct-Tape.pdf   Tuesday Electric Cloud Track Aggarwal, Manish, Intel\u0026rsquo;s Journey to Build Quality In How QA and Test Automation Drive DevOps Transformation.pdf   Tuesday Electric Cloud Track Priolo, Marc, Mastering the Three S’s for a Successful Pipeline-as-a-Service Strategy Standardization, Self-service, Scale.pdf   Tuesday Electric Cloud Track Stroud, Robert, DevOps From Analyst Inquiry to Organizational Action.pdf   Tuesday Electric Cloud Track Gruver, Gary, Starting and Scaling DevOps in the Enterprise.pdf   Tuesday Electric Cloud Track Reed, J. Paul, Navigating the Software Delivery Minefield DevOps and the Art of Release Engineering.pdf   Tuesday Breakout Session Blank-Edelman, David, SRE For Enterprises.pdf   Tuesday Breakout Session Lackey, Zane, DevSecOps How to use DevOps to make you more secure.pdf   Tuesday Breakout Session Burgin, Andy Devops in a Data Warehouse Inside Out.pdf   Tuesday Breakout Session Nowak, Chris, Alliances, Data and Startup Mentality – How we Led Three Banks through DevOps Transformations.pdf   Tuesday Breakout Session Rinehart, Aaron, Wickett, James, DevOps and the Healthcare Giant.pdf   Tuesday Breakout Session Kolli, Rama, Supercharging PayPal’s application development to help democratize financial services.pdf   Tuesday Breakout Session Fong, Richard, Nir, Erez, From Dev Opps to DevOps.pdf   Tuesday Breakout Session Nielsen, Suzanne, Shewell, Sarah, Transformation at Scale, One Cup at a Time.pdf   Tuesday Breakout Session Finster, Bryan, Pendergraft, Brent, CD Solving the talent problem.pdf   Tuesday Breakout Session Edmundson, Jill, Musil, Jill, Service Request Management CSG\u0026rsquo;s Journey from Chaos to Clarity.pdf   Tuesday Breakout Session Magennis, Troy, Prioritization – 10 different techniques for choosing what to start next.pdf   Tuesday Breakout Session Owczarek, David, Best Practices for Availability.pdf   Tuesday General Session Forsgren, Nicole, The key to high performance What the data says.pdf   Tuesday General Session Matthew, Tisson, The Making of Amazon Prime Now.pdf   Tuesday General Session Allspaw, John, How Your Systems Keep Running Day After Day - Resilience Engineering as DevOps.pdf   Tuesday General Session Brady, Jennifer, Pal, Tapabrata, Better Governance – Banking on Continuous Delivery.pdf   Wednesday Electric Cloud Track Morales, Marco, Process-as-Code Real-World Examples that Scale.pdf   Wednesday Electric Cloud Track Lynn, Angelo, Best Practices for DevOps-Ready Infrastructure Management and Automation.pdf   Wednesday Electric Cloud Track McKnight, Ken,Data-Driven DevOps Taking Action!.pdf   Wednesday Electric Cloud Track Doucet, Chris, Best Practices for Model Driven Approach to Application Release.pdf   Wednesday Electric Cloud Track Sutton, Mark, BizDevOps Using KPIs to Unlock a Common Language.pdf   Wednesday Electric Cloud Track Schuller, Manuel, How Financial Services are Leveraging Legacy IT Investments When Transitioning to DevOps.pdf   Wednesday Breakout Session England, Rob, Surviving DevOps.pdf   Wednesday Breakout Session Konno, Miki, Marks, Justin, User Feedback at the Speed of DevOps.pdf   Wednesday Breakout Session Finn, Ray, Singh, Aru, Service Ownership - Devops for Salesforce.pdf   Wednesday Breakout Session Hill, Chris, Context Switches in Software Engineering.pdf   Wednesday Breakout Session Wester, Julia, Taming the Chaos- Beyond the Quick Wins.pdf   Wednesday Breakout Session Kernaghan, Chris, Can you do Devops in SAP DOES.pdf   Wednesday Breakout Session Jelleda, Kishore, DevOps at Scale is a Hard Problem- Challenges, Insights and Lessons Learned.pdf   Wednesday Breakout Session Radcliffe, Rosalind, Two Amazing Mainframe DevOps Transformation Case Studies.pdf   Wednesday Breakout Session Shoup, Randy, Scaling Personalization- DevOps at Stitch Fix.pdf   Wednesday Breakout Session DeArdo, Carmen, Kersten, Mik, The Case for Value Stream Architecture.pdf   Wednesday Breakout Session Rizzo, David, Two Amazing Mainframe DevOps Transformation Case Studies.pdf   Wednesday General Session Boecker, Scott, Forrester, Ron There is No Finish Line.pdf   Wednesday General Session Clanton, Ross, Kumar, Nanda, Fear does not exist in the dojo - a devops journey with a competitive twist.pdf   Wednesday General Session Smart, Jonathan, The Yin and Yang of Speed and Control.pdf   Wednesday General Session Hendrickson, Elisabeth, Data and DevOps Breaking Down the Silos.pdf   Wednesday General Session Dekker, Sindey, The human factor Inspiring the pursuit of success and averting drift into failure.pdf    演讲稿下载 我从官网的Dropbox网盘里下载了所有演讲稿，分享到了微云的网盘里。\n点这里下载 以上文件压缩包大将近700MB。\n也可以从GitHub看到这些分享的文件：https://github.com/devopsenterprise/2017-San-Francisco\n同样的今年6月份在伦敦举行的欧洲场次的DevOps企业峰会的演讲稿下载地址在：https://github.com/devopsenterprise/2017-london\n",
    "ref": "/blog/2017-does-sfo/"
  },{
    "title": "为Docker Swarm群集配置Nutanix持久存储",
    "date": "",
    "description": "",
    "body": "本文介绍如何用Docker卷插件的方式，给Docker Swarm的群集挂载Nutanix存储。Nutanix Container Volume Plug-in 简称DVP，可以给容器提供数据持久化的功能。\n本文使用ownCloud网盘应用做功能测试。测试的过程如下，安装部署Docker Datacenter，配置好群集，在UCP的界面里调用DVP插件建持久的数据卷，建立ownCloud服务，部署和测试该服务。\nNutanix DVP (Docker Volume Plug-in)安装和配置 这一部分描述DVP的安装部署过程，需要连接互联网；安装调试完毕之后，作虚拟机的镜像模板使用。这样Docker Swarm的其它节点也都不需要重复这个步骤了。\n本文使用的是Docker社区文档稳定版 17.03.1-ce ；本文使用的OS是CentOS 7.3。所Docker安装的版本如下：\n[root@centos7-temp]# docker version Client: Version: 17.03.1-ce API version: 1.27 Go version: go1.7.5 Git commit: c6d412e Built: Mon Mar 27 17:05:44 2017 OS/Arch: linux/amd64 Server: Version: 17.03.1-ce API version: 1.27 (minimum version 1.12) Go version: go1.7.5 Git commit: c6d412e Built: Mon Mar 27 17:05:44 2017 OS/Arch: linux/amd64 Experimental: false [root@centos7-temp]# rpm -qa|grep docker docker-ce-17.03.1.ce-1.el7.centos.x86_64 docker-ce-selinux-17.03.1.ce-1.el7.centos.noarch 本文使用的Docker 安装yum源如下：\n[root@centos7-temp]# cat /etc/yum.repos.d/docker-ce.repo [docker-ce-stable] name=Docker CE Stable - $basearch baseurl=https://download.docker.com/linux/centos/7/$basearch/stable enabled=1 gpgcheck=1 gpgkey=https://download.docker.com/linux/centos/gpg [docker-ce-stable-debuginfo] name=Docker CE Stable - Debuginfo $basearch baseurl=https://download.docker.com/linux/centos/7/debug-$basearch/stable enabled=0 gpgcheck=1 gpgkey=https://download.docker.com/linux/centos/gpg [docker-ce-stable-source] name=Docker CE Stable - Sources baseurl=https://download.docker.com/linux/centos/7/source/stable enabled=0 gpgcheck=1 gpgkey=https://download.docker.com/linux/centos/gpg [docker-ce-edge] name=Docker CE Edge - $basearch baseurl=https://download.docker.com/linux/centos/7/$basearch/edge enabled=0 gpgcheck=1 gpgkey=https://download.docker.com/linux/centos/gpg [docker-ce-edge-debuginfo] name=Docker CE Edge - Debuginfo $basearch baseurl=https://download.docker.com/linux/centos/7/debug-$basearch/edge enabled=0 gpgcheck=1 gpgkey=https://download.docker.com/linux/centos/gpg [docker-ce-edge-source] name=Docker CE Edge - Sources baseurl=https://download.docker.com/linux/centos/7/source/edge enabled=0 gpgcheck=1 gpgkey=https://download.docker.com/linux/centos/gpg [docker-ce-test] name=Docker CE Test - $basearch baseurl=https://download.docker.com/linux/centos/7/$basearch/test enabled=0 gpgcheck=1 gpgkey=https://download.docker.com/linux/centos/gpg [docker-ce-test-debuginfo] name=Docker CE Test - Debuginfo $basearch baseurl=https://download.docker.com/linux/centos/7/debug-$basearch/test enabled=0 gpgcheck=1 gpgkey=https://download.docker.com/linux/centos/gpg [docker-ce-test-source] name=Docker CE Test - Sources baseurl=https://download.docker.com/linux/centos/7/source/test enabled=0 gpgcheck=1 gpgkey=https://download.docker.com/linux/centos/gpg 本机所使用的所有安装源如下：\n[root@centos7-temp]# yum repolist Loaded plugins: fastestmirror Loading mirror speeds from cached hostfile * base: mirrors.aliyun.com * epel: mirrors.aliyun.com * extras: mirrors.aliyun.com * updates: mirrors.aliyun.com repo id repo name status base/7/x86_64 CentOS-7 - Base - mirrors.aliyun.com 9,363 docker-ce-stable/x86_64 Docker CE Stable - x86_64 4 epel/x86_64 Extra Packages for Enterprise Linux 7 - x86_64 11,808 extras/7/x86_64 CentOS-7 - Extras - mirrors.aliyun.com 381 updates/7/x86_64 CentOS-7 - Updates - mirrors.aliyun.com 1,859 repolist: 23,415 安装docker引擎，并启动服务，并校验服务状态。安装过程参考如下：\n[root@centos7-temp]# yum install -y docker-ce [root@centos7-temp]# systemctl enable docker [root@centos7-temp]# systemctl start docker [root@centos7-temp]# systemctl status docker ● docker.service - Docker Application Container Engine Loaded: loaded (/usr/lib/systemd/system/docker.service; enabled; vendor preset: disabled) Active: active (running) since Tue 2017-06-20 20:30:49 CST; 19min ago Docs: https://docs.docker.com Main PID: 875 (dockerd) CGroup: /system.slice/docker.service ├─ 875 /usr/bin/dockerd ├─ 942 docker-containerd -l unix:///var/run/docker/libcontainerd/docker-containerd.sock --metrics-in... ├─2008 docker-containerd-shim 0ca2346b6126de702fb4dda5f807c0a69a402eb643f15c142730277d0eb7bbcb /var/... └─0ca2346b6126de702fb4dda5f807c0a69a402eb643f15c142730277d0eb7bbcb └─2038 /usr/bin/python /code/main.py --prism-ip 10.68.69.22 --dataservices-ip 10.68.69.23 --prism-... 到目前为止，Docker安装配置完成。\n下面开始安装DVP，安装和配置过程参考页面。\nhttps://store.docker.com/plugins/nutanix-dvp-docker-volume-plug-in\n下面是给操作系统安装iscsi initiator服务的参考步骤：\nyum install -y iscsi-initiator-utils systemd-tmpfiles --create systemctl start iscsid systemctl enable iscsid systemctl status iscsid ● iscsid.service - Open-iSCSI Loaded: loaded (/usr/lib/systemd/system/iscsid.service; enabled; vendor preset: disabled) Active: active (running) since Tue 2017-06-20 20:30:46 CST; 24min ago Docs: man:iscsid(8) man:iscsiadm(8) Main PID: 888 (iscsid) CGroup: /system.slice/iscsid.service ├─882 /usr/sbin/iscsid └─888 /usr/sbin/iscsid Jun 20 20:30:46 centos7-temp.zenlab.local systemd[1]: Starting Open-iSCSI... Jun 20 20:30:46 centos7-temp.zenlab.local iscsid[878]: iSCSI logger with pid=882 started! Jun 20 20:30:46 centos7-temp.zenlab.local systemd[1]: Failed to read PID from file /var/run/iscsid.pid: Inva...ent Jun 20 20:30:46 centos7-temp.zenlab.local systemd[1]: Started Open-iSCSI. Jun 20 20:30:47 centos7-temp.zenlab.local iscsid[882]: iSCSI daemon with pid=888 started! Hint: Some lines were ellipsized, use -l to show in full.  解释一下DVP的工作原理是，它是让Docker主机通过iSCSI协议连接Nutanix的存储服务。DVP插件的配置里包含了连接存储服务和存储容器（这个容器是Nutanix的存储术语，非Docker说的容器）的相关信息。这样Docker主机上用该卷插件建立的数据卷都会指向Nutanix后台的存储容器中；数据通过iSCSI协议连接Nutanix存储服务的时候，就可以利用到Nutanix群集提供的负载均衡能力；当数据块写入Nutanix存储池的过程中和之后，就可以利用到到Nutanix存储容器所具备的其它重要特性：数据块2~3副本的高可靠性、冷热数据分成、压缩、去重、纠删码等；而且存储空间对于容器或者Docker Swarm里的服务都是透明和无限容量的。\n 现在做一些安装DVP的准备工作，询问Nutanix系统管理员下面信息：\n 获得Prism 的IP 获得Nutanix群集数据服务的IP，这个IP是群集上的虚拟服务IP 获得群集的用户名和密码 新建一个测试存储容器，获得容器名  参考下面的DVP安装命令：\ndocker plugin install ntnx/nutanix_volume_plugin PRISM_IP=\u0026quot;10.68.69.22\u0026quot; DATASERVICES_IP=\u0026quot;10.68.69.23\u0026quot; PRISM_PASSWORD=\u0026quot;nutanix/4u\u0026quot; PRISM_USERNAME=\u0026quot;admin\u0026quot; DEFAULT_CONTAINER=\u0026quot;ddc-sc1\u0026quot; --alias nutanix 以上的命令执行结果如下：\n[root@centos7-temp]# docker plugin install ntnx/nutanix_volume_plugin PRISM_IP=\u0026quot;10.68.69.22\u0026quot; DATASERVICES_IP=\u0026quot;10.68.69.23\u0026quot; PRISM_PASSWORD=\u0026quot;nutanix/4u\u0026quot; PRISM_USERNAME=\u0026quot;admin\u0026quot; DEFAULT_CONTAINER=\u0026quot;ddc-sc1\u0026quot; --alias nutanix Plugin \u0026quot;ntnx/nutanix_volume_plugin\u0026quot; is requesting the following privileges: - network: [host] - mount: [/dev] - mount: [/lib/modules] - mount: [/etc/iscsi] - mount: [/var/lock/iscsi] - mount: [/proc] - allow-all-devices: [true] - capabilities: [CAP_SYS_ADMIN CAP_SYS_PTRACE CAP_IPC_LOCK CAP_IPC_OWNER CAP_NET_ADMIN CAP_MKNOD CAP_SYS_MODULE] Do you grant the above permissions? [y/N] y （输入y，按回车） latest: Pulling from ntnx/nutanix_volume_plugin be892c8cb64d: Download complete Digest: sha256:5a3730ffae077eb6ddc0c125620283d56852528b686cbe42f2f58696eab82c0d Status: Downloaded newer image for ntnx/nutanix_volume_plugin:latest Installed plugin ntnx/nutanix_volume_plugin 确认VDP安装结果，这个插件应该是最新版、启动的状态，如下：\n[root@centos7-temp]# docker plugin ls ID NAME DESCRIPTION ENABLED f0e38fbc11b3 nutanix:latest Nutanix volume plugin for docker true 执行下面的测试，确认DVP工作正常。\n[root@centos7-temp]# docker volume create testvol -d nutanix:latest testvol [root@centos7-temp]# docker volume ls DRIVER VOLUME NAME nutanix:latest testvol [root@centos7-temp]# 回到Nutanix的Prisum界面（主要的群集管理图形化界面）中查看Storage \u0026ndash;\u0026gt; table \u0026ndash;\u0026gt; Volume Group，应该能看到这个命令所创建的名为testvol的数据卷。如下图所示：\n在命令行删除这个测试的卷。\n[root@centos7-temp]# docker volume rm testvol testvol [root@centos7-temp]# docker volume ls DRIVER VOLUME NAME [root@centos7-temp]# 在回到Prisum界面中查看刚才看到的那个卷应该就消失了。到此为止所有节点的DVP部署配置工作就完毕了，并且确认docker服务和DVP功能都很正常。用 sys-unconfig 命令关机，把这个虚拟机在Prisum里面做一个快照备用，也可以在Nutanix的acli命令行里面把它做成一个基础镜像。\n我们已经理解和熟悉了DVP的基本操作，配置和部署，下面开始安装Docker Datacenter；Docker Datacenter的架构图如下所示： 本文安装的架构是：\n 一个 UCP manager 节点 一个 DTR 节点 两个 worker node 节点  在Nutanix的Prisum中用刚才制作的那个快照或者镜像模板，克隆/新建4个虚拟机。虚拟机的参考配置如下：\n 2 vCPU 4GB RAM 50GB Disk  安装UCP（Docker Universal Control Plane）节点 在Nutanix的Prisum中从刚才新建的四个虚拟机中选择一个，Power on开机；ssh登录到操作系统内之后，设定主机名和IP地址。\n安装配置参考文档：https://docs.docker.com/datacenter/ucp/2.1/guides/admin/install/install-offline/#download-the-offline-package\n注意事项，提前下载好安装包，这个tar包里面包含了UCP需要的所有镜像，可以一次性导入到UCP的节点上。\nwget https://packages.docker.com/caas/ucp_images_2.1.4.tar.gz -O docker-datacenter.tar.gz docker load \u0026lt; docker-datacenter.tar.gz 载入完毕后，可以看到如下镜像。\n[root@ucp-master ~]# docker images REPOSITORY TAG IMAGE ID CREATED SIZE docker/ucp-metrics 2.1.4 e3e24ef156bd 3 weeks ago 92.2 MB docker/ucp-swarm 2.1.4 d8b51d6801e5 3 weeks ago 21 MB docker/ucp-hrm 2.1.4 38a19323327d 3 weeks ago 14.8 MB docker/ucp-etcd 2.1.4 9aa382502e19 3 weeks ago 38.5 MB docker/ucp-controller 2.1.4 5a852aa3039e 3 weeks ago 28 MB docker/ucp-dsinfo 2.1.4 66ee9368796a 3 weeks ago 159 MB docker/ucp 2.1.4 7a28dbfc44e4 3 weeks ago 19.1 MB docker/ucp latest 7a28dbfc44e4 3 weeks ago 19.1 MB docker/ucp-cfssl 2.1.4 acdc1f147711 3 weeks ago 15.1 MB docker/ucp-compose 2.1.4 25775e989077 3 weeks ago 32.9 MB docker/ucp-auth-store 2.1.4 f27ad13dee6c 3 weeks ago 58.7 MB docker/ucp-agent 2.1.4 d716a096c331 3 weeks ago 22.5 MB docker/ucp-auth 2.1.4 1f4739cd3c08 3 weeks ago 25.1 MB [root@ucp-master ~]# 安装UCP的命令参考如下：\ndocker run --rm -it --name ucp \\ -v /var/run/docker.sock:/var/run/docker.sock \\ docker/ucp:2.1.4 install \\ --host-address 10.68.69.12 \\ --interactive 以上命令中10.68.69.12是UCP主机的ip地址，建议UCP使用固定IP。以上命令完毕后用浏览器访问这个IP。\n参考以下文档，完成UCP的安装步骤，其中需要到Docker网站获得30天的试用版许可证文件。\nhttps://docs.docker.com/datacenter/ucp/2.1/guides/admin/install/\n能够正常登陆访问UCP之后，在首页下方点击 【Add Node】按钮，获得加其它节点到群集里的命令，参考命令如下：\ndocker swarm join \\ --token SWMTKN-1-1310ah7gzj9e7bk6a5yobo2qyiwf93ybrd29flkved1zqydd6i-7pir0884sag5pjofwzjq5o1um \\ 10.68.69.12:2377 把以上命令记录在写字板中备用。\n加3个节点到群集里 把剩下的三个虚拟机开机，进入操作系统后设定主机名和IP。其中的一个安装DTR（Docker镜像仓库）的节点建议使用固定IP。\n在每个操作系统里面用docker命令确认DVP是否正常。\n docker plugin ls docker volume ls systemctl status iscsid  下面就可以把上一步所记录命令在命令行里面执行以下，完毕之后回到UCP的界面中查看是否它们已经添加成功。如下图所示： 安装DTR-Docker镜像仓库 在UCP首页的下方，找到并点击 【Install DTR】的按钮，取得安装命令（记得从清单中选择固定IP地址的DTR主机）；在登录DTR主机的控制台里面输入这个命令，命令如下：\ndocker run -it --rm \\ docker/dtr:2.2.5 install \\ --ucp-node 10.68.69.12 \\ --ucp-insecure-tls DTR节点没有离线安装的整合包，它需要联网下载很多相关镜像，如果网络速度不是很快的话，下载和安装的过程需要至少半个小时，过程中还需要输入UCP的管理员，用户名和密码。\n参考文档如： https://docs.docker.com/datacenter/dtr/2.2/guides/admin/install/#step-3-install-dtr\nDTR正常工作了以后，登录建立一个名为owncloud的镜像库，点击【New Rrepository】输入owncloud。 在一个节点上下载owncloud镜像，添加新的tag，上传到这个镜像到镜像库里备用。参考命令如下：\ndocker login dtr.zenlab.local docker pull owncloud docker tag owncloud:latest dtr.zenlab.local/admin/owncloud:latest docker push dtr.zenlab.local/admin/owncloud:latest 注意：如果你的环境中没有DNS，就把dtr.zenlab.local换成DTR的IP地址。\n以上这个步骤主要是方便以后，反复使用和测试这个镜像的可能性，如果所有的节点都有高速的互联网链接，可以忽略以上步骤。\nDocker Swarm群集中使用DVP 这里使用UCP的图形化界面，在一个所有节点都配置和部署了VDP的群集上，给群集挂载外部Nutanix的数据卷。\n登录UCP主页，点击Resource，点击Volumes，点击 【Create Volume】，输入相关参数，如下图所示。图中的sizeMb=500000这个参数是制定VolumeGroup的大小，不设定这个参数的话，默认是10GB。 在到Nutanix的Prism里面查看这个Volume Group是否存在。应该如下图所示：\n部署OwnCloud网盘服务 登录UCP主页，点击 Service ， 点击 【Create a Service】按钮；开始建立这个服务。输入服务名，镜像名；点击 【Next】按钮。\n点击 【Next】按钮。进入 Resource页面，这里需要配置端口和数据卷。 最后点击【Deploy Now】按钮。 部署完毕之后，显示这个服务的状态为正常。 点击这个服务，到这个页面的最下方，找到右下角的发布端口的链接，点击后，就可以看到ownCloud的初始化配置页面了。 输入管理员的用户名和密码，进入之后，上传一些图片，测试一下功能是否正常。\n尝试一些Docker Datacenter的高级功能，如服务的高可用性；同时Nutanix的DVP在底层保障了数据的持久性和完全性。测试步骤如下：\n 找到运行owncloud的容器，删除这个容器 在服务页面查看owncloud服务的状态变化 等ownCloud的状态恢复正常之后 再次登录ownCloud页面 查看和确认刚才上传的文件是否还在  总结 Nutanix是一种融合和了计算、存储和虚拟化（内置KVM）的超融合平台。Nutanix DVP (Docker Volume Plug-in)可以让平台里的容器用上持久化存储服务。DVP不仅可以给单独虚拟机里的容器提供持久卷服务，还能给类似于Docker Swarm的其它容器编排平台提供持久化数据服务功能。我后续的文章还会分享路测试Kubernetes等其它平台。\n",
    "ref": "/blog/nutanix-dvp/"
  },{
    "title": "Tips for Docker on Mac",
    "date": "",
    "description": "",
    "body": "Tips for Docker on Mac 在macOS上使用Docker很长时间了，本文总结一些我不想忘记的tips，方便自己反复使用的同时，也顺便总结分享一下，留下本文作为长期更新的备忘录。\n搭建私有镜像库 运行一个本地镜像库\n$ docker run -d -p 5000:5000 --restart=always --name registry registry:2 这条命令会从docker hub 下载 registry:2 镜像，在本机运行一个镜像库服务。\n下载一个测试用的镜像。\n$ docker pull ubuntu:16.04 给这个镜像打上私有镜像库的标签\n$ docker tag ubuntu:16.04 localhost:5000/ubuntu:16.04 push这个测试镜像到本地的镜像库\n$ docker push localhost:5000/ubuntu:16.04 这时候你会发现我的本地这样岂不是有了两份相同的镜像了，有这个必要么？是不是多余了？下面几个场景中会用到：\n当你用docker-machine在本机启动1个vm的时候，你运行任何docker run或者docker-compose up的时候你可能需要一个之前在本地就有的image，这是一种分享本机image给docker-machine vm的一种方式。\n当你用docker-machine在本机启动多个个vm的时候，你可能会把它们作出docker Swarm群集，当你在这个群集上启动一个服务的时候，docker compose文件中的镜像地址可以引用这个本地地址，引用地址类似这样 image: 192.168.99.1:5000/influxdb\n当你用 minikube start启动了一个minikube的vm的时候，你可能也需要本机的docker镜像，尤其是在你做demo的时候，这是最快的下载途径。 需要注意的是，以上三种情况都需要指定一下\u0026ndash;engine-insecure-registry 192.168.99.1:5000 这个参数。\n自动化创建Docker Swarm群集 在我的文件目录中存放着这个脚本\ncat create-swarm.sh docker-machine create manager --engine-insecure-registry 192.168.99.1:5000 docker-machine create agent1 --engine-insecure-registry 192.168.99.1:5000 docker-machine create agent2 --engine-insecure-registry 192.168.99.1:5000 docker-machine create agent3 --engine-insecure-registry 192.168.99.1:5000 eval `docker-machine env manager` docker swarm init --advertise-addr `docker-machine ip manager` docker-machine ssh agent1 docker swarm join --token `docker swarm join-token -q worker` `docker-machine ip manager`:2377 docker-machine ssh agent2 docker swarm join --token `docker swarm join-token -q worker` `docker-machine ip manager`:2377 docker-machine ssh agent3 docker swarm join --token `docker swarm join-token -q worker` `docker-machine ip manager`:2377 docker node ls 解释一下上面的代码：创建四个docker-machine vm，初始化swarm群集，把三个worker节点加入群集。这样四节点的群集就up and running了。\n清除以上群集虚拟机的命令如下：\ndocker-machine rm -y manager agent1 agent2 agent3 ",
    "ref": "/blog/tips-for-docker-on-mac/"
  },{
    "title": "关于DevOps 的那些事",
    "date": "",
    "description": "",
    "body": "DevOps是孕育于敏捷社区，又反哺给整个IT技术行业的，是一次彻底而全面的技术和文化运动。本文从它的出处谈起，一直描述到当前国内的现状。最后总结了相关的核心技术和主要实践。\nDevOps简史 在2008年多伦多举办的敏捷大会（Velocity Conf 2008 ）上，Patrick DeBois 和AndrewClay Shafer 先生首次提议讨论“敏捷基础架构”这个话题。在第二年的敏捷大会上有一个具有里程碑的意义技术分享，来自Flickr公司《每天部署10次》的分享，它激发了随后Patrick DeBios在同年十月，在比利时的根特市举办的首届DevOpsDays活动，这个活动是两天的日程，为了大家方便在twitter上的传播，人们把DevOpsDays这个词简写为 “#DevOps” 。 此后，“DevOps”一词问世了，这个词所包含的理念和实践一时在越来越广大的人群中产生了共鸣，随后成为全球IT界在各种大会和论坛里热议和讨论的焦点话题，很多大型IT论坛也都开设出了DevOps专题讨论。这就是DevOps这个词的由来。DevOpsDays活动随后在Patrick DeBios等相关核心发起人的推动下，在全球范围内蓬勃发展了起来。2010年在美国山景城(Mountain View) 举办的DevOpsDays 活动中，Damon Edwards先生使用“CAMS”这个缩写，高度概括和诠释了DevOps，即文化（Culture）、自动化（Automation）、度量（Measurement or Metrics）和分享（Sharing）。随后Jez Humble先生将“L”精益 (Lean) 原则也加入其中，最终变成了CALMS。\n Culture（文化）- 是指拥抱变革，促进协作和沟通 Automation（自动化）- 是指将人为干预的环节从价值链中消除 Lean（精益）- 是指通过使用精益原则促使高频率循环周期 Metrics（指标）- 是指衡量每一个环节，并通过数据来改进循环周期 Sharing（分享）- 是指与他人开放分享成功与失败的经验，并在错误中不断学习改进  “CALMS”完全吻合Patrick DeBois先生所一向倡导的“DevOps is a human problem” (DevOps 是关于人的问题) 的理念 。\nDevOpsDays活动的现状 从DevOps概念的产生，到如今它在全球范围内的蔓延和认同，已经经历了9个年头的时间。它的火爆推广也伴随着IT行业的迅速变迁和发展，现在已经到了移动互联网时代的后半场，国内的信息化建设已经完成了很多年；如今各行各业的企业也都亟待完成全方位的数字化转型。IT信息技术的先进程度标志着一个企业的核心能力，任何一个成功的企业，敏捷高效的软件开发创新实力和IT管理综合能力不只是门面而已，而是实实在在的市场竞争能力。DevOps倡导打敏捷、持续交付和ITIL三种实践的组合拳，同时应用精益生产理念为基础的管理思想，这正在逐渐地被广泛的接受和认可。\n在过去的几年中，国内的各种IT大会也蓬勃发展，其中DevOps相关的专题和分会场也颇受人们的关注。各种云计算、运维等IT技术的社交媒体也都非常重视DevOps这个话题的分享。一个专属于DevOps社群的、国际性的、有影响力的DevOps大会正呼之欲出。在这样的时代背景下DevOpsDays大会北京站在2017年的3月18日来到中国，在同年的8月18日上海，还要举办DevOpsDays Shanghai站的大会。\n下面列举一些DevOpsDays大会的相关数据，数据来源于DevOpsDays.org 网站。从2009年到2016年，已经在全球的61个城市/国家成功地举办了117场。\n下图是在过去九年中DevOpsDays大会在各个城市/国家的分布和举办次数。\n今年也就是2017年预计举办30场，其中已经有18场确定了举办城市和日期；还有12个城市的召开日期待定；这不包括年内还可能会提出申办的城市。以上数据的统计时间在2017年三月。\nDevOps在国内的现状 随着国内BAT等互联网巨头的崛起，互联网公司的开发运维经验也越来越多的在国内的各种技术大会上传播。从最近这两年（2016年和2017年）的技术活动日程中可以看出，国内互联网从业人员也不约而同的用DevOps来定位和分享自己的优势和经验。他们是传播和分享运维侧DevOps实践的先头部队。\n出了技术论坛的分享之外，很多线上线下的大会、论坛和讨论组也都越来越热议DevOps这一专题。国内其它相关流派的人群，例如敏捷和精益等，也对DevOps的蓬勃发展表示比较惊讶，DevOps与老牌的敏捷和精益等阵营也产生过一些争论。但这一切的发生也都增加了人们对于DevOps的更深入的兴趣。\n在培训认证这方面，Exin DevOps Master是一个国际认证的培训；其它公司和组织也正在举办关于DevOps工具链的培训，这些培训则注重于技术实操，关注在构建端到端的流水线的搭建方面。从DevOps的职位招聘方面，可以看到DevOps工程师相关的职位越来越多了，在职位需求中DevOps这个技能成了加分项，DevOps相关工具的技能也或将成为简历的亮点。在IT行业内不管是开发还是运维团队的人，都开始了学习和接受的过程。\n据我观察DevOps方面的厂商在最近3年呈现爆炸式的发展。我把他们分为三类：\n 搭顺风车型：主要是指所有CaaS容器云平台厂商 。Docker是它是在DevOps的时代背景下产生的，是DevOps技术工具集里不可缺少的一员。国内这些厂商目前的数量在20左右，数目趋于稳定。由于今年（2017）Docker公司商业化版本和开源版本正式的划分开来，这些公司的发展可能或多或少受到一些影响。 直奔主题型：这类厂商专注于开发端到端的、用户体验良好的DevOps流水线平台，这些公司的创始人团队多是来自于BAT公司，因此具有很好的DevOps实战经验，他们开发的产品在持续交付和流水线功能上恰好填补了当前企业在这个方面的工具和技术实践的缺位。目前这类公司的数量还不多，数量呈上升趋势。 BATH型：BAT大家都知道，这里的H指的是华为，这些企业在DevOps平台方面都表现出积极的技术输出的态势。BAT是基于过去的互联网运维的经验做DevOps的产品化。华为是成了独立的研发部门，招募业内这方面的精英前来助阵，打造出一方面可以自用，同时也可以商品化的DevOps产品。  目前国内大部分企业慢慢地开始关注了DevOps，大型传统企业也开始逐渐地从各个角度做试点和尝试。试点的角度和方向各不相同，有的从底层基础架构的容器化开始，有的从交付部署流水线的自动化开始；总的来说还处于初级的尝试阶段，还没有大规模成体系的推广。\n综上所述，目前国内DevOps发展的阶段还属于起步阶段。就像是ITIL/ITSM在2003年左右的状态。由于DevOps是去中心化的，所以没有唯一、权威的上游厂商的存在，各种理论实践的争执和PK都将终止与解决问题和提高效率的话题上，因此它具有百花齐放百家争鸣的发展条件。个人认为DevOps的实施和落地也不会完全依赖于传统的大型咨询厂商的咨询工作，由于它应该是在企业的内部，在内驱的作用下，自生长出来的；它必须是服务于企业的业务价值流的优化，加速业务价值产出的；而与之相关的工作和责任的担当，外部力量是很难以等量替换和承担的。\n核心技术和工具 在谈这个话题前先看一下DevOps相关工具集的全貌，如下图所示：\n最上面的箭头流程图表示了一个业务服务的全生命周期：开发协作、软件构建、质量测试、交付部署和投产运维。前三个阶段偏传统开发组织的工作内容，后两个阶段基本可以和运维组织的工作对应上。在每个阶段下可以看成是一个大分类，这些分类中还包含若干个小分类。这些工具可以粗放的划分为商业软件和开源软件两类；也可以分为SaaS服务类和企业内部部署型。大部分开源工具都有活跃的用户社区和群众基础，这给企业入手这些工具带来了很大的便利。在需要商业支持的场景里还可以选择使用这些开源软件的企业版。\nDocker容器技术在最近三年中异军突起，持续交付的技术门槛因此被降到最低，软件生产供应链的格局和效率被彻底提升；基于Docker的微服务架构实践的热度和成熟度也与日俱增。因此，国内的传统企业纷纷试水DevOps和容器技术，在最近两年的各种技术大会中，我们可以看到国内各个行业出现了在不同维度上的DevOps先行者。他们分享的主题大多集中在自动化运维、容器化和PaaS平台的等项目经验。\n从国内众多DevOps实践中，我们能看到下面三个技术尤其重要和火热：\n 容器：容器从根本上解决了软件对环境的依懒性，解决了各个环境之间的差异问题；它可以加速部署的速度，提高部署的效率；降低部署的成本。容器技术是在Linux的基础之上发展起来的，因此它本身的实施成本很低，就是在任何物理机和虚拟机的Linux操作系统上安装Docker服务（仅几十兆）就可以完成所有功能。在任何环境中实施Docker需要考虑好以下几个因素：主机的计算资源特性和容器允许的资源需求相匹配（计算密集型、内存密集型、IO密集型等）；容器网络类型和服务路由的选型；容器镜像仓库的选择等。 持续部署：这是所有企业普遍的短板，需要设计统一的自动化部署流水线作为软件系统部署和更新的基础设施。持续部署流水线底层是有Jenkins之类的工具来完成的，它能实现快速的、可重复使用的、适用于不同部署环境的发布流水线。所有服务都可以通过它实现各种风格的发布；这些发布风格中比较重要的两种：蓝绿部署和灰度发布。 微服务：为了解决传统软件所特有的单体应用的缺陷，用微服务的思路，全面地重构巨石应用，全面的在新系统中应用这种架构。微服务架构是容器技术出现之后，有迅猛发展的一项软件架构技术。它的松耦合和面向服务基础架构的特性都是现代软件和数据中心必备的特质。\n以上三种技术相辅相成，有着比较深刻的关联。首先微服务和持续部署各自解决了特别多的传统IT的问题，这些问题都是长期以来制约企业业务发展的难题。容器技术由于它的快速、轻量、微服务化的天然特性，很好的从不同侧面支持了持续交付和微服务架构。容器可以为持续交付提供弹性和高速的系统资源，环境管理和利用率提高了很多；容器的不可变性的特点也更好地支持了微服务架构。  我把DevOps的按照不同的技术特征做了从到1.0 到2.0的时代划分，并尽量通过以下维度比较与传统方式的差异。\n总结 我比较认可和接受的企业实践DevOps参考框架如下，其中包含了所需的最佳实践，如下图所示。\n（上图来源于：Exin DevOps白皮书）\n下面简要描述一下这四大支柱型最佳实践\n 敏捷管理：在产品的计划、需求、设计和开发阶段主要采用敏捷开发方法论。在这些阶段中DevOps强调，设置合理的任务大小，从而确保能够开展快速迭代和开发；强调持续集成的实施，通过CI提高软件的质量和可用性；强调用更短的发布周期，增强反馈的数量和频度。 持续交付：在开发和部署运营阶段采用持续交付的方法自动化软件系统的发布、变更和升级等工作。DevOps强调使用持续交付工具作为基础架构尽可能的自动化手工部署工作。在研发阶段就开始设计部署自动化的脚本，对其使用流水线工具来操作执行，并辅助自动化测试工具。通过严密的自动化测试方案，确保实现可以重复使用的自动化部署流水线。通过它的反复运作，提高部署的效率，降低部署的风险，提高部署的质量。 ITSM服务管理：DevOps强调从传统的ITSM管理理念上升到关注业务持续性的轻量ITSM管理方法。运维人员在项目的早期要和开发、测试和部署人员充分地沟通和落实运维需求。确保在业务系统开发的初期，系统的业务持续性和可运维性等非功能性需求，都得到充分的落实和满足。 精益管理：业务开发运维的整个生命周期中，以上三类工作实践的所有工作活动中，都必须坚持贯彻精益的原则。DevOps特别强调的点包括：准时制业务流程、精益且无浪费的工作方法、单件流的运作流程、持续改进等。它的这些管理思路需要严格的落实到所有工作环节中。  由此可见DevOps在企业，特别是大规模传统企业的落地和推广还是比较复杂的。虽然相关的最佳实践都是已经存在了很多年的；但是，通过DevOps的价值观重构企业从研发到交付到运维的价值流谈何容易。基于我的IT从业经验，我似乎感觉到DevOps不能单独依靠自顶向下的推广，当然高层领导的支持依然是重要的和必备的支持条件之一。 可能还需要中层的带动和底层的创新；借鉴生产制造业已经久经考验的精益制造实践也是势在必行。总之DevOps运动会在近几年给IT行业带来较大影响。\n",
    "ref": "/blog/something-you-must-know-about-devops/"
  },{
    "title": "切换到Ghost+七牛",
    "date": "",
    "description": "",
    "body": "在经历了一个很长的周期之后，我的blog又回到了最原始的状态。很早以前学习网页开发的时候，用写字板编写html代码，后来是Asp，工作以后是用Blogspot，之后是WordPress，然后是Jekyll+github，现在是Ghost+七牛。\n4个拐点\n我的blog经历了四个转折点，下面稍微说下，为啥选择了某个平台，为啥后来又放弃了。\n  免费博客平台：最初我试用了几个国内外免费的服务，最后发现Blogspot的体验要优于其他所有平台，而且具备一定的定制能力，还没有广告。然后就一直用到了Blogspot被墙的时候，那时候我还没有买域名。记得MSN的Space也用过，如果你没有用过MSN的话，当我没说这句话。总之免费blog空间的弊端就是，你码的字和图片是给别人的，不属于你自己，没有延续性。    WordPress：是我用的时间最长的平台，它的好处是可以host在任何php虚拟空间和云主机上；优势就是功能强。曾经浪花费了大量的时间，在测试和感受各种插件和皮肤上。而且WP的搬家工作也容易，因此换了很多个空间，一共有多少个主机空间现在已经都忘了。放弃WP的原因：维护LAMP堆栈的工作量还是有的，即使在PHP的虚拟空间里，这个系统的优化工作还是持续不断的要做的，否则网站速度会很慢，而且时快时慢，网站的访问性能其实无法保证。因此在这个过程中必须使用CDN服务，七牛的wp插件是我用的最长时间的，因此我早期的blog的图片都在七牛上，它给我了一个备份和加速图片的福利。性能不稳定，页面打开速度慢是放弃它的主要原因。    Jekyll+GitHub：选择这个组合，开始于我重度使用Github的时候。而且macOS上安装Jekyll这种静态blog程序很方便，捣鼓起来之后，就感觉比WP方便简单直接多了。发现这个方式非常轻量和简洁。而且Github.io的免费静态网站host服务还支持自定义域名。因此，我做了把之前所有WP的文章导出为MD格式文档的数据迁移工作。由于之前WP文章里的图，已近都存放在七牛里了，因此这次我做了一个出乎意料敏捷轻松的转身。使用过程中，逐渐发现了Jekyll的各种不足，界面和格式的定制工作还是有的，即使用几十刀买的皮肤都会让你用到难以忍受，毕竟不是想developer那样天天写代码，也逐渐感到Jekyll的简洁变成了简陋。代码定制的工作量和难度大是放弃它的主要原因。    Ghost+七牛：其实早就瞄上Ghost了，可是一种没有下决心换。直到最近我开始把Ghost安装在Mac OS的笔记本电脑上，发现在本机编辑和维护文章资料，速度飞快，和以前WP在线编辑简直是天壤之别。如果Ghost应用跑在自己的笔记本电脑上的话，既可以离线工作，像之前用Jekyll+Github组合一样，也更可以不需要购买任何虚拟主机和空间了，在本机离线工作的速度和效率好，而且稳定太多了。 buster这个程序是这次切换到Ghost的催化剂，它可以把Ghost网站的全站导出成静态文件，线上就只需要一个CDN空间了。七牛的qshell工具可以方便地把本地的静态网站文件夹，同步到CDN的buckte存储中。切换到这个方案的原因是：网站变为纯静态网页，全站html/css和图片全面上CDN，配置全球加速网站域名，享用七牛的免费套餐。    下面花一点篇幅介绍一下目前的blog环境细节。简单地说：目前是在笔记本上跑Ghost服务器，这样就省去了云主机和虚拟主机空间的需求，把ghost的站点导出为静态网页和图片，然后增量地上传到七牛的CDN上去。 Ghost本地安装\n我的操作系统是MacOS，用的是2017款MBP。\n先安装node.js，进入https://nodejs.org/en/ 在网站的首页上就可以下载到安装包，下载安装即可。也可以用 brew 安装。安装完了以后就获得了 npm 包管理程序。\n之后参考https://docs.ghost.org/v1.0.0/docs/install#pre-requisites 的文档安装 ghost-cli ； 然后用ghost的命令行来实现ghost程序的安装和升级。\n用ghost-cli安装ghost服务器的时候，要选择local的方式，它会使用sqllite作为数据库，这样做管理和维护Ghost应用栈的工作就都在本地了。\nghost服务器的初始化 ghost install local 这个命令会问你几个问题，全都用默认即可。安装完之后就可以看到服务器运行的状态了。\nmartin@mbp ghost status Process manager 'systemd' will not run on this system, defaulting to 'local' │ Name │ Location │ Version │ Status │ URL │ Port │ Process Manager │ │ localhost │ ~/source/ghost │ 1.8.7 │ running (production) │ http://martinliu.cn/ │ 2368 │ systemd │ 这样就表明本地安装成功，访问 http://martinliu.cn/ghost 建立管理员账户，登录以后，就可以在本地编辑和维护blog文章了。 Buster安装和使用\nBuster的安装也很简单，网上有很多安装使用攻略，此处忽略。我用下面的命令来把Ghost网站做导出：\nbuster generate --new-domain=martinliu.cn 在ghost的根目录下运行这个命令，就可以把本地的ghost网站都导出到一个名为static的目录里。可以直接在这个目录里打开这些html纯静态的网页，可以浏览和验证格式是否正常，一般不需要这样做，格式一般不会出错的。 配置七牛CDN\n七牛提供了本地的qshell，用于上传和同步文件到云端的存储里。安装过程文档见 https://github.com/qiniu/qshell\n我在ghost的根目录下，编辑了一个上传网站的配置文件upload.conf，内容如下：\n{ \u0026quot;src_dir\u0026quot; : \u0026quot;/Users/martin/source/ghost/static\u0026quot;, \u0026quot;access_key\u0026quot; : \u0026quot;XXXXXXXkAA9TYrcDmQPBAAcB7\u0026quot;, \u0026quot;secret_key\u0026quot; : \u0026quot;XXXXXXXXXXXXXXXXXXXXXndwt\u0026quot;, \u0026quot;bucket\u0026quot; : \u0026quot;martinliu-cn\u0026quot;， \u0026quot;ignore_dir\u0026quot; : false, \u0026quot;overwrite\u0026quot; : true, \u0026quot;check_exists\u0026quot; : true, \u0026quot;check_hash\u0026quot; : true, \u0026quot;rescan_local\u0026quot; : true, \u0026quot;log_file\u0026quot; : \u0026quot;./upload.log\u0026quot;, \u0026quot;log_level\u0026quot; : \u0026quot;info\u0026quot;, \u0026quot;log_rotate\u0026quot; : 1, \u0026quot;log_stdout\u0026quot; : true, \u0026quot;file_type\u0026quot; : 0 } 以上这个配置很重要，它的目的是实现：\n  增量上传    修改的文件覆盖上传    感谢七牛的工程师茅工，在我调试以上需求的时候，给我提供了及时的帮助。而且七牛的免费账户也可以开工单获取技术支持，支持的响应速度还不错。\n这样执行 qshell qupload 10 upload.conf 既可以完成一次上传同步工作，这个步骤是唯一需要在线操作的步骤。这条命令的输出结果如下：\n2017/09/25 00:00:21 [I] File `tag/cloud/index.html` exists in bucket, hash match, ignore this upload Uploading /Users/martin/source/ghost/static/tag/coding/index.html =\u0026gt; tag/coding/index.html [113/119, 95.0%] ... 2017/09/25 00:00:21 [I] File `tag/coding/index.html` exists in bucket, hash match, ignore this upload Uploading /Users/martin/source/ghost/static/tag/devops/index.html =\u0026gt; tag/devops/index.html [114/119, 95.8%] ... 2017/09/25 00:00:21 [I] File `tag/devops/index.html` exists in bucket, hash match, ignore this upload Uploading /Users/martin/source/ghost/static/tag/getting-started/index.html =\u0026gt; tag/getting-started/index.html [115/119, 96.6%] ... 2017/09/25 00:00:21 [I] File `tag/getting-started/index.html` exists in bucket, hash match, ignore this upload Uploading /Users/martin/source/ghost/static/tag/journey/index.html =\u0026gt; tag/journey/index.html [116/119, 97.5%] ... 2017/09/25 00:00:21 [I] File `tag/journey/index.html` exists in bucket, hash match, ignore this upload Uploading /Users/martin/source/ghost/static/tag/opensource/index.html =\u0026gt; tag/opensource/index.html [117/119, 98.3%] ... 2017/09/25 00:00:21 [I] File `tag/opensource/index.html` exists in bucket, hash match, ignore this upload Uploading /Users/martin/source/ghost/static/tag/running/index.html =\u0026gt; tag/running/index.html [118/119, 99.2%] ... 2017/09/25 00:00:22 [I] File `tag/running/index.html` exists in bucket, hash match, ignore this upload Uploading /Users/martin/source/ghost/static/test.html =\u0026gt; test.html [119/119, 100.0%] ... 2017/09/25 00:00:22 [I] File `test.html` exists in bucket, hash match, ignore this upload 2017/09/25 00:00:22 [I] -------------Upload Result-------------- 2017/09/25 00:00:22 [I] Total: 119 2017/09/25 00:00:22 [I] Success: 0 2017/09/25 00:00:22 [I] Failure: 0 2017/09/25 00:00:22 [I] NotOverwrite: 0 2017/09/25 00:00:22 [I] Skipped: 119 2017/09/25 00:00:22 [I] Duration: 36.533056019s 2017/09/25 00:00:22 [I] ---------------------------------------- See upload log at path ./upload.log 七牛的域名配置如下图所示： Blog工作流 下面就是我目前的blog工作流程说明。\n  启动本地的ghost服务器，开始编辑和维护blog文章，如新写一篇blog；其实我也根本就不关这个服务器，感觉它也没有什么消耗。这样的话飞机上的无聊时间，可以彻底得到充分利用了。    在本地发布和预览blog文章和内容，修订并定稿。    运行Buster命令导出全站文章到本地。    在想更新上线新内容的时候，在联网的情况下，运行qshell上传同步命令，把本地static文件夹和七牛上的存储bucket同步一下。    至此我完成了从动态blog到纯静态blog的转型，现在网页html和图片文件全都在七牛的CDN里，而且域名 martinliu.cn 的访问配置成了全球加速。\n目前使用的是七牛的免费流量和空间套餐，套餐内的各种数量限制如下。\n目前的疑问是这个免费套餐是否够用，不知道这个羊毛多久会被我薅完。我会定期在本文跟新以上解决方案，在使用期间的各种配置细节变更，或者遇到的问题和解决方法。\nTO-Do\n把static变成一个git库，以后配置Jenkins，基于它的变化，自动化触发后续的更新和上传动作 在上传前运行htlm和css文件的压缩工具（命令行执行），优化页面尺寸 在上传前运行图片的压缩工具（命令行执行），优化图片尺寸 在Ghost里加入评论功能 加入Google网站统计代码 测试Ghost网站备份和迁移过程，保证当前的ghost服务器崩溃了，数据不会丢失  ",
    "ref": "/blog/welcome-to-ghost/"
  },{
    "title": "用Minikube体验单节点K8S",
    "date": "",
    "description": "",
    "body": "Minikube为各种操作系统的开发者，提供了运行K8S最简洁的方式。它最小化了安装k8s的需求和工作量。而且在各种操作系统上可以实现相同的体验。本文用精简的语言，描述了从安装minikube到运行容器化应用的过程。主要命令和输出来自macOS。\n安装Hypervisor 需要在任何笔记本或者工作上安装一个Hypervisor，因此首先你需要坚持电脑的CPU是否开启了虚拟化的支持，检查BIOS的VT-X或者AMD-v的配置。\n OS X，安装 xhyve driver, VirtualBox 或 VMware Fusion Linux， 安装 VirtualBox 或 KVM Windows， 安装 VirtualBox or Hyper-V  Minikube会生成一个虚拟机，用于运行一个安装和部署好的k8s单节点系统。\n安装kubectl kubectl是k8s系统的管理工具，是一个命令行工具，它用于和master交互，完成群集和服务的管理等工作。\nkubectl的安装文档： https://kubernetes.io/docs/tasks/tools/install-kubectl/\n在macOS上最简单的安装方法是下面这条命令：\nbrew install kubectl  brew的好处是后续可以帮忙持续的升级。\n其它非brew安装方法，见以上安装文档的 Install kubectl binary via curl 部分。\n安装 minikube 在macOS上使用的默认的Hypervisor是VirtualBox，如果想要用xhyve需要在启动的时候加上参数 --vm-driver=xhyve\n安装最新版本的 minikube 需要参考这个网页 https://github.com/kubernetes/minikube/releases\nminikube 是一个命令行工具，它的命令行参数如下：\nMinikube is a CLI tool that provisions and manages single-node Kubernetes clusters optimized for development workflows. Usage: minikube [command]\nAvailable Commands: addons Modify minikube\u0026rsquo;s kubernetes addons completion Outputs minikube shell completion for the given shell (bash) config Modify minikube config dashboard Opens/displays the kubernetes dashboard URL for your local cluster delete Deletes a local kubernetes cluster docker-env Sets up docker env variables; similar to \u0026lsquo;$(docker-machine env)\u0026rsquo; get-k8s-versions Gets the list of available kubernetes versions available for minikube ip Retrieves the IP address of the running cluster logs Gets the logs of the running localkube instance, used for debugging minikube, not user code mount Mounts the specified directory into minikube profile Profile sets the current minikube profile service Gets the kubernetes URL(s) for the specified service in your local cluster ssh Log into or run a command on a machine with SSH; similar to \u0026lsquo;docker-machine ssh\u0026rsquo; ssh-key Retrieve the ssh identity key path of the specified cluster start Starts a local kubernetes cluster status Gets the status of a local kubernetes cluster stop Stops a running local kubernetes cluster update-context Verify the IP address of the running cluster in kubeconfig. version Print the version of minikube\nFlags: \u0026ndash;alsologtostderr log to standard error as well as files -b, \u0026ndash;bootstrapper string The name of the cluster bootstrapper that will set up the kubernetes cluster. (default \u0026ldquo;localkube\u0026rdquo;) -h, \u0026ndash;help help for minikube \u0026ndash;log_backtrace_at traceLocation when logging hits line file:N, emit a stack trace (default :0) \u0026ndash;log_dir string If non-empty, write log files in this directory \u0026ndash;loglevel int Log level (0 = DEBUG, 5 = FATAL) (default 1) \u0026ndash;logtostderr log to standard error instead of files -p, \u0026ndash;profile string The name of the minikube VM being used. This can be modified to allow for multiple minikube instances to be run independently (default \u0026ldquo;minikube\u0026rdquo;) \u0026ndash;stderrthreshold severity logs at or above this threshold go to stderr (default 2) -v, \u0026ndash;v Level log level for V logs \u0026ndash;vmodule moduleSpec comma-separated list of pattern=N settings for file-filtered logging\nUse \u0026ldquo;minikube [command] \u0026ndash;help\u0026rdquo; for more information about a command. \nminikube 就是一个命令行工具，就是一个可执行文件。在macOS上也可以用brew安装，安装命令如下：\nbrew cask install minikube  minikube 的快速参考文档在这里： https://github.com/kubernetes/minikube/blob/v0.22.2/README.md\n启动minikube 虚拟化的Hypervisor和kubctl就绪了以后，就可以启动minikube了，命令如下：\nminikube start Starting local Kubernetes v1.7.5 cluster\u0026hellip; Starting VM\u0026hellip; Getting VM IP address\u0026hellip; Moving files into cluster\u0026hellip; Setting up certs\u0026hellip; Connecting to cluster\u0026hellip; Setting up kubeconfig\u0026hellip; Starting cluster components\u0026hellip; Kubectl is now configured to use the cluster. \n启动以后随时都可以用下面这个命令检查minikube的状态。\nminikube status  停止minikube服务，也就是关机那个start命令创建的虚拟机。\nminikube stop  访问和使用minikube minikube ssh 登录到minikube的虚拟机里的命令就是ssh，进去之后，查看一下docker镜像。\nminikube ssh ## . ## ## ## == ## ## ## ## ## === /\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\\___/ === ~~~ {~~ ~~~~ ~~~ ~~~~ ~~~ ~ / ===- ~~~ \\______ o __/ \\ \\ __/ \\____\\_______/ _ _ ____ _ _ | |__ ___ ___ | |_|___ \\ __| | ___ ___| | _____ _ __ | '_ \\ / _ \\ / _ \\| __| __) / _` |/ _ \\ / __| |/ / _ \\ '__| | |_) | (_) | (_) | |_ / __/ (_| | (_) | (__| \u0026lt; __/ | |_.__/ \\___/ \\___/ \\__|_____\\__,_|\\___/ \\___|_|\\_\\___|_| Boot2Docker version 1.11.1, build master : 901340f - Fri Jul 1 22:52:19 UTC 2016 Docker version 1.11.1, build 5604cbe docker@minikube:~$ docker images REPOSITORY TAG IMAGE ID CREATED SIZE nginx latest da5939581ac8 9 days ago 108.3 MB gcr.io/google_containers/kubernetes-dashboard-amd64 v1.6.3 691a82db1ecd 8 weeks ago 139 MB \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; 2f7f7bce8929 11 weeks ago 107.5 MB gcr.io/google_containers/k8s-dns-sidecar-amd64 1.14.4 38bac66034a6 12 weeks ago 41.82 MB gcr.io/google_containers/k8s-dns-kube-dns-amd64 1.14.4 a8e00546bcf3 12 weeks ago 49.39 MB gcr.io/google_containers/k8s-dns-dnsmasq-nanny-amd64 1.14.4 f7f45b9cb733 12 weeks ago 41.42 MB gcr.io/google-containers/kube-addon-manager v6.4-beta.2 0a951668696f 3 months ago 79.24 MB gcr.io/google_containers/kubernetes-dashboard-amd64 v1.5.0 e5133bac8024 9 months ago 88.9 MB gcr.io/google-containers/kube-addon-manager v6.1 59e1315aa5ff 9 months ago 59.37 MB gcr.io/google_containers/kubedns-amd64 1.8 597a45ef55ec 11 months ago 57.89 MB gcr.io/google_containers/kube-dnsmasq-amd64 1.4 3ec65756a89b 11 months ago 5.13 MB gcr.io/google_containers/exechealthz-amd64 1.2 93a43bfb39bf 12 months ago 8.375 MB gcr.io/google_containers/echoserver 1.4 a90209bb39e3 16 months ago 140.4 MB gcr.io/google_containers/pause-amd64 3.0 99e59f495ffa 16 months ago 746.9 kB docker@minikube:~$ docker ps  以上的命令输出中，镜像的名称是以 gcr.io/google_containers/ 就都是属于k8s的系统容器，k8s的系统服务就都是这些docker容器提供的服务。\n用docker ps命令可以看到当前这个虚拟机正在运行的容器。\nkubectl run kubectl run 命令是用来运行一个docker镜像的，还可以制定在k8s群集中运行几个某镜像的容器。可以创建一个部署或者作业，用它们来管理容器的创建。包括在一个部署或者作业中，运行某个docker镜像的，容器数量，环境变量参数，开放的端口，启动的参数等等。看下面的这个实例。\n$ kubectl run hello-minikube --image=gcr.io/google_containers/echoserver:1.4 --port=8080 deployment \"hello-minikube\" created $ kubectl expose deployment hello-minikube --type=NodePort service \"hello-minikube\" exposed We have now launched an echoserver pod but we have to wait until the pod is up before curling/accessing it via the exposed service. To check whether the pod is up and running we can use the following: $ kubectl get pod NAME READY STATUS RESTARTS AGE hello-minikube-3383150820-vctvh 1/1 ContainerCreating 0 3s\nWe can see that the pod is still being created from the ContainerCreating status $ kubectl get pod NAME READY STATUS RESTARTS AGE hello-minikube-3383150820-vctvh 1/1 Running 0 13s\nWe can see that the pod is now Running and we will now be able to curl it: $ curl $(minikube service hello-minikube \u0026ndash;url) CLIENT VALUES: client_address=172.17.0.2 command=GET real path=/ query=nil request_version=1.1 request_uri=http://192.168.99.100:8080/\nSERVER VALUES: server_version=nginx: 1.10.0 - lua: 10001\nHEADERS RECEIVED: accept=/ host=192.168.99.100:31721 user-agent=curl/7.54.0 BODY: -no body in request-% \n命令含义简介：\n kubectl expose 在一个特定的端口上，把一个资源暴露为k8s的一个服务，这个资源可以是一个部署、副本集。可能的资源包括：pod (po), service (svc), replicationcontroller (rc), deployment (deploy), replicaset (rs) kubectl get 显示/查看一个或者多个资源的信息。 minikube service 获取本地k8s群集里某个特定服务的服务地址URL  访问API服务器 访问k8s的重要组件API服务器，访问的方法是：用kubectl先得到一个 Bearer Token 的访问令牌，用这个令牌访问API服务器的服务网址，下面的例子使用curl当api访问的客户端。\n$ TOKEN=$(kubectl describe secret $(kubectl get secrets | grep default | cut -f1 -d ' ') | grep -E '^token' | cut -f2 -d':' | tr -d '\\t') $ APISERVER=$(kubectl config view | grep https | cut -f 2- -d \u0026ldquo;:\u0026rdquo; | tr -d \u0026quot; \u0026ldquo;)\n$ curl $APISERVER \u0026ndash;header \u0026ldquo;Authorization: Bearer $TOKEN\u0026rdquo; \u0026ndash;insecure { \u0026ldquo;paths\u0026rdquo;: [ \u0026ldquo;/api\u0026rdquo;, \u0026ldquo;/api/v1\u0026rdquo;, \u0026ldquo;/apis\u0026rdquo;, \u0026ldquo;/apis/\u0026rdquo;, \u0026ldquo;/apis/admissionregistration.k8s.io\u0026rdquo;, \u0026ldquo;/apis/admissionregistration.k8s.io/v1alpha1\u0026rdquo;, \u0026ldquo;/apis/apiextensions.k8s.io\u0026rdquo;, \u0026ldquo;/apis/apiextensions.k8s.io/v1beta1\u0026rdquo;, \u0026ldquo;/apis/apiregistration.k8s.io\u0026rdquo;, \u0026ldquo;/apis/apiregistration.k8s.io/v1beta1\u0026rdquo;, \u0026ldquo;/apis/apps\u0026rdquo;, \u0026ldquo;/apis/apps/v1beta1\u0026rdquo;, \u0026ldquo;/apis/authentication.k8s.io\u0026rdquo;, \u0026ldquo;/apis/authentication.k8s.io/v1\u0026rdquo;, \u0026ldquo;/apis/authentication.k8s.io/v1beta1\u0026rdquo;, \u0026ldquo;/apis/authorization.k8s.io\u0026rdquo;, \u0026ldquo;/apis/authorization.k8s.io/v1\u0026rdquo;, \u0026ldquo;/apis/authorization.k8s.io/v1beta1\u0026rdquo;, \u0026ldquo;/apis/autoscaling\u0026rdquo;, \u0026ldquo;/apis/autoscaling/v1\u0026rdquo;, \u0026ldquo;/apis/autoscaling/v2alpha1\u0026rdquo;, \u0026ldquo;/apis/batch\u0026rdquo;, \u0026ldquo;/apis/batch/v1\u0026rdquo;, \u0026ldquo;/apis/batch/v2alpha1\u0026rdquo;, \u0026ldquo;/apis/certificates.k8s.io\u0026rdquo;, \u0026ldquo;/apis/certificates.k8s.io/v1beta1\u0026rdquo;, \u0026ldquo;/apis/extensions\u0026rdquo;, \u0026ldquo;/apis/extensions/v1beta1\u0026rdquo;, \u0026ldquo;/apis/networking.k8s.io\u0026rdquo;, \u0026ldquo;/apis/networking.k8s.io/v1\u0026rdquo;, \u0026ldquo;/apis/policy\u0026rdquo;, \u0026ldquo;/apis/policy/v1beta1\u0026rdquo;, \u0026ldquo;/apis/rbac.authorization.k8s.io\u0026rdquo;, \u0026ldquo;/apis/rbac.authorization.k8s.io/v1alpha1\u0026rdquo;, \u0026ldquo;/apis/rbac.authorization.k8s.io/v1beta1\u0026rdquo;, \u0026ldquo;/apis/settings.k8s.io\u0026rdquo;, \u0026ldquo;/apis/settings.k8s.io/v1alpha1\u0026rdquo;, \u0026ldquo;/apis/storage.k8s.io\u0026rdquo;, \u0026ldquo;/apis/storage.k8s.io/v1\u0026rdquo;, \u0026ldquo;/apis/storage.k8s.io/v1beta1\u0026rdquo;, \u0026ldquo;/healthz\u0026rdquo;, \u0026ldquo;/healthz/autoregister-completion\u0026rdquo;, \u0026ldquo;/healthz/ping\u0026rdquo;, \u0026ldquo;/healthz/poststarthook/apiservice-registration-controller\u0026rdquo;, \u0026ldquo;/healthz/poststarthook/apiservice-status-available-controller\u0026rdquo;, \u0026ldquo;/healthz/poststarthook/bootstrap-controller\u0026rdquo;, \u0026ldquo;/healthz/poststarthook/ca-registration\u0026rdquo;, \u0026ldquo;/healthz/poststarthook/extensions/third-party-resources\u0026rdquo;, \u0026ldquo;/healthz/poststarthook/generic-apiserver-start-informers\u0026rdquo;, \u0026ldquo;/healthz/poststarthook/kube-apiserver-autoregistration\u0026rdquo;, \u0026ldquo;/healthz/poststarthook/start-apiextensions-controllers\u0026rdquo;, \u0026ldquo;/healthz/poststarthook/start-apiextensions-informers\u0026rdquo;, \u0026ldquo;/healthz/poststarthook/start-kube-aggregator-informers\u0026rdquo;, \u0026ldquo;/healthz/poststarthook/start-kube-apiserver-informers\u0026rdquo;, \u0026ldquo;/logs\u0026rdquo;, \u0026ldquo;/metrics\u0026rdquo;, \u0026ldquo;/swagger-2.0.0.json\u0026rdquo;, \u0026ldquo;/swagger-2.0.0.pb-v1\u0026rdquo;, \u0026ldquo;/swagger-2.0.0.pb-v1.gz\u0026rdquo;, \u0026ldquo;/swagger.json\u0026rdquo;, \u0026ldquo;/swaggerapi\u0026rdquo;, \u0026ldquo;/ui\u0026rdquo;, \u0026ldquo;/ui/\u0026rdquo;, \u0026ldquo;/version\u0026rdquo; ] }%\n\n访问Web UI (Dashboard) Dashboad是k8s的一个图形界面，可以用它部署容器化的应用，排错和管理k8s群集。在minikube上启动这个界面的命令是 minikube dashboard ，你系统的默认浏览器会自动弹出如下界面。\n关于Dashbaord的文档在： https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/\n用minikube运行应用 minikube正常运行起来以后，就可以参考文档 https://kubernetes.io/docs/tasks/run-application/run-stateless-application-deployment/ 在这个k8s系统上运行一些demo的应用，对应用做启停、扩缩容等体验。\n",
    "ref": "/blog/install-minikube-k8s/"
  },{
    "title": "奔跑在西安的城墙上",
    "date": "",
    "description": "",
    "body": "来西安出差很多次了，每次都想绕城墙跑一圈，后来也不止一次看到其他朋友，要么绕城跑，要么在城墙上跑过；因此这根草也就越长越高，这次跑步的动力主要是拔草。\n从上图可以看出，绕城一周的距离是13.49公里，西安的城墙东西方向长，所以是一个比较扁的长方形。我是下午7点钟开始跑的，如果稍微晚几分钟到西门的话，售票处就会关门，我就错过了此次城墙上奔跑的机会，门票是45元，可一天中多次上下城墙使用。幸亏我从酒店（城西的老喜来登酒店）骑着摩拜及时赶到。\n城墙上的地砖较硬度比较大，建议穿缓冲好的鞋。7点半以后，天就彻底黑了，城墙上没有路灯，我有四分之三的距离感觉是摸黑跑，虽然路面是清晰可见的，不过在路过上下斜坡和台阶的时候，还是要加倍小心，毕竟安全第一。\n上图除了中间一张城墙砖的图片以外，其余的8张都是我用手机拍的。我想留下真实的时空的记忆。从左中的西门开始，我的路线是顺时针跑的，跑到北门，也就是上中的那张图，天就黑彻底了，完全失去了自然光。我在东南西北的城门都拍照了。在四个角楼也拍了。\n下图是在南门城墙上，往北拍的鼓楼，这个方向的路是西安城的中轴线，这个距离是城墙上离鼓楼最短的距离。也就是800左右的距离。\n总结 这次跑步并非是纯粹的拔草之旅，城墙给我们的历史感和沧桑感是非常强烈的。在这个城墙上跑一圈，你大概能够回想起秦黄汉武的盛世，能够想到玄奘西天取经等经典历史片段。感觉朝拜华夏文明历史的意义大于跑步健身。不过也要感谢跑步的习惯，否则没有这么强烈的仪式感，自己的身体和精神也就不会有这么强烈的冲击。这样的文化之旅，的确值得强烈推荐给所有跑友。\n",
    "ref": "/blog/running-on-xian-city-wall/"
  },{
    "title": "台大校园游览跑",
    "date": "",
    "description": "",
    "body": "趁着参加DevOpsDays Taipei的机会晨跑台大校园。在台北的这几天总体感觉是非常好的，和很多大陆来的好朋友一起，愉快地玩耍了几天。只跑了这一次，算是前往台大打卡留念吧！\n下图算是台大的东门，校门并不是很大，可是进去之后，看到了纵贯南北的校内大路的时候，才会有豁然开朗的感觉。\n下图就是中午的校园大道，两边高大的棕榈树凸显了亚热带海洋性气候的感觉。 下图是清晨的校园大道，时间大概是7点半左右，可以看到太阳已经很高了。 下图是这条大道的尽头，也就是台北国立大学的主教学楼。 下图是一栋比较新的教学楼，路两边依然是这种热带的树种 下图是这次的跑步地图，从Garmin网站上导出的数据文件，用过Google Earth查看截屏得到的图。 从上图中可以看出我几乎走遍了这个学校的所有主干道，有些地方是教职工宿舍区，有些地方是施工封闭的路段，还由于太阳太晒了，所以并没有凑够10公里整数。 总结 台大校园是台湾的最高学府之一，地位堪比国内的北大、清华和复旦，是台湾学术和科技交流活跃的地点，校内的免费wifi，无墙，而且下载速度在10m左右，网速比大陆快n倍。校园里路面平整，软硬适中，很适合跑步。校内的风景独特而优美，值得来游走一番。如果是北方的人，而且向我一样不是很耐热的，建议早点来，温度和日照强度都低一些。我跑的虽然不远，可是一路上一直是汗流浃背，建议带瓶水。本次跑步是我在台湾的首次跑步，台大校园路线已经进入了我的个人路线集。\n",
    "ref": "/blog/ntu-running/"
  },{
    "title": "Game of Cloud 对比三大主流公有云厂商",
    "date": "",
    "description": "",
    "body": "在全球范围内，公有云发展的正如火如荼，对IT行业技术的发展产生了很大的影响，从私有云到公有云，到混合云，再到云原生应用和DevOps。这一连串的连锁，也反映出了最近10年来IT行业发展的主流趋势。\n各种味道的云计算 参考来源：Battle of the clouds: Amazon Web Services vs. Microsoft Azure vs. Google Cloud Platform 作者 Brandon Butler, Senior Editor, Network World ，FEB 22, 2017 12:42 PM PT Which flavor of IaaS public cloud has what you need?\n对于行业观察者而言Amazon AWS是IaaS公有云市场里，不容争辩的领导者。而Azure正在逐渐缩小与AWS之间的差距，后来者GCP正大踏步的走来。\n根据Gartner对云厂商的深度评估，它分析了云厂商对企业工作负载的满足情况，AWS在最近的三年里，在234项功能对比中，保持着92%的满足度，Azure从75%上升到了88%。GCP也进入到了70%的程度。如下图所示：\nGartner对IaaS厂商的评估 重点看Required这一列的百分比。这些企业级功能被分类为三个级别：\n  Required 必须具备的；    Preferred 最好能具备的；    Optional：推荐具备的。    Amazon Web Services AWS是IaaS公有云市场的缔造者，它在2006年发布了第一项云服务Simple Storage Service - S3；Gartner认为它是最成熟的公有云服务提供商，它的功能从广度和深度上，都能最广泛的，能覆盖各种使用场景。它的优缺点如下图所示：\nAWS的优缺点 优点 缺点 最大和最成熟的公有云IaaS厂商，具有最强大和多样性的功能集合，被Garter称为：最广泛使用场景里的”安全之选“ 尽管AWS的入门和上手是容易的，它还是需要专业人士的管理和驾驭。由于它的功能性的宽广，这会让用老用于也难于面对多种的实施方案，需要第三方的专业顾问帮忙。 市场里的思想领袖和创新者，不断推出各种IaaS的新特性，例如Lambda无服务计算平台 对于用户的时间和实施能力而言，AWS有时候创新速度太快了，用户的知识很快就会过时，需要他们持续地更新AWS功能和平台的知识。 AWS的云市场具有最广泛的第三方工具的选择。而且它的顾问和专家的人数也是最多的，他们可以帮助到AWS的用户。 AWS一直以来都不是追求高价格。用户在每次购买服务的时候都有不同折扣，有时候需要使用第三方的工具帮忙管理成本。\n从技术的角度看，AWS持续创新的速度和动力都是非常强大的，服务更新的频率和速度非常快，在某种程度上超过了客户的适应和学习的速度，增加了客户的学习成本。它的SLA的规定有时候过于繁琐的，例如：需要客户的工作负载必须跨两个AZ部署，这会增加客户的成本。刨除以上所有对于客户的挑战，Gartner依然称之为云计算使用的“安全之选”。\nMicrosoft Azure 微软Azure逐渐变成了//Application development platform as a service (PaaS)的PaaS平台，其实它可以提供包括IaaS、PaaS和SaaS等广泛的服务。微软Azure最大的优势可能是他广大的企业客户基础。很多客户已经把Office系统迁移到了Office 365 SaaS服务上了，微软继续给用户提供大量的IaaS使用折扣（点卡），鼓励用户上云。\nAzure从功能角度看不管是计算、存储，还是数据库和IoT等方面，都与AWS非常的接近和匹配。微软试图通过混合云的策略区别于AWS。因此它提供了Azure Stack私有云方案。\nMicrosoft Azure的优势和劣势 优点 缺点 微软在构建Azure全球的数据中心基础设施方面和云功能开发上已经做出了巨大的投资。Gatner说Azure在IaaS公有云方面是”足够好了” 尽管Aure具有了大多数Gartner企业工作负载所需的功能，这些产品和API在某些情况下还不像它的友商AWS那样的成熟。 微软和几乎所有的大型企业具有长期和稳定的关系，在现有的企业协议EA里提供了非常具有吸引力的Azure的供给。 与Azure云集成的第三方公司的产品数量有限，相对于AWS，它的专家顾问社区也比较小。 微软Azure提供集成化的IaaS、PaaS和SaaS（Office 365）。Azure是已经多年投资于微软系列产品者的理想的选择。它的混合云的方案是很有吸引力的，包括Hyper-V，Windows Server，Active Direcitory， Visual Studio 和最近的Azure Stack。 在区域的设计中，Azure和AWS不同，它的Zone的概念和AWS不同，这会让工作负载的备份相对的稍微有点难。尽管在支持开源和非微软技术方面花费了大量的精力，微软公司任然不算是一个开源的领导者，而AWS和Google的云则是开源技术工作负载的一个更中立的选择。\n显然Azure最适合运行的是微软类型的工作负载，或者最适用于把已有的微软平台应用跑在公有云中。对于那些企业客户的EA，其中会包含一定数目的Azure点卡，不用可惜，用起来的话，Azure的使用还是比较经济的。\nAzure没有AZ的概念可谓是技术上的硬伤，比起AWS，这会导致跨区的备份略显麻烦一点。 业内Azure的专家和顾问还是相对较少。Gartner IaaS Magic Quadrant认为Azure对于大多数企业工作负载而言，已经是 足够用了“good enough”。\nGoogle Cloud Platform GCP与Azure类似，开始于PaaS，然后扩展到IaaS。分析师认为它特别适合跑某些使用场景，包括容器、大数据和机器学习。GCP在全球范围的数据中心相对较少。\nGoogle也有类似于Office 365 的办公套件SaaS服务，是G Suite，它的价格策略是，用的人越多，单价越便宜。\nGCP还是在发展中的云计算，从功能上讲，根据Gartner的年度评估，GCP仅满足70%的必选功能。技术上的优势在于：Google是开源的大数据（Hadoop、 Spark 等）技术、机器学习技术（Tensorflow）和容器编排技术（Kubernetes），它在开发者社区里从来没有缺少过粉丝，它对技术发展的影响不可小觑，这些影响最终都可以通过吸引用户使用GCP来使Google收益，并把这些技术变现。\nGoogle Cloud Platform\n在2016年Google招聘了VMWare的联合创始人Diane Greene，这标志着它计划向企业级能力和市场挺进。 Game of Cloud 公有云的游戏\n分析师认为对于大多数云的用户来说，并不是做的“零和游戏”的选择，很多人使用多云的策略。多云管理平台厂商RightScale，对1000个用户的调查分析 可以看出，用户57%的应用在AWS上，34%的应用在Azure上，15%跑在GCP上。85%的 RightScale的用户使用多云的策略，可能是：公有云+私有云；或者公有云A+公有云B+？？。\n硬碰硬功能对比 计算 AWS Azure GCP EC2 云中的虚拟服务器 Virtual Machines 在几秒钟内预配好 Windows 和 Linux 虚拟机 Compute Engine: Run VMs on Google\u0026rsquo;s infrastructure EC2 Container Service/Registry 运行和管理 Docker 容器，容器镜像仓库服务。 Service Fabric 在 Windows 或 Linux 上开发微服务和安排容器 Container Engineer: Container cluster, Workloads, Discovery\u0026amp;load balancing, Configuration, storage Lightsail 启动和管理虚拟专有服务器 App Service 快速创建适用于 Web 和移动的强大云应用 Cloud Launcher: Cloud Launcher lets you quickly deploy software on Google Cloud Platform Elastic Beanstalk 运行和管理 Web 应用 Cloud Services 创建高度可用且可无限缩放的云应用程序和 API App Engine: PaaS for apps and backends Lambda 运行您的代码以响应事件 Functions 使用无服务器代码处理事件 Cloud Functions : Serverless Applications on Google’s Infrastructure Batch 运行任意规模的批处理作业 Batch 云规模的作业计划和计算管理 无专门的服务，Google App Engine provides a Cron service. Using this service for scheduling and Google Cloud Pub/Sub for distributed messaging, you can build an application to reliably schedule tasks across a fleet of Compute Engine instances. Auto Scaling 自动化弹性扩展 Virtual Machine Scale Sets 管理并扩展到数千台 Linux 和 Windows 虚拟机 Instance Groups: managed instance groups can automatically scale the number of instances in the group.\n从概念上讲，提供的虚拟机功能是没什么差别的，包括虚拟机的自动化扩容和缩容功能都是类似的。区别在于其他的相关功能上。\nAWS在Serverlesss架构方面的Lambda是最领先的，它有最丰富的云市场，能提供最丰富的第三方应用服务，通过Lightsail和云市场都可以一键式启动特定配置的预装应用虚拟机/虚拟机集合。\nAzure在发布Winddows客户端应用上是有优势的。在其它功能上基本上可以和AWS对齐。\nGCP的明显优势是GEK，K8S如日中天的热度刺激人么对其GKE和GCE的关注和使用。\n###全世界数据中心覆盖\nAWS Location 数据中心在全球的覆盖 AWS Regions and Availability Zones\nhttps://aws.amazon.com/about-aws/global-infrastructure/\n已经开放的区和AZ： US East N. Virginia (6), Ohio (3)\nUS West N. California (3), Oregon (3)\nAsia Pacific Mumbai (2), Seoul (2), Singapore (2), Sydney (3), Tokyo (3)\nCanada Central (2)\nChina Beijing (2)\nEurope Frankfurt (3), Ireland (3), London (2)\nSouth America São Paulo (3)\nAWS GovCloud (US-West) (2)\n绿色的圈是要开放的区。\nChina\nFrance\nHong Kong\nSweden\nAWS GovCloud (US-East)\nAzure Region https://azure.microsoft.com/en-us/regions/\n蓝色三角的是要开放的区。\nGCP 的 Cloud Locations https://cloud.google.com/about/locations/ 蓝色的是要开放的区。\nGCP的另外一个卖点是它的全球高速光缆链接的网络。 存储服务 参考来源： https://www.networkworld.com/article/3191520/cloud-computing/deep-dive-on-aws-vs-azure-vs-google-cloud-storage-options.html\n块存储对比 对象存储 文件存储 Game of Clouds AWS 2017 云市场应用排名\nFrom: https://www.cloudendure.com/blog/aws-cloud-computing-map-game-of-clouds-2017\nAWS的云市场反映出它强大的第三方伙伴和生态系统。\nAzure Stack\n这是它区别于其它云的功能点，是可以在企业数据中心里部署的私有云IaaS平台。它与Azure公有云遥相呼应，为客户提供了混合云方案。\n本地运行 Azure 服务 根据你的需求正确组合云和本地部署来满足业务和技术要求。Azure 基础结构即服务 (IaaS) 传输远优于传统虚拟化。借助虚拟机规模集，新式工作负荷的真正自动扩展可实现快速部署。一致的 Azure 平台即服务 (PaaS) 功能将混合部署选择和可移植性引入云应用程序。因此，可在本地运行完全托管的 PaaS、无服务器计算、分布式微服务体系结构和容器管理。\n生成跨混合云环境的新式应用程序 Azure Stack 是 Azure 的扩展，将云计算的敏捷性和快节奏创新引入到本地环境。只有 Azure Stack 才能让你从组织的数据中心提供 Azure 服务，同时适度平衡灵活性和控制程度，实现真正一致性的混合云部署。\n利用一致的环境加速开发 无论应用是在 Azure 还是在 Azure Stack 上运行，开发人员都能以相同的方式生成和部署应用程序，从而实现工作效率最大化。一套工具 - 使用相同的应用程序模块、自助服务门户和由 Azure Resource Manager 启用的 API。常规 DevOps — 通过 Jenkins 和 Visual Studio Team Services 体验持续部署和集成，通过 Chef 和 Azure PowerShell DSC 扩展体验自动化。 开源 — 使用 Java、Python、Node.js、PHP、Docker 集成式容器、Mesosphere DC/OS 和 Cloud Foundry 等众多开源技术。\n",
    "ref": "/blog/aws-vs-azure-vs-gcp/"
  },{
    "title": "不一样的台北，不一样的感受",
    "date": "",
    "description": "",
    "body": "这是一次偶然的旅行，在最近的两年里，我很荣幸的认识了很多新朋友；偶然间受到了台湾朋友的邀请；这也是一次必然的旅行，由于我锁定了DevOps这个方向，参加更多的DevOpsDays活动也就成了必然。\n台湾旅行提示 前往台湾所需要的手续是相对的麻烦一些。如果从北京出发的话，最简单的方式还是使用【 往来台湾通行证 + 个人旅游签注 ，有大陆的出入境管理大厅办理，在北京的各个区都有，外地户口的需要网上预约，提交资料，等待数个工作日之后，能够拿到这张二合一的IC卡片】和 【中华民国台湾地区入出境许可证 这个由旅行社可以办理个人旅游类型的】。\n我这次是参加itHome主办的DevOpsDays台北站，由于是参加商务演讲，所以中华民国台湾地区入出境许可证需要是商务型的，这样就需要台湾的大会举办方提供本次活动的资料，然后我在去北京市的台湾事务办公室申请立项，在批准之后才能拿到大陆发出的商务签注。由于来不及办理这个流程；因此不得不绕道香港转机前往。\n如果是经过香港转机前往台湾的话，在北京机场办理乘机手续的时候，必须使用港澳通行证（要带有有效签注的）和护照（台湾的大会举办方用护照帮我买的机票）。办理完登机手续后使用港澳通行证在北京机场出境，现在的港澳通行证也是二合一的IC卡片，所以可以用来进入自助入关通道，刷卡门开了就过去。\n乘坐飞机抵达香港机场之后，按照指示去往转机的安检通道即可，经过一次安全检查之后，你就进入了楼上的出港候机大厅，去往下一个飞台北的登机口即可。\n在抵达了台北的桃园机场之后，在入境台湾之前，要填写一张入境表格，拿着护照和中华民国台湾地区入出境许可证即可通过海关，海关会在这张必须是彩色打印的纸上盖下入境的时间戳；由于我的行程是固定的7天的行程，所以理论上讲，我必须是2号入境7号离境的行程；如果时间上有推迟和延后，是可能会有一定的麻烦的。\n我现在座在回程台北飞往香港的飞机上，在出海关的时候需要用到护照和中华民国台湾地区入出境许可证，海关会在中华民国台湾地区入出境许可证这张纸上盖第二个场景的时间戳。我从香港回北京，通过北京海关入境的时候，应该使用港澳通行证即可。\n如果我中华民国台湾地区入出境许可证的目的是旅游型的，我就可以从北京直飞台北桃园机场了，就不用再香港转机了。我这次行程比较特殊，用到的证件如下：\n 中华民国台湾地区入出境许可证 - 商务，彩色打印，出入台湾海关用，需要遵守出入境行程时间 港澳通行证/带有签注 - 办理离境登机牌，出入中国海关使用 护照 - 出入台湾海关用  我从机场到酒店座的是巴士，走到机场到达大厅的最底层，花145块买票，巴士其实是很方便的一种方式，我在远东香格里拉酒店下车之后，在走路大约10多分钟就到了我的酒店。\n回程的时候，我选择了做出租车，在酒店门口随手叫了一辆，打表到桃园机场的价格是1300台币，我记得是40公里左右，走了将近40是多分钟，七点多路上并没有明显的堵车的现象。\n野柳地质公园 我是9月2日周六下午到的台北，第二天和其它朋友商量后，觉得去野柳地质公园；这个公园在台北市的正北面。我们选择做公交去，公交站就在酒店附近，在车站大约等了30分钟左右上车，车走了大概40多分钟后就到了公园大门附近。\n可能是我们那天的天气原因，公园关闭了一半，走到中间的那个区域，就不能继续往前一直走到头了。下面是来自马蜂窝网站的简介\n 野柳地质公园为大屯山余脉伸出海中的岬角，长约1700 公尺，野柳奇岩是这里的主要看点，它是世界奇观之一。 波浪侵蚀、岩石风化及海陆相对运动、地壳运动等地质作用的影响乃生成罕见的地形、地质景观，极具观赏、研究价值。 除了奇特的地质和石头以外，种类繁多、在海边栖息的海鸟也是不可错过的观赏目标。  我觉得如果是天气晴朗就更好了，那样岩石、大海和环境的色彩才会更加的漂亮。整个公园不是很大，景色变化不大；由于没有看到公园的另外一半，感觉还是有些缺憾。\n国立故宫博物院 到目前为止，我看过的博物馆也不少了，这个博物馆也有点超预期的感觉。从外表上看，这个坐落在士林公馆附件山上的博物馆不是很宏伟的建筑。看起来比较小巧。\n博物馆里的展品的数量是非常多的，每一个展厅里的每个展位，感觉都拜访的满满当当的，一定要租一个语音导游，语音讲解内容制作的也是很精良。这么琳琅满目的展品，从数量上说就是非常让人大饱眼福的。\n展品的展览和分类的水平还是很高的，让我比较印象深刻的有两块展板，一块是青铜器按年代的分类展示板，一块是类似的瓷器的展板；横轴是器物的分类（按用途和功能），纵轴是历史年代。这种逻辑让人在看完展品之后，我们还能大概的看出青铜器和瓷器的发展史。\n国立台湾大学 这里才是本次出游的目的地，我帮忙DevOpsDays台北组委会联络并组织了本次的大陆讲师团；在我的建议下，还引进了“凤凰项目”沙盘。我的分享在最后一天的下午，前几天基本是呼朋唤友的游玩的时光。\n当然唯有跑步是不能辜负的，台大校园是一个不能错过的跑步地点，很多建筑物在日本统治时期就有了。校区的风景和规划仅仅有条。从南门进入之后，就是一条校内最宽的大路，两边种着整齐的椰子树，和并不高大的红色教学楼群，形成了鲜明而特别的风格。\n9月6日早晨在校园里跑了6公里多，7点多在校园里，感觉阳光非常强烈，很热，不一会就挥汗如雨了。校园内的树木其实是很多的，也都很高大，经常可以在树荫下面跑，这极大地缓解了强烈的日照。校内有些部分在维修和施工中，因此并没有完全地踏遍整个校园，不过这所校园的特点和美丽已经尽收眼底。\n这几天的大会也是在校内办的，六七百人的大会，办的细致周达，有声有色，这边的技术社区对DevOps也是比较刚兴趣的。大会的很多细节做的都很好。\n总结 其它的景点还是游玩了不少的，国父纪念馆、101大厦楼顶、还去过几个夜市。诚品书店给我了深刻的印象，强烈推荐信义店，这是台北最大的一家书店。我去了两次，忍不住买了几本书，还买了一只LAMY Studio的钢笔。把玩钢笔也是一个挺大的坑，有可能我已入坑。\n台北是一个很特别的城市，如果不是亲自来感受一下的话，你是在很难想象出，在海峡的这一边，还有着这样的一座神奇的宝岛。美中不足的是，这几天都在台北转悠了。由于台北市是最繁华的大都市，城市的嘈杂和喧闹还是难免的。等下次有机会在来感受休闲和静谧的台湾。\n",
    "ref": "/blog/taipei/"
  },{
    "title": "Las Vegas流水账-大峡谷篇",
    "date": "",
    "description": "",
    "body": "Las Vegas到大峡谷（Grand Canyon National Park）的距离并不遥远，但是离最佳风景观看点南峡（South RIM）还有大半天的路程。很值得去，绝对不会后悔。 行程\n我们走的路线和预先计划的稍微有些差异，主要是受了同时Danny的影响，他曾经自驾车在大峡谷玩过。根据他的建议，我们设计了大峡谷南峡的两日游。路线如下：\n从拉斯维加斯出发–93号公路–40号公里–住在威廉斯小镇–64号公路–大峡谷国家公园（南峡）。本来计划先去游玩胡夫大坝、西峡（Eagle Point和Guano Point），之后晚上住在威廉斯小镇，第二天再去南峡一日游。西峡被Danny果断的否定了，他建议我们要在南峡的主景点多花时间；现在看来这个决定是对的。\n我们在10号早晨4点起床，出发前往大峡谷。在出门的第一个小时，里别导航搞得几乎是崩溃的。出现了几个状况：\n用iPad上的Google Map下载了三个州的离线地图是不好用的，甚至让iPad链接上国内手机热点的型号后，GPS定位还是不正常工作的（不知道是否是我的iPad的问题待查）。 用国内iPhone手机做以上相同的操作，问题是一样的。 用iPhone手机自带的苹果地图，能工作，可是由于没有离线地图，使用的时候略感延迟，也害怕使用过多的流量，因此还是放弃了。 大家各自用手机导航，有人的路线是南峡方向，有人是走北峡方向。在经过路口时大家意见不统一了，才意识到问题，大家都有中枪的感觉。 最后发现用国内手机，在来之前，在家下载好的三个州的Google Map离线地图是唯一好使的方案，在使用过程中可以完全不需要开数据网络，可以用飞行模式。 从拉斯维加斯市区到威廉斯小镇的酒店的路程大约是350公里，整个行程差不多花了5个小时左右（第一个小时忽略不计呵呵）。\n在酒店放下行李，checkin了以后，我们就奔向了大峡谷南峡的南门（东门才是正门），大约从酒店出发，又走了一个小时多才进入公园，车停在了Bright Angle附近的停车场。接着开始了一天的大峡谷之旅。 大峡谷-Day1\n我们按照Danny的建议先乘坐西线（橙色）的Bus，到达了西峡的最远端（Herimt Point），在哪里稍微观赏了一下后，正好是午餐实践，在哪里的零食店一人买了一个三明治吃。然后回程的Bus在第一个停靠点下车，开始了徒步5.9公里的观赏，也就是从第一个停车点走到第二个停车点，回程总共三个停车点。\n这一段路在大峡谷当中，景色算不上是最好的，可是这段路包括了Green Road这一段路。这一段路里包括了大峡谷里的所有主要种类的树木和植物。大量的信息展示牌上介绍着各种动植物的信息，在途中前后碰到了三只鹿，可以算是给徒步者的一个奖励，这几只鹿貌似并不把人类放在眼里，它们各自闲散地吃着树叶，只有在人特别靠近的时候，才不耐烦的走开。\n在路上碰见了不少骑自行车的人，他们很多是以家庭为单位了，三五成群的前后照应着向前行驶而去，有些人的车是自己带的，有些人是在公园里面租车骑行的。\n我们的徒步的路段是：Pima Point到Mojave Point。在Mojave Point看到了著名的、教科书般的、明显的6层、分层地质峡壁和讲解的展板。\n在我们正要回去的时候，我们眼睁睁的错过了一辆Bus。在等下一辆Bus到来的时候遭遇到突如其来的阵雨的袭击。这里的天气很多变，雨滴打在身上特别凉。不一会就把我的上身都打湿了，我只穿了短袖和短裤，所以很快就迫使我我不得不躲到了树下。第二辆Bus在20多分钟之后，终于来了，上车之后，在回程的路上，阵雨下的更大了，能挤上车，顿时感觉自己很幸运。\n在回到了Right Angel Lodge的停车场之后，想着Gary应该在温暖的车里等着我们呢！可是没想到车里没有人，此时从车站冒雨跑过来的三个人鞋子都湿透了，冷风嗖嗖的刮着。大家躲在一个酒店房间的屋檐下，打着哆嗦的等了几分钟，后来觉得这样不行，就各自四处寻找拿着车钥匙的Gary去了。\n我在Lookout Studio附近和Bright Angle Lodge的商店里面寻找Gary的同时，倒也算是另外一番游览；找了30分钟以后，觉得应该回车子看下了，回去后发现Gary已经和曾旭在车里了，赶紧上车喝水休息。等了一会吴东也回来了。这时候雨还在下，时间大约是下午3点多，我们大家一致觉得回酒店休息了，结束了第一天新的游玩。 晚餐\n回到了酒店之后，我们进了房间，我赶紧脱下深山湿漉漉的衣服和鞋子，洗了个热水澡，换上干净温暖的衣服，直接钻进了被窝，昏昏沉沉的休息了大约一个多小时，也正好到了饭点了，外面的雨星星点点的没有停。我们就开车去往镇上吃饭了。\n我们先走进了一家美式当地的餐厅，发现菜单基本看不懂，就走人了。然后打算去吃一家意大利餐厅，发现等座位的人还是很多。后来我建议来这家 Cafe 66 Bar and Grill。这家是一家很地道的美式烧烤餐厅。\n我点的是上图的烤牛肉，其它人主要点的是下图的烤猪排。肉都烤的很嫩很香，几乎都吃不完就吃到顶了，大家饱餐一顿之后，回去妥妥的休息了。\n大峡谷-Day2\n第二天早晨起来大约是7点多，我睡的还行。大家去吃早餐，我泡了碗麦片牛奶、烤了两片土司、烤了一个圈圈面包、乘了一些炒鸡蛋和小香肠、倒了一杯橙汁，吃完了这些后吃了两个苹果。在这温暖的小店里，在一个没有任何赶路压力的行程上，我在这一周的行程当中，在此刻才算是真真的满血复活了。\n早餐后，我们就继续上路了。\n我们先把车停在了Visitor Center的停车场，然后从Mather Point走到了Yavapai Point and Geology Museum。一路上才发现好多大峡谷的明信片照片都是从这里取景拍摄的，这一段是大峡谷游览的必经之旅。\n然后我们驱车前往大峡谷南峡的最东头，也就是Desert View观景点，其实这个景点并不是东边的最后一个景点。我们在哪里看完之后，想一直往东开，看看到底还有什么景点。其实看到了不少的观景台，甚至于在密林中的头角硕大的鹿。最后走出了公园的东门，在往外开，才来到了公园的标识牌设立处。在往外开了几英里之后，就返回了。其实大家想起了再继续往北走180多公里就是著名的羚羊峡谷，Windows7桌面图片中出现过这个景点。可是行程来回要大约4个小时（370公里以上），在我的建议下大家还是忍痛放弃了这个景点。否则今天早晨应该还需要4点出发，回程晚上11点的飞机，想想当天还要赶飞机回家，其实压力还是有的。\n我们从公园外又兜了一圈回来之后，我们中途停在了Tusyan小镇上吃了午餐麦当劳，休息片刻之后继续上路了。路上我们加满油一下跑到了胡佛水坝，到了才知道最后一个游览是5点钟，虽然我已经尽力开快车赶路了，可是还是错过了。稍微浏览一下之后，接着回机场还车。然后座免费bus去机场了。晚上饭是吴东请客。大家在机场踏实的等了2个多小时就登机了。 小节\n这次出行美中不足的是：没有把徒步的装备带好，包括防晒、防雨措施；各种长短方便更换的速干衣裤，帽子等。还很重要的户外徒步的鞋子。\n在开车方面，三个司机的好处非常明显，这样大家分担着开非常有乐趣和安全。\n有可能的话大峡谷南峡的游览方向可以调整为，从东北方向南下过来，也就是羚羊峡谷的方向过来。这样的好处是，从公园东门进来之后，其实在Desert view之前有很多不错的路边的观景点，而且停车特别方便和顺手，这样的方式可以更充分的利用汽车的便利程度，多看了景点，还不累。\nHoover Dam错过了，我还是觉得有些小小的遗憾的。因为这个地方就在路上，时间安排的合理的话，能够参加上他们的水坝游览，里里外外都看一遍，应该还是很不错的。毕竟很多影视剧都到此取过景。\n总之这次拉斯维加斯之旅还是很棒的，除了去打枪射击的这一项没有Checked之外，其它的都算是完美收官了。这次入手了美国国家公园的Passport，用它来记录和收集所到过的国家公园的印章，以后可以统计一下，一共可以去几个了。\n",
    "ref": "/blog/las-vegas-p2/"
  },{
    "title": "Las Vegas流水账-进城篇",
    "date": "",
    "description": "",
    "body": "Las Vegas-拉斯维加斯，国人简称拉丝，美国人简称Vegas/威嘎斯。来过很多次美国，可是这个城市还是第一次造访，写个流水账记录一下。 航班\n这次来回都是韩国航空。从北京飞首尔转机直飞美国。这也是第一次乘坐韩国航空公司的飞机，第一次入境韩国。\n中午从北京出发的飞机晚点了30分钟后起飞了，在3点左右达到首尔机场，沿着指示标记，走向国际转机通道，经过安检后就进入了下图的首尔国际机场航站楼。\n这个航站楼还是很大的，里面有各种免税商店，包括化妆品、烟酒、食品和各种奢侈品。为了到此一游我也买了一副墨镜（Rudy意大利产），在此留个纪念；价格上比美亚可能要便宜20刀左右，而且还免税。基本上觉得还是划算的。\n与其它城市的几位同事及其家属碰头以后，我们四处转了转，由于转机的时间比较长，大家相谈甚欢，还是相当的休闲和愉快的。在那一刻也非常同情另外一波从北京出发的同事们，他们的飞机出现了机械故障。\n大约七点多大家想找个地方吃点饭，结果由于机场的人超级多，想找个吃饭的地方，居然不能找到一个能让我们四五个人一起坐下的饭馆，随即放弃吃饭的想法，买了杯星巴克了事。在夕阳的余晖下，大家津津有味地听宇宙同学普及各种会员身份使用攻略和褥羊毛秘籍，不知不觉也到了登机时间了。登机后吃了两顿饭，看了一部电影，快到的时候睡了大约2小时，然后就准时的在当地时间周日下午5点到达了。然后大家商量之后，果断的打了一辆Uber，直奔拉丝的北奥特莱斯去也。 进城\n汽车载着我们穿过市区的主街道，往北走直奔奥特莱斯。 这个奥特莱斯还是蛮大的，在8点下班前，我不紧不慢的买了两双鞋和一件T恤，之后和同事们一起打出租车会到酒店。 到 Aria酒店 Checkin了之后，进房间放下行李箱，同事们一起去酒店的Pool Bar吃晚饭，具体说是一个欢迎酒会。其实也吃不上什么正式的晚餐。当天晚上还是有时差的感觉，到晚上3点才昏昏睡去，睡了4个小时。早晨起来感觉还行，起床后完成了会议登记，接着去吃早餐，早餐是我吃过的所有会务餐中最差的，不提了略过。接着进入开会的节奏。 大会开始\n开场主持人是加拿大的一个Sales，他的气势和技巧还是很专业的，据说粗口的风格是与HR和公司的VP们请示过的，不过的确达到了逗乐和暖场的目的。随着“镜子”舞团的暖场舞，视频上播放了公司大佬们录制的视频，hipop风格的逗乐视频。由于印度裔大佬们较多，我看下来有点宝莱坞的感觉，哈哈！ 公司的大佬们悉数登场，各尽其职的讲述自己的部分。讲解了公司的市场前进和进入4B公司的计划。下午的各种session完了之后，晚餐也还是社交为主的，去了一个高尔夫训练场，大家基本也以聊天为主，至于晚餐么，我忽略不写了。 Night walk 晚餐之后和同事们一起来夜游Vegas的主大街夜景。从美高梅酒店走路到埃菲尔铁塔酒店，最后回房间休息。 横穿美高梅酒店赌场，感觉MGM的人气确实很旺，比其它酒店生意好。 经过自由女神像的纽约酒店赌场。 走到埃菲尔铁塔附近 看完百樂宮酒店（Bellagio）的音乐喷泉后，走路回到酒店。\n考虑到最后两天去大峡谷的路程比较远，希望能早走，我取消了之前的租车订单后，又下单订车，提前了一天取车，而且取车的地方就选择了酒店楼下。这样时间就不紧张，而且取车更方便了。\n这就是此次拉斯维加斯之行的第一部分，航班安全顺利到达，进城后参加了一天平淡无奇的公司大会。大概领略了一下这个极致的城市。\n",
    "ref": "/blog/las-vegas-p1/"
  },{
    "title": "互联网规模的超融合平台",
    "date": "",
    "description": "",
    "body": "nu.shool 牛学院系列以视频加文字的形式，向您展示Nutanix云平台的技术特性和细节。\n本期视频是由《Nutanix圣经》的作者Steven Poitras，向您介绍Nutanix超融合系统架构。\n\n《Nutanix圣经》章节推荐。\n",
    "ref": "/blog/nu-school-converged-platform/"
  },{
    "title": "2017DevOps采用和趋势现状-信息图",
    "date": "",
    "description": "",
    "body": "在过去的一两年里DevOps持续升温，逐渐成为一场IT行业内的谁不可回避的运动。\nDevOps 定义 我个人是一直以来反对给DevOps做一个名词解释样式的定义的。不过这种需求实在强大，摘抄几条供大家参考，上图是一种定义。\n 定义2：You cannot buy DevOps and install it. DevOps is not just automation or infrastructure as code. DevOps is people following a process enabled by products to deliver value to end users. \u0026ndash; Donovan Brown, Microsoft DevOps Program Manager\n 以上出自：Donovan\u0026rsquo;s blog post on \u0026ldquo;What is DevOps\u0026rdquo;.\n 定义3：DevOps（Development和Operations的组合词）是一种重视“软件开发人员（Dev）”和“IT运维技术人员（Ops）”之间沟通合作的文化、运动或惯例。透过自动化“软件交付”和“架构变更”的流程，来使得构建、测试、发布软件能够更加地快捷、频繁和可靠。\n 以上出自：维基百科 Wikipedia - DevOps\n兴趣和搜索量 以上结果来自Google趋势，上图是从2004年到现在，一共13年的趋势图。下面再看一下最近五年的趋势详情。\n最近5年的搜索趋势 国际关注度 相关话题和查询 关注者年龄和性别 上图年龄分布情况。\n上图是性别分布情况。\nDevOps应用状态  正在应用的:从66%上升到74% 没有应用的:从19%下降到16% 不知道的：从15%下降到6%  DevOps Checklist 不管你做不做DevOps？不管你知不知道你是不是DevOps？不管你从哪个角度入手DevOps？看看这个清单中有几项和您相关，就知道你和DevOps的关系是否密切。 检查清单如下：\n 基础架构即代码 每天多次部署  研发人员直接部署都生产环境 研发和运维共同奋战在支持的一线   消除研发和运维的部门墙  DevOps流程 下面看看两种相关流程图。  持续业务计划 协作型软件开发 持续测试 持续发布和部署 持续监控 协作式客户反馈和优化  上图来源于《Exin DevOps Master 白皮书 - 企业DevOps的成功之路》 作者：Koichiro(Luke) Toda、Nobuyuki Mitsui、译者：刘颋，史鹏程；审校：EXIN，刘征\n 计划 需求 设计 开发 部署 运营 终止  7大DevOps 趋势  DevOps将进入主流，并产生大量关注；因此2017年将成为“DevOps之年”。 随着DevOps的推广，三个C：持续集成、持续部署和持续交付，将形成巨大的势头。 即将产生越来越多新的DevOps自动化工具，这些工具改变了我们软件开发的方式。 “容器化”也将引人注目（例如使用Docker容器）。 许多软件公司将转向微服务架构。 自动化测试和持续测试将变得更加普遍，且更加重要。 必须拥有的工具和平台，包括Docker、AWS、GitHub和JIRA将在开发者社区更受欢迎。  本文参考来源：\n http://www.rightscale.com/blog/cloud-industry-insights/new-devops-trends-2016-state-cloud-survey https://www.storybase.com http://pt.slideshare.net/johnpviner/devops-be-careful-what-you-wish-for https://en.wikipedia.org/wiki/DevOps http://www.Google.com  ",
    "ref": "/blog/state-devops-adoption-trends-2017/"
  },{
    "title": "Nutanix AHV（KVM）Windows虚拟机安装全攻略",
    "date": "",
    "description": "",
    "body": "Windows 虚拟机安装 Nutanix的AHV虚拟机是基于KVM的。本文件假设您使用和安装的是Nutanix社区版本的群集。在上面安装Windows虚拟机的步骤如下：\n 下载操作系统安装光盘 上传操作系统安装光盘到Nutanix群集 （安装Windows虚拟机需要 Fedora virtio 驱动） 新建和配置虚拟机 安装OS 安装Nutanix Guest Tools （NGT）  下面用安装Windows 10举例，说明详细的安装步骤。\n第一步：下载操作系统 ISO 如果你需要下载 Ubuntu Desktop 点这里。\n从微软的TechNet Evaluation Center下载 Microsoft ISO 注意，评估的服务器版只能使用180天，桌面版能使用90天。\n第二步：上传ISO文件到Nutanix群集 Nutanix群集上提供了镜像服务，可以存储几种格式的镜像：ISO格式的操作系统安装镜像，虚拟机的磁盘(如KVM格式等)。这些镜像文件可以被虚拟机通过挂载CD-ROM设备使用，或者直接克隆出虚拟机的磁盘。操作步骤如下。\n点击右上角的齿轮图标，选择image configuration 点击 upload image按钮\n界面字段解释：\n Name: 镜像文件的名字（用ISO来与磁盘镜像区分一下） Image Type: 选择 ISO Container: 选择用来存储ISO文件的容器 Image Source: 选择上传文件作为镜像来源 Save: 点击Save按钮可以看到上传的进度条。  在上传成功之后，镜像清单中显示刚才的镜像为 Active 状态。\n由于Nutanix的hypervisor是基于Linux KVM技术，它需要附加的Windows驱动，需要下载 Fedora Windows virtio 驱动。 下载地址如下：\nhttps://fedoraproject.org/wiki/Windows_Virtio_Drivers\n点击第三条 Direct download\n点击 “Stable virtio-win iso” 下载最新的驱动 ISO 文件。\n下载到的文件名如：virtio-win-0.1.126.iso；重复上述Windows IOS文件上传的步骤，把这个文件上传到镜像服务中。\nFedora 的开源版 VirtIO驱动和Nutanix的版本稍微有些不同。Nutanix的 VirtioIO驱动是经过数字签名的，能从Nutanix客户门户下载。由于Nutanix CE社区版是提供给所有人做体验测试的，因此这里使用的是开源版本的VirtioIO驱动，而不是Nutanix的官方版本的驱动。\n##第三步：创建和配置虚拟机\n我们已经准备好了Windows 10 ISO文件和 Fedora VirtIO驱动IOS文件，现在可以安装虚拟机了。步骤如下：\n点击 Home\u0026ndash;VM\n点击右侧的 Create VM 按钮。\n在下面的页面中输入虚拟机的配置。\n主要配置介绍如下：  Name: Win10Desktop 虚拟机的名称 vCPUs: 2 两颗虚拟CPU Number of Cores per vCPU: 1 Memory: 2GB (只是做测试的话，2GB可以了)  下面添加用于虚拟机挂载Windows 10 安装盘的 CDROM设备。删除默认的CDROM设备。 由于偶尔安装Windows 10的时候默认的CDROM驱动器中Fedora Virtio驱动会显示不出来，因此删除默认的CDROM设备。\n添加vm系统安装的磁盘。点击添加磁盘，输入如下实例信息，得到一块40GB的SCSI磁盘用来安装Window 10操作系统。\n添加一个新的CDROM驱动盘，用来挂载 Windows 10 的ISO镜像文件，如下图所示。\n Type: CDROM 类型 Operation: Clone from Image Service Bus Type: IDE 类型的应该是默认类型 Image: 选择刚才上传的 Win10ISO  添加一个新的CDROM设备，用来挂载 Fedora Virtio驱动IOS文件，如下图所示。\n Type: CDROM 类型 Operation: Clone from Image Service Bus Type: IDE Image: 选择 FedoraVirtISO  配置完成之后的磁盘配置布局如下。\n现在来添加网卡，点击下面的按钮。\n使用默认的ID为0的网络，如下图所示。（此VLAN时之前建立好的）\n现在所有配置都已经完成，点击 Save 保存按钮。\n页面的状态栏会出现一个绿色的执行的提示，表示后天虚拟机正在创建中。\n第四步：运行并安装虚拟机 做如下操作来开启并运行虚拟机，进入Windows操作系统的安装过程。\n 点击到 VM 视图 点击 Table 点击 Win10Desktop VM 刚才创建的虚拟机 点击 Power on 当 VM 启动了, 点击 Launch Console 进入控制台页面。  在Windows安装的界面，选择Custom ：高级安装选项。\n由于我们使用的 AHV 是KVM虚拟化，所以需要加载Virtio驱动。点击 Load Driver 按钮。\n点击 Browse 浏览。\n点击并浏览驱动器 E： （这是之前我们挂载 Fedora Virtio ISO文件的CDROM）\n浏览驱动盘到目录 vioscsi\n选择 w10 目录\n选择 amd64 目录，点击 ok\n选择所显示出来的 Red Hat VirtIO SCSI 驱动，点击 Next\n这样刚才创建的 40GB的磁盘就可以看到了，选择 Next\n点击了 Next 按钮之后， Windows 10 开始安装，这个过程大约是3~10分钟不等。最后就到了Windows的账户创建的环节。虽然现在Windows已经安装完成了，还需要进入Windows的设备管理器中查看一下，设备的状态。\n 右击Windows的图标 选择 Device Manager  在设备官开启中，我们需要更新一下网卡设备的驱动。\n右击网卡设备，选择 Update Driver Software\u0026hellip;\n点击 Browse，选择当前的 virtio-win-0.11 ，也就是 Fedora VirtIO 驱动的光驱设备，点击 Next\n选中了合适的目录后，网卡设备的驱动安装正常了显示如下：\n到目前为止，我们的Windows 10 虚拟机安装完毕了。\n第五步： 安装Nutanix Guest Tools （NGT） Nutanix Guest Tools 可以实现自服务恢复和应用一致性快照功能，它需要Microsoft Volume Shadow Copy Services (VSS)服务的配合。下面来安装它。\n 进入虚拟机的清单视图 点击 Table 点击选中刚才安装的Windows 10 虚拟机 点击 Enable NGT （这个操作需要有一个空闲的CDROM设备，可以点击虚拟机的编辑，把之前的两个光驱中挂载的ISO盘退出一个） 在后续的窗口中点击 Yes  在网页上成功启用了NGT之后，进入Windows 10桌面的控制台页面。打开Windows的资源管理器，双击带有Nutanix图标的CDROM设备，进入该设备安装NGT软件。\n点击 Install 按钮。\n跟随安装向导完成NGT的安装。安装完成之后，在Windows10中关机，在网页上编辑这个虚拟机的配置，删除多余的CDROM设备，之后在开机。至此Windows10虚拟机的安装过程全部完毕。\n扩展阅读：Nutanix AHV 虚拟机模板制作\n",
    "ref": "/blog/install-vms-on-nutanix/"
  },{
    "title": "日本旅行-第一部分京都休闲游",
    "date": "",
    "description": "",
    "body": "这次并不是刻意安排来日本，为了和同学凑行程，意外来日本国一游。行程稍微有点周折，从北京\u0026ndash;威海\u0026ndash;大板西关\u0026ndash;京都\u0026ndash;大板\u0026ndash;大板西关\u0026ndash;北京。这个行程的缺点在于选择了同一个城市进出日本。本文讲讲京都的几天。\n新京极 在京都期间都住在了锦市场北边的一个市场附近的一家Airbnb。其实从锦市场到新京极的几个街区中间是京都市中心附近。从住所往北一站就是京都市的市政厅。往北一站就是鸭川，这是一条从北到南穿过京都市区的河流，冬季河水特别浅。\n住所在市场旁边吃喝玩逛都非常方便。属于在居民楼中的一个商住楼。\n由于这个区域靠近商业中心，因此楼下临街商业也很发达，大街小巷遍布着各种饭馆和小店，买什么的都有。各种类型的各式各样的小店。\n伏见稻荷 这里是一座山伏见稻荷山所在，山上的这个神庙以它的狐狸大神最为有名。从下图可以看出，这座香火旺盛的主庙的屋脊还是有唐朝的感觉。即使是工作日也有很多人专门来这里朝拜。\n除了在正门的主殿有人朝拜，还有山上的其它地方，凡是有人供奉的地方的石台上，都是有人书有供奉者的名字，或者是毛笔写的或者是石刻的。\nFrom wiki\n 伏见稻荷大社位于稻荷山的山麓，在传统上整个稻荷山的范围都被视为是神域（圣地）的范围。伏见稻荷大社主要是祀奉以宇迦之御魂大神为首的诸位稻荷神，自古以来就是农业与商业的神明，除此之外也配祀包括佐田彦大神、大宫能卖大神、田中大神与四大神等其他的神明。由于每年都有大量的香客前来神社祭拜求取农作丰收、生意兴隆、交通安全，使得该神社成为京都地区香火最盛的神社之一。另外，起源于江户时代的习俗，前来此地许愿的人们往往会捐款在神社境内竖立一座鸟居来表达对神明的敬意，使得伏见稻荷大社的范围内竖有数量惊人的大小鸟居，而以“千本鸟居”之名闻名日本全国乃至于海外。捐款竖立鸟居的单位包含个人、公司行号乃至于各地的商会组织，目前现存的鸟居，最早可以追溯到明治年间。 在神社的\n 从右侧上山，到山顶后从左侧下山，如果走的快的话，两个小时左右可以玩完。这里可以看到日本所信奉的神的多样性。各种植物、动物和农业相关的东西比较多。\n我们走到半山腰的一个桔园时，有些迷路的感觉，觉得找不到路了。有一个出租车司机回家，把车停到了路边换鞋回家；看到我们似乎找不到路了，他回家后拿来一张地图给我们指路。由于日本的英语真的不通，他所以回家那地图来，大约至少用了他四十分钟的时间，拿着地图来告诉我们继续向前走就可以到山顶了。他说的所有话里面，就两个词可以听懂“Top”和“thirty minutes”；很感谢这个指路人。\n上顶上有一个能够俯瞰市区景色的地方，几排长椅上，人们一边看风景，一遍晒太阳，还是很休闲的。\n奈良 奈良到京都不远。来这里大部分时间都放在了，带孩子喂鹿上了，基本没有怎么逛著名的东大寺。\n我们在路上换车的时候，做错了车，做了一辆特急的快车，结果需要补票花了1千多。\n出了地铁站不远，就可以看到奈良公园的小鹿，一波一波的喂鹿，孩子总是能想出各种奇思妙想的喂法，基本一天没干别的。\nFrom Wiki\n 东大寺（日语：東大寺），位于日本奈良县奈良市杂司町，是华严宗大本山，南都七大寺之一，距今约有一千二百余年的历史。1998年作为“古都奈良的文化财”的一部分被列为世界文化遗产。 佛寺是728年由信奉佛教的圣武天皇建立的。东大寺是全国68所国分寺的总寺院。因为建在首都平城京以东，所以被称作东大寺。另外有西大寺。\n 最后到寺院里面转了一圈依然下班了。发现日本的景点都是在寺庙附近的；和各种大寺相关的公园非常多，有寺庙，就有公园，就有风景。\n二条城 这个城是一个将军府，距离天皇住所不远。麻雀虽小五脏俱全，它内城和外城，有两层的护城河，城墙是很低的。\nFrom wiki\n 二条城是一座位于日本京都府京都市中京区二条城町的城堡，建设于江户时代初期（1603年）。曾经是德川家康的寓所。位于京都市街的一座平城。1994年，被联合国教育科学文化组织列入世界遗产中的古都京都的文化财之一。狭义上，二条城，就是江户时代筑起的城池，但是在广义上，是指第十三代室町幕府将军足利义辉的居城、织田信长为十五代将军足利义昭建造的城池，1573年织田信长举兵将足利义昭放逐河内，此城便被焚毁，在其它地方另筑二条御所，之后献给皇太子。但是一般所提及的二条城，是德川家康筑城的二条城（朝廷则称之为二条亭）。1867年（庆应3年）第十五代将军德川庆喜，在二条城举行“大政奉还”仪式，将政权归还给了天皇，二条城因而闻名。1871年（明治4年） 二之丸御殿作为京都府厅舍。1873年（明治6年）除二之丸外归陆军省。1885年（明治18年）京都府的新厅舍完成移转新址后，二之丸御殿开始修理直到1892年（明治25年）。1893年（明治26年）到1894年（明治27年）将桂宫邸本丸移筑，始有本丸御殿。1915年（大正4年）大正天皇即位仪式大典于二之丸御殿举行，并开始增建南门二之丸御殿的附属建物。1939年，天皇又将之赐给宫内省，并于隔年更名为“元离宫二条城”，正式对外开放参观。\n 这是一个比较小规模的景点，出了地铁站，东门正在维修，绕到北门，顺序参观完了外城、内层和各种建筑。这座建筑也是重建的，大约有80多年的历史，曾经被焚毁；最近一次好像是被雷击失火。\n鸭川 我下图的跑步路线大约就是鸭川的主要部分。其中三条到5条的河岸左侧就是京都旧市井的所在，感觉像是北京的南锣鼓巷，不过原貌保护的更好一些。 炸猪排饭 日餐里面的食物和中餐是非常相似的，随便进一个店，都不用为吃啥发愁；有些饭馆是有日文、英语和中文菜单的。下图是一家专门做炸猪排饭的饭馆。这家饭馆主要做三总餐：炸猪排饭、红烧猪排饭和炸大虾饭。套餐的价格在900日元左右，量还是比较多的。我点了一杯扎啤配炸猪排饭味道非常好。\n这家餐厅吃了两次，感觉非常好，年长的老人在店里带领几个非常年轻的孩子们，把这家店搭理的井井有条。看着食物制作的每一个工序，感觉还是不错的。\n",
    "ref": "/blog/kyoto/"
  },{
    "title": "Nutanix AHV 虚拟机模板制作",
    "date": "",
    "description": "",
    "body": "本文描述了AHV虚拟化的虚拟机模板的制作过程。首先使用ssh登录cvm，进入acropolis命令行。\n找出模板对应的虚拟机 使用 vm.disk_get 命令，按多次tab，显示虚拟机清单，复制模板机名称\n\u0026lt;acropolis\u0026gt; vm.disk_get vm-fedora25 ide.0 { addr { bus: \u0026quot;ide\u0026quot; index: 0 } cdrom: True empty: True } scsi.0 { addr { bus: \u0026quot;scsi\u0026quot; index: 0 } container_id: 4427 container_uuid: \u0026quot;9279ba2c-8e8d-4aea-b00f-410df5a18a23\u0026quot; vmdisk_size: 10737418240 vmdisk_uuid: \u0026quot;7476458e-7917-4df8-b830-a0df5a95dae9\u0026quot; } 创建模板镜像 使用从虚拟机磁盘克隆出镜像的命令。\n \u0026lt;acropolis\u0026gt; image.create fedora25-Template clone_from_vmdisk=7476458e-7917-4df8-b830-a0df5a95dae9 image_type=kDiskImage annotation='Fedora 25 Server Template' fedora25-Template: complete 模板测试 登录Prism界面，点击镜像服务，确认清单中刚才创建的虚拟机模板镜像；进入vm页面，创建虚拟机，使用 fedora25-Template 镜像做磁盘\n",
    "ref": "/blog/clone-ahv-vm-template/"
  },{
    "title": "DevOps术语表",
    "date": "",
    "description": "",
    "body": "简介 这份术语表的旨在为DevOps实践者提供参考，在重要的专业术语上保持一致。最初的来源是《DevOps Handbook》英文版。译者在翻译的过程中，梳理和总结了一部分。Exin的DOP认证考试基于此书，考试样题也影响和参考了本术语表。本术语表是开放的，欢迎各界业内人士对其修订和增补。目标是形成一份较为完整和准确的参考资料。参与修订的方式见页脚。欢迎但不限于以下方面的专家参与评审和修订：\n 敏捷开发 精益/精益UX/精益创业 丰田生产系统 ITIL 互联网公司 传统企业  这个页面的另外一个存在：https://handbook.martinliu.cn/glossary/\n变更日志  2017年1月7日，在Martin‘s Blog和Github上发布了第一个版本。有几个人在Github上参与了修订（请参与者通过邮件或者其他方式告诉我，这里希望再次申明致谢。） 2017年12月27日，参与修订的人包括卢梦纯（Exin）、刘征、张乐、Wang Jun和许峰。 本网页当前接受繁体中文的增补，所有参与者名单  术语表    英文 中文     A/B Testing A/B测试   Acceptance Stage 验收阶段   Acceptance Test-Driven Development (Atdd) 验收测试驱动开发   Acceptance Tests 验收测试   Accident 事故   Affinity 亲和   Agile 敏捷   Andon Cord 安灯拉绳   Anomaly Detection Techniques 异常探测技术   Antifragility 抗脆弱性   Application Deployment 应用部署   Artifact Management 构件制品库管理   Artifacts 制品   Automated Tests 自动化测试   Automation 自动化   Backlog 待办事项列表   Bad Apple Theory 坏苹果理论   Bad Paths 失败路径   Batch Sizes 批次尺寸、批量大小   Blame 责备   Blameless Post Mortem 免责事后分析   Blamelessness 免责   Blue-Green Deployment 蓝绿部署   Blue-Green Deployment Pattern 蓝绿部署模式   Branching Strategy 分支策略   Brownfield 棕地   Build 构建   Business Value 业务价值   Canary Release 金丝雀发布   Canary Release Pattern 金丝雀发布模式   Card 卡片   Change Categories 变更类别   Change Schedules 变更计划   Cloud Computing 云计算   Cloud Configuration Files 云配置文件   Cluster Immune System Release Pattern 集群免疫系统发布模式   Code Branch 代码分支   Code Review Forms 代码审查表   Codified Nfr 成文的非功能需求   Collaboration 协作   Commit Stage 提交阶段   Commit Code 提交代码   Compliance Requirement 合规性要求   Compliance Checking 合规性检查   Compliancy Officer 合规检测官   Configuration Management 配置管理   Container(S) 容器   Continuous Deployment 持续部署   Continuous Integration 持续集成(CI)   Continuous Delivery 持续交付(CD)   Conways Law 康威定律   Cycle Time 周期时间   Defect Tracking 缺陷跟踪   Definition Of Done (Dod) 完成的定义   Dev Rituals 开发仪式   Developer 开发人员   Development 开发   Devops Transformation DevOps转型   Downstream/Upstream 下游/上游   Downwards Spiral 恶性循环   E-Mail Pass-Around 电子邮件轮查   Expand/Contract Pattern 扩张/收缩模式   Exploratory Test 探索性测试   Fast Feedback 快速反馈   Feature 特性   Feature Flag 特性标志   Feature Toggles 特性开关   Feedback/Feedback Loop 反馈/反馈回路   Feedforward/Feedforward Loop 前馈/前馈回路   Flow 流   Gated Commit 门控提交   Gaussian Distribution 高斯分布   Green Build 绿色构建   Greenfield 绿地   Handoff 交接   Hand-Off Readiness Review 交接就绪评审   Happy Paths 快乐路径   Hypothesis-Driven Development 假设驱动开发   Incident 事件   Information Radiators 信息辐射器   Infosec 信息安全   Infrastructure Automation 基础架构自动化   Infrastructure As Code 基础设施即代码   Integration Tests 集成测试   I-Shaped, T-Shaped, E-Shaped I型，T型，E型   Iteration 迭代   Itsm (It Service Management) IT服务管理   Ji-Kotei-Kanketsu (Jkk) 质量检查（JKK）   Just Culture 公正文化   Just-In-Time (Jit) 准时制   Kaizen (In Lean) 持续改善   Kaizen Blitz (Or Improvement Blitz) 持续改善闪电战   Kanban 看板   Kata Kata   Large Batch Size Merge 大批量合并   Latent Defects 潜在缺陷   Lauching Guidance 发布指导   Launch Readiness Review 投产就绪评审   Lead Time 前置时间   Lean 精益   Learning Culture 学习文化   Logging Levels 日志级别   Loosely Coupled Architecture 松耦合架构   Micro-Services 微服务   Minimum Viable Product 最小化可行产品   Monitoring Framework 监控框架   Monolithic Applications 单体应用   Monolytics 单体应用   Mttr 平均恢复时间   Non-Functional Requirement (Nfr) 非功能性需求   Non-Functional Requirement (Nfr) Testing 非功能需求测试   (Non) Ideal Testing Pyramid （非）理想测试金字塔模型   One-Piece-Flow 单件流   Operations 运维   Operations Story 运维故事   Ops Liaison 运维联络人   Organisational Typology Model 组织结构模型   Organization Archetypes 组织原型   Organizational Learning 组织级学习   Over-The-Shoulder 观察者评审   Packages 包   Pair Programming 结对编程   Peer Review 同行评审   Pilot 试点   Pipeline 流水线   Plan-Do-Check-Act Cycle (Pdca Cycle) 计划-实施-检查-改进 （戴明环）   Post Mortems 事后回顾   Post-Mortem 事后剖析   Process Time 处理时间   Product Owner 产品负责人   Pull Request Process 拉动请求流程   Qa 质量保证   Reduce Batch Size 降低批次尺寸   Reduce Number Of Handoffs 减少交接次数   Regression Test 回归测试   Release Branch 发布分支   Release Managers 发布经理   Release Patterns 发布模式   Retrospective 回顾   Rhythm 节奏   Roll-Back 回滚   Sad Path 悲伤路径   Safety Culture 安全文化   Safety Conditions 安全条件   Scaling 规模化   Scrum Scrum   Scrum Master Scrum Master   Security Testing 安全测试   Self Service Capability 自服务能力   Service Deployment 服务部署   Service Level Agreement (Sla) 服务级别协议(SLA)   Shared Goals 共享目标   Shared Operations Team (Sot) 共享运维团队   Shared Version Control 共享版本控制   Single Repository 单一存储库   Smoke Testing 冒烟测试   Sprint 冲刺   Staging Staging   Staging Environments, Sit 准生产环境   Stakeholder 利益干系人   Standard Deviation 标准差   Standard Operations 标准运维   Static Code Analysis 静态代码分析   Swarm 聚集、聚焦、会诊、围观（动词）   Swarming 聚集   System Of Engagement (Soe) 交互系统   System Of Records (Sor) 记录系统   Technical Debt 技术债务   Technology Adaption Curve 技术适应曲线   Technology Executives 技术主管   Telemetry 遥测   Test Coverage Analysis 测试覆盖率分析   Test Story 测试故事   Test-Driven Development 测试驱动开发   The Downward Spiral - Tds 下行螺旋   The Agile Manifesto 敏捷宣言   The Lean Movement 精益运动   The Simian Army: Chaos Gorilla, Chaos Kong, Conformity Monkey, Doctor Monkey, Janitor,Monkey, Latency Monkey, Security Monkey 猿猴军团（可靠性监控服务），Chaos Gorilla（混沌大猩猩）， Chaos Kong（混沌金刚）, Conformity Monkey（一致性猴子）, Doctor Monkey（医生猴子）, Janitor Monkey（看门猴子）, Latency Monkey（延迟猴子）, Security Monkey（安全猴子）   The Three Ways 三步工作法   Theory Of Constraints 约束理论   Ticketing System 工单系统   Tightly-Coupled 紧耦合   Tool-Assisted Review 工具辅助评审   Tools 工具   Toyota Production System (Tps) 丰田生产系统   Toyoto Kata 丰田套路   Transformation Team 转型团队   Trunk 主干   User Story 用户故事   Value Stream Mapping 价值流映射   Value Stream 价值流   Velocity 速率   Version Control 版本控制   Virtualized Environment 虚拟化环境   Visible 可视的   Visualisation 可视化   Waste 浪费   Waste Reduction 减少浪费   Waterfall 瀑布式   Wip (Work In Progress / Process) 在制品   Wip Limit 在制品限制   Work Center 工作中心                    参与修订说明 请帮忙改进本术语表，请直接Fork本代码库，然后提交PR；或者发邮件到：liuzh66@gmail.com\n建议最好提供修订原文的简要说明和参考依据。\nGitHub操作注意事项：\n 建议Fork整个repo做批量更新，小批量可以直接在github网页上提交 请不要完全删除之前的翻译，可以把旧翻译划横线（使用markdown），在右边添加新的中文意思。  ",
    "ref": "/2017/01/07/devops-glossary/"
  },{
    "title": "Nutanix资源站点清单",
    "date": "",
    "description": "",
    "body": "做Nutanix的那些不可不知道的资源网站，这里列出了常用的官方和非官方网站。\nNutanix 官方站点 http://portal.nutanix.com/ http://portal.nutanix.com/\n 在线文档 在线技术支持，case查看和操作 产品和补丁下载  https://next.nutanix.com/ https://next.nutanix.com/\n 产品网上论坛和社区 社区版论坛 博客， Nutanix Connect Blog  技术达人网站和博客 myvirtualcloud.net by Andre Leibovici http://myvirtualcloud.net/nutanix/\nVirtual life style by Joep Piscaer https://www.virtuallifestyle.nl/\nThe Nutanix Bible by Steven Poitras http://nutanixbible.com/\nMark\u0026rsquo;s Blog by Mark Lavi http://mlavi.github.io/\nJeremy Sallee - Nutanix UI/Frontend 设计师 http://salleedesign.com/stuff/sdwip/home/\n想知道Prism是怎么设计出来的：点这里\nVirtual Dennis by Dennis Laube http://www.virtualdennis.com/category/nutanix/\n 如何ova格式的虚拟机导入Nutanix AHV 镜像服务能够支持Web界面上传导入的格式包括：raw, vhd, vmdk, vdi, iso 和 qcow2 磁盘，导入为Disk后，即可用做模板 如何在Nutanix中制作AHV虚拟机模板 使用acli命令：vm.disk_get；image.create W2K12R2-Template clone_from_vmdisk=69df5abd-6570-4ce1-ba77-2d117c3df7e5 image_type=kDiskImage   其他资源 Nutanix viso 图标下载 http://www.visiocafe.com/nutanix.htm\n",
    "ref": "/2017/01/07/nutanix-resource-sites/"
  },{
    "title": "云计算时代的终结",
    "date": "",
    "description": "",
    "body": "天下事分久必合，合久必分，移动互联网代表了现在的云计算时代，很多企业还正在朝这个方向发展呢！革命还没有成功，怎么这个时代就要结束了。来听听XenSource前CEO怎么给你解读边缘计算时代的到来。\n“I’m going to take you out to the edge to show you what the future looks like.” So begins a16z partner Peter Levine as he takes us on a “crazy” tour of the history and future of cloud computing — from the constant turns between centralized to distributed computing, and even to his “Forrest Gump rule” of investing in these shifts.\nBut… how can we say cloud computing is coming to an “end” when it hasn’t even really started yet?? Because the edge — where self-driving cars and drones are really data centers with wheels or wings — is where it’s at. So where does machine learning in the enterprise come in? How does this change IT? As software programs the world, these are some of the shifts to look at…\n视频在这里 在线观看。\n\n",
    "ref": "/2017/01/05/The-End-of-Cloud-Computing/"
  },{
    "title": "Nutanix AOS 5.0 新版本新特性",
    "date": "",
    "description": "",
    "body": "Nutanix AOS 5.0 是一个很重要的功能更新大版本，它一气儿带来了46项之多的新功能；在您安装或者测试这个版本\u0026gt; 之前，先通过本文快速了解一下这些更新，可能是更加节省时间的方法。\n主要功能清单 myvirtualcloud.net网站用了4个blog，讲了下面的36项新特性：\n Cisco UCS B-Series Blade Servers Support Acropolis Affinity and Anti-affinity Acropolis Dynamic Scheduling (DRS++) REST API 2.0 and 3.0 Support for XenServer TechPreview Network Visualization What-if analysis for New workloads and Allocation-based forecasting Native Self-Service Portal Snapshots – Self Service Restore UI Network Partner Integration Framework Metro Availability Witness VM Flash Mode Improvements Acropolis File Services GA (ESXi and AHV) Acropolis Block Services (CHAP authentication) Oracle VM and Oracle Linux Certified for AHV SAP Netweaver stack Certified for AHV Prism Search Improvements (support for Boolean expressions) I/O Metrics Visualization 1-Click Licensing LCM – Lifecycle Manager Additional Prism Improvements AHV Scale Improvements AHV CPU and Memory Hot Add (Tech Preview) Advanced Compression for Cold Data Acropolis Change Block Tracking (CBT) for Backup Vendors Predictable Performance with Autonomic QoS NCC 3.0 with Prism Integration 1-Node Replication Target Improved Mixed Workload Support with QoS Simplified SATADOM Replacement Workflow Mixed Node Support with Adaptive Replica Selection Dynamically Decreased Erasure Coding Stripes – Node Removals Multi Metadata Disk Support for use available SSDs on the node for metadata Erasure Coding(EC) support for changing the Replication Factor (RF) on containers Inline Compression for OpLog Linux Kernel Upgrade   Nutanix 5.0 Features Overview (Beyond Marketing) – Part 1 Nutanix 5.0 Features Overview (Beyond Marketing) – Part 2 Nutanix 5.0 Features Overview (Beyond Marketing) – Part 3 Nutanix 5.0 Features Overview (Beyond Marketing) – Part 4  Nutanix官方Blog新版本介绍 Nutanix 官方Blog的新版本发布帖 The 5.0 Release is Here\nNutanix AOS 5.0 is available now for you to download and will carry a huge payload of innovation across Acropolis – the data plane, Prism – the management plane and AHV – built-in hypervisor. Over the last couple of months we have spoken about different capabilities that will be part of this release. Before we get into details of the release, it is important to take a step back and understand how the core platform is evolving.\n These services are announced but will be generally available in a subsequent product release  To deliver on the vision of Enterprise Cloud and offer public cloud-like services within the datacenter, it is important for us to provide infrastructure services similar to what the public cloud offers. Different workloads have different infrastructure needs and it is important to provide services that can be “turned-on” and “turned-off” based on applications needs – all without having to touch the underlying physical infrastructure. This is exactly what AWS does and that is what we are working towards with our Enterprise Cloud Platform as well.\nHere is a comparison of some of these infrastructure services offered by AWS and Nutanix. The core tenets of the public cloud and the pay-as-you-grow economics are as applicable to Nutanix as it is to the public cloud.\nThe 5.0 release adds new infrastructure services to the platform and enhances the ones that already exist; delivering greater flexibility and potential cost savings for IT organizations of all sizes. With over 45 new capabilities in the software and hundreds of feature enhancements, this release is definitely a huge milestone for us.\nWhile it is impossible for us to cover all the capabilities in detail in one single blog, let me attempt to do a quick walk through of the ones we think you will love!\nAcropolis – Data Plane Enhancements Acropolis File Services (AFS)Generally Available: AFS is a natively built file storage service that eliminates the need for standalone NAS solutions. This capability was in Tech Preview for the past several months and is generally available with the 5.0 release. With AFS, customers can consolidate their virtual machines and the file data they rely on within the same cluster. AFS will work on ESXi and AHV hypervisors for a wide variety of use cases such as user-profiles, home directories, archives and more. You can learn more about this capability in this blog. Here is a quick summary blog on AFS.\nAcropolis Block Services (ABS) Enhancements: ABS, like AFS, is natively built to expose storage to non-virtualized workloads. This capability was introduced in the 4.7 release. We have significantly enhanced ABS in 5.0 with support for dynamic load balancing and flash pinning for better performance, improved security through CHAP for safer client-server conversations and online resizing for higher availability. Additionally, Oracle joins the list of certified workloads on ABS. Here is a quick summary blog on ABS.\nMetro Availability Witness: Metro Availability is Nutanix’s synchronous replication solution for DR. Metro Availability Witness is a light-weight service that will be able to run anywhere to enable automatic failover from one site to another without service disruption by monitoring the status of both sites.\nCompression Enhancements: The compression algorithm used for capacity optimization has significantly improved in the 5.0 release resulting in more efficient data compression. Additionally, on All-flash systems, compression will be turned on by default. With compression, deduplication, erasure coding and other native capacity optimization capabilities, customers can achieve up to 4:1 savings (depending on data type).\nSingle-node Replication Target: One of the common asks from Remote and Branch office/SMB customers was to have a single-node backup/replication target for smaller deployments of Nutanix. This enables customers to use native backup capabilities and replicate data to a storage heavy node of Nutanix that can be on the same site or a different remote site. With 5.0, this is possible with the single Nutanix node having ~40TB of raw capacity and act as a destination for backup/snapshot data.\nAHV – Hypervisor Enhancements AHV, the native hypervisor solution from Nutanix, continues to grow leaps and bounds with several customers standardizing on AHV for all workloads. We have continued to add newer capabilities with every release of the product. 5.0 is no different and adds a couple of very important capabilities.\nAHV Affinity Rules: Workloads such as Microsoft SQL or Oracle are often attached to a specific node for licensing, security or HW configuration related reasons. With affinity rules, virtual machines can now be “pinned” to a specific host or a set of hosts. Additionally AHV will also support VM VM anti-affinity rules to try ensure that specific VMs are never on the same host together.\nAcropolis Dynamic Scheduling (ADS): AHV has supported intelligent initial placement for a while now to make sure VMs are placed on the most optimal hosts when they are initially deployed. With ADS, the hypervisor can detect CPU, memory and storage controller hotspots and can move deployed VMs to a host that is ideal suited. Legacy hypervisor solutions factor in CPU and memory alone while making similar decisions. But with AHV, the VM placement algorithms will also factor in storage resources as well as storage controller bottlenecks before making a decision.\nCPU/Memory Hot Add: With this capability, administrators can add vCPU and memory to a running VM without any service impact. As applications evolve, it is important to dynamically adjust resources assigned to them so that there is no performance impact for the end user. This is what the hot add feature will enable. In the 5.0 release, this feature will be available in Tech preview and is expected to be generally available in a subsequent release.\nWith these capabilities, AHV is ready for all your production workloads and there is very little reason as to why any virtualized workload cannot be run on Nutanix and on AHV. Nutanix customers are already standardizing on AHV and are seeing significant savings in the overall cost of ownership across their entire infrastructure stack.\nPrism – Management Plane Enhancements Over the last year Prism has evolved into a product suite of its own – with Prism Starter and Prism Pro, customers now have an option of choosing a one-click infrastructure management solution or a one-click infra management and operations management solution based on their needs.\nPrism Self-Service: Self-service will bring the goodness of AWS to enterprise datacenters. With this new capability, end-users can login to Prism with their own AD credentials and deploy and monitor applications whenever they want, based on Admin set policies. This removes common friction around developers and end users having to rely on IT admins for common tasks. Instead, administrators just assign resources for specific users or AD groups and end users have complete independence to perform actions that he/she is allowed to do. Here is a quick blog that summarizes this capability.\nNetwork Visualization: This is another key capability that is part of Prism. With Network Visualization, administrators will be able to get an end-to-end operational view of the infrastructure all the way down to the networking layer. With views that provide insight into how virtual machines are connected to the host, NICs, the top of rack switches, the VLANs they are part of as well as the health of these connections, administrators will be able to get all the information they want about their infrastructure in a single screen, without having to rely on separate tools. This will help isolating and fixing common networking issues that result in application downtimes.\nESXi Management: The simplicity of VM management with Prism will extend to ESXi as well with this release – common VM operations that customers relied on vCenter for will be performed from within Prism. One of the common asks from customers was to not go back and forth to vCenter and instead consolidate all operations on Prism. In the first release as part of 5.0, Prism will enable administrators to perform common VM operations such as VM create, update, delete, clone etc. from within Prism. Combining VM operations and the rich monitoring and analytics, vCenter is only needed for less common maintenance and configuration tasks. With the hypervisor becoming commodity, end users get greater simplicity at the management layer.\nJust-in-time Capacity Forecasting (available in Prism Pro): This is probably one of the most important additions to Prism. Just-in-time forecasting will enable IT to stay ahead of the game by modeling and understanding infrastructure needs based on application requirements even before applications are deployed. This way, IT not only understands application-centric capacity usage patterns and what can be done to optimize existing capacity, they can also plan their infrastructure needs for the future and deploy infrastructure if and only when they need them at “byte” sized granularity all based on recommendations from Prism.\nSearch Enhancements (Available in Prism Pro): One of the core aspects to delivering a personalized and consumer-grade management experience is to enable administrators to perform actions the same way they would do it in their personal lives. Prism Search, a Google like search engine, was introduced earlier this year so that administrators can perform all administrative actions through a simple search query. With support for Boolean expressions, saved searches, auto correct, synonyms based search and more, the 5.0 release will take Prism Search to a whole new level. As an example, administrators can type in “vm iops \u0026lt;1500” and quickly see all the VMs across all the sites that have IOPS less than 1500.\n有用链接：\n 西瓜哥的微信文章介绍了部分上面的更新 点这里。 Acropolis 5.0 release notes Nutanix Cluster Check 3.0 release notes Nutanix Cluster Check 3.0 download PRISM Central 5.0 release notes  ",
    "ref": "/2017/01/04/Nutanix-AOS-5.0/"
  },{
    "title": "DevOps书单",
    "date": "",
    "description": "",
    "body": "学习DevOps应该会使用到的书籍清单。\n我在豆瓣建立了一个书单，欢迎在豆瓣给我留言，评论和建议。豆瓣书单点这里。\n 本清单来自于《DevOps Handbook》书中提到的书，更新到第五本；《看板方法》、《精益思想》、《Implementing Lean Software Development: From Concept to Cash》、《第五项修炼:学习型组织的艺术与实践》、《探索吧!深入理解探索式软件测试》\n《看板方法-科技企業漸進變革成功之道》 转自：Rubbyblog.wordpress.com/images/\n今天要介紹看板方法的由來， 上面這本書是由看板方法之父 David J. Anderson 於: 2010年 4月所著。簡字版是 2014 年2月出版。這篇文章在我上 TechDays 課程時就想登出來了，想把好書介紹給大家。但由於台灣的書商都沒有進口，所以一直等到我拿到第一批書後，肯定大家可以在坊間買到書時才把他登出來。原文書名: Kanban: Successful Evolutionary Change for Your Technology Business.\n看板方法：它是敏捷陣營中實施起來阻力最小，生產力又能大幅提升、前置時間大幅下降，而可預測性又絕佳的敏捷解決方案之一。好神奇喔 … 哈哈! 確實如此，所以我才會這麼急切的推薦給大家。另一個原因是Kanban Method 現在在美國正熱烈風行中，而我們現在開始追正是時候。為此放下了許多手上正在做的工作(包括一本 Scrum的教本)，努力開始推廣希望大家能受用。首先說明: 為何他推廣起來阻力最小?\n※ 實施起來阻力最小:\n因為David J. Anderson 本身是一個微軟的 PM出身，他跟大家一樣知道變革會讓許多人害怕，人們會認為自己的技術是否落伍了，開始擔心害怕變革會對自己的工作事業帶來不利，這種恐懼常常會帶來一種莫名的對立，因此在還沒開始變革之前就已經採取抵制的態度了。所以他創始的看板方法選擇從哪裡開始實施呢? 就從現在既有的流程開始。由工作者本身最熟悉的地方開始。起步的秘訣是甚麼呢? 是精實精神中從豐田系統中學來的原則，先從不浪費開始，作法: 在識別浪費後消除浪費。\n※ 如何能讓生產力大幅提升?\n由審視既有流程，依據 Little’s law的最大產出方法，接著找出阻礙最大產能的瓶頸所在，然後正視這個造成瓶頸的問題，把它顯現在看板上面，讓大家一起站在看板前面討論如何解決它，解決之後再持續進行改善的作業。\n※ 前置時間大幅下降\n過去我們都以為唯有透過良好的規劃及配合才能夠讓前置作業時間下降，但豐田企業的及時(Just In Time)備料讓庫存降至最低，讓半成品減至最少改變了工作流程的前置時間(Lead time)，因此得到大幅下降。\n看板還是看板方法 (Kanban or Kanban Method) 英文叫 Kanban，上網去搜尋會得到一大堆有關製造業的看板資料。所以請使用 Kanban Method去搜尋，因此中文就該叫做「看板方法」。簡體版的作者有用心在翻譯因此翻對了，值得買來閱讀。全書分成四部分:\n※ 第一部分；導讀: 作者說出他的想法，以及創作看板方法的原由。\n※ 第二部分；談使用看板方法的好處: 這裡有他個人做顧問時的經驗談，值得仔細閱讀。\n※ 第三部分；開始談實施看板方法的步驟了。(由六到十五章，好長又夠完整)\n※ 第四部分；談持續改進。在這裡你終於可以感受到精實軟體開發對作者的影響，以及作者由經濟學的角度來看精實軟體開發的第一原則: 消除浪費。\n接下來我就不在多說了，請讀者自己去看吧!(透漏一下，為了共襄盛舉，我正在寫一本有關精實開發的書，內容除了看板方法之外會大幅談到精實軟體開發，在這裡不想打廣告，因此書名就等出版後再說了!)\n精益思想(白金版) 这本书在亚马逊中国有售：https://www.amazon.cn/精益思想-詹姆斯P-沃麦克 简介\n《精益思想》于1996年秋季首次出版，历经20年，畅 销十多个国家，累计销量上百万册。本书的成功在于它对精益生产方式做了最 好的总结，为读者提供了精益的核心原则，实地考察了美国、德国、日本若干具有代表性的大小企业推行精益的实际情况和心得，为准备跨入精益之门和进一步学习、实施精益的人提供了最 好的指南，从而成为精益方面的经典著作。\n基本信息\n出版社: 机械工业出版社; 第1版 (2015年8月1日) 外文书名: Lean Thinking ：Banish Waste and Create Wealth in Your Corporation 丛书名: 精益思想丛书 平装: 365页 语种： 简体中文 开本: 16 ISBN: 7111510712, 9787111510710 条形码: 9787111510710 商品尺寸: 24 x 17.4 x 1.8 cm 商品重量: 621 g 品牌: 机械工业出版社 ASIN: B0142EC7AA 用户评分: 平均4.5 星 浏览全部评论 (82 条商品评论) 亚马逊热销商品排名: 图书商品里排第7,694名 Implementing Lean Software Development: From Concept to Cash 基本信息 出版社: Addison-Wesley Professional; 1 (2009年10月31日) 丛书名: Addison-Wesley Signature Series (Beck) 平装: 312页 语种： 英语 ISBN: 0321620704 条形码: 9780321620705 商品尺寸: 17.5 x 1.8 x 22.9 cm 商品重量: 499 g 品牌: Pearson ASIN: 0321620704 用户评分: 分享我的评价 亚马逊热销商品排名: 图书商品里排第1,441,726名 (查看图书商品销售排行榜) 第64位 - 图书 \u0026gt; 进口原版书 \u0026gt; Computers \u0026amp; Technology（计算机与科技） \u0026gt; Business \u0026amp; Management（商业与管理） \u0026gt; Project Management 第393位 - 图书 \u0026gt; 进口原版书 \u0026gt; Computers \u0026amp; Technology（计算机与科技） \u0026gt; Programming（编程） \u0026gt; Software Design, Testing \u0026amp; Engineering \u0026gt; Software Development 作者简介 Mary Poppendieck has led teams implementing various solutions ranging from enterprise supply chain management to digital media. Mary is the president of Poppendieck LLC, which specializes in bringing lean techniques to software development.\nTom Poppendieck, an enterprise analyst, architect, and agile process mentor, currently assists organizations in applying lean principles and tools to software development processes. The Poppendiecks are authors of Lean Software Development, winner of the 2004 Jolt Software Development Productivity Award, and Implementing Lean Software Development (both from Addison-Wesley).\nThe Fifth Discipline: The Art \u0026amp; Practice of The Learning Organization 基本信息 第五项修炼：学习型组织的艺术与实践  出版社: 中信出版社; 第1版 (2009年10月1日) 外文书名: The Fifth Discipline:The Art \u0026amp; Practice of The Learning Organization 平装: 455页 语种： 简体中文 开本: 16 ISBN: 7508616820, 9787508616827 条形码: 9787508616827 商品尺寸: 22.8 x 17 x 2.8 cm 商品重量: 739 g 品牌: 中信出版股份有限公司 ASIN: B002QMKJ4C 用户评分: 平均4.5 星 浏览全部评论 (322 条商品评论) 亚马逊热销商品排名: 图书商品里排第1,333名 (查看图书商品销售排行榜) 第6位 - 图书 \u0026gt; 经济管理 \u0026gt; 管理学理论与方法论 \u0026gt; 管理学基础理论 第17位 - 图书 \u0026gt; 经济管理 \u0026gt; 企业经营与管理 \u0026gt; 管理指南 第617位 - 图书 \u0026gt; 在线试读 编辑推荐 《第五项修炼:学习型组织的艺术与实践(新世纪全新扩充修订版)》由当代最杰出的新管理大师彼得•圣吉撰写的著作，被誉为21世纪的管理圣经、20世纪屈指可数的几本管理经典、世界上影响最深远的管理书籍之一，并被《哈佛商业评论》评为过去75年具有影响力的管理类图书，还荣获世界企业学会荣誉的开拓者奖！ 进入21世纪以来，全球经济的迅猛发展，使得全球企业管理趋势、管理理念也顺应发生了巨大的变化，作为新世纪全新扩充修订版，《第五项修炼:学习型组织的艺术与实践(新世纪全新扩充修订版)》其背后是15年来把原书理念付诸实践的经验和案例。圣吉明确指出，从长远来看，你的组织可持续的竞争优势，就是比对手更好更快的学习能力。15年前，许多《第五项修炼》的核心理念都曾显得很激进。但这些理念的许多应用方法，后来已经被融入到人们观察世界的方式中，也被整合到人们的管理实践中；《第五项修炼:学习型组织的艺术与实践(新世纪全新扩充修订版)》对前一版进行了全面修订，新版书中的领导力案例故事揭示了这些经历。并增添了新的内容：实践中的反思，为企业、个人读者更准确理解最新管理理念，对学习型组织进行了有效的反思，对建设学习型组织所面临的新疑惑提供了新的思维。\n名人推荐 流行的管理体系很摧残人……教育界、工商界和政府机构的管理层的任务，应该是使系统最优化……彼得·圣吉的著作《第五项修炼》是帮助开始这项工作的好书，它让我学到了许多东西。 ——爱德华·戴明博士，全面质量管理运动(TQM）的先驱。\n媒体推荐 《第五项修炼》是过去75年来最有影响力的管理学著作之一。 ——《哈佛商业评论》 圣吉的这本著作已经是一本不折不扣的管理学经典。 ——《波士顿环球报》\n作者简介 作者：（美国）彼得•圣吉 译者：张成林\n彼得•圣吉博士（Dr.Peter M. Senge），麻省理工学院斯隆管理学院的高级教授讲师，国际组织学习学会（SoL）和索奥中国（SoL China）的创始主席。除《第五项修炼》之外，他还与人合著了《第五项修炼实践篇》（1994）、《变革之舞》（1999）、《学习型学校》（Schools that Learn, 2000）、《体悟当下》（Presence, 2004），以及最近出版的《必要的革命》（The Necessary Revolution, 2008）等著作。圣吉被誉为最富创新精神的世界级管理学和领导学思想大师之一。他早年毕业于斯坦福大学工程专业，并获得麻省理工社会系统模型硕士和管理学博士，现家居美国马萨诸塞州。\nExplore It!: Reduce Risk and Increase Confidence with Exploratory Testing 探索吧!深入理解探索式软件测试 出版社: 机械工业出版社; 第1版 (2014年1月1日) 外文书名: Explore It! Reduce Risk and Increase Confidence with Exploratory Testing 丛书名: 软件工程技术丛书 平装: 151页 语种： 简体中文 开本: 16 ISBN: 9787111451587 条形码: 9787111451587 商品尺寸: 24.2 x 16.8 x 0.8 cm 商品重量: 281 g 品牌: 机械工业出版社 ASIN: B00IHQBQZC 编辑推荐 《探索吧!深入理解探索式软件测试》给出实用性很强的理念，可用于探索从典型GUI场景到测试软件需求的一切，还包括如何探索低层级代码的建议。此书不只是给软件测试人员看的，对软件管理人员、开发人员也具有重大意义。\n名人推荐 “Elisabeth开创了将探索式测试应用于敏捷开发的先河，并推动它不断演进，使其成为了一种主流实践。” ——Ward Cunnningham wiki概念的发明者 设计模式和敏捷软件方法的先驱之一\n“这是我看到的最佳书籍之一。优良的测试设计源自优良的测试思路，这本书里满是各种优秀的测试思路，辅以故事情节烘托，涎玉沫珠。” ——Alan Page 微软公司Principal SDEI《微软的软件测试之道》作者\nThe Field Guide to Understanding \u0026lsquo;Human Error‘ This latest edition of The Field Guide to Understanding ‘Human Error\u0026rsquo; will help you understand how to move beyond \u0026lsquo;human error\u0026rsquo;; how to understand accidents; how to do better investigations; how to understand and improve your safety work. You will be invited to think creatively and differently about the safety issues you and your organization face. In each, you will find possibilities for a new language, for different concepts, and for new leverage points to influence your own thinking and practice, as well as that of your colleagues and organization.\nProduct Details File Size: 3149 KB Print Length: 247 pages Publisher: Ashgate; 3 edition (December 28, 2014) Publication Date: December 28, 2014 Sold by: Amazon Digital Services LLC Language: English ASIN: B00Q8XCSFI Text-to-Speech: Enabled X-Ray: Not Enabled Word Wise: Enabled Lending: Not Enabled About the Author Sidney Dekker (PhD Ohio State University, USA, 1996) is currently professor at Griffith University in Brisbane, Australia, where he runs the Safety Science Innovation Lab. He is also Professor (Hon.) of psychology at The University of Queensland, and Professor (Hon.) of human factors and patient safety at the Royal Children\u0026rsquo;s Hospital in Brisbane. Previously, Sidney was Professor of human factors and system safety at Lund University in Sweden. After becoming full professor, he learned to fly the Boeing 737, working part-time as an airline pilot out of Copenhagen. Sidney is the best-selling author of a multitude of human factors and safety books, including, most recently, Safety Differently (2014), Second Victim (2013), Just Culture (2012), Drift into Failure (2011), and Patient Safety (2011).\nLean IT: Enabling and Sustaining Your Lean Transformation ###Review\nThis book will have a permanent place in my bookshelf. In my ten-year study of high performing IT organizations, I’ve found that businesses rely on IT far more than they think. The impacts of poor flow from application development into IT operations can be devastating: ever increasing cycle times and amounts of rework, and an ever increasing amount of heroics required in IT operations to preserve the illusion of stability and reliability. ―Gene Kim, Chief Technology Officer, Tripwire, Inc.\nThere has never been a more critical time to improve how IT integrates with the global business enterprise. This book provides an unprecedented look at the role that Lean will play in making this revolutionary shift and the critical steps for sustained success. ―Steve Castellanos, Lean Enterprise Director; Nike, Inc.\nTwenty years from now the firms which dominate their industries will have fully embraced lean strategies throughout their IT organizations. Ten years from now those organizations will have started pulling ahead of their competitors as the result of lean IT. Today this book will show those organizations the path they need to start out on. Will your organization be one of them? ―Scott W. Ambler, Chief Methodologist for Agile and Lean, IBM Rational\n\u0026hellip; goes both wide and deep in its exploration of Lean … a great survival manual for those needing nimble and adaptive systems. ―Dr. David Labby, MD, PhD, Medical Director and Director of Clinical Support and Innovation, CareOregon\nThis book makes a major contribution in an often-ignored but much-needed area. It ranges over a huge area – including excellent cases – that will bring IT professionals into the Lean fold but will also enable Lean managers to reach out to IT. ―John Bicheno, Program Director MS in Lean Operations, Cardiff University\n… a comprehensive view into the world of Lean IT, a must read! ―Dave Wilson, Quality Management, Oregon Health \u0026amp; Science University\n###About the Author\nSteve Bell, CFPIM brings over twenty years' experience in finance, operations management and information systems. He is the author of Lean Enterprise Systems, Using IT for Continuous Improvement. (2006)\nMike Orzen, CMA, CFPIM, PMP delivers a unique blend of IT, operations management, Lean, Six Sigma, and project management. With a BA from Stanford University in economics and an MBA from the University of Oregon, Mike has been consulting, coaching, and teaching for over 20 years.\nSteve and Mike are faculty members of the Lean Enterprise Institute. Together, the authors combine their experience in information systems and process improvement to share their lessons learned.\nProduct Details Hardcover: 370 pages Publisher: Productivity Press; 1 edition (September 14, 2010) Language: English ISBN-10: 1439817561 ISBN-13: 978-1439817568 Product Dimensions: 6.1 x 1 x 9 inches Shipping Weight: 1.4 pounds (View shipping rates and policies) Average Customer Review: 4.9 out of 5 stars See all reviews (20 customer reviews) Amazon Best Sellers Rank: #129,956 in Books (See Top 100 in Books) True North: Discover Your Authentic Leadership ###Review\n\u0026ldquo;With great clarity and insight, Bill George and Peter Sims make a persuasive argument that the journey toward authentic leadership—that finding and pursuing your own True North\u0026ndash;is the key to leadership in all fields, whether in business, government, or the nonprofit arena.\u0026rdquo; —From the Foreword by David Gergen\n\u0026ldquo;In True North, Bill George once again provides a roadmap for leadership in the 21st Century. The future belongs to leaders who want to win, without ever losing track of their own values. We live in a day when the best people can work anywhere. They will follow only authenticity—a person who leads with passion and purpose.\u0026rdquo; —Jeff Immelt, CEO, General Electric\n\u0026ldquo;True North is an awe-inspiring gift to the world. The 125 men and women whose leadership journeys are so beautifully rendered in this book show us that we can have enormous impact without compromising our values—indeed, that we are more successful when we stay true to our ideals. Every aspiring leader (or leader who aspires to become even better) will draw strength and wisdom from this wonderful book.\u0026rdquo; —Rosabeth Moss Kanter, Harvard Business School professor and best-selling author of Confidence: How Winning Streaks \u0026amp; Losing Streaks Begin \u0026amp; End\n\u0026ldquo;True North is about the power of authentic leadership. Great leaders are defined by a sense of passion and purpose and by a profound desire to make a difference. Anyone can find their own True North, if you care deeply and love what you do. This book is a wonderful roadmap for how to get started on the journey.\u0026rdquo; —Andrea Jung, chairman and CEO, Avon Products, Inc.\n\u0026ldquo;If you want to move your leadership in the right direction, read True North. Drawing on the personal stories of some of the world’s most effective leaders, the book shows that you become a successful leader when you stay on course with your highest self.\u0026rdquo; —Ken Blanchard, coauthor of The One Minute Manager® and Leading at a Higher Level\n\u0026ldquo;True North provides a new leadership paradigm and a window into the stories and approaches of dozens of our nation’s best leaders. It is an inspirational, invaluable source of guidance for those who want to make a significant impact.\u0026rdquo; —Wendy Kopp, president and founder of Teach for America\n\u0026ldquo;True North reveals just how powerful authentic leadership can be and, best of all, how to achieve it.\u0026rdquo; —Warren Bennis\nProduct Details Hardcover: 251 pages Publisher: Jossey-Bass; 1 edition (March 9, 2007) Language: English ISBN-10: 0787987514 ISBN-13: 978-0787987510 Product Dimensions: 6.3 x 1 x 9.4 inches Shipping Weight: 1 pounds Average Customer Review: 4.5 out of 5 stars See all reviews (129 customer reviews) Amazon Best Sellers Rank: #17,250 in Books (See Top 100 in Books) Gemba Walks Editorial Reviews In 12 new essays, ranging from the provocative to the practical and written specially for the second edition of Gemba Walks author and management expert Jim Womack reflects on the past 30 years of lean, and assesses the current state of lean today. He also shares thoughts on how lean thinking and practice can continue to make the world a better place by gaining traction in areas such as government and healthcare, provides practical guidance for how leaders everywhere can realize the full benefits of a lean management system, and shares hope for continued improvement on the path to better work and more value. Over the past 30 years, Womack has developed a method of going to visit the gemba at countless companies and keenly observing how people work together to create value. He has shared his thoughts and discoveries from these visits with the lean community through a monthly letter. With Gemba Walks second edition, Womack has selected and re-organized his key letters, as well as written 12 new essays. Gemba Walks shares his insights on topics ranging from the application of specific tools, to the role of management in sustaining lean, as well as the long-term prospects for this fundamental new way of creating value. Reading this book will reveal to readers a range of lean principles, as well as the basis for the critical lean practice of: go see, ask why, and show respect. Womack explains: • whatever happened to Toyota and what happens next to lean? • how lean got its name 25 years ago; a special essay co-authored by Jim and John Krafcik, president and CEO, Hyundai Motors America • work, management, and leadership \u0026ndash; what is the real work of the lean leader? • don’t offshore or reshore –leanshore • why companies need fewer heroes and more farmers (who work daily to improve the processes and systems needed for perfect work and who take the time and effort to produce long-term improvement) • how “good” people who work in “bad” processes become as “bad” as the process itself • how the real practice of showing respect comes down to helping workers frame and solve their own problems • how the short-term gains from lean tools can be translated to enduring change from lean management. • how the lean manager has a “restless desire to continually rethink the organization’s problems, probe their root causes, and lead experiments to test the best currently known countermeasures” By sharing his personal path of discovery, Womack sheds new light on the continued adoption and development of the most important new business system of the past fifty years. His journey will provide courage and inspiration for every lean practitioner today.\n###Product Details\nPaperback: 311 pages Publisher: Lean Enterprise Institute, Inc.; 2nd ed. edition (January 1, 2013) Language: English ISBN-10: 193410938X ISBN-13: 978-1934109380 Product Dimensions: 6 x 1 x 8.9 inches Shipping Weight: 1.6 pounds Average Customer Review: 3.7 out of 5 stars See all reviews (10 customer reviews) Amazon Best Sellers Rank: #357,633 in Books (See Top 100 in Books) 11799 in Books \u0026gt; Textbooks \u0026gt; Business \u0026amp; Finance 39798 in Books \u0026gt; Business \u0026amp; Money Continuous Delivery: Reliable Software Releases Through Build, Test, and Deployment Automation\n持续交付：发布可靠软件的系统方法\nhttp://item.jd.com/10843669.html\nEric J.Evans在《领域驱动设计》一书中\n**Domain Driven Design by Eric J. Evans.\n《Architecture and Patterns for IT Service Management, Resource Planning, and Governance: Making Shoes for the Cobbler’s Children, observes》\n正如Steven j. Spear在他的书《The High-Velocity Edge》\n1984年由Eliyahu M. Goldratt博士写的《目标：简单而有效的常识管理》。\n2009年，Mike Rother编写了《丰田套路：转变我们对领导力与管理的认知》（Toyota Kata: Managing People for Improvement, Adaptiveness and Superior Results）\nValue Stream Mapping: How to Visualize Work and Align Leadership for Organizational Transformation\n(英语) 精装 – 2013年12月16日 Karen Martin (作者), Mike Osterling (作者)\nhttps://www.amazon.com/dp/B00EHIEJLM/ref=dp-kindle-redirect?_encoding=UTF8\u0026amp;btkr=1\nIn the book Implementing Lean Software Development: From Concept to Cash, Mary and Tom Poppendieck describe waste and hardship in the software development stream as anything that causes delay for the customer, such as activities that can be bypassed without affecting the result.\n“点名、责备和羞辱”模式是Sydney Dekker博士批评的坏苹果理论的一部分，在他的书《The Field Guide to Understanding Human Error》里有深入讨论。\n《Gemba Walks》的作者Jim Womack描述了领导者和前线工作者之间必须发生的互补工作关系和相互尊重。根据Womack的说法，这种关系是必要的，因为谁都无法单独解决问题 - 领导者并不会足够的贴近一线工作，这是解决任何问题所需要的，而前线工作者也没有更广的组织背景的认知或权\nAfter the near-death experience of eBay in the late 1990s, Marty Cagan, author of Inspired: How To Create Products Customers Love, the seminal book on product design and management, codified the following lesson:\n界定上下文(Bounded contexts)是Eric J.Evans在《领域驱动设计》一书中提出的概念。其思路是开发人员能够理解和更新服务的代码，而不需要知道其关联服务（peers）的内部逻辑。同时，服务间严格通过API协作，不共享数据结构、数据库Schema或内部的对象。界定上下文确保服务间职责的划分，并具有良好定义的接口，同时也提高了可测试性。\nScrumisanagiledevelopmentmethodology,describedas“aflexible,holisticproductdevel- opment strategy where a development team works as a unit to reach a common goal.” It was first fully described by Ken Schwaber and Mike Beedle in the book Agile Software Development with Scrum. In this book, we use the term “agile development” or “iterative development” to encompass the various techniques used by special methodologies such as Agile and Scrum.\n",
    "ref": "/2017/01/03/devops-booklist/"
  },{
    "title": "HPE 分兵两路进军超融合市场",
    "date": "",
    "description": "",
    "body": "关于HP超融合产品家族的变迁简史和相关评论，本文转自 HC 250? HC 380? What are they actually for?。\n转帖：《HC 250? HC 380? What are they actually for?》 http://www.theregister.co.uk/2016/12/05/the_state_of_hpes_hyperconverged_play/ \nHP/HPE 超融合产品线发展如下图所示 +Comment The positioning of these two hyper-converged systems is confusing. We observe that the physically larger and vSphere-only HC 380, with its brand number larger than the HC 250, is for use by operators requiring operational simplicity, whereas the physically smaller and denser HC 250 is for more complicated operations in both vSphere and Hyper-V environments, yet it covers ROBO needs where customers don\u0026rsquo;t have skilled IT staff.\nGetting some ProLiant DL380 brand goodness in the HC 380 name, Apollo supercomputer brand messages in the HC 250 name, and not yet providing HCOE v2 to the HC 250, has provided confusing brand positioning.\nIt also seems that both systems should support Hyper-V and HCOE v2. That would make customers' lives simpler. The HC 380 should have its scale-out limit go past 16 nodes. Thirty-two would be good and then it would match the non-standard and non-recommended 32-node limit of the HC 250. ®\nNutanix Exec: Cisco, HPE, VMware Can\u0026rsquo;t Provide AWS-Like Experience For Hyper-Converged Market http://www.crn.com/news/data-center/300083025/nutanix-exec-cisco-hpe-vmware-cant-provide-aws-like-experience-for-hyper-converged-market.htm\nOne of Nutanix\u0026rsquo;s top executives said Cisco, Hewlett Packard Enterprise and VMware cannot provide a best-in-class experience for their hyper-converged products since they don\u0026rsquo;t own the entire software stack.\n\u0026ldquo;Everybody and their dog is in this space right now,\u0026rdquo; said Sunil Potti, Nutanix\u0026rsquo;s chief product and development officer. \u0026ldquo;But unless you are owning most of the stack, you can\u0026rsquo;t provide that full experience with a single click.\u0026rdquo;\nPotti told attendees of the Raymond James Technology Investors Conference on Monday that up until 18 months ago, much of the market felt that hyper-converged infrastructure – which combines compute, storage, networking and virtualization on server hardware - could be a good product, but questioned whether it would support all use cases.\nBut as end users became more adamant about having hyper-converged architectures deployed for their new workloads, Potti said the space has gone from being the exclusive domain of smaller IT vendors to attracting some of the biggest names in IT.\nAnd while Potti said the big guys bring a lot of go-to-market muscle to the table, some of them don\u0026rsquo;t seem to grasp the importance of providing totally seamless functionality.\n\u0026ldquo;Some of them are very formidable, but some of them are also sleeping giants because they are growing old,\u0026rdquo; Potti said at the conference at the Westin New York Grand Central. \u0026ldquo;You can\u0026rsquo;t just take a Nokia phone, slap on Windows and say \u0026lsquo;I won the smartphone war.\u0026rsquo; There\u0026rsquo;s a reason why those things didn\u0026rsquo;t work.\u0026rdquo;\nPotti pointed to the example of Cisco\u0026rsquo;s hyper-converged offering, which he said competes with VMware\u0026rsquo;s products, but is also dependent on VMware to properly function.\n\u0026ldquo;None of them have their own virtualization experience,\u0026rdquo; Potti said. \u0026ldquo;When you go to Amazon, you don\u0026rsquo;t go buy VMWare for Amazon. It\u0026rsquo;s built in.\u0026rdquo;\nA Cisco spokesman said its customers prefer having a hyperconverged product that integrates with existing converged infrastructure and traditional storage rather than having to create another infrastructure silo. More than 600 organizations have adopted Cisco\u0026rsquo;s HyperFlex since it was launched a few months ago, the spokesman said.\nPaul Miller, VP of marketing for HPE\u0026rsquo;s converged data center infrastructure group, said HPE\u0026rsquo;s new hyperconverged offering is as easy as public cloud, allowing users adjust VMs from their cell phones with just a few clicks. And unlike the hyperconverged-only vendors, Miller said HPE\u0026rsquo;s hyperconverged offering won\u0026rsquo;t become and IT island since it can be managed across a large footprint of infrastructure.\nVMware did not respond to a request for comment.\nPotti said Nutanix, in contrast, evolved beyond simply being a storage technology company four years ago when it started building its own hypervisor and virtualization tools. As a result, Potti said, Nutanix has completely re-imagined how the software stack is built from the ground up.\n\u0026ldquo;Nutanix is a platform player,\u0026rdquo; Potti said. \u0026ldquo;It\u0026rsquo;s not a product player … If you don\u0026rsquo;t provide the full stack, you can\u0026rsquo;t provide that Amazon-like experience.\u0026rdquo;\nNutanix\u0026rsquo;s prime objective is providing an AWS-like experience in the data center, Potti said, and the company isn\u0026rsquo;t trying to replicate the hyper-converged offerings Cisco and VMware are bringing to market.\nThe rising adoption of AWS and other public cloud services over the past five or six years has been tremendously helpful for Nutanix since many end users have already worked through departmental feuds and have grown accustomed to consuming a one-click service across the entire company, Potti said.\n\u0026ldquo;It has emotionally built a cognitive bias toward an architecture like this,\u0026rdquo; Potti said. \u0026ldquo;We are looking to provide an Amazon-like experience for the global enterprise.\u0026rdquo;\n",
    "ref": "/2017/01/03/HPE%20%E5%88%86%E5%85%B5%E4%B8%A4%E8%B7%AF%E8%BF%9B%E5%86%9B%E8%B6%85%E8%9E%8D%E5%90%88%E5%B8%82%E5%9C%BA/"
  },{
    "title": "Nutanix CE All In One",
    "date": "",
    "description": "",
    "body": "Nutanix CE是Nutanix社区版软件的简称，它是Nutanix企业版产品的功能精简集合，是体验和测试Nutanix技术的很方便的途径。\nNutanix Community Edition 社区版简介 这个产品目前的位置在 https://www.nutanix.com/products/community-edition/；目前这个页面还没有中文化，下面简单介绍以下。\n Feature Rich Software 它是一个功能丰富的软件 Broad Hardware Support \u0026amp; Available On-demand 很丰富的硬件支持，在网上可以按需体验 Zero Cost 零成本  用Nutanix CE社区版体验，体验超融合技术的三个步骤。\n 注册 ： 这次Nutanix社区，下载安装镜像 部署 ： 在你的服务器上部署，或者在Ravello上在线开启体验；官方安装部署视频点这里 玩耍 ： 安装完之后就可以开心地玩耍了，有问题请移步 社区版论坛  用物理机安装和体验的几点注意事项如下：\n 物理机安装支持1，3，4个节点的部署；推荐内存在32GB以上；由于版本CE 2016.12.22的CVM的内存需求是24GB，由于加入了自服务门户功能；建议使用SSD硬盘，最好能混搭一些普通硬盘。 安装后的首次启动需要系统能链接互联网，否则CVM会启动不了，首次启动成功之后就不用再联网了 用虚拟机安装，请注意本机的内存，和给虚拟机分配的内存，网上也有修改对内存和CPU限制修改的脚本  产品在社区里的文档页面： 点这里\n参考配置 Intel NUC 最新版一台，i7处理器，两条16GB内存，两条512GB硬盘。它的好处是便携；然而内存还是有限，不能跑多少个虚拟机。\n相关文档  在VMware Workstation上安装Nutanix CE Nutanix Community Edition安装在vSphere环境中 浅尝超融合之Nutanix(上)介绍篇 浅尝超融合之Nutanix(下)安装篇 Nutanix超”容”合之ACS Acropolis Container Service(下)实战篇01 Nutanix超”容”合之ACS Docker Volume Plugin的使用和数据持久化测试 http://nutanix.club/ Nutanix圣经  ",
    "ref": "/2017/01/02/Nutanix-CE-all-in-one/"
  },{
    "title": "美国西岸旧金山之行",
    "date": "",
    "description": "",
    "body": "这次旅行的目的地是硅谷腹地圣何塞，工作了一周之后，周末在旧金山简单游玩了一下。\n交通 从北京到硅谷（圣何塞）有了海航直飞的飞机还是很方便的，在淡季的时候票价也不错。如果你的目的地就在圣何塞市附近的话，乘坐这个航班无疑是最佳的选择。\n我是星期天从北京出发的，飞机经过了11个多小时的飞行后，抵达圣何塞的时间是：同一天的上午。由于机场离我住的酒店太近了，我就经历了人生第一次，从机场走路去酒店入住。\n我在圣何塞待了大约5天，公司和酒店离的非常近，而且公司每天的餐食足够让人忘记去找饭馆吃饭这回事，这也是我首次出差这么不计较吃饭这回事。\n值得一提的是，一天和一位华人同事聊天，得知他家附近有OUTLETS，当时就说您那天下班回家，求顺道带去。第二天我如约坐上了这位同事的宝马和他一同经历了一次，硅谷人的下班。没想到的不到五点，在从圣何塞去往东湾的路上就非常的堵了，正常情况下40分钟的路程走了快两个小时。不过好在我近半年多创业公司的经理起了大用处，有很多谈资，对于这位硅谷的资深前辈来说也非常有兴趣。\n乘坐Uber替代租车是我本次出行最明智的选择，Uber选择拼车，如果和您同程的话，交通费用会非常的便宜。我的几次必要的打车经历都是用Uber解决的。只是最后一天回家的时候，到时出了状况，由于前一天晚上Uber升级，导致需要密码登录，而我的那个备用手机又没有带，最后只能请房东打了一辆正常的Yellow CAB出租车。\n乘坐Uber从圣何塞到旧金山市区的那一趟，让我在周五的下午再次领略了硅谷的堵车，足足走了3个多小时。从此我再也不觉得帝都是世界上唯一的堵车严重的城市了。\n我在旧金山期间的交通是乘坐公交电车，价格便宜又方便；不过也部分依靠了这个红色旅游巴士，两天45刀的价格倒也不便宜；买票的原因主要是，当我暴走至金门大桥的北岸的时候，觉得好像再也不能走回头路，而且附近并没有方便的公共交通工具。因此就上车了，不过对于第一天的市区游也是增色不少，一下子就让我对三藩市的整个情况摸了个七七八八，对第二天的行程非常有帮助。\n上图就是三藩市有名的叮当单车，其实就是有轨电车，由于保留了怀旧的车厢，因此一下子就成为了一个游客必选的项目。如果不是我买了CITY TOUR的票，我肯定也会去体验一把。\n公司 Nutanix是我工作十几年来所加入的一家最年轻的公司，这家公司在16年9月刚刚IPO，公司只有六七年的时间，超融合架构这块独特的市场空间可以说是他们创造的。\n公司目前还在一栋很平常的办公楼中，由于人员扩张的比较快，左侧的那栋楼也几层入住了。公司的文化还保留了比较浓的创业公司的气质，这么说是由于，公司的中高层大部分已经被来自于：VMWare、EMC、NetApp、Dell、HP等大公司的职业经理人们占据了，公司的执行层面上是不折不扣的职业经理人负责的路线，几天的培训下来，感觉所有的人都赶紧十足，大家对市场和机遇的感受和我们之前经历的所有公司都是不同的。很多本次一起来的同事中，有的是已经有一两年的Nutanix产品经验的，有的已经入职了半年左右的；相比之下我是第二周上班的新丁，在几天的培训过程中，我也是只有沉默的份。\n两个大冰箱，左边其实还有一个冰箱一个冰柜，里面都是各种饮料和食品。 这些小货架上是零食和水果。这间屋子有人搭理，会及时补充缺少了的食品。这几天的培训管两餐，在加上这些零食和补给，基本上晚餐不吃也行了。到下班的时候，可以看见有人在这些货架和冰箱里自然地往背包里装东西，后来的两天里面我晚餐基本没有出去，和很快学会这种行为也很有关，晚餐不吃的另外一个原因是时差。这次我经理了前所未有的严重的时差，几乎每天下午6点左右就困得快要昏倒，到凌晨3点左右肯定是清醒的。当然这些食品肯定比不上一线的互联网公司，可是也基本上赶超了我之前所经理过的所有的传统公司的情况。工作相关的内容就此打住。\n游玩 我住在了教会区的一个非常安静的民宅里面，是租的Airbnb的房间。房间的外形如下所示。\n家里也非常整洁、宽敞和温馨。这家附近有公交车，30分钟可以到达渔人码头所在的北滩。我第一天的路线基本上是从渔人码头沿着海边不行到进门桥下，上桥，从桥上不行到桥的北岸，最CITY TOUR红色双层BUS，回城区，然后横穿过金门公园内部的一部分，在回到联合广场。之后我有步行到了三藩市的China Town吃饭。一天的暴走下来，其实对这个城市的感觉还是非常不错的。有几个可圈可点之处：\n 特色景点比较多，这里不一一枚举，都是大家耳熟能详的 城市地形高低起伏，建筑物各具特色，错落有致，绝无前篇一律的感觉。 城市的色彩丰富，特别是那些个精彩的墙壁彩绘  金门大桥 随拍的几张图片如下。\n慕名上桥走一圈的游客还是蛮多的。距离对于我这样的暴走一组来说，也没啥强度。可以感谢的是苍天有眼，让我在这抑郁、寒冷的冬季，让我待了一周已经对天气绝望的心境再次激活。后来要走的几天里，天天是艳阳高照万里无云。\n其他景点 渔老人码头比我想象中的小，而且由于并非捕鱼的季节，有赶上是寒冷的冬天，真的也就是觉得是到此一游，没有看到什么特殊的地方。 China Town的墙壁彩绘，不像是人随手为之，而这样质量的墙壁彩绘在三藩市还有很多很多。\n金门公园是我这个跑步爱好者的毕竟之地，由于本次身体状态不佳，没有跑在这个公园里面；而是从东门到西门的暴走了一趟。公园的面积其实和纽约的中央公园差不多，也就是从东到西大约5公里左右。\n公园里面被分成了很多不同的区域，正值周末各种狗友、航模、跑步、飞碟、航模等等的爱好者聚集在自己的区域里面消遣着周末时光。\n走到了三藩市西侧的海边，面朝大海的位置离注明的悬崖屋餐厅不远，我可以清晰的看到那个餐厅的建筑物。\n斯坦福 对于我来说各个著名的大学有很深的吸引力，想想这所大学和硅谷的IT行业是有多麽重要和紧密的联系。\n上图是校园里著名的教堂，是一座美丽而古典的建筑，是校园的心脏。来这里游览应该从南边的正面进入，直接走到这个教堂，然后在看其他的部分。\n美食 酸面包算是渔人码头景点的美食之一，性价比很高。 面包产自下面这家店。 最后的一次正餐，选择了北滩海景叫做Dinner的餐厅，主要吃个海景；餐食炸鱼陪薯条。 压轴的是这个早餐，点名叫“8 AM”；三藩市早餐分类在点评网站上排第五。吐司三吃。 ",
    "ref": "/2016/12/31/west-coast-SFO/"
  },{
    "title": "EXIN DevOps Master 认证考试",
    "date": "",
    "description": "",
    "body": "DevOps这个词在去年参加红帽全球用户大会的时候就深深吸引了我，实际上哪个会上Docker容器的概念要比DevOps还火爆。Docker／openshift相关的session都尝尝是爆满的。从那里开始我逐渐感觉到了开源容器技术的强大和吸引力。\n从红帽开始OpenShift的考试就是我在完成RHCA红帽认证架构师之后的一个心结，至今也没有完成。不过这根草我早晚是要拔掉的。主要是由于OpenShift是Docker ＋ kubernetes 的组合；是如今企业级PaaS容器平台的主要技术路线。总之离开红帽是如此的仓促，说实话这也是我职业生涯中的一个不小的遗憾。当时确实觉得 kubernetes 的命令行操作不是很方便，而且在OpenShift并没有降低这个门槛，也即是说在OpenShift里面还是要有一定的工作量和技能的要求在编写kubernetes的yml文件上。在这一点上，及时我熟练掌握了Rancher之后，同样发现编写compose file也是难以逃避的。在推广一步，大部分Docker PaaS平台也都是这样，很多产品也是在界面上提供一个文本输入框，让人输入容器服务定义文件的内容。\n在最近的半年中，我的所有技术研究都集中在Docker和其服务编排技术上。与很多用户做过技术交流，PoC测试，有些单子也落地。总结后，有些结果让我感叹。国内的所有企业不区分规模和行业，其实他们对国内原生的创业公司是欢迎的，由于这些公司提供的是国产软件和技术服务。在Docker这个火热的领域中，已经有20多家国内创业公司，我想所有的公司也都已经接受到了这一点的福利了。外国软件通常给人的感觉是：不是国产软件（不要小看国内公司对国产软件的诉求），纯英文操作界面和文档，可能的水土不服，高昂的软件价格和服务费，如果技术太新的化很可能厂商也不具备足够的技术实力和服务力量。\n经过了一些Docker容器项目之后，可以断言的是容器市场的火爆和它的技术优势是直接相关的。容器化之后的应用可以通过服务编排工具快速地部署／更新、弹性地伸缩和使用资源，优化其传统应用运维的若干缺陷。容器的轻量和just enough的隔离技术让资源池的管理更加简单，利用率大幅度提升，这对研发部门的环境管理是不小的提升，使CI的过程更加高效和经济。Docker对微服务的支持也深深地诱惑了所有开发者，做系统微服务实施开发者能想到的实施技术大多数会是容器。\n以上容器的优势和特性使得国内的这些项目落地和实施的可能性进一步提高，甚至很多项目的速度远远超预期；按照我多年的经验看，一个软件技术型的项目，用户纠结半年到一年以上是很正常的。可能也跟国内企业包容本土化软件公司，追捧新潮技术直接相关；我观察到的一些项目，在2～4个月内落单的屡见不鲜。有些试点的DevOps咨询项目也落地很快。\n这些项目都殊途同归地指向了DevOps这个关键词，这让我不得不从去年开始就关注和学习这个最佳实践。当然，我对DevOps的前途非常看好，因此当我听说业内出现了相关认证考试之后，我毫不犹豫地报名参加了。经过2个多月的缜密的准备，我终于幸运地一次通过了这个考试。考试获得了两个证书。\nDevOps Master\nDevOps Master 认证自由讲师\n我参加的是讲师认证培训TTT，很高兴能成为Exin在国内的首批5个认证人员之一。在准备这个考试的过程中我学习了一些书籍，现在还在深度学习的书有两本。\n我完成了这本黑皮书的读书笔记，很遗憾的是，我发现它的最新版，把封面改成了白底的了，我不能在叫它黑皮书／黑宝书了。这本书我起码看了两遍；目前正在调试它的书中的代码，代码中的营养还是很高的，计划尽快把所有代码调试通过；从而完成我许下多次的线上分享本书的诺言。\n这本书被我称为CD红皮书／红宝书。本书早在10年就出版了，也就是说比Docker早好多年。他给我最大的印象就是，作者每一页上似乎都在介绍这做事情的原则和规矩是什么？我一点也不夸张，他对CD的介绍，就是通过讲解一系列在项目上的经验总结。对作者这种级别的经验，和写书的房子只能用一个词总结“服”。这本书太干，我至今还没有消化完。他让我看到了解决发布和变更风险的终极解决方案，没有一次性解决问题的部署／配置／发布工具，有的是历练和打磨了千万次的持续部署流水线；隐约地觉得没用入手的企业都会慢慢跟上的。\n以上是我对DevOps的阶段性总结，跨度有半年之久。这半年中我逐渐看清了我的主要兴趣点，抛除所有其他主题，目前剩下的就是：云计算和DevOps。一方面觉得年纪不饶人，不能可能在和年轻人拼精力、体力和创意；我的背景和经验都让我感觉，在这两个话题上，我还是有很多年的经验和技术积累和总结的。云计算是（公有云＋私有云）未来企业IT基础架构的走向；DevOps是目前看比较正确的运作实践。一个便技术，一个便管理，正好完整覆盖了我的经验；在其对应的开源技术这个分支里，我想它们都还有这很多的为探索和研究的项目。\n",
    "ref": "/2016/11/07/exin-devops-master-e8aea4e8af81e88083e8af95/"
  },{
    "title": "DevOps 的起点-入手微型数据中心",
    "date": "",
    "description": "",
    "body": "测试环境说明 我的笔记本电脑的环境描述如下。\nOS MacBook Pro 2011 版， 2.3 GHz Intel Core i5， 8GB DDR3， 256 GB SSD。 OS X EI Capitan version 10.11.5\nDocker Docker for Mac Version 1.12.0-rc2-beta17 (build: 9779)\n$ docker version Client: Version: 1.12.0-rc2 API version: 1.24 Go version: go1.6.2 Git commit: 906eacd Built: Fri Jun 17 20:35:33 2016 OS/Arch: darwin/amd64 Experimental: true Server: Version: 1.12.0-rc2 API version: 1.24 Go version: go1.6.2 Git commit: a7119de Built: Wed Jun 29 10:03:33 2016 OS/Arch: linux/amd64 Experimental: true $ docker-machine version docker-machine version 0.8.0-rc1, build fffa6c9 martin@localhost ~/Documents [9:38:31] $ docker-compose version docker-compose version 1.8.0-rc1, build 9bf6bc6 docker-py version: 1.8.1 CPython version: 2.7.9 OpenSSL version: OpenSSL 1.0.2h 3 May 2016 VirtualBox version 5.0.22r108108\n本机下载的 Docker 镜像 /Users/martin/Downloads/1.12.0-rc2/boot2docker.iso\n~/Downloads/rancher-all/rancher-agent-v1.0.1.tar\n~/Downloads/rancher-all/rancher-agent-instance-v0.8.1.tar\n~/Downloads/habitat-docker-registry.bintray.io-studio.tar\n~/Downloads/rancher-all/rancher-server-stable.tar\n我本机还有一个 Docker Registry 的 vm，这里面提供了我需要积累以后用的镜像存储，想象一下你在飞机上的时候去哪里拉取镜像 ：）\n本机下载的代码 https://github.com/habitat-sh/habitat-example-plans https://github.com/janeczku/habitat-plans https://github.com/chrisurwin/may2016-demo https://github.com/docker/example-voting-app\n注意以上代码可能需要修改才能在本机调试成功。\n创建 Rancher 服务器 生成虚拟机 用 docker-machine 创建 rancher 服务器。\ndocker-machine create rancher --driver virtualbox --virtualbox-cpu-count \u0026quot;1\u0026quot; --virtualbox-disk-size \u0026quot;8000\u0026quot; --virtualbox-memory \u0026quot;1024\u0026quot; --virtualbox-boot2docker-url=/Users/martin/Downloads/1.12.0-rc2/boot2docker.iso \u0026amp;\u0026amp; eval $(docker-machine env rancher) 导入 Rancher 服务器镜像 用 docker-machine ls 应该看到 rancher 这个节点打了星号。否则 docker 命令会执行失败或者错误。\ndocker load \u0026lt; ~/Downloads/rancher-all/rancher-server-stable.tar docker run -d --restart=always --name rancher-srv -p 8080:8080 rancher/server:stable docker logs -f rancher-srv 查看 rancher 服务器的 ip 地址。 docker-machine ip rancher\n用浏览器打开Rancher 服务器的登录页面。 open http://Rancher_Server_IP:8080\n下面是一些如何让虚拟机保持固定 IP 和 rancher 容器存储的数据持久存在的代码，我没有测试成功，留下大家一起搞，成功了，给我一个回复。另外还有关于稿 jekins 和 mirror 的代码。\necho \u0026quot;ifconfig eth1 192.168.99.60 netmask 255.255.255.0 broadcast 192.168.99.255 up\u0026quot; | docker-machine ssh node1 sudo tee /var/lib/boot2docker/bootsync.sh \u0026gt; /dev/null docker-machine regenerate-certs node1 -f docker-machine ssh ndoe1 sudo mkdir /mnt/sda1/var/lib/rancher docker@node1:/mnt/sda1/var/lib/boot2docker$ cat bootsync.sh ifconfig eth1 192.168.99.60 netmask 255.255.255.0 broadcast 192.168.99.255 up sudo mkdir /mnt/sda1/var/lib/rancher/ sudo ln -s /mnt/sda1/var/lib/rancher/ /var/lib/ docker load \u0026lt; ~/Downloads/rancher-all/jenkins.tar docker run -d --name jekins --privileged -p 9001:8080 -v /var/lib/docker/:/var/lib/docker/ -v /var/run/docker.sock:/var/run/docker.sock -v /usr/bin/docker:/usr/bin/docker -v /lib64/libdevmapper.so.1.02:/usr/lib/libdevmapper.so.1.02 --label io.rancher.container.network=true jenkins docker-machine create mirror --driver virtualbox --virtualbox-cpu-count \u0026quot;1\u0026quot; --virtualbox-disk-size \u0026quot;8000\u0026quot; --virtualbox-memory \u0026quot;512\u0026quot; --virtualbox-boot2docker-url=/Users/martin/Downloads/boot2docker.iso docker load \u0026lt; ~/Downloads/rancher-all/registry.tar docker run -d -p 80:5000 --restart=always --name registry registry:2 容器运行节点 Rancher Agent 节点 创建 node1 虚拟机 使用 docker-machine 命令创建容器运行节点。\ndocker-machine create node1 --driver virtualbox --engine-insecure-registry 192.168.99.20:5000 --virtualbox-cpu-count \u0026quot;1\u0026quot; --virtualbox-disk-size \u0026quot;80000\u0026quot; --virtualbox-memory \u0026quot;1024\u0026quot; --virtualbox-boot2docker-url=/Users/martin/Downloads/1.12.0-rc2/boot2docker.iso docker-machine create node2 --driver virtualbox --engine-insecure-registry 192.168.99.20:5000 --virtualbox-cpu-count \u0026quot;1\u0026quot; --virtualbox-disk-size \u0026quot;80000\u0026quot; --virtualbox-memory \u0026quot;1024\u0026quot; --virtualbox-boot2docker-url=/Users/martin/Downloads/1.12.0-rc2/boot2docker.iso 在 node1 或者 node2 测试运行一个容器，使用 mirror 中的 busybox 镜像。如果你的笔记本内存小于8GB 的话，node2就别搞了。一个 node 也够用了。\ndocker pull 192.168.99.20:5000/busybox:latest docker run 一下这个镜像，验证 node1工作正常。\n加载 Rancher Agent 的镜像 确保 node1 是 docker-machine ls 中打星号的。\ndocker load \u0026lt; ~/Downloads/rancher-all/rancher-agent-v1.0.1.tar docker load \u0026lt; ~/Downloads/rancher-all/rancher-agent-instance-v0.8.1.tar docker load \u0026lt; ~/Downloads/habitat-docker-registry.bintray.io-studio.tar 你翻墙下载回来的habitat-docker-registry.bintray.io/studio镜像可能需要打标签，否则回头 hab 命令执行失败。 先用 docer images 看下是否所有 image 的标签信息正确。\ndocker tag fc27342e5e0e habitat-docker-registry.bintray.io/studio:latest 添加 node1 节点到 Rancher Server。 docker run -d --privileged -v /var/run/docker.sock:/var/run/docker.sock -v /var/lib/rancher:/var/lib/rancher rancher/agent:v1.0.1 http://192.168.99.100:8080/v1/scripts/33B68ED65CEF18F6D7BD:1466694000000:lug2KswoXOOQV4d09ZNMGTphVs0 注意：以上命令需要到您的 Rancher Server 的页面上获取，否则参数都是不对的。 现在在 Hosts 页面上应该能看到该刚创建的节点。在页面上创建一个最小化的容器（如 busybox），来拉起 Network Agent 容器。\n调试 habitat 的测试程序 参考的文档 https://www.habitat.sh/tutorials/ 记得一定要把这一组文章先看完，在去调试它的代码，不懂这些基本概念的话，后面对了错了都不知道该怎么搞。\n前置条件，翻墙下载 habitat studio 的 docker image 镜像，load 到 node1 上，下面的所有测试都是在 node1 上完成的。\n安装 hab habitat 的程序只有一个可执行程序， 目前支持 mac 和 linux 版本。下载地址： https://www.habitat.sh/docs/get-habitat 就是一个 tag 包，解压缩后放到 shell 的 PATH 里面就安装完了。\n配置 hab cli 运行 hab setup\nmartin@localhost ~/Documents $ hab setup Habitat CLI Setup ================= Welcome to hab setup. Let's get started. Set up a default origin Every package in Habitat belongs to an origin, which indicates the person or organization responsible for maintaining that package. Each origin also has a key used to cryptographically sign packages in that origin. Selecting a default origin tells package building operations such as 'hab pkg build' what key should be used to sign the packages produced. If you do not set a default origin now, you will have to tell package building commands each time what origin to use. For more information on origins and how they are used in building packages, please consult the docs at https://www.habitat.sh/docs/build-packages-overview/ Set up a default origin? [Yes/no/quit] yes 这里输入 yes Enter the name of your origin. If you plan to publish your packages publicly, we recommend that you select one that is not already in use on the Habitat build service found at https://app.habitat.sh/. You already have a default origin set up as `martin', but feel free to change it if you wish. Default origin name: [default: martin] 这是用来做 Habitat 包签名和加密用的标识，在代码里面会用到。 You already have an origin key for martin created and installed. Great work! GitHub Access Token While you can build and run Habitat packages without sharing them on the public depot, doing so allows you to collaborate with the Habitat community. In addition, it is how you can perform continuous deployment with Habitat. The depot uses GitHub authentication with an access token (https://help.github.com/articles/creating-an-access-token-for-command-line-use/). If you would like to share your packages on the depot, please enter your GitHub access token. Otherwise, just enter No. For more information on sharing packages on the depot, please read the documentation at https://www.habitat.sh/docs/share-packages-overview/ Set up a default GitHub access token? [Yes/no/quit] yes 这里选择yes Enter your GitHub access token. You already have a default auth token set up, but feel free to change it if you wish. GitHub access token: [default: martin-github-token] 这个 token 需要自己去 github 里面生成 Analytics The `hab` command-line tool will optionally send anonymous usage data to Habitat's Google Analytics account. This is a strictly opt-in activity and no tracking will occur unless you respond affirmatively to the question below. We collect this data to help improve Habitat's user experience. For example, we would like to know the category of tasks users are performing, and which ones they are having trouble with (e.g. mistyping command line arguments). To see what kinds of data are sent and how they are anonymized, please read more about our analytics here: https://www.habitat.sh/docs/about-analytics/ Enable analytics? [yes/No/quit] no 这里选择 no » Opting out of analytics ☑ Creating /Users/martin/.hab/cache/analytics/OPTED_OUT ★ Analytics opted out, we salute you just the same! CLI Setup Complete That's all for now. Thanks for using Habitat! martin@localhost ~/Documents $ 该注意的都写到上面的代码里面了。这个配置的结果在这里\n$ cat ~/.hab/etc/cli.toml auth_token = \u0026quot;martin-github-token\u0026quot; origin = \u0026quot;martin\u0026quot; 调试 Habitat demo 应用 git clone https://github.com/habitat-sh/habitat-example-plans 进入到 mytutorialapp 目录，修改 plan.sh 的 第二行代码，我改后的代码是\npkg_origin=martin martin 是我在 hab cli 里面配置的 origin。\n其实下面的测试就执行了两个 hab 的命令，都是在 hab studi 的 shell里面执行的，这个 shell 其实就是一个studio 容器的 shell。\n在运行下面的命令，确保你是和 node1正常通讯的，下面我用 default 节点做演示。做完的演示环境我已经删除了。\n$ docker-machine ls NAME ACTIVE DRIVER STATE URL SWARM DOCKER ERRORS default - virtualbox Running tcp://192.168.99.100:2376 v1.11.1 $ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 正常的意思是执行所有 docker 命令不报错。\nbuild habitat demo 代码 进入到代码的 plan.sh 的目录 执行 hab studio enter 命令。\nmartin@localhost ~/Documents/GitHub/habitat-example-plans/mytutorialapp $ hab studio enter [±master ●●] hab-studio: Creating Studio at /hab/studios/src (default) hab-studio: Importing martin secret origin key » Importing origin key from standard input ★ Imported secret origin key martin-20160630040241. hab-studio: Entering Studio at /hab/studios/src (default) hab-studio: Exported: HAB_ORIGIN=martin [1][default:/src:0]# build : Loading /src/plan.sh mytutorialapp: Plan loaded mytutorialapp: hab-plan-build setup mytutorialapp: Using HAB_BIN=/hab/pkgs/core/hab/0.7.0/20160614230104/bin/hab for installs, signing, and hashing mytutorialapp: Resolving dependencies » Installing core/node → Using core/gcc-libs/5.2.0/20160612075020 → Using core/glibc/2.22/20160612063629 → Using core/linux-headers/4.3/20160612063537 ↓ Downloading core/node/4.2.6/20160612143531 6.44 MB / 6.44 MB \\ [=======================================================================] 100.00 % 457.82 KB/s ↓ Downloading core-20160612031944 public origin key 75 B / 75 B | [=============================================================================] 100.00 % 575.13 KB/s ☑ Cached core-20160612031944 public origin key ✓ Installed core/node/4.2.6/20160612143531 ★ Install of core/node complete with 4 packages installed. mytutorialapp: Resolved dependency 'core/node' to /hab/pkgs/core/node/4.2.6/20160612143531 mytutorialapp: Setting PATH=/hab/pkgs/core/node/4.2.6/20160612143531/bin:/hab/pkgs/core/hab-plan-build/0.7.0/20160614232259/bin:/hab/pkgs/core/bash/4.3.42/20160612075613/bin:/hab/pkgs/core/binutils/2.25.1/20160612064534/bin:/hab/pkgs/core/bzip2/1.0.6/20160612075040/bin:/hab/pkgs/core/coreutils/8.24/20160612075329/bin:/hab/pkgs/core/file/5.24/20160612064523/bin:/hab/pkgs/core/findutils/4.4.2/20160612080341/bin:/hab/pkgs/core/gawk/4.1.3/20160612075739/bin:/hab/pkgs/core/grep/2.22/20160612075540/bin:/hab/pkgs/core/gzip/1.6/20160612080637/bin:/hab/pkgs/core/hab/0.7.0/20160614230104/bin:/hab/pkgs/core/sed/4.2.2/20160612075228/bin:/hab/pkgs/core/tar/1.28/20160612075701/bin:/hab/pkgs/core/unzip/6.0/20160612081414/bin:/hab/pkgs/core/wget/1.16.3/20160612081342/bin:/hab/pkgs/core/xz/5.2.2/20160612080402/bin:/hab/pkgs/core/acl/2.2.52/20160612075215/bin:/hab/pkgs/core/attr/2.4.47/20160612075207/bin:/hab/pkgs/core/glibc/2.22/20160612063629/bin:/hab/pkgs/core/less/481/20160612080021/bin:/hab/pkgs/core/libcap/2.24/20160612075226/bin:/hab/pkgs/core/libidn/1.32/20160612081104/bin:/hab/pkgs/core/ncurses/6.0/20160612075116/bin:/hab/pkgs/core/openssl/1.0.2h/20160612081127/bin:/hab/pkgs/core/pcre/8.38/20160612075520/bin mkdir: created directory '/hab/cache/src' mytutorialapp: Downloading 'https://s3-us-west-2.amazonaws.com/mytutorialapp/mytutorialapp-0.1.0.tar.gz' to 'mytutorialapp-0.1.0.tar.gz' --2016-07-01 02:27:51-- https://s3-us-west-2.amazonaws.com/mytutorialapp/mytutorialapp-0.1.0.tar.gz Resolving s3-us-west-2.amazonaws.com (s3-us-west-2.amazonaws.com)... 54.231.184.216 Connecting to s3-us-west-2.amazonaws.com (s3-us-west-2.amazonaws.com)|54.231.184.216|:443... connected. HTTP request sent, awaiting response... 200 OK Length: 1041 (1.0K) [application/x-gzip] Saving to: 'mytutorialapp-0.1.0.tar.gz' mytutorialapp-0.1.0.tar.gz 100%[===================================================\u0026gt;] 1.02K --.-KB/s in 0.03s 2016-07-01 02:28:08 (32.1 KB/s) - 'mytutorialapp-0.1.0.tar.gz' saved [1041/1041] mytutorialapp: Downloaded 'mytutorialapp-0.1.0.tar.gz' mytutorialapp: Verifying mytutorialapp-0.1.0.tar.gz mytutorialapp: Checksum verified for mytutorialapp-0.1.0.tar.gz mytutorialapp: Clean the cache mytutorialapp: Unpacking mytutorialapp-0.1.0.tar.gz mytutorialapp: Setting build environment mytutorialapp: Setting PREFIX=/hab/pkgs/martin/mytutorialapp/0.1.0/20160701022725 mytutorialapp: Setting LD_RUN_PATH=/hab/pkgs/core/node/4.2.6/20160612143531/lib mytutorialapp: Setting CFLAGS=-I/hab/pkgs/core/node/4.2.6/20160612143531/include mytutorialapp: Setting LDFLAGS=-L/hab/pkgs/core/node/4.2.6/20160612143531/lib mytutorialapp: Preparing to build mytutorialapp: Building npm WARN package.json mytutorialapp@0.1.0 No repository field. npm WARN package.json mytutorialapp@0.1.0 No README data nconf@0.8.4 node_modules/nconf ├── ini@1.3.4 ├── secure-keys@1.0.0 ├── async@1.5.2 └── yargs@3.32.0 (decamelize@1.2.0, camelcase@2.1.1, window-size@0.1.4, y18n@3.2.1, os-locale@1.4.0, cliui@3.2.0, string-width@1.0.1) mytutorialapp: Installing 'node_modules/nconf' -\u0026gt; '/hab/pkgs/martin/mytutorialapp/0.1.0/20160701022725/node_modules/nconf' 忽略了好几百行输出 'node_modules/nconf/node_modules/secure-keys/test/simple-test.js' -\u0026gt; '/hab/pkgs/martin/mytutorialapp/0.1.0/20160701022725/node_modules/nconf/node_modules/secure-keys/test/simple-test.js' 'node_modules/nconf/node_modules/secure-keys/test/test.secret.key' -\u0026gt; '/hab/pkgs/martin/mytutorialapp/0.1.0/20160701022725/node_modules/nconf/node_modules/secure-keys/test/test.secret.key' 'node_modules/nconf/node_modules/secure-keys/package.json' -\u0026gt; '/hab/pkgs/martin/mytutorialapp/0.1.0/20160701022725/node_modules/nconf/node_modules/secure-keys/package.json' mytutorialapp: Writing configuration mytutorialapp: Writing service management scripts mytutorialapp: Stripping unneeded symbols from binaries and libraries mytutorialapp: Creating manifest mytutorialapp: Building package metadata mytutorialapp: Generating blake2b hashes of all files in the package mytutorialapp: Generating signed metadata FILES » Signing mytutorialapp_blake2bsums ☛ Signing mytutorialapp_blake2bsums with martin-20160630040241 to create /hab/pkgs/martin/mytutorialapp/0.1.0/20160701022725/FILES ★ Signed artifact /hab/pkgs/martin/mytutorialapp/0.1.0/20160701022725/FILES. mytutorialapp: Generating package artifact /hab/pkgs/core/tar/1.28/20160612075701/bin/tar: Removing leading `/' from member names /hab/cache/artifacts/.martin-mytutorialapp-0.1.0-20160701022725-x86_64-linux.tar (1/1) 100 % 121.4 KiB / 900.0 KiB = 0.135 » Signing /hab/cache/artifacts/.martin-mytutorialapp-0.1.0-20160701022725-x86_64-linux.tar.xz ☛ Signing /hab/cache/artifacts/.martin-mytutorialapp-0.1.0-20160701022725-x86_64-linux.tar.xz with martin-20160630040241 to create /hab/cache/artifacts/martin-mytutorialapp-0.1.0-20160701022725-x86_64-linux.hart ★ Signed artifact /hab/cache/artifacts/martin-mytutorialapp-0.1.0-20160701022725-x86_64-linux.hart. '/hab/cache/artifacts/martin-mytutorialapp-0.1.0-20160701022725-x86_64-linux.hart' -\u0026gt; '/src/results/martin-mytutorialapp-0.1.0-20160701022725-x86_64-linux.hart' mytutorialapp: hab-plan-build cleanup mytutorialapp: mytutorialapp: Source Cache: /hab/cache/src/mytutorialapp-0.1.0 mytutorialapp: Installed Path: /hab/pkgs/martin/mytutorialapp/0.1.0/20160701022725 mytutorialapp: Artifact: /src/results/martin-mytutorialapp-0.1.0-20160701022725-x86_64-linux.hart mytutorialapp: Build Report: /src/results/last_build.env mytutorialapp: SHA256 Checksum: d4bfb3a44989b8a5b1295eac2600d75f42dd2be6f537344312c8917cba47d05d mytutorialapp: Blake2b Checksum: fbff257eb36fffa61e6cbf5ec89fa3f507095f80f5cca610c2bb72685d758706 mytutorialapp: mytutorialapp: I love it when a plan.sh comes together. mytutorialapp: mytutorialapp: Build time: 1m3s [2][default:/src:0]# 检查结果，在代码的目录中可以看的 result 目录，关注一下这个目录，关键看 build 命令的最后一段。\n mytutorialapp: hab-plan-build cleanup mytutorialapp: mytutorialapp: Source Cache: /hab/cache/src/mytutorialapp-0.1.0 mytutorialapp: Installed Path: /hab/pkgs/martin/mytutorialapp/0.1.0/20160701022725 mytutorialapp: Artifact: /src/results/martin-mytutorialapp-0.1.0-20160701022725-x86_64-linux.hart mytutorialapp: Build Report: /src/results/last_build.env mytutorialapp: SHA256 Checksum: d4bfb3a44989b8a5b1295eac2600d75f42dd2be6f537344312c8917cba47d05d mytutorialapp: Blake2b Checksum: fbff257eb36fffa61e6cbf5ec89fa3f507095f80f5cca610c2bb72685d758706 mytutorialapp: mytutorialapp: I love it when a plan.sh comes together. mytutorialapp: mytutorialapp: Build time: 1m3s 昨晚分享的高潮部分, habitat 导出 docker image 其实就是一条命令，在 habitat Studio 中执行 导出命令 hab pkg export docker martin/mytutorialapp\n导出 docker 镜像的过程和 build 的过程一样，都可能会失败；由于它需要到网上下载所需要的代码，下载所需要的 habitat 模块，core/ 开头的都是 habitat出品的核心的模块，他们的想法基本也是说把所有的可能用到的模块都做封装，成为自己的 pkg 格式的内容。然后在用他们的 Habitat 服务来解析、部署和运行。\n[4][default:/src:0]# hab pkg export docker martin/mytutorialapp hab-studio: Creating Studio at /tmp/hab-pkg-dockerize-XxsS/rootfs (baseimage) Using local package for martin/mytutorialapp Using local package for core/gcc-libs/5.2.0/20160612075020 via martin/mytutorialapp Using local package for core/glibc/2.22/20160612063629 via martin/mytutorialapp Using local package for core/linux-headers/4.3/20160612063537 via martin/mytutorialapp Using local package for core/node/4.2.6/20160612143531 via martin/mytutorialapp » Installing core/hab ↓ Downloading core/hab/0.7.0/20160614230104 2.23 MB / 2.23 MB / [=======================================================================] 100.00 % 500.60 KB/s ↓ Downloading core-20160612031944 public origin key 75 B / 75 B | [=============================================================================] 100.00 % 378.76 KB/s ☑ Cached core-20160612031944 public origin key ✓ Installed core/hab/0.7.0/20160614230104 ★ Install of core/hab complete with 1 packages installed. » Installing core/hab-sup ↓ Downloading core/busybox-static/1.24.2/20160612081725 510.89 KB / 510.89 KB | [====================================================================] 100.00 % 89.61 KB/s ✓ Installed core/busybox-static/1.24.2/20160612081725 ↓ Downloading core/bzip2/1.0.6/20160612075040 141.05 KB / 141.05 KB - [===================================================================] 100.00 % 349.94 KB/s ✓ Installed core/bzip2/1.0.6/20160612075040 ↓ Downloading core/cacerts/2016.04.20/20160612081125 132.32 KB / 132.32 KB | [===================================================================] 100.00 % 370.21 KB/s ✓ Installed core/cacerts/2016.04.20/20160612081125 → Using core/gcc-libs/5.2.0/20160612075020 → Using core/glibc/2.22/20160612063629 ↓ Downloading core/libarchive/3.2.0/20160612140528 584.98 KB / 584.98 KB | [===================================================================] 100.00 % 340.75 KB/s ✓ Installed core/libarchive/3.2.0/20160612140528 ↓ Downloading core/libsodium/1.0.8/20160612140317 187.96 KB / 187.96 KB \\ [===================================================================] 100.00 % 200.27 KB/s ✓ Installed core/libsodium/1.0.8/20160612140317 → Using core/linux-headers/4.3/20160612063537 ↓ Downloading core/openssl/1.0.2h/20160612081127 2.10 MB / 2.10 MB | [=======================================================================] 100.00 % 518.78 KB/s ✓ Installed core/openssl/1.0.2h/20160612081127 ↓ Downloading core/xz/5.2.2/20160612080402 247.38 KB / 247.38 KB \\ [===================================================================] 100.00 % 468.42 KB/s ✓ Installed core/xz/5.2.2/20160612080402 ↓ Downloading core/zlib/1.2.8/20160612064520 73.06 KB / 73.06 KB / [=====================================================================] 100.00 % 315.44 KB/s ✓ Installed core/zlib/1.2.8/20160612064520 ↓ Downloading core/hab-sup/0.7.0/20160614232939 1.54 MB / 1.54 MB | [=======================================================================] 100.00 % 563.90 KB/s ✓ Installed core/hab-sup/0.7.0/20160614232939 ★ Install of core/hab-sup complete with 12 packages installed. » Symlinking hab from core/hab into /tmp/hab-pkg-dockerize-XxsS/rootfs/hab/bin ★ Binary hab from core/hab/0.7.0/20160614230104 symlinked to /tmp/hab-pkg-dockerize-XxsS/rootfs/hab/bin/hab » Symlinking bash from core/busybox-static into /tmp/hab-pkg-dockerize-XxsS/rootfs/bin ★ Binary bash from core/busybox-static/1.24.2/20160612081725 symlinked to /tmp/hab-pkg-dockerize-XxsS/rootfs/bin/bash » Symlinking sh from core/busybox-static into /tmp/hab-pkg-dockerize-XxsS/rootfs/bin ★ Binary sh from core/busybox-static/1.24.2/20160612081725 symlinked to /tmp/hab-pkg-dockerize-XxsS/rootfs/bin/sh Sending build context to Docker daemon 194.3 MB Step 1 : FROM scratch ---\u0026gt; Step 2 : ENV export PATH=:/hab/pkgs/core/glibc/2.22/20160612063629/bin:/hab/pkgs/core/node/4.2.6/20160612143531/bin:/hab/pkgs/core/hab-sup/0.7.0/20160614232939/bin:/hab/pkgs/core/busybox-static/1.24.2/20160612081725/bin:/hab/pkgs/core/bzip2/1.0.6/20160612075040/bin:/hab/pkgs/core/glibc/2.22/20160612063629/bin:/hab/pkgs/core/openssl/1.0.2h/20160612081127/bin:/hab/pkgs/core/xz/5.2.2/20160612080402/bin:/hab/pkgs/core/busybox-static/1.24.2/20160612081725/bin:/hab/bin ---\u0026gt; Running in 117e90c151e7 ---\u0026gt; 7f33585a25ae Removing intermediate container 117e90c151e7 Step 3 : WORKDIR / ---\u0026gt; Running in 952257966d96 ---\u0026gt; c0cf3715cbcf Removing intermediate container 952257966d96 Step 4 : ADD rootfs / ---\u0026gt; d2691da93ccf Removing intermediate container 4aa80e97ea57 Step 5 : VOLUME /hab/svc/mytutorialapp/data /hab/svc/mytutorialapp/config ---\u0026gt; Running in f1edcb653432 ---\u0026gt; bd8888453939 Removing intermediate container f1edcb653432 Step 6 : EXPOSE 9631 8080 ---\u0026gt; Running in 9ca7725ed13e ---\u0026gt; 256a04cd0fe2 Removing intermediate container 9ca7725ed13e Step 7 : ENTRYPOINT /init.sh ---\u0026gt; Running in 81930dff8f4e ---\u0026gt; d7bdec08530e Removing intermediate container 81930dff8f4e Step 8 : CMD start martin/mytutorialapp ---\u0026gt; Running in c8cc53d92bc8 ---\u0026gt; 8d5e0fe85395 Removing intermediate container c8cc53d92bc8 Successfully built 8d5e0fe85395 [5][default:/src:0]# 查看 docker 镜像是否存在。推出 studio 容器，运行 docker images\n[5][default:/src:0]# exit logout martin@localhost ~/Documents/GitHub/habitat-example-plans/mytutorialapp $ docker images [±master ●●] REPOSITORY TAG IMAGE ID CREATED SIZE martin/mytutorialapp 0.1.0-20160701024401 8d5e0fe85395 3 minutes ago 187.7 MB martin/mytutorialapp latest 8d5e0fe85395 3 minutes ago 187.7 MB 运行这个 demo 在命令行运行\n$ docker run -it -p 8080:8080 martin/mytutorialapp\n用浏览器打开 node1的 ip 8080 端口，应该可以看到 hello world 页面。\n在 rancher web 页面添加测试\n在 rancher 中上架这个 demo https://github.com/martinliu/hab-catalog 以上代码是半成品，欢迎协助完成。\n测试 Rancher 官方的 redis demo 参考文章 http://rancher.com/using-habitat-to-create-rancher-catalog-templates/ 它的 demo 和上架的目录都可以正常测试通过，但是服务运行不起来，报主机名错误，redis 节点的群集建立不起来。\n如果您修复了，请回复贴出代码位置。\n福利：调试 docker 官方投票应用 下载投票实例程序。\ngit clone https://github.com/martinliu/example-voting-app.git 进入该程序的目录，修改所有 image 的来源镜像库，修改为指向本地的 mirror 服务器。 1. result/tests/Dcokerfile -\u0026gt; FROM 192.168.99.20:5000/node 2. result/Dockerfile -\u0026gt; FROM 192.168.99.20:5000/node:5.11.0-slim 3. vote/Dockerfile -\u0026gt; FROM 192.168.99.20:5000/python:2.7-alpine 4. worker/Dockerfile -\u0026gt; FROM 192.168.99.20:5000/microsoft/dotnet:1.0.0-preview1 5. docker-compose.yml -\u0026gt; image: 192.168.99.20:5000/redis:alpine 6. docker-compose.yml -\u0026gt; image: 192.168.99.20:5000/postgres:9.4\n由于以上应用在构建的过程中需要在线安装各种软件包，最好先翻墙，确认你有足够稳定的国外的互联网访问，建议翻墙到美国，然后在执行项目的构建命令。\nping facebook.com 64 bytes from 173.252.90.132: icmp_seq=0 ttl=79 time=4187.066 ms 64 bytes from 173.252.90.132: icmp_seq=1 ttl=79 time=3186.904 ms 64 bytes from 173.252.90.132: icmp_seq=2 ttl=79 time=2515.415 ms 64 bytes from 173.252.90.132: icmp_seq=6 ttl=79 time=296.457 ms 64 bytes from 173.252.90.132: icmp_seq=7 ttl=79 time=410.215 ms ^C --- facebook.com ping statistics --- 8 packets transmitted, 5 packets received, 37.5% packet loss round-trip min/avg/max/stddev = 296.457/2119.211/4187.066/1537.275 ms docker-compose build 以上结果表明，翻墙成功，以上结果显示翻墙的效果比较差，延迟和丢包都比较严重，可能到只构建的时候下载软件包失败。\n构建完毕之后，可以检查一下是否生产了目标镜像文件，如果输出如下所示，则表明本次本地的项目集成构建成功。\n$ docker images REPOSITORY TAG IMAGE ID CREATED SIZE examplevotingapp_result latest 9bb4126b0905 5 minutes ago 225.8 MB examplevotingapp_worker latest 292396a5aba4 6 minutes ago 644.1 MB examplevotingapp_vote latest 28052191beea 10 minutes ago 68.31 MB 在当前 node1 节点上做本地的集成结果的功能测试，用 docker-compose 启动这个项目。先检查 compose 文件，然后运行 up。\n$ docker-compose config networks: {} services: db: image: 192.168.99.20:5000/postgres:9.4 redis: image: 192.168.99.20:5000/redis:alpine ports: - '6379' result: build: context: /Users/martin/Documents/GitHub/example-voting-app/result command: nodemon --debug server.js ports: - 5001:80 - 5858:5858 volumes: - /Users/martin/Documents/GitHub/example-voting-app/result:/app:rw vote: build: context: /Users/martin/Documents/GitHub/example-voting-app/vote command: python app.py ports: - 5000:80 volumes: - /Users/martin/Documents/GitHub/example-voting-app/vote:/app:rw worker: build: context: /Users/martin/Documents/GitHub/example-voting-app/worker version: '2.0' volumes: {} $ docker-compose up Recreating examplevotingapp_vote_1 Recreating examplevotingapp_worker_1 Starting examplevotingapp_db_1 Starting examplevotingapp_redis_1 Recreating examplevotingapp_result_1 Attaching to examplevotingapp_db_1, examplevotingapp_redis_1, examplevotingapp_worker_1, examplevotingapp_result_1, examplevotingapp_vote_1 redis_1 | _._ redis_1 | _.-``__ ''-._ redis_1 | _.-`` `. `_. ''-._ Redis 3.2.1 (00000000/0) 64 bit redis_1 | .-`` .-```. ```\\/ _.,_ ''-._ db_1 | LOG: database system was shut down at 2016-06-20 09:58:19 UTC redis_1 | ( ' , .-` | `, ) Running in standalone mode redis_1 | |`-._`-...-` __...-.``-._|'` _.-'| Port: 6379 redis_1 | | `-._ `._ / _.-' | PID: 1 redis_1 | `-._ `-._ `-./ _.-' _.-' redis_1 | |`-._`-._ `-.__.-' _.-'_.-'| redis_1 | | `-._`-._ _.-'_.-' | http://redis.io redis_1 | `-._ `-._`-.__.-'_.-' _.-' redis_1 | |`-._`-._ `-.__.-' _.-'_.-'| db_1 | LOG: MultiXact member wraparound protections are now enabled redis_1 | | `-._`-._ _.-'_.-' | redis_1 | `-._ `-._`-.__.-'_.-' _.-' db_1 | LOG: database system is ready to accept connections redis_1 | `-._ `-.__.-' _.-' redis_1 | `-._ _.-' redis_1 | `-.__.-' redis_1 | redis_1 | 1:M 20 Jun 10:13:36.216 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128. redis_1 | 1:M 20 Jun 10:13:36.216 # Server started, Redis version 3.2.1 redis_1 | 1:M 20 Jun 10:13:36.216 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect. db_1 | LOG: autovacuum launcher started redis_1 | 1:M 20 Jun 10:13:36.216 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never \u0026gt; /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled. redis_1 | 1:M 20 Jun 10:13:36.216 * The server is now ready to accept connections on port 6379 vote_1 | * Running on http://0.0.0.0:80/ (Press CTRL+C to quit) vote_1 | * Restarting with stat result_1 | [nodemon] 1.9.2 result_1 | [nodemon] to restart at any time, enter `rs` result_1 | [nodemon] watching: *.* result_1 | [nodemon] starting `node --debug server.js` result_1 | Debugger listening on port 5858 vote_1 | * Debugger is active! vote_1 | * Debugger pin code: 139-254-286 worker_1 | Found redis at 172.19.0.2 result_1 | Mon, 20 Jun 2016 10:13:40 GMT body-parser deprecated bodyParser: use individual json/urlencoded middlewares at server.js:67:9 result_1 | Mon, 20 Jun 2016 10:13:40 GMT body-parser deprecated undefined extended: provide extended option at ../node_modules/body-parser/index.js:105:29 result_1 | App running on port 80 result_1 | Connected to db 打开浏览器测试 vote 应用。\nopen http://192.168.99.114:5000 正常显示结果如下图所示： 打开浏览器测试 result 应用。\nopen http://192.168.99.114:5001 正常显示结果如下图所示： 在 Rancher 的 hosts 界面中应该看到这些运行的容器。 至此所有关于应用构建和功能测试的过程完成，按 ctl + c 结束 docker-compose up 的运行。\n^CGracefully stopping... (press Ctrl+C again to force) Stopping examplevotingapp_worker_1 ... done Stopping examplevotingapp_result_1 ... done Stopping examplevotingapp_vote_1 ... done Stopping examplevotingapp_db_1 ... done Stopping examplevotingapp_redis_1 ... done ",
    "ref": "/2016/07/01/devops-in-a-box/"
  },{
    "title": "用 Docker 构建 Serverless 应用",
    "date": "",
    "description": "",
    "body": "Martin解读Serverless Serverless 不意味着没有服务器，而是从应用可以在一个抽象层上忽略它的存在，而只关注在功能实现上和自身的请求处理上；每一个功能实现在不是单纯的业务逻辑处理的代码，相反每个功能调用具有了 server 的特质，进化成为了一个具有自省、自知和自治的工作负载单元；他们更像是能够衍生出其它新功能单元的生物体。这样整个 Serverless 应用架构之内，每个生命可以衍生下去，子子孙孙无穷匮也。\n本文编译了：https://blog.docker.com/2016/06/building-serverless-apps-with-docker/ 一下是正文内容。\n处在这技术日新月异的时代里，新的技术浪潮经常对当前的技术产生着威胁和颠覆。在编写应用的时候我们目前经常谈论到“Serverless”技术。它的核心思想是把应用作为一系列的功能/function来部署，这些功能在需要的时候被按需部署。服务器管理应该是不需要去操心的事情，所有功能被按需调用，被运行在群集之上。\n但是 Serverless 里不意味着没有 Docker，事实上 ”Docker 就是 Serverless”。你可以用 Docker 来容器化这些功能，然后按需地运行在 Swarm 群集上。Serverless 是一种构建分布式计算的应用的方法，而 Docker 是完美的构建和运行他们的平台。\n从Server 到 Serverless 那么我们如何来编写 Serverless 的应用？让我们先看下这个例子：“一个有5个子服务组成的投票应用”：\n它的结构如下：\n 两个 web 前端 一个后台的处理投票的 worker 服务 一个处理投票的消息队列  一个数据库  那个后台处理投票的进程是非常容易成为转换为 Serverless 架构的目标。在投票应用内，我们可以运行一点类似于下面的代码，来执行后台任务：\n import dockerrun client = dockerrun.from_env() client.run(\u0026quot;bfirsh/serverless-record-vote-task\u0026quot;, [voter_id, vote], detach=True) Worker 和消息队列能用按需在 Swarm 上运行的容器来替换，并自动地按需扩容。\n我们甚至可以消除掉 web 前端。我们可以这么做：用 Docker 容器来相应每一个HTTP 请求，每个 HTTP 请求都用一个自生长的跑着轻量 HTTP 服务器的容器来处理。之前使用的是长时间持续运行的 HTTP 服务器，现在变成了具有 HTTP 相应和处理能力的按需跑起来的容器，而且他们能自动地扩容来支持所有访问请求。\n我们新的架构大概如下图所示：\n其中红色的方块是需持续长期运行的服务，而绿色方块成了按需被调用的 Docker容器。这样这个应用变成了只有少数几个需要被管理的 long-running 服务，在相应请求的时候使用原生的 Swarm 扩容能力，处理能力的上限是 Swarm 群集的上限。\n具体如何实现 这里有三个有用的技巧，可以在你的程序中使用：\n 把你代码中的 function 作为按需拉起的 Docker 容器 使用 Swarm 在群集上运行这些容器 从容器里面运行这些功能容器，绕过了一个 Docker API socket  使用以上技术的组合，程序执行负载发生的可能性将和您如何架构你的应用相关。运行后台任务就是一个非常适合的例子，但是整个应用中的其它工作负载也是有可能的，例如：\n 考虑到延迟，用启动一个容器来服务所有用户的 HTTP 请求可能是不现实的。可是你可以写一个内置的负载均衡逻辑，让它知道何时需要主动地自动扩容 Web 前端自身，通过在 Swarm 群集上运行更多 web 处理容器。 一个 MongoDB 容器可以在 Swarm 上成为一个具有自省能力的架构，它能自动地运行出正确数量的 shard 和 replica 容器。  接下来 我们已经得到了这些激进的新工具，用做构建应用的抽象层，我们隐约看到了如何深入下去的可能性。我们依然像长时间以来在一堆服务器上构建应用一样，而以后可以来利用 Swarm 能按需地在基础架构里的任何地方执行功能代码的能力。\n希望这些能够给您一些如何构建应用的新思路，但是我们还需要你们的帮助。我们已经有的是一些构建 Serverless 应用的基础功能，然而他们依然不是很完备，我们需要更好的工具、库、样例程序，文档等等。\n这个 Github 库有一些工具、库、代码和文章的链接。基于此，如果您想学习更多的话，请共享任何相关的链接，这样我们可以开始协作在一起。\n大家一起来搞，并祝 hacking 愉快！\n",
    "ref": "/2016/06/22/building-serverless-apps-docker/"
  },{
    "title": "DockerCon 2016 D2 超萌码头酷黑客 大会圆满闭幕",
    "date": "",
    "description": "",
    "body": "Closing General Session 的主题是 Moby Dock‘s Cool Hacks ； 从字面意思上看，这个主题的意思是“超萌码头酷黑客”的意思。我已经看到了关于最后一天开幕主题演讲的评论，说是“剑指商业”什么的；而我认为 Docker 从开始的第一天，无论它是否开源，它都是为了商业利益而已。话在说回到开源，Docker 只是完美的应用了开源软件这种实践而已；而且docker 把开源这种模式应用的如此成功，并在商业上也如此让人眼红和侧目，这也算是开源软件商业化登峰造极的一种极端性个案。个人认为开源无疑是在软件行业中做出爆款技术当之无愧的首选的实践方式。我在红帽碰到很多参与开源十几二十年的老黑客，他们不乏会表达关于开源纯洁性沦丧的抱怨；我对此也非常理解和认同。而我更认同开源可以对软件技术带来无比活力的这个积极的方面。\n言归正传，小编我还是“模拟现场”播报一下大会闭幕主题演讲的盛况。这是大会的结束的 session，现场的人数明显的少于第一天开幕式的人。在十几分钟内，人们稀稀拉拉的进入了会场。会场中的座位大约还有一部分空位。美女Mano 和 黑客Kristie 作为主要演讲人上台。美女上台后先用手机自拍了几下。两个人开始宣布，Docker 大会之后举行为期一个月的黑客大赛，这是我们的传统，Docker 大会虽然今天会结束，而docer 黑客大赛将从今天开始。我们来请大家欣赏三个非常酷的黑客项目演示。\n本次大会的录音点这里 http://www.ximalaya.com/32280565/sound/17388272\n黑客演示1：微服务自毁平台 Jeff 登场。Jeff 开始讲述微服务的故事，我们都在试图让基础架构做到冗余，容所有的服务都冗余，让群集能够自愈；但是故障，断网，宕机还是会发生。我们所做的这些真的能够保证业务不宕机么，服务不终端么？你怎么能确认这一点？因此回归到故障的发生上吧？如果服务要出故障，请让它有规律的发生。请程序猿和 ops 都投入到故障处理的战斗中，以此为契机来优化和改造应用，让应用变的更加强壮。我们都听说过混乱猴子，而 Jeff 团队正式帮人们构建一堆这样的工具的人。\n有一个思路是：如何让我的系统的服务出故障，如何主动的在系统中注入故障。我们需要一种特殊的编排工具来在系统中模拟和触发故障的发生。我用容器做工具平台来触发故障注入的动作。当然这个故障是在容器架构的微服务系统中触发这个动作。\nJeff 开始做这个 Demo。说：如果你的”网络没有故障，天下太平。“其实这很无聊的说，有木有？有木有？我现在开始用工具来注入 网络延迟的网络故障吧！ 。用一个基于策略的工具。配置一个网络故障模拟的策略，故障什么时间发生，发生多久。这里设计一个每10秒钟注入一次网络延迟故障提高到600ms 的故障。然后配置故障影响的范围，这里使用 Docker 的 lable 来做故障发生节点的选择的条件。符合标签的系统将受到这次故障影响。我们的这个故障模拟编排系统，帮您提前体验故障的发生。现在你看故障发生了，从这些容器里面 ping google 的网络延迟比之前大多了， 目前延迟到了600ms。希望你们能开始体验和使用这个而工具。\n黑客演示2：Serverless 架构的应用不是梦 Ben 是大家在 Docker 大会喜闻乐见的一个黑客，他经常给做 demo 和 session。他绝对符合超萌的标准。\nBen 开讲，Serverless 是如何做的？ben 认为 Serverless 是一种全新的应用编程的思路，而 docer 可以很好的支持这种思路，并实现和执行这种思路。docer 群集可以让Serverless引用按需执行，并让该应用的底层变得资源冗余并路由可达。ben 开始演示 他的几张 slides， 说 Sererless == docker这个概念。本开始讲解：如何用Serverless架构来实现投票应用的改造。如何把这个5个服务模块的纯粹容器微服务系统转换为 serverless 架构的应用。开始修改源代码，把发入队列的票，变成一个处理投票的容，把 http 服务器变成一个 CGIHander（）服务；但是 nodejs 不支持 CGIhander，肿么办？我用 perl 重写了这部分，为毛用 perl，被忘了它乃是古董级的黑客神器的好不好，呵呵！改造完之后的系统架构如下。架构是把处理 postgresql 意外的模块都重写了。数据库保留在最下层。这种Serverless重构实践遵从的原则如下。\n三个原则翻译一下：\n  把每个模块的核心功能打包，并作为容器来运行。解读：这意味着把所有服务模块组重构，把每个服务模块中的核心功能代码作为一个在容器里面跑的对象。这里其实牵扯到很深的业务重构和应用重构，程序猿或将抛弃以前的代码，甚至以前所习惯使用的程序开发堆栈。\n  把这些容器用 Docker 的 Swarm 跑起来。解读：docker 原生的Swarm 编排能力将为您的应用提供，功能的运行，workload 的分布，服务的冗余，服务的路由等等支持；这样的架构能支持到 Serverless 的应用的模型。\n  从容器中去运行其它容器。解读：容器编排平台或将不是容器生命起源的唯一起点，容器里面的应用可能可以决定系统中需要滋生出什么样的容器，当然说的是需要实现和运行什么功能的容器。\n  好了，目前为止，ben 的心的应用重构完成，还是用 docker-compose up 启动了改造之后的应用。现在看到了这个 serverless 的应用工作正常。\nBen 说：我们在这demo 了 serverless 应用的改造的过程，可以看到 docker 是如何支持这种应用架构的。你可以打包 web front 为服务，它自动的在 Swarm 群集上无限延展这个服务。成为分布式计算的架构。还可以打包微服务的其它应用模块为 Serverless 应用架构。欢迎大家 参与到我的 Serverless github 项目中，和我一起互动，把 Serverless 在 docker 上的应用搞起来。https://github.com/bfirsh/serverless-docker 这里包括了以上演示的应用。\n黑客演示3：在线更新的无人机 这个团队做 in the air update 无人机实时演示。无人机其实是树莓派加他们的 docker 软件系统。这是一个嵌入式系统的设计。\n实时新旧系统的切换秘密在这里。新版的容器会先运行起来，新系统用一个队列来接收旧系统的数据，这些数据是新旧系统交接的必要的数据，系统会判断需要多长时间，需要收集那些数据来完成这个交接的过程。直到旧系统到新系统的割接完毕。\n程序猿开始更新 v1的代码，加入了摄像头实时视频功能。更新提交了 v2的镜像文件。在下图可以实时的监视到无人机的状态。\n无人机在在线更新软件中。并没有掉地上哈哈哈！\n右下角是新版本软件的摄像头把大会现场的视频拍摄，并实时传递到控制台的效果。此图上面的那个图，中间凸起震荡的那个块是无人机软件升级实时更新的过程。\n本黑科技演示完毕。\nhackathon 黑客大赛启动 主此人再次上台启动了黑客大赛。\n为期一个月的 hackathon 正式开始。\n最后看点 CEO CTO 上台感谢赞助商。所罗门开始讲黑客骚扰现象。号召大家通过http://hackharassment.com 网站来抵制中现象。\nBump UP 是通过手环实现的，人们的手环彼此碰撞会在系统中增加一个点数。宣布了碰撞点数最多的前5名，感谢他们在本次大会中，积极的和其它人互动和沟通，请他们去领奖。所罗门号召所有现场的人再次相互碰撞手环，系统系统的点数增加到两百万。来解锁 Docker 奖学金基金。很快大家碰撞起来。奖学金解锁。\n感谢进三千名的社区 贡献者，感谢 docker 的员工。所有人发来的自拍形成了一个西雅图拼图。最后大会圆满结束。\n看到最后的才能做最后的评论。这更感觉是一个黑客大会，引入了 docker 对社会的责任感的概念。商业财富越大的人社会责任感应该更多。更像是黑客公司商业成功之后，继续创新，并开始践行自己的社会责任的大会。大会并没有结束，黑客大赛在接下来的一个月里将在全球各地延续。\n",
    "ref": "/2016/06/22/closing-general-session-moby-docks-cool-hacks/"
  },{
    "title": "DockerCon 2016 D1 Keynote",
    "date": "",
    "description": "",
    "body": "看点：开场乌龟引起了喵星人大战，首次有吉祥物开启的科技盛会。 和往常一样 CEO 和 CTO 挑大梁将首日 keynote。 所罗门提出了 Docker 技术发展的三个核心方向和着眼点，并在每个方向上做了新技术发布。 1. 开发者体验提升， 正式发布 Docker for Mac/Windws 2. 编排能力的提升，正式发布 Docker 1.12 ，其中有四项能力提升；这是要废掉所有其他编排器的节奏啊~ 3. 运维体验提升，正式发布 beta.docker.com ；这是和公有云深度结合的产品，分为 AWS 和 Azure 两个模块。 一共有三个实景演示，都没有出现问题，演示很成功。\n现场录音 点上面的播放键，播放整场录音。请注意中间的数秒钟乃至数十秒的中断是正常，请快进收听。\n开场 屏幕上出现了乌龟开始做 demo，运行了一个容器。 猫咪大战，混乱了，猫星人入侵了。猫叫~~乱作一团··· 发生了什么？ dockercon16 吹起了号角。 乌龟再次出现在电脑上，运行了另外一个容器惊喜，这次是美妙的音乐。 调皮的乌龟折腾完了之后，主题曲想起来。4000多人的场子，大家很期待。\nCEO Ben Golub 演讲 Ben Golub CEO 出场。 Today we are all docker blue. 欢迎所有人。 我们和前两年的不同，我们发布了1.0 等等。 谈了很多 Docker 取得的成就。 感谢和表扬了社区。 感谢2900+贡献者。 社区的状态动态，每周超过300 PR，三分之二来自 Docker 公司之外。 docker meetup 的状况， 250+城市举行，125K 人参加聚会。 内容构建方面，docker hub 上有 460K 个应用，到目前为止有4.1B 此镜像下载。 感谢 docker 的生态社区。 讲述了这两年的使用场景的变化。Docker 逐渐成为了企业级的应用。 所有穿着红色衣服的起立，他们是 Dockr 公司的员工，感谢他们，请鼓掌。 感谢今年的赞助商。 向 Demo Gods 致敬，给神献上祭品，保证后续的演示顺利。 we pray to the old codes and the new.\nCTO 所罗门演讲 所罗门出场。 我去，4000多人在场，我老爸也在家看我视频直播。 很荣欣大家来参加，感谢大家来参会。 谁参加过 DockerCon14？ 我们要开始做很多的 demo 在会议过程中。 最精彩的部分是，我们来自全球各个行业的不同层面，多样性简直是不可思议。原因是：Programming is changing the world. 我们在一起的原因是：Docker 是编程创新的助力工具。 We’re building Docker incrementally, in the open. 最好的工具目前看不是那些软件工具巨人的公司提供的，而是来自社区和群众的创新，是你们指引着我们构建了愈来愈多的工具。 社区告诉我们几个方面需要努力。\n1 开发者体验 构建最好的工具，这个工具需要有这些特质：\n  get out of the way;\n  adopt to you；\n  make the powerful simple\n  我们努力地践行着这些理念。 Docker for Mac/Windows 将是最无缝的开发者体验。 Making things easy is really hard. 我们在寻找最佳的系统工程师，我们收购了 Unikernel 公司。 在移动游戏行业里面找到最佳的设计者。\n第一个演示 – Docker for Mac 演示者登台。 我是个开发者，今天第一天上班。 安装了 Docker for Mac 打开这个应用，启动它。 克隆\ngit clone viting-app 运行\ndocker-compose up 打开投票应用的两个web界面。 我不知道这个应用是什么，但是一个命令就启动了所有5个服务。 我发现了程序的 bug。 是否我第一天上班就能修复它？ 分析了一下程序架构图。 查看 docker-compose.yml 文件。 找到了一个 debug 显示的的那一行。 在代码中加入了 live debug 的断点。 开始 review 代码，发现了奇怪的地方。 找到了 git 上的代码，增加了评论，提出源码结果计算方法有问题。 现在删除了有问题的哪一行代码。 删除了断点。 用 live debug 的方式修复代码。 回到程序界面，发现 bug 没了。 做 git commit 提交修正后的代码。 查看了该应用在 staging 环境的情况，发现也有相同的结果计算的问题。 进入该环境的 Docker Cloud界面，看到了这个运行环境。 查看 result 服务的构建策略是自动构建。 Docker Cloud 自动接收了新的代码，Staging 环境的构建完成并通过了测试脚本，程序正常了。 查看云里的 Staging 环境的 bug 也被除掉了。demo 结束。\nSplice 的 CTO Matt 案例分享 Splice 的 CTO Matt；我们做的是个音乐服务的技术，我们构建的服务像是给音乐人用的 github。 每天都有人上传上很多 TB 的音乐数据。 我们在 Mac 上开发，在 Linux 上部署。 我们使用多种数据存储。 Docker 让我们保持多种环境的一致，降低了 debug 的时间。 所有的程序运行在容器中。 我们一天更新线上的业务20多次。 Developer 的第一天工作就能为业务提供价值。 我们使用 Docker for Mac。\n2 Orchestration 编排能力 我们听到很多 happy user 的故事。 感谢所有7万多 Docker for Mac beta 的反馈参与者。 我宣布 Docker for Mac/Widnwos beta 完全开放下载。 很多人告诉我们需要在 Orchestration 上更加努力。 它在 ship 方面提供支持，能发布你整个的应用，让你不再关心单个的容器。 Orchestration是个技术活，只有专家才能干。很少人能做这个工作。 可是用户怎么能即不出现手头人才短缺，又不被某些厂商在这方面给技术锁定呢？ 更好的方法是什么？ Docker 1.12 将内置编排功能。 最佳的编排技术将是 Docker 自己。\n我们先提前介绍一些它的新功能。\n  Swarm mode\n  Cryptographic node identity\n  Docker Service API\n  Build-in Routing Mesh\n  非常简单的演示，你就明白了。 欢迎第三个 编排的演示 Docker 1.12 技术。\n第二个演示 – docker swarm 功能演示 两个人上场。 用一个新的机器，上面只安装了 docker。 有三个节点。 第一个节点上初始化群集 docker swarm init 第二个节点上加入群集 docker swarm join 在第三个节点上加入群集 docker swarm join 三节点的群集建立完成。\n为毛它没有让输入任何安全的信息和选项，这就对了，我们有内置的 PKI 安全通讯机制。 所有节点都有自己的身份标识。密钥定期自动变化。所有通讯都可以追述到发起者的身份。\n你们都懂 docker run 子命令。 docker service 命令是新来的子命令。 service 的定义是将要维持服务的状态。\ndocker service create --name voting-app -p 5000 docker service ls 所有的服务只启动了一个容器，分布在三个节点上。\n看到投票应用页面显示了。\n浏览器访问了第一个节点的 ip:5000 ，然后第二个节点的 ip:5000 端口，发现实际上访问到了第一个节点上的的容器。这就是新的容器路由的功能。所有的节点访问这个服务的端口，都可以路由到该服务的容器里。\ndocker service scale 6 现在扩容服务的容器。 每次刷新页面，页面上容器的ID都在变，这是群集内置的 round robin 负载均衡策略，把访问分发到所有容器。这就是内置的负载均衡功能。\n我们升级这个 app 吧。\ndocker service update 演示容器镜像文件的更新 选择另外一个 tag 的镜像来升级 现在我们可以对电影投票了\n滚动升级可以支持 加上一次升级2个容器的升级选项，因此它现在是做两个一次的服务容器升级，直到所有容器都升级结束。\n我们说的自愈功能是说，能让应用可以在机器宕机的时候，业务也不中断。 请把有两个容器的 node3 关机。 调度器现在自动在 node2上长出刚才运行在 node3上的那两个容器。保持6个容器的服务配置。\n演示成功，并没有出问题。\nZenly 的创始人案例分享 所罗门高兴的再次上台。 这说明我们的祭品生效了，演示没有出毛问题。 docker 1.12 在几周后就发布，Docker for Mac beta 版本上现在就有这些功能。你们这些已经安装的现在就可以尝试这些功能。 我们自由的扩容业务应用，而服务速度不受到影响。 在大规模的关键业务中的部署才是目标。我们请 Zenly 的兄弟们上台。\nZenly 的人喝了两杯祭品的冰咖啡上台了。 我们有1M 用户，是最近的三个月内获得的。 500M events/day 一共才 6 engineers 我们运行业务在云上。 我们现在把部分业务迁移回自己的物理机。 我们在10台物理机上运行部分业务。 部分运行在 GCE 上。 我们感觉按需扩容很爽。\n3 运维体验 我们谈到开发者体验，业务编排。 群众还告诉我们“Ops experience” 运维体验是需要关注第三个侧面。 Docker 应该深度和云基础架构集成。\nbeta.docker.com 发布 我宣布beta.docker.com 发布。包括 docker for aws 和 docker for Azure 是最原生的 AWS 和 Azure 体验。是和云基础架构最深的集成。 现在可以用 AWS CloudFormation 来部署 Swarm 群集。 可以自动配置所有的负载均衡端口等配置。\nwww.docker.com/dab 发布 www.docker.com/dab 是新的可移植多容器应用打包格式。 这是新的 ops 体验。是让 developer 和 Ops 更容易工作在一起的方案。\n第三个演示 – 云运维体验 Developer：我想赶紧回家。我还需要赶紧交货。\ndocker compose bundle 产生了一个.dab 文件，齐活了。 把应用的 .dab 文件给 Ops 即可。 Ops：你的应用是 docker的么？ 额的个神啊！ 我喜欢在 AWS 上用Docker。 看我新建Stack的 AWS 向导，这里可以配置了一个新的 docker swarm 群集。 看我这有一个已经部署了100节点的群集。 所有网络、存储、负载均衡都不用手动配置。 复制 这个网址。 在 Mac 电脑的 shell 粘贴 ，后点击回车。 我们进入了命令行 docker for aws 的特殊的 shell 我能看的所有群集和主机的状态 把你的 .dab 文件给我，就欧了~ 用 USB copy 给你。 把文件 copy 给了 Ops scp .dab 文件到 swarm 群集中。 在进入 shell ls 能看的这个文件\ndocker deploy voting-app xxx.dab 看这些所有服务都运行了\ndocker service ls docker service update -p 80:80 voting-app docker service update -p 8080:8080 result-app docker service scale 扩容这些服务的容器数量 打开浏览器确认应用部署结果，找到 ELB 的配置，配置已经自动生成了。 浏览器中访问 ELB 的80端口上看的投票页面 在 ELB 的 8080 端口看的结果页面 这下应用部署完毕。 原来你的 Ops 工作怎么这么简单啊！！ I got go home ~~~\n结束 所罗门感谢大家，所请访问 docker.com/getdocker 有需要的尽管说。 请在这几天内，尽量多的告诉我们，你们的需求和使用场景。 请告诉我们 what we build next ! thank you very much ！！\n注意 我是 Maritn Liu 为您播报本次大会的各种信息，对以上内容有任何问题和疑问请加我微信咨询，我的微信号是 martinliu_cn ，这篇文章也会在我的微信公众号（aws-faq）和 ”刀客微播报“上发布。以上会议记录中所有命令的操作并不是准确的演示者输入，尽量参考这些命令来想想其可能的参数和语法，如果你安装了最新版本的 Docker for Mac 可以自己试一下。\n",
    "ref": "/2016/06/20/dockercon-2016-d1-keynote/"
  },{
    "title": "下一代应用为中心的平台 OpenShift",
    "date": "",
    "description": "",
    "body": "Amadeus uses next-generation containerized application platform with OpenShift from Martin on Vimeo.\n以上视频来源于：https://blog.openshift.com/openshift-3-amadeus-red-hat-summit-session-recording-recap/\n",
    "ref": "/2016/01/12/e4b88be4b880e4bba3e5ba94e794a8e4b8bae4b8ade5bf83e79a84e5b9b3e58fb0-openshift/"
  },{
    "title": "用 Jekyll + Github 建立静态站点",
    "date": "",
    "description": "",
    "body": "新建库 建立一个用户名开头的库，如我的github用户名是 martinliu， 新建的库的名字为 martinliu.github.io ; 这个库将是存放web页面的。包括该域名下的站点的所有相关页码代码文件和相关css,图片等文件。\n更新并上传新库 参考的命令如下：\n[bash] git clone https://github.com/martinliu/martinliu.github.io cd martinliu.github.io echo \u0026ldquo;Martin Liu\u0026rsquo;s Github Homepage\u0026rdquo; \u0026gt; index.html git add \u0026ndash;all git commit -m \u0026ldquo;Initial commit\u0026rdquo; git push -u origin master [/bash]\n打开浏览器测试你的网站，访问网址： http://martinliu.github.io ， 你已经可以看到你的初始化页码了。\nJekyll博客系统 Github网站上推荐使用Jekyll创建和管理这个博客系统。它是支持Markdown语法，不需要使用数据库，纯文本的静态网站和博客系统。使用它可以建立和管理一个风格美观，容易管理的网站，生成的网页可以上传到以上生成的网站库中。\n安装Jekyll系统 我的测试系统：Fedora 23。操作步骤如下。 安装依赖的包和ruby环境\n[bash] dnf install ruby ruby-devel gem gcc libffi redhat-rpm-config [/bash]\n更用国内的rubygem源 [bash] gem source -r https://rubygems.org/ gem source -a http://mirrors.aliyun.com/rubygems/ gem update \u0026ndash;system\ngem install jekyll [/bash]\n##本地测试jekyll站点 进入克隆到本地的库，并创建jekyll站点。\n[bash] cd martinliu.github.io rm index.html\njekyll new . New jekyll site installed in /root/martinliu.github.io. [root@demo-w540 martinliu.github.io]# ls about.md css _includes _layouts _sass _config.yml feed.xml index.html _posts [root@demo-w540 martinliu.github.io]# jekyll server Configuration file: /root/martinliu.github.io/_config.yml Source: /root/martinliu.github.io Destination: /root/martinliu.github.io/_site Incremental build: disabled. Enable with \u0026ndash;incremental Generating\u0026hellip; done in 0.205 seconds. Auto-regeneration: enabled for \u0026lsquo;/root/martinliu.github.io\u0026rsquo; Configuration file: /root/martinliu.github.io/_config.yml Server address: http://127.0.0.1:4000/ Server running\u0026hellip; press ctrl-c to stop. [/bash]\n编辑站点的相关文件，测试成功之后，在上传到github上，然可到 maritnliu.github.io 上检查和本地的显示效果是否相同。\n",
    "ref": "/2016/01/10/e794a8-jekyll-github-e5bbbae7ab8be99d99e68081e7ab99e782b9/"
  },{
    "title": "My Arduino Project status",
    "date": "",
    "description": "",
    "body": "Source code on github https://github.com/martinliu/ArduinoProjects\nProject 2 SOS led S.O.S LED device from Martin on Vimeo.\nProject 2 blink led Arduino Project 1 blink LED from Martin on Vimeo.\n",
    "ref": "/2016/01/04/my-arduino-project-status/"
  },{
    "title": "vimeo video sharing vs youku.com",
    "date": "",
    "description": "",
    "body": "vimeo 的特别域名没想到还给我留着的 http://vimeo.com/martinliu 从国内访问和上传视频是有问题的，需要用vpn才能正常访问，vimeo能共享到Wordpress上的video是没有视频的，播放的时候稍微有点卡；就算是稍微卡一点，也比youku视频前后的广告好，以后计划转战vimeo发布视频了。\n",
    "ref": "/2016/01/01/vimeo-video-sharing-vs-youku-com/"
  },{
    "title": "No Content Found",
    "date": "",
    "description": "",
    "body": "重新整理了blog的菜单样式，增加了三列显示模式，发布了各种格式的post，觉得blog样式还是越简单看着越顺眼。\n",
    "ref": "/2015/12/29/54083/"
  },{
    "title": "Nino Rota - Main Title (The Godfather Waltz)",
    "date": "",
    "description": "",
    "body": "[wm_audio] [audio mp3=\u0026ldquo;http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2015/12/Nino-Rota-Main-Title-The-Godfather-Waltz.mp3\u0026rdquo;][/audio]\n",
    "ref": "/2015/12/29/nino-rota-main-title-the-godfather-waltz/"
  },{
    "title": "IoT 是怎么被黑的？",
    "date": "",
    "description": "",
    "body": "IoT有公众的立场，也有厂商的算盘。微软的动作是比较快得，2015年春季就发布了IoT战略，其他厂商IBM，Amazon等等也都有各自的布局。在硬件厂商这一次侧，Raspberry则占据了比较显眼的位置；确实也吸引了比较多的眼球。它从2013年起一气出了很多型号的板子。回忆起来，当时除了记得SoC技术是价格非常便宜的，并没有太多关注这种硬件相关的东西。直到昨天我入手Raspberry 2 model B后，大致玩了一下，我隐约的感觉，今天谈到的 IoT 和以往确实不同了；这或许是” 范在型智能可互联网 “ 时代的到来，智能和wifi的植入是maker们欲罢不能的一件事情，在商业上是必要的卖点和噱头，是用户现实的和潜在的需求；可联网和可连接互联网，绝对是两个层面上的概念；封闭的信息孤岛式的网络已经无法通过自身实现其信息的价值，信息价值的实现必须通过与互联网的链接和互动来实现。联网意味着链接互联网，在哪里信息的融合和分析再反馈回到真实世界中，并完成某种动作，在这个闭环中，真实世界被投射到虚拟世界中去，然后再得到一个预期的反馈，计算机信息处理和控制在过程中起到了推动作用，真实世界中的人或者物对它的一个反馈使之所有抽象而似乎无形的信息技术和互联网实现了存在的价值；这是一种虚拟现实世界和人类主动且有意识地互动。\n扯远了，在某东购买的树莓板是这个这样的，如下图：\n\n它链接外部世界的方式就是通过板子上面的三个接口，下侧比较明显的排针，中上侧白色竖着的，和中右侧的两个白色排线插头。这些主要是链接传感器用的。另外还包括板载的4个USB口，USB口也可以接外设和Wifi模块。当然还有网线插口。\n这是 Raspberry 的2代B型版，它的特点是计算处理能力是比较强劲的。感觉做控制中心比较合适，如智能家庭的总控制中心。它还可以和Arduino组合起来，Arduino 的处理能力较低，可以通过它作为外部传感器的hub，单纯的做信息收集，和动作指令的执行（发出继电器开关的开合信号等）。就某种单一具体的IoT功能的实现，Raspberry和Arduino没有太大的差异。但是在构建复杂系统的时候，把两者结合起来的设计还是多见的。接下来，我可能会去把Amazon上的那个Arduino开发套装买回来，这样就配齐了，当然 Raspberry A型板也可以入。\n如果你把所有的东西都连接到互联网了，那么安全性怎么保证？今天在http://www.wired.com 网站上看到的头条就是《How IoT got hacked 》看完后，不得不倒吸一口凉气。不过安全总是在任何时间点、场合拿出来，可以吓死人的东西。不hack出一些值得被人黑的东西来，那你还能做出什么更有意义的事情呢。以上就是本次树莓派入手记录贴。\n",
    "ref": "/2015/12/29/iot-e698afe6808ee4b988e8a2abe9bb91e79a84/"
  },{
    "title": "超人组成的团队还是超级团队",
    "date": "",
    "description": "",
    "body": "建议所有管理者都可以反思一下：是否需要supper chicken 团队。先看下这个视频。 http://video-subtitle.tedcdn.com/talk/podcast/2015W/None/MargaretHeffernan_2015W-480p-zh-tw.mp4\nAbout the book In this wise and witty guide to creating strong company culture, business leader Margaret Heffernan lays the groundwork for a new kind of thinking: Organizations can create seismic shifts by making deceptively small changes.\nFar beyond a prescriptive list, this book spills over with fascinating anecdotes from organizations around the world. Heffernan reveals the surprisingly small changes any organization can make: how to empower every person as a leader: how to open channels as a real, active listening; the important of cutting back hours (and also leaning into crunch time); why leaving the office does wonders for your working brain; how conflict works as an essential tool for creative thinking; why companies that actively solicit involvement beyond their walls are so much more effective; how simple activities strengthen social capital between workers.\nPacked with compelling stories and startling statistics, Heffernan takes readers on a tour across the globe. Drawing from her years of experience as a business leader and ultimately proving that it\u0026rsquo;s often the small changes that make the greatest, most lasting impact.\n  This book is aimed at everyone — from the CEO to the janitor — who wants a better place to work. It looks at the accumulation of small, everyday thoughts and habits that generate and sustain culture: ways of speaking, listening, arguing, thinking, seeing. These aren’t multimillion dollar, multi-year programs; these are small steps that anyone can take at any time, the small steps that mark the beginning of big change.\n   Press and reviews Read a Q\u0026amp;A with Margaret on Huffington Post: \u0026ldquo;America\u0026rsquo;s Competition Fetish Kills Creativity and Produces Human Sheep\u0026rdquo;\nAn illustrated excerpt from Beyond Measure on MEDIUM: \u0026ldquo;Small Steps to Huge Change\u0026rdquo;\nRead what TIME has to say about Beyond Measure: \u0026ldquo;The Real Way to Fix Finance Once and for All\u0026rdquo;\nA great synopsis of Beyond Measure in Tech Cocktail: \u0026ldquo;What Makes Some Teams Better than Others\u0026rdquo;\nRead a wonderful review in The Globe and Mail: \u0026ldquo;Corporate culture the \u0026lsquo;secret sauce\u0026rsquo; of success\u0026rdquo;\n About the author Margaret Heffernan is an entrepreneur, chief executive, and author. She was born in Texas, raised in Holland, and educated at Cambridge University. She worked for the BBC producing television and radio programs and also developed interactive multimedia products with Peter Lynch, Tom Peters, Standard \u0026amp; Poors, and The Learning Company. She has served as Chief Executive Officer for InfoMation Corporation, ZineZone Corporation, and iCAST Corporation. Her book, Willful Blindness, was named one of the best business books of the decade by the Financial Times, and her most recent book, A Bigger Prize won the Transmission Prize in 2015. She blogs for the Huffington Post and Inc.com.\n",
    "ref": "/2015/10/12/e8b685e4babae7bb84e68890e79a84e59ba2e9989fe8bf98e698afe8b685e7baa7e59ba2e9989f/"
  },{
    "title": "Wordpress 创始人英年早逝-结肠癌",
    "date": "",
    "description": "",
    "body": "今天看到这条让人哀伤的新闻，真是感觉很难过。我是一个多年的Wordpress用户，本博客也是wordpress些的，而且记录多年的文章。wordpress是一个能让人很着迷的程序。它是一个__GPLv2__的开源软件。对我来说有一件事情是始终在于之斗争的，这就是“测试/更换wordpress的Theme和插件”；不夸张的说，当一个不需要编写一丁点css/php代码的人也能够完美地控制一个网站的功能和外表的时候，你会觉得渐渐的忽视了这个网站软件本身，你会被一下子陷入到，那浩如烟海的与之共生的生态系统所开发的免费资源中。wordpress具备了开源软件的一个核心特质“提供开放的平台，让周边的开发者和设计师能通过扩展开发来够推动它的用户社区的发展和繁荣”。 以wordpress为核心的周边生态系统有：功能插件、theme设计、SOE咨询、网店功能等等；以上这些养活了互联网上无数的个体或者公司；给无数的网站设计爱好者提供了创造和互动的机会。虽然，我最近对blog软件的注意力渐渐地转向了ghost，但是本站必将持续使用wordpress，会继续一如既往地关注它可能会给用户带来的惊喜，长期使用和关注一个开源软件的体验是无法替代的，是欲罢不能的。仅此献给Alex King，希望他的灵魂能升入天堂，一路走好。\nAlex King是wordpress的创始人之一，他的个人blog停止于2015-8-24日的一篇自己关于他的病情的文章，到目前为止有142个回复。http://alexking.org/about  这个页面是他的自述页面。\n",
    "ref": "/2015/09/30/wordpress-e5889be5a78be4babae88bb1e5b9b4e697a9e9809d-e7bb93e882a0e7998c/"
  },{
    "title": "Ghost 博客",
    "date": "",
    "description": "",
    "body": "话说本站也经历过很多变迁，使用的系统主要经历如下：google的blogspot （正式开始写blog的第一篇子在那，后来被墙）\u0026ndash;\u0026gt; 某共享wordpress平台（免费，名字已经几乎忘记了）\u0026ndash;\u0026gt; 免费国外VPS 主机wordpress (主机的ip很不靠谱，经常被墙) \u0026ndash;\u0026gt; 国外付费 VPS wordpress + 国内CDN，现在这样一直快三四年了。\nWordpress用了这么多年下来，真是觉得什么都可以做了，其中有一段时间也捣鼓过一阵子Drupal，但是还是觉得不如wordpress好使，它的功能非常成熟；themes和plugin 的生态系统非常成熟；价格在30～50$的themes我也是买过几个了；可是最后还是维持在了当前这个free theme 。\nGhost 给我的感觉就是简洁、干净和快速。http://hidocker.io 打建的过程中更是让我彻底的感觉到它的这些特点。它依赖的 nodejs和ngnix 两个包都只有几MB大小，它的安装包也很小。因此安装和配置也非常的简单，数量了10分钟之内就完成安装配置。使用了 ghost 两天之后，客观地讲它还是比较初级阶段，很多扩展和的定义都必须修改代码，这可能就会把恐惧修改代码的大批人拒之门外；甚至于安装新的theme这样的工作也是在linux的shell里面完成的。\n之后我会发布一篇详细的安装文档到 http://www.aws-faq.com/ 上，点这里 http://www.aws-faq.com/aws-ec2/ghost-%E5%8D%9A%E5%AE%A2%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E9%85%8D%E7%BD%AE.html\n",
    "ref": "/2015/09/27/ghost-e58d9ae5aea2/"
  },{
    "title": "Atomic Host 原子主机最简测试",
    "date": "",
    "description": "",
    "body": "环境准备 本文使用笔记本电脑+KVM虚拟化进行以下的测试过程，当然也可以用其它的操作系统加虚拟化软件的组合，测试机需要满足以下的条件： 测试虚拟机的建议配置1C/2GB/10GB 虚拟机使用的网络需要能连接到互联网 虚拟机需要能加载光盘iso文件 可以执行起停虚拟机操作，能通过控制它登陆来做初始化配置\n本文测试机是Lenovo T440s笔记本电脑，安装的操作系统是Fedora 22，使用KVM虚拟化，用Virt-Manager做GUI图形管理工具。建立了一个NAT的静态虚拟网络，虚拟机可以使用该网络来从互联网下载需要的文件包。\n下载Fedora Atomic Host虚拟机文件；下载页面： http://www.projectatomic.io/download/ 点击绿色的下载按钮。下载qcow2格式的Atomic Host虚拟机文件。复制下载的文件到虚拟机运行的存储目录中，文件名可以是master.qcow2，新测试虚拟机会基于它创建。\n在通过这个虚拟机模版文件生成测试机前，需要准备一个init.iso的文件，用来初始化测试机的主机名和初始用户密码。\n[bash] [root@martin-fedora vm]# cat meta-data instance-id: master local-hostname: master.xenlab.com [root@martin-fedora vm]# cat user-data #cloud-config password: smartvm ssh_pwauth: True chpasswd: { expire: False } [root@martin-fedora vm]# genisoimage -output init.iso -volid cidata -joliet -rock user-data meta-data I: -input-charset not specified, using utf-8 (detected in locale settings) Total translation table size: 0 Total rockridge attributes bytes: 331 Total directory bytes: 0 Path table size(bytes): 10 Max brk space used 0 183 extents written (0 MB) [/bash]\n以上的两个配置文件meta-data和user-data，最后使用genisoimage命令生成出文件init.iso。至此，Atomic Host 测试机的运行镜像文件和初始化配置文件都准备好了。\n创建Atomic host测试虚拟机 使用虚拟化的管理工具基于准备好的镜像文件（master.qcow2）创建测新的试虚拟机。在首次启动前，还需要添加光驱设备，指定光驱设备在启动时加载上文中创建的init.iso配置参数文件。 首次在虚拟管理工具上启动新创建的Atomic Host测试虚拟机，查看整个的启动过程。由于本文的测试网络不是DHCP的，因此测试机在启动后，还需要登陆虚拟机控制台，使用默认账户，用户名：fedora用户，fedora的密码在前面的配置文件中已经指定。静态IP地址参考的配置文件如下：\n[bash] [fedora@master ~]$ cat /etc/sysconfig/network-scripts/ifcfg-eth0 DEVICE=\u0026ldquo;eth0\u0026rdquo; BOOTPROTO=\u0026ldquo;static\u0026rdquo; ONBOOT=\u0026ldquo;yes\u0026rdquo; TYPE=\u0026ldquo;Ethernet\u0026rdquo; PERSISTENT_DHCLIENT=\u0026ldquo;yes\u0026rdquo; IPADDR=192.168.10.42 NETMASK=255.255.255.0 BROADCAST=192.168.10.255 NETWORK=192.168.10.0 GATEWAY=192.168.10.1\n[fedora@master ~]$ cat /etc/resolv.conf\nGenerated by NetworkManager search xenlab.com nameserver 192.168.10.1 nameserver 8.8.8.8 [fedora@master ~]$ [/bash]\n至此，Atomic Host测试虚拟机初始化安装完毕。\nAtomic Host基本操作 登陆Atomic Host测试虚拟机 master 之后首先需要测试是否能和互联网连接，ping外部的网址，看是否能够正常解析。由于后面很多相关测试都需要从联网下载内容。 用ssh工具登陆之后，看下它： [bash] [fedora@master ~]$ cat /etc/redhat-release Fedora release 22 (Twenty Two) [fedora@master ~]$ uname -a Linux master.xenlab.com 4.0.4-301.fc22.x86_64 #1 SMP Thu May 21 13:10:33 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux [fedora@master ~]$ dnf bash: dnf: command not found [fedora@master ~]$ yum bash: yum: command not found [/bash]\n根据以上显示发现它貌似就是一个Fedora 22 的服务器，不过默认没有dnf, yum包管理工具，不过有rpm。查询一下这个系统上有什么默认安装的软件包：根据rpm -qa 结果显示，Atomic Host 虚拟机默认安装了324个软件包。下面初步尝试一下 Atomic Host 操作系统更新和管理的主要命令 atomic / rpm-ostree\n[bash] [fedora@master ~]$ sudo atomic usage: atomic [-h] {host,info,install,run,uninstall,update} \u0026hellip;\nAtomic Management Tool\npositional arguments: {host,info,install,run,uninstall,update} commands host execute Atomic host commands info display label information about an image install execute container image install method run execute container image run method uninstall execute container image uninstall method update pull latest container image from repository\noptional arguments: -h, \u0026ndash;help show this help message and exit\nerror: too few arguments [fedora@master ~]$ sudo rpm-ostree Usage: rpm-ostree [OPTION\u0026hellip;] COMMAND\nBuiltin Commands: compose upgrade rebase rollback status db\nHelp Options: -h, \u0026ndash;help Show help options\nApplication Options: \u0026ndash;version Print version information and exit\nerror: No command specified\n[fedora@master ~]$ sudo atomic host status TIMESTAMP (UTC) VERSION ID OSNAME REFSPEC\n 2015-05-21 19:01:46 22.17 06a63ecfcf fedora-atomic fedora-atomic:fedora-atomic/f22/x86_64/docker-host [fedora@master ~]$ sudo rpm-ostree status [fedora@master ~]$ sudo atomic host usage: atomic host [-h] {rollback,status,upgrade} \u0026hellip;  positional arguments: {rollback,status,upgrade} host commands rollback switch to alternate tree at boot status list information about all deployments upgrade upgrade to the latest Atomic tree if one is available\noptional arguments: -h, \u0026ndash;help show this help message and exit\nerror: too few arguments [fedora@master ~]$ [/bash]\n下面使用 atomic host upgrade 来升级这个系统，使它运行在最新的补丁和版本下。这个过程需要下载180+MB的升级包，这个过程无法断点续传，但是可以任意中断。再次运行该命令后，可以重新从头下载，直到下载成功。下载成功并升级成功以后，重起操作系统。\n[bash] [fedora@master ~]$ sudo atomic host upgrade Updating from: fedora-atomic:fedora-atomic/f22/x86_64/docker-host\n0 metadata, 5051 content objects fetched; 183267 KiB transferred in 330 seconds Copying /etc changes: 25 modified, 0 removed, 41 added Transaction complete; bootconfig swap: yes deployment count change: 1 Changed: avahi-autoipd-0.6.31-31.fc22.x86_64 avahi-libs-0.6.31-31.fc22.x86_64 \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;. tcpdump-14:4.7.4-2.fc22.x86_64 tzdata-2015e-1.fc22.noarch udisks2-2.1.6-1.fc22.x86_64 Removed: docker-storage-setup-0.0.4-2.fc22.noarch pciutils-libs-3.3.0-1.fc22.x86_64 Added: docker-selinux-1.7.0-6.git74e7a7a.fc22.x86_64 iptables-services-1.4.21-14.fc22.x86_64 kubernetes-master-0.20.0-0.3.git835eded.fc22.x86_64 kubernetes-node-0.20.0-0.3.git835eded.fc22.x86_64 python-pip-6.0.8-1.fc22.noarch python-setuptools-17.1.1-3.fc22.noarch Upgrade prepared for next boot; run \u0026ldquo;systemctl reboot\u0026rdquo; to start a reboot [/bash]\n在reboot之后，这个系统就可以投入使用了。在启动的GRUB菜单上可以看到出现两个条目，默认进入最新的这个系统版本。\n[bash] [fedora@master ~]$ sudo atomic host status TIMESTAMP (UTC) VERSION ID OSNAME REFSPEC\n 2015-07-15 23:33:20 22.61 db540a53ba fedora-atomic fedora-atomic:fedora-atomic/f22/x86_64/docker-host 2015-05-21 19:01:46 22.17 06a63ecfcf fedora-atomic fedora-atomic:fedora-atomic/f22/x86_64/docker-host [/bash]  进入系统之后，我们看到上面这个命令输出，目前 Atomic Host 的操作系统有了两个版本，该系统可以从最新的系统回退或者回滚到旧的版本。可以认为它同时具有多个可以前后切换的操作系统版本。\n在一个Atomic Host上有两种软件交付方式： rpm-ostree 管理部署和升级host系统自身的软件 Linux 容器（目前Docker）提供很多容器来跑各种软件应用服务\n运行第一个Docker镜像 现在测试的是Atomic Host自身的管理工具，传统的Linux系统中，这个软件是用rpm包和系统服务的方式，被安装到被管理节点的，可是我们下面使用容器的技术来部署，也达到相同的管理功能。Cockpit是之前介绍过的一款系统管理工具，兼具对docker的管理功能，它可以Docker image的形式被下载，并且运行在本机的一个专有权限（提权）的容器中。它可以作为Atomic Host的主机管理工具，对Linix系统管理不熟练的人可以使用这个图形工具，查看和监控系统的状态，并且可以管理容器中Image。下面是安装和运行这个特殊功能容器的命令。\n[bash] [fedora@a1 etc]$ sudo atomic run cockpit/ws /usr/bin/docker run -d \u0026ndash;privileged \u0026ndash;pid=host -v /:/host cockpit/ws /container/atomic-run \u0026ndash;local-ssh efd3cbbad8452ff394e1d1a0c309870634207538597ba0cead26d790510e7a5e [/bash]\n上面这条命令执行完后，就可以在笔记本电脑的浏览器，输入网址，来访问这个工具，如： https://192.168.10.41:9090 登陆的用户名和密码是 Atomic Host的fedora和它的密码。\nHW实战篇 不错HW就是Hello World！它太有名了，掠过对它的介绍。现在可以让docker命令出场了。在命令行中不加任何参数，看下它的默认输出。输出一下它的版本信息。\n[bash] [fedora@master ~]$ sudo docker version Client version: 1.7.0.fc22 Client API version: 1.19 Package Version (client): docker-1.7.0-6.git74e7a7a.fc22.x86_64 Go version (client): go1.4.2 Git commit (client): 74e7a7a/1.7.0 OS/Arch (client): linux/amd64 Server version: 1.7.0.fc22 Server API version: 1.19 Package Version (server): docker-1.7.0-6.git74e7a7a.fc22.x86_64 Go version (server): go1.4.2 Git commit (server): 74e7a7a/1.7.0 OS/Arch (server): linux/amd64 [/bash]\n下面的实战内容是和过程如下：\n  下载fedora image\n  构建httpd image\n  构建HW主页\n  构建并测试HW网站\n  具体的命令执行过程如下：\n[bash] [fedora@master ~]$ sudo docker run -i -t fedora bash Unable to find image \u0026lsquo;fedora:latest\u0026rsquo; locally latest: Pulling from docker.io/fedora ded7cd95e059: Already exists 48ecf305d2cf: Already exists docker.io/fedora:latest: The image you are pulling has been verified. Important: image verification is a tech preview feature and should not be relied on to provide security. Digest: sha256:10ba981a70632d7764c21deae25c6521db6d39730e1dd8caff90719013858a7b Status: Downloaded newer image for docker.io/fedora:latest [root@f1c79aa4c931 /]# dnf update -y Fedora 22 - x86_64 608 kB/s | 41 MB 01:09 Fedora 22 - x86_64 - Updates 439 kB/s | 12 MB 00:27 Last metadata expiration check performed 0:00:19 ago on Fri Jul 17 13:30:18 2015. Dependencies resolved. Package Arch Version Repository Size Installing: python-pip noarch 6.0.8-1.fc22 fedora 1.7 M python-setuptools noarch 17.1.1-3.fc22 updates 425 k Upgrading: bash x86_64 4.3.39-4.fc22 updates 1.6 M\n\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;.\nTransaction Summary Install 2 Packages Upgrade 59 Packages Total download size: 48 M Downloading Packages: (1/61): python-pip-6.0.8-1.fc22.noarch.rpm 434 kB/s | 1.7 MB 00:03 \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;. Installed: python-pip.noarch 6.0.8-1.fc22 python-setuptools.noarch 17.1.1-3.fc22\nUpgraded: bash.x86_64 4.3.39-4.fc22 bash-completion.noarch 1:2.1-7.20150513git1950590.fc22 coreutils.x86_64 8.23-10.fc22 curl.x86_64 7.40.0-5.fc22 \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;.. systemd.x86_64 219-19.fc22 systemd-libs.x86_64 219-19.fc22 tzdata.noarch 2015e-1.fc22\nComplete! [root@f1c79aa4c931 /]# [root@f1c79aa4c931 /]# [/bash] 上面的过程下载和启动了一个fedora，然后更新系统到最新的包，为安装Web服务器打好了基础。\n[bash] [root@f1c79aa4c931 /]# dnf install -y httpd Last metadata expiration check performed 0:06:11 ago on Fri Jul 17 13:30:18 2015. Dependencies resolved. Package Arch Version Repository Size Installing: apr x86_64 1.5.1-3.fc22 fedora 111 k apr-util x86_64 1.5.4-1.fc22 fedora 96 k fedora-logos-httpd noarch 22.0.0-1.fc22 fedora 33 k httpd x86_64 2.4.12-1.fc22 fedora 1.2 M httpd-filesystem noarch 2.4.12-1.fc22 fedora 24 k httpd-tools x86_64 2.4.12-1.fc22 fedora 87 k mailcap noarch 2.1.44-1.fc22 fedora 36 k\nTransaction Summary Install 7 Packages\nTotal download size: 1.6 M Installed size: 4.4 M Downloading Packages: (1/7): apr-1.5.1-3.fc22.x86_64.rpm 128 kB/s | 111 kB 00:00 (2/7): apr-util-1.5.4-1.fc22.x86_64.rpm 100 kB/s | 96 kB 00:00 (3/7): httpd-filesystem-2.4.12-1.fc22.noarch.rpm 123 kB/s | 24 kB 00:00 (4/7): mailcap-2.1.44-1.fc22.noarch.rpm 123 kB/s | 36 kB 00:00 (5/7): httpd-tools-2.4.12-1.fc22.x86_64.rpm 185 kB/s | 87 kB 00:00 (6/7): fedora-logos-httpd-22.0.0-1.fc22.noarch.rpm 151 kB/s | 33 kB 00:00 (7/7): httpd-2.4.12-1.fc22.x86_64.rpm 363 kB/s | 1.2 MB 00:03 Total 264 kB/s | 1.6 MB 00:06 Running transaction check Transaction check succeeded. Running transaction test Transaction test succeeded. Running transaction Installing : apr-1.5.1-3.fc22.x86_64 1/7 warning: Unable to get systemd shutdown inhibition lock Installing : apr-util-1.5.4-1.fc22.x86_64 2/7 Installing : httpd-tools-2.4.12-1.fc22.x86_64 3/7 Installing : fedora-logos-httpd-22.0.0-1.fc22.noarch 4/7 Installing : mailcap-2.1.44-1.fc22.noarch 5/7 Installing : httpd-filesystem-2.4.12-1.fc22.noarch 6/7 Installing : httpd-2.4.12-1.fc22.x86_64 7/7 Verifying : httpd-2.4.12-1.fc22.x86_64 1/7 Verifying : apr-1.5.1-3.fc22.x86_64 2/7 Verifying : apr-util-1.5.4-1.fc22.x86_64 3/7 Verifying : httpd-filesystem-2.4.12-1.fc22.noarch 4/7 Verifying : httpd-tools-2.4.12-1.fc22.x86_64 5/7 Verifying : mailcap-2.1.44-1.fc22.noarch 6/7 Verifying : fedora-logos-httpd-22.0.0-1.fc22.noarch 7/7\nInstalled: apr.x86_64 1.5.1-3.fc22 apr-util.x86_64 1.5.4-1.fc22 fedora-logos-httpd.noarch 22.0.0-1.fc22 httpd.x86_64 2.4.12-1.fc22 httpd-filesystem.noarch 2.4.12-1.fc22 httpd-tools.x86_64 2.4.12-1.fc22 mailcap.noarch 2.1.44-1.fc22\nComplete! [root@f1c79aa4c931 /]# [root@f1c79aa4c931 /]# exit exit [fedora@master ~]$ [/bash] 上面在一个互动的Bash里面完成了httpd的安装，exit命令之后，容器会停止运行，可以把这个停下来的镜像文件用下面的命令提交到本地的image库中。\n[bash] [fedora@master ~]$ sudo docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES f1c79aa4c931 fedora \u0026ldquo;bash\u0026rdquo; 17 minutes ago Exited (130) 3 minutes ago desperate_franklin [fedora@master ~]$ sudo docker commit f1c79aa4c931 fedora-httpd c77c91fd4af681e736afc2ec76fc316732e25f52f6f3dd8aa97c973f28c55eb2 [fedora@master ~]$ sudo docker images REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE fedora-httpd latest c77c91fd4af6 25 seconds ago 605.7 MB docker.io/cockpit/ws latest 9a4331b694a6 3 weeks ago 572.2 MB docker.io/fedora latest ded7cd95e059 7 weeks ago 186.5 MB [/bash]\n第一个名为 “fedora-httpd” 的就是刚才安装完毕之后，停止的docker image，用commit提交到本第的库中待用。下面开始准备网站的内容，其实只有一个主页，上只有一句话“HW”\n[bash] [fedora@master ~]$ pwd /home/fedora [fedora@master ~]$ vi index.html [fedora@master ~]$ cat index.html Hello World! [fedora@master ~]$ tar -cf mysite.tar index.html [fedora@a1 ~]$ ls Dockerfile index.html mysite mysite.tar [fedora@master ~]$ vi Dockerfile [fedora@master ~]$ cat Dockerfile FROM fedora-httpd MAINTAINER MartinLiumartin@aws-faq.com\nAdd the tar file of the web site ADD mysite.tar /tmp/\nDocker automatically extracted. So move files to web directory RUN cp /tmp/index.html /var/www/html\nEXPOSE 80\nENTRYPOINT [ \u0026ldquo;/usr/sbin/httpd\u0026rdquo; ] CMD [ \u0026ldquo;-D\u0026rdquo;, \u0026ldquo;FOREGROUND\u0026rdquo; ] [/bash]\n上面这段命令中最重要的是 Dockerfiler 文件，这个文件的语法还有很多，以上是一个最简化的例子。使用它可构建一个具有静态页面内容的网站。下面开始构建这个网站的Docker image。\n[bash] [fedora@a1 ~]$ sudo docker build -rm -t mysite . Warning: \u0026lsquo;-rm\u0026rsquo; is deprecated, it will be replaced by \u0026lsquo;\u0026ndash;rm\u0026rsquo; soon. See usage. Sending build context to Docker daemon 31.74 kB Sending build context to Docker daemon Step 0 : FROM fedora-httpd \u0026mdash;\u0026gt; 05ce6f68d3f2 Step 1 : MAINTAINER A D Ministator email: martin@aws-faq.com \u0026mdash;\u0026gt; Running in 7ee99e26ab76 \u0026mdash;\u0026gt; 03cc8c0deff1 Removing intermediate container 7ee99e26ab76 Step 2 : ADD mysite.tar /tmp/ \u0026mdash;\u0026gt; 52abfb1966ad Removing intermediate container e6c20f7ca5ed Step 3 : RUN mv /tmp/* /var/www/html \u0026mdash;\u0026gt; Running in ef455353caff \u0026mdash;\u0026gt; 6e24f9a9ea6f Removing intermediate container ef455353caff Step 4 : EXPOSE 80 \u0026mdash;\u0026gt; Running in 252b59576b54 \u0026mdash;\u0026gt; 7dd7c049c9d2 Removing intermediate container 252b59576b54 Step 5 : ENTRYPOINT /usr/sbin/httpd \u0026mdash;\u0026gt; Running in 572c3dafa53a \u0026mdash;\u0026gt; fa01c160e081 Removing intermediate container 572c3dafa53a Step 6 : CMD -D FOREGROUND \u0026mdash;\u0026gt; Running in b133650a6e18 \u0026mdash;\u0026gt; f828e1847160 Removing intermediate container b133650a6e18 Successfully built f828e1847160\n[fedora@master ~]$ sudo docker images REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE mysite latest 1bd6d7c1970f 45 seconds ago 605.7 MB fedora-httpd latest c77c91fd4af6 18 minutes ago 605.7 MB docker.io/cockpit/ws latest 9a4331b694a6 3 weeks ago 572.2 MB docker.io/fedora latest ded7cd95e059 7 weeks ago 186.5 MB\n[fedora@master ~]$ sudo docker run -d -P mysite 6122ac7d4dff6cc73c4abc1523ac5dd02606c90d4e42da64823942d787694c1f [fedora@master ~]$ sudo docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 6122ac7d4dff mysite \u0026ldquo;/usr/sbin/httpd -D 37 seconds ago Up 35 seconds 0.0.0.0:32768-\u0026gt;80/tcp evil_bardeen e5032443ab69 cockpit/ws \u0026ldquo;/container/atomic-r 16 minutes ago Up 16 minutes stoic_sammet [fedora@master ~]$ curl localhost:32768 Hello World! [/bash]\n在最后的命令行输出中，成功的看到了Hello World!的出现。用的是curl的命令行 web 浏览器。\n",
    "ref": "/2015/07/18/atomic-host-e58e9fe5ad90e4b8bbe69cbae69c80e7ae80e6b58be8af95/"
  },{
    "title": "红帽媒体日",
    "date": "",
    "description": "",
    "body": "本次演讲用了大约25分钟，超时了大约5分钟多，但是其中有些观点还是没有叙述的很倒位。只能算是我的一种理解和解读，希望对道场的媒体朋友们对认识红帽公司有帮助。\n演讲源版slide和录音在这个网页上： http://investors.redhat.com/events.cfm 的这部分：\nJun 24, 2015\n10:30 AM - 1:00 PM ET\n Red Hat Analyst Day\nListen to webcast \nView Presentation\n12.2 MB\nAdd to Briefcase\nView Additional Information\n    我做了Pual这一段的翻译，翻译的文档下载点这里：[RH_Summit_Analyst_Day_Master_20150714_MartinLiu](http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2015/07/RH_Summit_Analyst_Day_Master_20150714_MartinLiu.pdf) ",
    "ref": "/2015/07/14/e7baa2e5b8bde5aa92e4bd93e697a5/"
  },{
    "title": "Ovirt 服务器虚拟化测试",
    "date": "",
    "description": "",
    "body": "本文安装和测试的软件是Ovirt+KVM的服务器虚拟化，这两个项目是红帽RHEVM+KVM服务器虚拟化的上游社区产品。可以通过这个文档清晰的了解到红帽服务器虚拟化产品的大体功能，基本特点。本测试文档使用的是Centos7+社区yum 源；因此是最新的ovirt和kvm的功能。如果是正式的企业级需求测试，请使用光纤或者传统存储，从而达到和vmware等商业产品最好的类比测试。尽量避免使用嵌套kvm虚拟化的方式，除非您很熟悉Linux，使用两个笔记本是最简单的测试环境。\n下图是Ovirt服务器的详细架构图。其中的ovirt-engine是本文安装和部署的部分，是用一个centos7的虚拟机安装的。Host1也是用一个centos7的虚拟机安装的。半年之前我也配置过一次嵌套kvm，根本是一头雾水，而且还没有成功，不过这次的配置过程却这么简单容易，就正常工作了。希望简单一点的人，可以把Host1用物理机来安装，也会节省很多时间。\n[caption id=\u0026ldquo;attachment_53901\u0026rdquo; align=\u0026ldquo;alignnone\u0026rdquo; width=\u0026ldquo;512\u0026rdquo;]ovirt 架构图[/caption]\nKVM嵌套虚拟化准备 在测试KVM服务器虚拟化的过程中，如果您能有独立的物理机跑Hypervisor，那么您可以忽略本节。至今进入ovirt的安装。 下面的测试的物理机是 Lenovo T440s 笔记本，运行的 Fedora 22 操作系统，使用 KVM manager 做虚拟机的管理工具。本次测试用到两个虚拟机：\n  ovirt: 运行服务器虚拟化的管理机ovirt，这个程序类似于vmware 的 vcenter。\n  ovirt-host : 用来被ovirt管理的hypervisor；使用 kvm 嵌套 kvm 的方式，来跑虚拟机。\n  确认本机的服务器虚拟机CPU Bios配置正常。\n[bash]\negrep -c \u0026lsquo;(vmx|svm)\u0026rsquo; /proc/cpuinfo 4\n[/bash]\n本机是i5的CPU，双核开启超线程，显示为4。还没有启用嵌套KVM的虚拟机，需要新建下面这个配置文件，操作系统不同，可能稍微不同，下面是以 Fedora 22 为例。\nvi /etc/modprobe.d/kvm-nested.conf 编辑以上文件，增加下面这行参数即可 options kvm_intel nested=1\n运行下面的命令，为操作系统内核加載此功能。\n[bash]\nmodprobe -r kvm_intel # unload modprobe kvm_intel # reload again\ncat /sys/module/kvm_intel/parameters/nested Y\n[/bash]\n用上面最后的cat的命令确认嵌套功能启用正常，看到的是Y即可。\n查看本机虚拟化的Cpu相关参数。\n[bash]\n[root@martin-fedora vm]# virsh capabilities | egrep \u0026ldquo;/model|/vendor\u0026rdquo; Westmere Intel none dac [root@martin-fedora vm]#\n[/bash]\n到此，物理机的相关准备工作完成。下面使用 Martin\u0026rsquo;s Perfect CentOS7 模板新建一个2C/4Gd的虚拟机 ovirt-host; 用这个虚拟机作为跑虚拟机的hypervisor把建立好的虚拟机先别开机，需要对它的配置做修改。编辑 ovirt-host虚拟机的配置，给这个嵌套的KVM hypervisor 增加和物理机相同的cpu属性。\nvirsh edit ovirt-host\n本嵌套kvm的虚拟机 cpu 参数如下，如果测试的物理机使用非 i5 的 CPU， 实际的配置参数应该和下面不同。\nWestmere Intel  保存配置，启动这个虚拟机，配置好主机名和网络ip地址。安装ovirt yum 源。做 yum update 之后，reboot待用。\n[bash] yum -y update yum install http://plain.resources.ovirt.org/pub/yum-repo/ovirt-release35.rpm\n[/bash]\n安装ovirt 服务器虚拟化管理机 使用 Martin\u0026rsquo;s Perfect CentOS7 模板新建一个1C/4G 的虚拟机 ovirt；这个虚拟机上还需要配置 NFS 服务器，用来做 跑虚拟机的共享存储和用于存储iso光盘的存储。\n安装和配置NFS的过程如下：\n安装 nfs 服务相关的包 yum install -y nfs-utils\n创建存储目录 mkdir -p /srv/ovirt/{iso,export,sata} chown -R vdsm:kvm /srv/ovirt/ chmod -R 770 /srv/ovirt/\n编辑nfs配置文件 /ect/exports ， 加入下面三行。\n/srv/ovirt/iso 192.168.10.0/24(rw,anonuid=36,anongid=36,all_squash) /srv/ovirt/export 192.168.10.0/24(rw,anonuid=36,anongid=36,all_squash) /srv/ovirt/sata 192.168.10.0/24(rw,anonuid=36,anongid=36,all_squash)\n由于centos 7 的nfs默认是v4，这和ovirt不兼容，需要修改配置文件改为 v3， 编辑 /etc/nfsmount.conf 加入下面两个参数。\nDefaultvers=3 Nfsvers=3\n#重启动 nfs 服务器 ，设置开机启动服务 systemctl start rpcbind.service \u0026amp;\u0026amp; systemctl enable rpcbind.service systemctl start nfs-server.service \u0026amp;\u0026amp; systemctl enable nfs-server.service\n下面开始安装ovirt服务器。\nyum -y update yum install http://plain.resources.ovirt.org/pub/yum-repo/ovirt-release35.rpm yum -y install ovirt-engine\n安装完后，用 engine-setup 命令配置和部署ovirt 服务器。\n[bash]\n[root@ovirt ~]# engine-setup [ INFO ] Stage: Initializing [ INFO ] Stage: Environment setup Configuration files: ['/etc/ovirt-engine-setup.conf.d/10-packaging-jboss.conf', \u0026lsquo;/etc/ovirt-engine-setup.conf.d/10-packaging.conf\u0026rsquo;] Log file: /var/log/ovirt-engine/setup/ovirt-engine-setup-20150711225251-f9k7an.log Version: otopi-1.3.2 (otopi-1.3.2-1.el7.centos) [ INFO ] Stage: Environment packages setup [ INFO ] Yum Downloading: ovirt-3.5-patternfly1-noarch-epel/x86_64 (0%) [ INFO ] Stage: Programs detection [ INFO ] Stage: Environment setup [ INFO ] Stage: Environment customization\n\u0026ndash;== PRODUCT OPTIONS ==\u0026ndash;\nConfigure Engine on this host (Yes, No) [Yes]: #回车，选择Yes Configure WebSocket Proxy on this host (Yes, No) [Yes]: #回车，选择Yes\n\u0026ndash;== PACKAGES ==\u0026ndash;\n[ INFO ] Checking for product updates\u0026hellip; [ INFO ] No product updates found\n\u0026ndash;== ALL IN ONE CONFIGURATION ==\u0026ndash;\n\u0026ndash;== NETWORK CONFIGURATION ==\u0026ndash;\nSetup can automatically configure the firewall on this system. Note: automatic configuration of the firewall may overwrite current settings. Do you want Setup to configure the firewall? (Yes, No) [Yes]: No #选择no，由于本机的服务没有安装防火墙 Host fully qualified DNS name of this server [unknown.prolexic.com]: ovirt.xenlab.com #回车继续\n\u0026ndash;== DATABASE CONFIGURATION ==\u0026ndash;\nWhere is the Engine database located? (Local, Remote) [Local]: #回车，选择 Local 继续 Setup can configure the local postgresql server automatically for the engine to run. This may conflict with existing applications. Would you like Setup to automatically configure postgresql and create Engine database, or prefer to perform that manually? (Automatic, Manual) [Automatic]: #回车，选择 继续\n\u0026ndash;== OVIRT ENGINE CONFIGURATION ==\u0026ndash;\nEngine admin password: Confirm engine admin password: [WARNING] Password is weak: it is based on a dictionary word Use weak password? (Yes, No) [No]: yes Application mode (Virt, Gluster, Both) [Both]: #回车，选择 Both 继续\n\u0026ndash;== PKI CONFIGURATION ==\u0026ndash;\nOrganization name for certificate [xenlab.com]:\n\u0026ndash;== APACHE CONFIGURATION ==\u0026ndash;\nSetup can configure the default page of the web server to present the application home page. This may conflict with existing applications. Do you wish to set the application as the default page of the web server? (Yes, No) [Yes]: Setup can configure apache to use SSL using a certificate issued from the internal CA. Do you wish Setup to configure that, or prefer to perform that manually? (Automatic, Manual) [Automatic]:\n\u0026ndash;== SYSTEM CONFIGURATION ==\u0026ndash;\nConfigure an NFS share on this server to be used as an ISO Domain? (Yes, No) [Yes]: no # 选择 no，本测试手工配置NFS，不需要安装程序配置。 继续\n\u0026ndash;== MISC CONFIGURATION ==\u0026ndash;\n\u0026ndash;== END OF CONFIGURATION ==\u0026ndash;\n[ INFO ] Stage: Setup validation [WARNING] Cannot validate host name settings, reason: resolved host does not match any of the local addresses [WARNING] Less than 16384MB of memory is available\n\u0026ndash;== CONFIGURATION PREVIEW ==\u0026ndash;\nApplication mode : both Update Firewall : False Host FQDN : ovirt.xenlab.com Engine database name : engine Engine database secured connection : False Engine database host : localhost Engine database user name : engine Engine database host name validation : False Engine database port : 5432 Engine installation : True PKI organization : xenlab.com Configure local Engine database : True Set application as default page : True Configure Apache SSL : True Configure WebSocket Proxy : True Engine Host FQDN : ovirt.xenlab.com\nPlease confirm installation settings (OK, Cancel) [OK]: #回车，选择 OK 继续 [ INFO ] Stage: Transaction setup [ INFO ] Stopping engine service [ INFO ] Stopping ovirt-fence-kdump-listener service [ INFO ] Stopping websocket-proxy service [ INFO ] Stage: Misc configuration [ INFO ] Stage: Package installation [ INFO ] Stage: Misc configuration [ INFO ] Initializing PostgreSQL [ INFO ] Creating PostgreSQL \u0026lsquo;engine\u0026rsquo; database [ INFO ] Configuring PostgreSQL [ INFO ] Creating/refreshing Engine database schema [ INFO ] Creating CA [ INFO ] Configuring WebSocket Proxy [ INFO ] Generating post install configuration file \u0026lsquo;/etc/ovirt-engine-setup.conf.d/20-setup-ovirt-post.conf\u0026rsquo; [ INFO ] Stage: Transaction commit [ INFO ] Stage: Closing up\n\u0026ndash;== SUMMARY ==\u0026ndash;\n[WARNING] Less than 16384MB of memory is available SSH fingerprint: DF:FF:42:14:80:35:E2:7D:68:3A:1F:83:65:6E:89:EA Internal CA 99:17:7A:42:D0:9D:D7:33:DE:C3:3E:07:EE:15:5D:01:28:63:4A:BF Web access is enabled at: http://ovirt.xenlab.com:80/ovirt-engine https://ovirt.xenlab.com:443/ovirt-engine Please use the user \u0026ldquo;admin\u0026rdquo; and password specified in order to login In order to configure firewalld, copy the files from /etc/ovirt-engine/firewalld to /etc/firewalld/services and execute the following commands: firewall-cmd -service ovirt-postgres firewall-cmd -service ovirt-https firewall-cmd -service ovirt-fence-kdump-listener firewall-cmd -service ovirt-websocket-proxy firewall-cmd -service ovirt-http The following network ports should be opened: tcp:443 tcp:5432 tcp:6100 tcp:80 udp:7410 An example of the required configuration for iptables can be found at: /etc/ovirt-engine/iptables.example\n\u0026ndash;== END OF SUMMARY ==\u0026ndash;\n[ INFO ] Starting engine service [ INFO ] Restarting httpd [ INFO ] Stage: Clean up Log file is located at /var/log/ovirt-engine/setup/ovirt-engine-setup-20150711225251-f9k7an.log [ INFO ] Generating answer file \u0026lsquo;/var/lib/ovirt-engine/setup/answers/20150711225734-setup.conf\u0026rsquo; [ INFO ] Stage: Pre-termination [ INFO ] Stage: Termination [ INFO ] Execution of setup completed successfully\n[/bash]\n安装成功，用浏览器，访问ovirt 服务器IP地址使用 admin / 密码 登陆管理员控制台，第一次比较慢，验证安装是否完全成功。\n使用命令确认nfs [root@ovirt ~]# showmount -e Export list for ovirt.xenlab.com: /srv/ovirt/sata 192.168.10.0/24 /srv/ovirt/export 192.168.10.0/24 /srv/ovirt/iso 192.168.10.0/24\n在ovirt服务器中添加这三个存储，然后在命令和中确认iso存储已经可用。\n[bash]\n[root@ovirt ~]# engine-iso-uploader list Please provide the REST API password for the admin@internal oVirt Engine user (CTRL+D to abort): ISO Storage Domain Name | Datacenter | ISO Domain Status ovirt-iso | Default | active\n[/bash]\n把需要安装的光盘镜像文件，先复制到ovirt服务器上，然后传入iso存储。\n[bash]\n[martin@martin-fedora iso]$ scp CentOS-7-x86_64-Minimal-1503-01.iso root@192.168.10.25:/root/ The authenticity of host \u0026lsquo;192.168.10.25 (192.168.10.25)\u0026rsquo; can\u0026rsquo;t be established. ECDSA key fingerprint is SHA256:KMGYLWZu14ZKaUwizIORgQ598Bpc0PKzNWF0qop2VAQ. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added \u0026lsquo;192.168.10.25\u0026rsquo; (ECDSA) to the list of known hosts. root@192.168.10.25\u0026rsquo;s password: CentOS-7-x86_64-Minimal-1503-01.iso 100% 636MB 90.9MB/s 00:07 [martin@martin-fedora iso]$\n[/bash]\n用这个命令上传光盘。 engine-iso-uploader upload -i ovirt-iso /root/CentOS-7-x86_64-Minimal-1503-01.iso\n之后就可以在控制台中创建虚拟机了。在Web界面上安装虚拟机，是需要安装客户的程序的，在 Fedora 22 笔记本中安装它们。 yum install spice-xpi virt-viewer\n点击新创建的虚拟机，启动之后，选择控制台，打开后，开始系统安装。\n参考文档 本文没有做截图，是由于以下参考文档都有相关截图和步骤说明；因此，在使用本文档的过程中，一定要同时打开这几篇文档。\nhttp://www.ovirt.org/Quick_Start_Guide#Install_oVirt_Engine_.28Fedora.29%60\nhttp://jensd.be/?p=550\nhttps://xrsa.net/2015/02/04/installing-ovirt-3-5-on-centos-7-hosted-engine/\nhttp://www.server-world.info/en/note?os=Fedora_22\u0026amp;p=kvm\u0026amp;f=8\n",
    "ref": "/2015/07/12/ovirt-e69c8de58aa1e599a8e8999ae68b9fe58c96e6b58be8af95/"
  },{
    "title": "Boston 和 NYC 的 运动日志",
    "date": "",
    "description": "",
    "body": "波士顿的跑步 第一跑 - 12公里 \n推辞了饭局的夜跑，跑步过程中被阵雨浇透，找错了回来的桥，路程没有记录完整。\n第二跑 - 8公里 \n本想跑的比前一次更远，结果起晚了，跑了8公里就被晒的不行，汗狂出，提前失去斗志，返回。这时感觉还是有跑友会更好些。\n第三跑 - 10公里 \n陪同事满跑10K，在一个海湾处，居然海湾是闭合的，跑了三圈，其实那个Castle Island Park有点意思，可惜没有进去。\n第四跑 - 10公里 \n领略了市内最繁华的街道，最美的市中心公园，跑过了 林阴道，再次重温河边的感觉，这是下午下班后的跑步，不管你是什么时间，什么地点跑，基本上到处都是跑步的人。\n波士顿骑行 第一次 46.4 km \n自行车租金是25刀，下午开完会发现其它两个同伴时差严重，因此我独自骑行出去。骑行的方向其实是波士顿马拉松延伸的方向，只是那个路线是要在公路上的，车多没法骑行那个赛道，骑车出去闲逛，也超过了一个全马的距离，基本上把哈佛和MIT逛清楚了。\n第二次 21.7 km \n第二次，本来不想去，可是需要给伙伴去带路，就带他们走了一遍昨天的路，让他们也浏览了我看过的景点。\n纽约跑步 - 中央公园 10KM \n中央公园打卡跑过，很满意的得到了这个路线，公园里里面的运动氛围很强，爽跑一圈。\n",
    "ref": "/2015/07/09/boston-nyc-running-log/"
  },{
    "title": "首次美国东海岸之旅",
    "date": "",
    "description": "",
    "body": "行程 在波士顿的住宿是非常完美的体验。先住了两天剑桥的LeMeridien（SPG）；由于6月是我的生日，因此酒店给我加了早餐，使用IBM的企业代码订房确实便宜了一大块。剩下几天住的Westin Waterfront，和另外一个SPG白金卡同事同住，由于是白金卡，所以直接就给升级到套房了，当然附赠免费早餐；今房间一看，很大的两间房间，各自独立的电视和洗手间。\n说下在美国第一次做长途BUS的感受，我是在网上定的票。从波士顿到纽约4个多小时的路程，28$的价格。由于我记错了时间，同事开车送我去车站后，我看了票后，才惊醒，到达候车室的时候，我的那班车已经开车15分钟了。车票是电子邮件中的二维码。我问车站的工作人员，他说你需要去standby下一班车，下一班车要过1小时后发车，我到了那边standby的队列中。心里真是有点没谱，如果那个车上没有空位的话，我就残了。还好，开始上车时第一批是买了那班车票的人；第二批是standby的人，还好有空座位。最后一波是需要副现金上车，而没有买票的人，那部分人好像话了50多刀。在开车的过程中没有停车，车上居然有卫生间，就在车的尾部，我也用了一下，确实很方便，很干净。到了纽约之后，一下车我就走向最近地铁站开始了我的纽约之行。\n波士顿 波士顿有美国的雅典之称，到处透露着历史感，街道相当干净，气温体感非常舒服。这是一个运动的城市每年的波士顿马拉松比赛不知道吸引了多少人，作为一个跑步爱好者，我到此地也算是朝圣之旅了。到的第二天，就有BAA的10公里的比赛，我看到了才意识到，应该提前报名，说不定可以参加上呢！\n在波士顿我跑了三次。第一次本想早晨跑，提前规划好的路线，可是早晨下雨，没有跑成。结果晚上回来后，同事拉我去配客户吃饭，没去，夜跑了十二公里。在跑的中间下雨了，是阵雨，淋了我20多分钟，浑身湿透了，快回到酒店的时候雨停了。回来查跑步轨迹一看，还是跑错了路线，返回的桥还是选择错了，回程的路线基本正确。第二次跑步是早晨晨跑，起的有点晚，还是在查尔斯河边和前一次一样，这次看到了很多早晨练习划船的人，非常多的人在河上划着各种船，有些是有教练指导的，有些是自己联系的。第三次是和同事一起，在海边找了一个港口的地方，港口恰好是环形封闭的，跑了3圈，10公里。第四次是开晚会去跑步，在市中心的酒店跑到城市中心公园，有跑回查尔斯河，然后返回，返回过程中遇到上坡下坡，一个人有点累，10公里做罢。回程一边找路一边欣赏城市，也算是把波士顿城区看了仔细。剩下两次运动是骑行，这里骑行的人也很多。自己骑了一次，和同事一起骑行一次，一共50公里。顺便欣赏了哈佛和MIT学校的校园。\n波士顿的龙虾不可以不提，吃了三次，后两次在同一家吃的，这家专门做龙虾，吃的非常过瘾。\n纽约 在纽约我住在airbnb的一个民宅里，主人是个南美小国的人，他没有工作；估计也是租来的房子，然后转祖一间卧室做房东，airbnb算是让他也有钱赚，有生计了。这个公寓里中央公园很近，我去中央公园跑了一次，感觉非常好，那里有浓厚的运动气息，各种人在里面跑步，骑车，散步，骝狗。两次穿过中央公园都有看到跑步比赛。我买了一张5天的地铁票，算是用足了。去了很多景点，感受到了大纽约的感觉。现在感觉纽约一周可以逛的差不多，4天根本不够。我最完美的两天是大都会博物馆和自由女神/爱丽丝岛。大都会博物馆里面我足足泡了一天，停没电了3个讲解器；直到人闭馆赶人，我才走，看了四分之三不到。真是有点走马观花，很多没有看仔细。自由女神像其实可以注册一下，就能够登到它的身体里，到达头部，从眼睛往外看，我也是去了才知道。爱丽丝岛值的仔细看，它是美国移民博物馆，看了它，彻底颠覆了我对美国移民的看法。\n时间有限，工作太忙，就这个流水帐，算是总结一下这次美国东岸之旅吧！\n图片 以下图片都是手机拍摄。\n[gallery link=\u0026ldquo;file\u0026rdquo; ids=\u0026ldquo;53844,53845,53846,53847,53848,53849,53850,53851,53852,53853,53854,53855,53856,53857,53858,53859,53860,53861,53862,53863,53871,53865,53866,53867,53868,53869,53870,53873,53874,53877,53876,53875,53878\u0026rdquo;]\n",
    "ref": "/2015/07/09/e9a696e6aca1e7be8ee59bbde4b89ce6b5b7e5b2b8e4b98be69785/"
  },{
    "title": "icinga2 企业级功能评测1",
    "date": "",
    "description": "",
    "body": "Icingaweb 2 用户权限管理 icingaweb 2 是诸多GUI中最新的一种，也有替代其它之前所有GUI的趋势，目前看还比较新，只有最基本的功能。登陆Web界面的用户，用户和组的信息可以使用自己的数据库存储或者配置文件存储，也可以使用外部的LDAP集成，使用php-ldap模块集成外部的LDAP/MS AD服务器。 具有完整的RBAC模式; User -\u0026gt; Group -\u0026gt; Role = Permission Set（操作 action） + monitoring/filter/objects(范围 scope)\n   \nIcinga2 的联系人和联系人组 在icinga2服务器端，在配置文件中定义了组和用户，他们在Web GUI界面上叫做 Contacts / Contactgroups 。\n[bash] [root@icinga2-test conf.d]# cat users.conf /**\n The example user \u0026lsquo;icingaadmin\u0026rsquo; and the example group \u0026lsquo;icingaadmins\u0026rsquo;. */  object User \u0026ldquo;icingaadmin\u0026rdquo; { import \u0026ldquo;generic-user\u0026rdquo;\ndisplay_name = \u0026ldquo;Icinga 2 Admin\u0026rdquo; groups = [ \u0026ldquo;icingaadmins\u0026rdquo; ]\nemail = \u0026ldquo;martin@aws-faq.com\u0026rdquo; }\nobject UserGroup \u0026ldquo;icingaadmins\u0026rdquo; { display_name = \u0026ldquo;Icinga 2 Admin Group\u0026rdquo; } [/bash]\nUser / UserGruop 是Icinga出发通知的对象，定义在这个配置文件中，使用规则把他们和监控对象（host/service/等）关联起来，在通知规则中实现不同的通知策略。如发邮件等。\nIcinga2的HA和分布式架构 \nicinga2的Cluster是通过多个运行的实例配置在一起的，有这样几个特性：实例之间使用SSL的加密通信；彼此之间是双向连接；用Zone来分隔不同租户的配置域；基于Hash的负载分配；系统的各种功能组件由Cluster来管理其分布。它可以实现某个节点宕机后的自动分布监控数据采集命令在其它节点上的执行。\n\nicinga2 Client是远程执行的一种节点，它和Cluster中的所有节点形成群集，在数据中心的其它网段或者地点采集本地的监控状态数据，然后把结果传送回上级的Cluster群集节点。icinga2可以通过配置向导完成远程client/Satellite卫星节点的配置。它们之间的通行是基于证书的TLS加密，这个证书可以借用puppet的证书。远程Client/Satellite节点可以运行在三种模式下：具有本地监控配置，没有本地监控配置，靠上级群集发送监控配置。\n其它企业级功能在后续文章中继续评测，您可以通过下面的评论，来提出您所关注的待评测功能。\n",
    "ref": "/2015/07/09/icinga2-e4bc81e4b89ae7baa7e58a9fe883bde8af84e6b58b1/"
  },{
    "title": "Red Hat Summit之Paul的开源逻辑思维",
    "date": "",
    "description": "",
    "body": "应用为王，操作系统是心跳。从整个行业的角度，而不只是操作系统和某种工具的角度看，行业已经发生了重大的变化。下面是一些例证。\n  VMWare几年前说操作系统已死，可是最近却发布了Linux操作系统的容器技术的产品线。\n  微软也把它的一些技术开源了，并且在这些方面取得了一些它们认为可喜的进展。\n  IDC的调查显示，数据中心的操作系统目前是两个主要选择：Linux和Windows。以上说明了：开源不再是非主流，而进入了数据中心主流技术，企业现在开发的应用将不得不在两种操作系统中做出选择。\n[caption id=\u0026ldquo;attachment_53819\u0026rdquo; align=\u0026ldquo;aligncenter\u0026rdquo; width=\u0026ldquo;800\u0026rdquo;] Keynote 笔记[/caption]\n从这个角度出发，Red Hat的使命才刚过开始，它中在用Linux和相关开源技术来变革整个企业数据中心的技术堆栈；从基础架构一直到应用开发。\n为何开源技术当今如此之火热？开源技术正在解决和处理现实社会中那些最复杂的业务问题。为什么会这样？驱动因素是什么？是动态变化的企业业务需求。\n开源技术最擅长的是快速地创新，这成为了企业技术创新和业务变革的动力，IT也逐渐因此从成本中心转变为价值和创新中心。\n开源不仅仅只是看到源代码，更重要的：它是自由开放的平台，是分享的平台，它萌生了持续不断的创新，一个创新基于另外一个创新之上，一环接一环地扩散开来，根本停不下来。 这意味着技术问题能够被更快、更好地解决；而不是丢给私有软件技术厂商们各自独自解决，企业最等来消费他们的产品。\nLinux是计算供给层，毫无疑问云计算和软件定义存储都基于它。它不能叫做一个Linux社区，而是一组相关的社区项目协作在一起共同创新，这样才带来了企业可以使用的高性能稳定的操作系统；这样Red Hat才有可能给企业带来企业级Linux操作系统。\nKVM是计算的虚拟化抽象层，VMWare最先进入这一企业市场，它试图用封闭的管理层和锁定的模式来控制这个市场，从而控制客户。Red Hat的使命是：为企业提供了Linux操作系统和至上的开放虚拟化技术；企业可以在这个层面消费开源开放虚拟化技术，并做出备份的方案选择。\n没有Linux和开放虚拟化云计算就不存在。公有云提供商使用这些技术构建了共有云服务。可是企业不想让自己的业务运行在防火墙之外，因此OpenStack 项目应运而生。它让企业构建私有云成为可能。Red Hat在OpenStack上面所有的贡献都100%的提交到社区，成为主流代码的一部分；从而OpenStack能够运行在Red Hat Linux和KVM之上，这使得Red Hat巨大的Linux生态系统的价值服务与OpenStack领域；企业能够借此放心地在OpenStack构建的私有云，并运行企业重要的业务。\n在开源的开发框架里，开发人员可以有更多、更新的开发语言、开发工具、库和社区的支持，这使他们能更快地解决业务问题。这些框架首先被广泛应用于互联网行业公司。Red Hat基于JBoss社区为企业提供了企业级的应用服务器、集成工具、规则引擎和丰富的开发语言。让企业级应用能像互联网公司一样地使用开放应用所需的开发框架和开发平台。相比私有技术公司用了四十多年达到目前的程度，开源领域的快速创新用十几年就做到了，发展速度比私有软件快很多。\n现在看到了基础架构和开发框架都极大地受到了开源技术的影响、冲击和变革。运维和开发之间亟待出现一种融合技术，来改善目前的互为孤岛的现状。这种联系将使开源技术为他们带来最大的共同价值。\n容器技术实际上在操作系统中存在了很多年了，只是最近才被引入开源领域；它的出现将确实会改善孤岛问题，为开发人员解决了应用在各种混合的计算和存储平台之间的可移植性、一致性和敏捷性等问题。\n开发和运维之间的割裂还导致了业务创新的迟钝，这个问题已经持续存在很多很多年了。因此Red Hat发布了Red Hat Atomic Enterprise Platform。让企业应用可以安全地在各种形式的计算平台上一致地运行。Red Hat 发布了OpenShift v3 ，它是一些列容器的自动化调度和部署管理工具集合，并包含全套的开放应用开发框架平台。它能帮助企业基于容器技术发展出新一代的混合应用。\n为何企业IT技术会有这些变革？为何这些变革会发生？其实还是企业不得不快速地响应业务的变化，企业不得不使用IT技术来创造出更多的价值，应用开发不得不跟上需求变化的脚步，基础架构的运作和运维再也不允许我们手工地安装一台服务器，频繁地去手动更改网口跳线。企业必须面对和适应动态的业务变化，不光要从开发层面，同时从运维层面。\n企业需要构建和重写无状态的业务应用，并使用软件定义存储来解决传统存储的空间不能无限扩容的问题。Gluster和Ceph在这方面已经日臻成熟，并或将去替换私有的传统存储技术。\n\n企业应用DevOps是一种趋势，它不是一个理论，而是一种实践。Red Hat的全线企业级开源技术平台已经做好了准备，企业现在就可以开始DevOps实践之旅。\n开源和闭源之战将不可逆转地持续下去，Red Hat将持续守护开源阵营。私有软件技术不愿意看到逐渐开放的变化，他们不希望开放，不愿意去分享；Pual坚信开放不仅仅是看到代码而已，而是与之共生，是开放的软件开发流程，是基于开放代码上的不断创新活动。这是一场宏大的战役，开源逐渐开始在一些战斗中取胜，待到明年此时，或将看到开源是如何在企业IT基础架构上全面获胜的。\n本演讲的官方Blog报道：http://summitblog.redhat.com/2015/06/24/paul-cormier-announces-new-products-and-technologies-at-red-hat-summit/\n下面是演讲实况视频。\n",
    "ref": "/2015/07/01/red-hat-summite4b98bpaule79a84e5bc80e6ba90e980bbe8be91e6809de7bbb4/"
  },{
    "title": "Boston Running #1 Charles River",
    "date": "",
    "description": "",
    "body": "时差如期而至，现在时本地时间清晨3：40，我还是一点睡意也没用，百无聊赖中计划一下明天的跑步路线。根据Boston的Garmin的热力地图，我观察了一下Clarles河附近的跑步路线，看着很不错。计划明天早晨跑右侧的这一部分。如下图所示。 \n这部分是Charles河入海口的这个部分。从酒店出门大概的路线如下：\n  从酒店 右拐 到 Sidney St + Massachusetts Ave， 在右拐一直到河边\n  到河边的桥头，右拐顺河边向东跑，一直跑到头\n  在Longfellow bridge 桥下，顺着Edwin H Land Blvd穿过该桥\n  延河边来到 Museum of science 前，左拐，绕Lechmere Canal Park，来到科学博物馆门前的路\n  经过Charles大坝这条路，到河的南岸\n  在State Police 警察局门口右拐到河边，眼查尔斯河滨大道一直往西跑\n  经过Boston University Bridge，继续向前跑\n  经过 Western Ave Bridge 继续向前跑\n  到了John W. Weeks Bridge 上桥过河，到达河对岸\n  进入 Dewolfe St， 到Arrow St 右拐\n  跑回 Massachusetts Ave, 沿着街道一直跑回去\n  跑步的实际路线图和数据贴图如下。\n\n",
    "ref": "/2015/06/21/boston-running-1-charles-river/"
  },{
    "title": "icinga2 监控工具评测",
    "date": "",
    "description": "",
    "body": "本来想写一个安装手册，可是安装完成之后发现其实非常简单，最后就把题目改为评测了。本文也不是全面的评测文章，关于它的能力和功能，待后续了解的深入了在继续更新本文。\nicinga2 架构分析 请下载和查看这个icinga2官方的文档：[su_button url=\u0026ldquo;http://pan.baidu.com/s/1qW3JkJE\u0026rdquo; target=\u0026ldquo;blank\u0026rdquo; style=\u0026ldquo;stroked\u0026rdquo; background=\u0026quot;#cccc00\u0026quot; size=\u0026ldquo;6\u0026rdquo; icon=\u0026ldquo;icon: cubes\u0026rdquo;]下载点这里[/su_button]\n\n为什么用icinga，原因如下：\n[su_list icon=\u0026ldquo;icon: eye\u0026rdquo;]\n  Nagios的架构不能扩展\n  增加模块是比较困难的\n  不是群集和分布式监控架构\n  安全性相对糟糕\n  配置功能有限\n  [/su_list]\n安装配置 icinga2的安装可以说非常简洁，基本上配置好yum源，几条命令就装万了，而且就可以用了。只是在web界面选择和配置上稍微有点麻烦，它目前有三个可以安装配置的界面：classic, icinga-web, icinga-web2； classic太老了，不具有极其强烈的怀旧情节，就别碰了。建议生产环境中还是使用icinga-web；web2太新了，很多集成的项目的都还没有做好，还比较初级，功能不完善。\n待续~~\n",
    "ref": "/2015/06/18/icinga2-e79b91e68ea7e5b7a5e585b7e8af84e6b58b/"
  },{
    "title": "在 RHEL 7 上安装 Foreman 1.8",
    "date": "",
    "description": "",
    "body": "首先安装RHEL7使用光盘安装最小化系统，安装完成之后，关闭防火墙和SELinux（为了测试方便），配置主机名为FQDN格式，如 fm1.8.xenlab.com； 加本机的主机名解析到/etc/hosts 文集中。之后注册到RHN。\n[bash]\n[root@fm18 ~]# subscription-manager register [root@fm18 ~]# subscription-manager attach \u0026ndash;auto [root@fm18 ~]# subscription-manager repos \u0026ndash;disable=\u0026quot;*\u0026quot; [root@fm18 ~]# subscription-manager repos \u0026ndash;enable=rhel-7-server-optional-rpms [root@fm18 ~]# subscription-manager repos \u0026ndash;enable=rhel-server-rhscl-7-rpms [root@fm18 ~]# subscription-manager repos \u0026ndash;enable=rhel-7-server-rpms [root@fm18 ~]# rpm -ivh http://yum.puppetlabs.com/puppetlabs-release-el-7.noarch.rpm [root@fm18 ~]# yum -y install http://yum.theforeman.org/releases/1.8/el7/x86_64/foreman-release.rpm [root@fm18 ~]# yum -y install http://ftp.sjtu.edu.cn/fedora/epel/epel-release-latest-7.noarch.rpm [root@fm18 ~]# yum clean all [root@fm18 ~]# yum makecache [root@fm18 ~]# yum update -y [root@fm18 ~]# reboot [root@fm18 ~]# yum install foreman-installer\n[/bash]\n安装foreman-installer可能会出现的错误是ruby包依赖的问题，导致这个问题的原因可能有：网速太满导致的yum meta-data 失效，国外的epel源下载失败等。解决方法是：使用国内较快的epel源，在安装foreman-installer前，清除yum 缓存，重新建立yum原数据缓存。\n我的测试机的yum 源配置如下：\n[bash]\n[root@fm18 yum.repos.d]# yum repolist Loaded plugins: fastestmirror, product-id, subscription-manager Loading mirror speeds from cached hostfile\n epel: mirrors.neusoft.edu.cn repo id repo name status epel/x86_64 Extra Packages for Enterprise Linux 7 - x86_64 8,076 foreman/x86_64 Foreman 1.8 379 foreman-plugins/x86_64 Foreman plugins 1.8 199 puppetlabs-deps/x86_64 Puppet Labs Dependencies El 7 - x86_64 17 puppetlabs-products/x86_64 Puppet Labs Products El 7 - x86_64 175 rhel-7-server-optional-rpms/7Server/x86_64 Red Hat Enterprise Linux 7 Server - Optional (RPMs) 5,832 rhel-7-server-rpms/7Server/x86_64 Red Hat Enterprise Linux 7 Server (RPMs) 7,036 rhel-server-rhscl-7-rpms/7Server/x86_64 Red Hat Software Collections RPMs for Red Hat Enterprise Linux 7 Server 3,596 repolist: 25,310 [root@fm18 yum.repos.d]# cat /etc/yum.repos.d/epel.repo [epel] name=Extra Packages for Enterprise Linux 7 - $basearch baseurl=http://download.fedoraproject.org/pub/epel/7/$basearch #mirrorlist=https://mirrors.fedoraproject.org/metalink?repo=epel-7\u0026amp;arch=$basearch failovermethod=priority enabled=1 gpgcheck=1 gpgkey=https://fedoraproject.org/static/352C64E5.txt  mirrorlist=https://mirrors.fedoraproject.org/metalink?repo=epel-7\u0026amp;arch=$basearch [epel-debuginfo] name=Extra Packages for Enterprise Linux 7 - $basearch - Debug baseurl=http://ftp.sjtu.edu.cn/fedora/epel/7/$basearch/debug #mirrorlist=https://mirrors.fedoraproject.org/metalink?repo=epel-debug-7\u0026amp;arch=$basearch failovermethod=priority enabled=0 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-7 gpgcheck=1\n[epel-source] name=Extra Packages for Enterprise Linux 7 - $basearch - Source baseurl=http://ftp.sjtu.edu.cn/fedora/epel/7/SRPMS #mirrorlist=https://mirrors.fedoraproject.org/metalink?repo=epel-source-7\u0026amp;arch=$basearch failovermethod=priority enabled=0 gpgkey=file:///etc/pki/rpm-gpg/RPM-GPG-KEY-EPEL-7 gpgcheck=1 [root@fm18 yum.repos.d]#\n[/bash]\n以上应该是安装foreman-installer宝过的攻略了。接下来该安装foreman的各个组建和插件了。使用 foreman-installer -i 发现是个不错的方法。还可以顺便了解一下当前foreman版本的各个主要功能项，如下所示：\n[bash]\n[root@fm18 yum.repos.d]# foreman-installer -i Welcome to the Foreman installer! This wizard will gather all required information. You can change any parameter to your needs.\nReady to start? (y/n) y\nMain Config Menu\n [✓] Configure foreman [✓] Configure foreman_cli [✗] Configure foreman_compute_ec2 [✗] Configure foreman_compute_gce [✓] Configure foreman_compute_libvirt [✗] Configure foreman_compute_openstack [✓] Configure foreman_compute_ovirt [✗] Configure foreman_compute_rackspace [✗] Configure foreman_compute_vmware [✓] Configure foreman_plugin_bootdisk [✗] Configure foreman_plugin_chef [✓] Configure foreman_plugin_default_hostgroup [✗] Configure foreman_plugin_digitalocean [✓] Configure foreman_plugin_discovery [✗] Configure foreman_plugin_docker [✗] Configure foreman_plugin_hooks [✗] Configure foreman_plugin_openscap [✗] Configure foreman_plugin_ovirt_provision [✗] Configure foreman_plugin_puppetdb [✗] Configure foreman_plugin_salt [✓] Configure foreman_plugin_setup [✓] Configure foreman_plugin_tasks [✗] Configure foreman_plugin_templates [✓] Configure foreman_proxy [✗] Configure foreman_proxy_plugin_abrt [✗] Configure foreman_proxy_plugin_chef [✗] Configure foreman_proxy_plugin_openscap [✗] Configure foreman_proxy_plugin_pulp [✗] Configure foreman_proxy_plugin_salt [✓] Configure puppet Display current config Save and run Cancel run without Saving Choose an option from the menu\u0026hellip;  [root@fm18 yum.repos.d]# puppet agent \u0026ndash;test Info: Retrieving pluginfacts Info: Retrieving plugin Info: Caching catalog for fm18.xenlab.com Info: Applying configuration version \u0026lsquo;1434466089\u0026rsquo; Notice: Finished catalog run in 0.21 seconds [root@fm18 yum.repos.d]#\n[/bash]\n输入数字即可进入每个选项打开和关闭这个功能和服务，这个是对foreman的功能配置管理，不光是首次安装可以使用，以后的服务器功能变更也可以这么作，这个对我这样不感冒answerfile的人来说甚好。如果是首次安装，可以什么都不选择，来一个说装就装的默认安装也不错。安装完全成功之后，就会显示登陆网址和 管理与密码等信息。用初始的admin密码登陆后，修改密码，你的全新的foreman就安装成功了。注意在，运行foreman-installer过程中是需要联网的，安装过程会按照需求，下载所需要的组建包，例如数据库和web服务器等等其它必须的包。登陆后界面如下：\n[gallery size=\u0026ldquo;medium\u0026rdquo; link=\u0026ldquo;file\u0026rdquo; ids=\u0026ldquo;53781,53782,53783\u0026rdquo;]\n接下来需要作配置自动化的测试了，我做了一个录像，通过一个简单的示例来说明，如何在foreman中测试pupput module。过程中我使用一个最简单的 /etc/motd 文件的配置的类。演示的内容涉及：\n[su_list icon=\u0026ldquo;icon: check-square\u0026rdquo;]\n  安装puppet module 到生产环境中\n  导入并且定制puppet 类的功能\n  测试和验证puppet 类是否工作正常\n  [/su_list]\n视频下载：[su_button url=\u0026ldquo;http://pan.baidu.com/s/1ntpBXfN\u0026rdquo; target=\u0026ldquo;blank\u0026rdquo; style=\u0026ldquo;stroked\u0026rdquo; background=\u0026quot;#cccccc\u0026quot; size=\u0026ldquo;6\u0026rdquo; icon=\u0026ldquo;icon: cloud-download\u0026rdquo;]下载在这里[/su_button]\n本文参考文档：\n  http://theforeman.org/manuals/1.8/index.htm\n  http://itgeeker.net/centos-7-epel-china-mirror-repository/\n  ",
    "ref": "/2015/06/16/e59ca8-rhel-7-e4b88ae5ae89e8a385-foreman-1-8/"
  },{
    "title": "用 powertop 给笔记本电脑省电",
    "date": "",
    "description": "",
    "body": "如何安装：\n[bash]\nsudo dnf install powertop\nsudo powertop\nsudo systemctl start powertop.service\nsudo systemctl enable powertop.service\n[/bash]\n[gallery link=\u0026ldquo;file\u0026rdquo; ids=\u0026ldquo;53761,53762,53763,53764,53765\u0026rdquo;]\n使用Tab和shift + tab 键在以上屏幕直接切换。\n我发现我主要使用 Tunables 这个tab来找出可以安全关闭的设备服务。以上测试是在我目前的 Fedora 22 on Lenovo T440s上作的。\n本文参考：http://fedoramagazine.org/saving-laptop-power-with-powertop/\n",
    "ref": "/2015/06/13/e794a8-powertop-e7bb99e7ac94e8aeb0e69cace794b5e88491e79c81e794b5/"
  },{
    "title": "在CentOS 7上安装部署Katello2.2",
    "date": "",
    "description": "",
    "body": "Katello的系统架构如下图：\nKatell系统是一个复合型开源项目，是Pulp, Candlepin 和 Foreman的组合。Foreman默认使用Puppet作配置管理。\n它的安装文档见官方手册：http://www.katello.org/docs/2.2/installation/index.html\n为了简化安装，请下在本站提供的CentOS7完美安装模板。使用它来创建一个虚拟机，6GB内存，2VCPU；网络上为了方便，请在virt-manger中新建如下所示的网络。\n虚拟机启动之后，确保host能正常联网。启动刚才创建的虚拟机，配置好IP，ping 外网网站，确保它能正常联网即可。其它安装命令如下：\n[bash]\nyum -y localinstall http://fedorapeople.org/groups/katello/releases/yum/2.2/katello/RHEL/7Server/x86_64/katello-repos-latest.rpm yum -y localinstall http://yum.theforeman.org/releases/1.8/el7/x86_64/foreman-release.rpm yum -y localinstall http://yum.puppetlabs.com/puppetlabs-release-el-7.noarch.rpm yum -y localinstall http://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm yum -y install foreman-release-scl\nyum -y install katello\nkatello-installer -v\n\u0026ndash;foreman-admin-username admin\n\u0026ndash;foreman-admin-password smartvm\n\u0026ndash;capsule-dns true\n\u0026ndash;capsule-dns-interface eth0\n\u0026ndash;capsule-dns-zone xenlab.com\n\u0026ndash;capsule-dns-forwarders 192.168.10.1\n\u0026ndash;capsule-dns-reverse 10.168.192.in-addr.arpa\n\u0026ndash;capsule-dhcp true\n\u0026ndash;capsule-dhcp-interface eth0\n\u0026ndash;capsule-dhcp-range \u0026ldquo;192.168.10.100 192.168.10.240\u0026rdquo;\n\u0026ndash;capsule-dhcp-gateway 192.168.10.1\n\u0026ndash;capsule-dhcp-nameservers 192.168.10.10\n\u0026ndash;capsule-tftp true\n\u0026ndash;capsule-tftp-servername $(hostname)\n\u0026ndash;capsule-puppet true\n\u0026ndash;capsule-puppetca true\n[/bash]\n以上的安装命令如果成功，katello服务器将具有一下功能：\n  Foreman 服务器：用于自动化网络安装linux系统\n  Puppet Master服务器\n  Repos管理服务器\n  DNS，DHCP，PXE服务器\n  安装成功之后，使用默认的用户名和密码就可以登陆了。\n",
    "ref": "/2015/06/07/e59ca8centos-7e4b88ae5ae89e8a385e983a8e7bdb2katello2-2/"
  },{
    "title": "安装完美 CentOS7 虚拟机模板",
    "date": "",
    "description": "",
    "body": "初始化安装 下载最新版CentOS7 DVD 选择mini安装。\n网络配置 安装过程中设置了静态网络地址，如下：\n[bash]\n[root@centos7-tmp ~]# cat /etc/sysconfig/network-scripts/ifcfg-eth0 TYPE=Ethernet BOOTPROTO=none DEFROUTE=yes IPV4_FAILURE_FATAL=no IPV6INIT=no NAME=eth0 DEVICE=eth0 ONBOOT=yes DNS1=192.168.10.1 DOMAIN=xenlab.com IPADDR=192.168.10.8 PREFIX=24 GATEWAY=192.168.10.1 UUID=5fb06bd0-0bb0-7ffb-45f1-d6edd65f3e03\n[/bash]\n软件包 Change log:\n   yum install wget telnet perl perl-devel net-tools kernel-devel\n  yum install vim-enhanced.x86_64\n  yum -y install git\n  yum install acpid\n  yum install tree\n  yum install ntp\n  yum install unzip\n  Repo 软件更新源 Change log:\n  初始化安装，添加了个几个国内的源\n   rpm -Uvh http://rpms.famillecollet.com/enterprise/remi-release-7.rpm\n /etc/yum.repo/bk/dvd.repo ；这个是在用KVM虚拟机挂ISO文件光驱的时候用的，到时候 mount /dev/cdrom /media/dvd , 把该文件方的夫目录中即可使用iso文件中的repos\n   当前的软件源如下：\n[bash]\n[root@centos7-tmp ~]# yum repolist Loaded plugins: fastestmirror Repository base is listed more than once in the configuration Repository updates is listed more than once in the configuration Repository extras is listed more than once in the configuration Repository centosplus is listed more than once in the configuration Loading mirror speeds from cached hostfile\n base: mirrors.163.com epel: mirrors.neusoft.edu.cn extras: mirrors.btte.net remi-safe: remi.kazukioishi.net updates: mirrors.btte.net repo id repo name status base/7/x86_64 CentOS-7 - Base 8,652 epel/x86_64 Extra Packages for Enterprise Linux 7 - x86_64 8,022 extras/7/x86_64 CentOS-7 - Extras 128 remi-safe Safe Remi\u0026rsquo;s RPM repository for Enterprise Linux 7 - x86_64 123 updates/7/x86_64 CentOS-7 - Updates 609 repolist: 17,534 [root@centos7-tmp ~]#  [/bash]\n系统服务配置 Change log:\n  关闭SELinux\n  关闭 NetworkManager\n  关闭 FirewallD\n  systemctl enable acpid.service\n  开启 truned-adm virtual-guest 服务模式\n  systemctl enable ntpd\n  [bash]\n[root@centos7-tmp tuned]# tuned-adm list Cannot talk to Tuned daemon via DBus. Available profiles:\n balanced blog latency-performance network-latency network-throughput powersave throughput-performance virtual-guest virtual-host Cannot talk to Tuned daemon via DBus. It seems that tuned daemon is not running, preset profile is not activated. Preset profile: virtual-guest  [/bash]\n模板文件封装 用sys-unconfig 关机。用 virt-sysprep, virt-sparsify 去除不必要信息，压缩。\n[bash]\n[root@martin-fedora vm]# ll -h total 12G -rw-r\u0026ndash;r\u0026ndash; 1 qemu qemu 81G Jun 5 22:36 centos7-tmp.qcow2 -rw-r\u0026ndash;r\u0026ndash; 1 root root 81G Jun 5 22:34 centos7-tmp.qcow2.bk -rw-r\u0026ndash;r\u0026ndash; 1 root root 2.9G Jun 5 07:56 rhel66-clone-1.qcow2 -rw-r\u0026ndash;r\u0026ndash; 1 root root 1.6G Jun 3 15:01 rhel66-clone.qcow2 -rw-r\u0026ndash;r\u0026ndash; 1 root root 81G Jun 3 13:03 rhel66.qcow2 -rw-r\u0026ndash;r\u0026ndash;. 1 root root 81G Jun 1 00:59 rhel71.qcow2 [root@martin-fedora vm]# export TMPDIR=/home/martin [root@martin-fedora vm]# virt-sparsify \u0026ndash;compress centos7-tmp.qcow2 centos7-tmp-v1.qcow2 Input disk virtual size = 85899345920 bytes (80.0G) Create overlay file in /home/martin to protect source disk \u0026hellip; Examine source disk \u0026hellip; Fill free space in /dev/centos/root with zero \u0026hellip; 100% ⟦▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒⟧ 00:00 Clearing Linux swap on /dev/centos/swap \u0026hellip; 100% ⟦▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒▒⟧ 00:00 Fill free space in /dev/sda1 with zero \u0026hellip; Fill free space in volgroup centos with zero \u0026hellip; Copy to destination and make sparse \u0026hellip;\nSparsify operation completed with no errors. Before deleting the old disk, carefully check that the target disk boots and works correctly. [root@martin-fedora vm]# ll -h total 12G -rw-r\u0026ndash;r\u0026ndash; 1 qemu qemu 81G Jun 5 22:36 centos7-tmp.qcow2 -rw-r\u0026ndash;r\u0026ndash; 1 root root 81G Jun 5 22:34 centos7-tmp.qcow2.bk -rw-r\u0026ndash;r\u0026ndash; 1 root root 520M Jun 5 23:11 centos7-tmp-v1.qcow2 -rw-r\u0026ndash;r\u0026ndash; 1 root root 2.9G Jun 5 07:56 rhel66-clone-1.qcow2 -rw-r\u0026ndash;r\u0026ndash; 1 root root 1.6G Jun 3 15:01 rhel66-clone.qcow2 -rw-r\u0026ndash;r\u0026ndash; 1 root root 81G Jun 3 13:03 rhel66.qcow2 -rw-r\u0026ndash;r\u0026ndash;. 1 root root 81G Jun 1 00:59 rhel71.qcow2\n[/bash]\nyum update -y   2015-07-10 : Done yum updated. 删除了不需要的Kernel，安装了unzip, 修改启动过程为直接文字启动。\n  2015-11.15: update kernel to 7.1, set old kernel 1: package-cleanup \u0026ndash;oldkernels \u0026ndash;count=1\n  使用方法 root 密码 martinliu.cn 开机后记得一定要先修改。\n百度网盘下载地址 [su_button url=\u0026ldquo;http://pan.baidu.com/s/1pJurap9\u0026rdquo; target=\u0026ldquo;blank\u0026rdquo; style=\u0026ldquo;stroked\u0026rdquo; size=\u0026ldquo;6\u0026rdquo; icon=\u0026ldquo;icon: codepen\u0026rdquo;]centos7-tmp-v7[/su_button]\n",
    "ref": "/2015/06/05/e5ae89e8a385e5ae8ce7be8e-centos7-e8999ae68b9fe69cbae6a8a1e69dbf/"
  },{
    "title": "Achilles的脚后跟",
    "date": "",
    "description": "",
    "body": "今天是红帽服务团队深圳Bootcamp的最后一天，我是最后一个session的演讲者，讲的内容是补丁管理，这是个老生常谈的话题，看看我怎么构思和解读的。\n[su_button url=\u0026ldquo;http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2015/06/Patch-Management.pdf\u0026rdquo; target=\u0026ldquo;blank\u0026rdquo; style=\u0026ldquo;stroked\u0026rdquo; size=\u0026ldquo;2\u0026rdquo; icon=\u0026ldquo;icon: cloud-download\u0026rdquo;]PPT下载在这里[/su_button]\n主要思路还是把目前的相关知识梳理一边。特别是借鉴了公司安全大师Shawn的一些内容。\n玩好防塔游戏 把操作系统的该打的补丁都打好，避免已知漏洞的暴露。\n做好安全加固 修补Achilles的脚后跟，是说把安全配置基线落实到系统中，并行成为长效保持机制。\n其实这些还是和配置管理有关和CMDB有关，真是老生常谈呵呵\n",
    "ref": "/2015/06/04/achillese79a84e8849ae5908ee8b79f/"
  },{
    "title": "Fedora 22 使用体验不错",
    "date": "",
    "description": "",
    "body": "下面是随手的几个截图。\n\n\n\n一部分F22新功能评测在这里http://fedoramagazine.org/whats-new-fedora-22-workstation/\n",
    "ref": "/2015/05/28/fedora-22-e4bdbfe794a8e4bd93e9aa8ce4b88de99499/"
  },{
    "title": "我已经很久没用ppt了",
    "date": "",
    "description": "",
    "body": "Kenote的在我的工作中已经完全替代PPT了。其实我的电脑上还有LiberOffice，不过要编写什么ppt，还是必须要使用Keynote，这可能就是所谓的由奢入俭难吧，哈哈！\n通常做完的Slides，还需要导出成ppt和pdf格式，然后上传到网盘上，一般在讲完当天，就最好能通过微信把下载链接发给用户。想想十多年来也做了至少上万页的ppt，可恶的事工作性质其实还没有太大变化。\n现在看着这个课程，有点想法是：是否有必要把自己的重要的ppt也录制成课程，做系列的播出。没准也能卖出几千份哈哈\n",
    "ref": "/2015/05/24/e68891e5b7b2e7bb8fe5be88e4b985e6b2a1e794a8ppte4ba86/"
  },{
    "title": "Fedora 22 将于5月26日发布",
    "date": "",
    "description": "",
    "body": "No Content Found\n",
    "ref": "/2015/05/24/fedora-22-e5b086e4ba8e5e69c8826e697a5e58f91e5b883/"
  },{
    "title": "RedHat互联网平台解决方案",
    "date": "",
    "description": "",
    "body": "ppt点这里下载：[su_button target=\u0026ldquo;blank\u0026rdquo; style=\u0026ldquo;stroked\u0026rdquo; size=\u0026ldquo;2\u0026rdquo; icon=\u0026ldquo;icon: cloud-download\u0026rdquo;]下载[/su_button]\n参考文档： AS深圳2014演讲PPT最终稿 http://pan.baidu.com/s/1i3KQFRJ QCon北京2015（PPT） http://pan.baidu.com/s/1sj2t1yl 这两个目录里面干货还是不少，可以下载了慢慢看。\n\n学习了一写文档后，逐渐对互联网公司的架构挑战需求和现状有了一些了解。下面先聊下这方面的一些理解。\n中国规模交易量 什么叫中国规模交易量，以淘宝2014-11-11 双十一当天的数据举例：\n[su_list icon=\u0026ldquo;icon: rocket\u0026rdquo;]\n  交易创建 80000笔/秒\n  支付 38000笔/秒\n  24小时完成交易额 571亿元人民币 // 93 亿美元\n  [/su_list]\n乍一看这个数字可能没什么感觉，可以比较一下美国的情况。全美所有的传统商场在“黑色星期五”一天的销售也仅为91亿美元，即使加上网络销售的24亿美元也比天猫“双十一”多不了太多。也就是说，美国黑五当天全网的电商是中国淘宝/天猫一家的四分之一。\n因此中国人口基数大，网民数量大，假如您能激起大众的兴趣的话，你是不缺访问量的。对于意外的大规模的峰值访问量的处理，如果系统架构和应用没有提前经过特别的架构调整、优化；用膝盖都能想到系统挂掉、基础架构崩溃、交易数据出错是必然的事情。\n理解到这个潜在的风险、需求和调整，我们所有设计和从事IT基础架构技术服务的人，可以想想，不向前看，不向BAT学习，不站在他们的肩膀上设计和调整自己的应用的话。想保证系统平安，除非业务是失败的业务（没有流量），否则没有平安可言。\n架构特点 且不说马云家系统已经多么牛叉，我们看下京东的架构，我们也可以看到其架构设计在两个维度都非常清晰到位。业务架构维度上尽可能的松耦合，所有业务单元分解清晰，貌似莫名的遵循了分布式架构的要求；这样每个业务单元都可以对IT资源的消耗联动，弹性的供给必要的业务处理能力。IT架构维度上分解为三个层次：应用架构、数据架构、基础架构。基本上JD的这个PPT改变了我对这个企业的印象。从我的职业经验告诉我，这份PPT中规中矩，比较专业，堪称教科书式的架构设计。相对马云家的架构师的PPT图画的比较豪放，风格不同。JD这份PPT下载在这里。\n[su_button url=\u0026ldquo;http://pan.baidu.com/s/1o6MI0t0\u0026rdquo; target=\u0026ldquo;blank\u0026rdquo; style=\u0026ldquo;stroked\u0026rdquo; size=\u0026ldquo;2\u0026rdquo; icon=\u0026ldquo;icon: cloud-download\u0026rdquo;]AS深圳2014 京东架构设计-吴博[/su_button]\n除了分层细致设计业务架构之外，我们还能看到，电商公司多使用多数据中心多活的模式并发处理海量交易量，每个数据中心都可以处理全业务，都能在灾备和并行处理上一石二鸟。这和我们高贵的传统企业不同，他们往往可以实现同城双中心运行，异地数据中心往往是灾备中心；有些灾备切换并不是全业务的切换，有些灾备中只用于灾备切换演练，并不真的运行业务；有些异地灾备中心也会和主数据中心中的一部分业务做周期性的切换运行。这些高贵的客户往往把核心的数据放在主机上，这在他们想扩展到3个或者更多个数据中心的时候，略显尴尬；新增的数据中心也要配置一套新主机系统么？新的主机上数据和应用怎样快速迁移过来？需要多长时间？数据同步的和其他两个数据中心一致么？这些问题的回答都不简单？主机硬件固然是贵？但是所有问题都解决周全的话，可能更贵。\n全新的纯X86的架构就在面前，BAT已经证明了它和开源技术组合在一起就是多快好省的架构。因此，IT架构的转型也成了必然选择。试想转型之后的机房，每个机架都是标准化的工作单元，它可能是几种类型：纯物理机计算节点、纯虚拟机计算节点（服务器虚拟化或者OpenStack等）、纯物理机存储节点（软件定义存储）；或运行容器的物理机或者虚拟机。另外机架上的网络设备和核心网络设备必然有他们自己的设计。这是我的一个猜测，有机会还需要和BAT的人多了解。\n开源技术 BAT用到的开源技术真的是不甚枚举，也没有必要逐一分析。基本上各个领域里从开发堆栈、到架构堆栈和运维管理堆栈；各个方面的前几位的项目都有实践和应用。\n红帽 那么红帽的互联网平台解决方案是什么？红帽的定位是基础架构技术厂商，因此红帽的全套技术框架就是它的互联网解决方案。如下图所示。\n\n有些产品模块需要稍微说明一下，方便和开源项目对应起来。\n[su_list icon=\u0026ldquo;icon: linux\u0026rdquo;]\n  Red Hat Storage server / ICE : Gluster, Ceph\n  Red Hat Enterprise Linux : Fedora Linux\n  RHEV-M : Ovirt - 服务器虚拟化\n  RHELOSP ： OpenStack 企业版IaaS平台\n  OpenShift ：OpenShift社区\n  JBoss : JBoss 社区\n  Satellite ： Puppet + Foreman 等等其它配置管理工具\n  CloudForms ：CloudForms社区 - 混合云管理\n  [/su_list]\n红帽的技术支持范围还包括很多操作系统内的功能组件，包括：HA-Proxy，LVS，MySQL等等。在技术面的广度上，并不限于以上框架图。不过那幅图是全堆栈的最简易的展示。\n",
    "ref": "/2015/05/17/redhate4ba92e88194e7bd91e5b9b3e58fb0e8a7a3e586b3e696b9e6a188/"
  },{
    "title": "OpenStack Enterprise Ready",
    "date": "",
    "description": "",
    "body": "不是好不好，而是用不用？ 要说OpenStack的优点，技术人员能说出一堆词汇，如开源、弹性、稳定、可扩展、迅速搭建私有云、对硬件要求不高、解耦、能快速扩展新业务等等。但实际应用的案例为何这么少。\n    国内传统企业用的少，互联网公司用了不少了，创业公司捣鼓OpenStack部署公有云服务的业务也不少了，总体看OpenStack水平高的人不在数量巨大的传统企业里，当前人员也不存在这个流向，更重要的是传统企业没有合适的在OpenStack上跑的workload。因此少。\n    一个数据是，这两年计划部署OpenStack的企业为84%，可见大多数企业仍观望。这问题出在哪里？\n   原因同上。\n   技术仍旧是问题。OpenStack的问题是半年快速迭代，发布新产品，速度太快，老版本跟不上。理论上，新版本向下兼容。但在一些版本较大改动，加入新的功能时，如果企业已经深度应用了旧版本，可能面临技术无法升级，或者需要重度开发的问题。\n     开发改动大么？那些地方大改动了？深度开发的部分是什么组件？是遵循了向下一个版本兼容的原则了么？代码提交会社区了么？OpenStack社区版升级了，企业就一定要升级旧的版本么？什么情况下升级版本？什么情况下打补丁知道么？OpenStack是云操作系统，我们看到的常见的开发场景是：界面友好度的调整、虚拟机功能的增强、辅助管理功能的增加等等。如果基于某个版本把这些附加功能开发出来了，其实业务需求清晰和随后调整不大的话，其实是可以用一定时间的。升级有两个原因：修复bug，增加新版本的功能。我见过创业公司把之前开发的东西一次一次废掉重来的情况，主要原因还是他们首先不能提交代码会社区，其次开发的东西不是外挂式和主框架松耦合的。企业面对开发是谨慎的，往往不会在投入大量功能评估后，在清晰的需求下二次开发。二次开发做的多得还是想做OpenStack生意的创业公司，而传统企业的这些金主客户，我感觉他们还真没有这个需求和闲工夫。因此开发重，不能平滑进入下一代新版本不是用的少和不用的原因。\n     另外与企业规模有关。多大企业需要使用OpenStack，需要部署在哪些生产环境，是否是全面替代，还是迁移，包括从VMware迁移到OpenStack，或者是新应用局部部署OpenStack？这些不考虑清楚，没办法应用。\n     这是一个很普遍的误区，太多人这么想了。从VMWare迁移到OpenStack真的这么重要么？真的存在这个场景了？服务器虚拟化和OpenStack是两种同类型的基础架构技术。服务器虚拟化跑传统的有状态应用；OpenStack跑需要弹性扩展的无状态应用。有状态应用不适合跑在OpenStack上。也不太可能不做任何改变就能适应OpenStack环境。企业的无状态应用少，但这是一个发展过程和阶段。原因在于无状态应用和合适在OpenStack上跑得workload太少了。企业目前的应用workload是因，OpenStack部署少是果。不存在OpenStack替代服务器虚拟化的事情，他俩会并存很长时间，不是非黑即白的替代逻辑。\n     当前看，对企业应用需求的评估太少，大多是IT产业（厂商）一头热，鼓吹OpenStack太好，反而令人生疑。\n      说的好就怀疑了？这里说的应用需求评估有两方面。或者两个理解方向。这里可能是说OpenStack功能性方面，客观的讲，当一个技术在风口上的时候，说好话的多，这是客观规律，多年前服务器虚拟化也这样，现在热度低了，它再发新版本大家连个搭理的功夫都没有了，也没有啥评测文章出来，这都是自然规律。OpenStack也有失去热捧的那天，我最近看了一些基于它创业的技术型公司也都在反思和总结经验中。\n      怎么用，谁来带头？ 当前案例也有，如电信运营商阿尔卡特朗讯（名字太长，以后会不会再加上西门子诺基亚）、诺基亚、西班牙电信；汽车领域宝马汽车、银行企业西班牙BBVA、传媒领域时代华纳有线等。这些企业具有标杆意义，不具有示范效应。企业规模不一样，生产环境不同，这是最大的不同。这些案例最明显的是以信息为核心资源的企业，IT系统建设较为完善和复杂，有意愿、有钱尝试新的IT技术。\n      规模、环境、以信息为核心资源、IT成熟、有意愿、有钱；这些都不能说成是中外企业IT的差异，也完全和是否用OpenStack无关的因素。我朝存在大量的传统大型企业，都已经排名全球100强了，很多是我们的客户。它们的市值比以上公司大得多。举个例子：CCB的市值是2015年4月30日 - 成交量 4.88亿股 市值 18,151.51亿；宝马的市值是2012年12月 宝马市值增至奔驰两倍 达3700亿元；这么高大上制造型企业，连CCB的零头都不如。\n      总体看，当前应用较多的是IT产公司（包括互联网公司），国内互联网公司如去哪儿、携程等公司都有应用。\n      传统的金融部门呢，我国核心的制造企业呢？可能本人孤陋寡闻，如果多一些传统企业的案例会好一些。\n      做过OpenStack测试的，验证过功能的很多，包括我以前了解的CloudStack的测试和评估也很多。金融行业企业它们都懂OpenStack，甚至有些做定制开发的也有。这些作者可能确实看不到。他们已经准备好了，时间到了，无状态的合适的workload出现了，OpenStack这种东西自然就上去了，根本不用急着看案例。\n      这么多企业如何选择？ 每个厂商说完OpenStack的好处之后，必然要说自己公司长处，这对用户来说，容易困扰：市面上一堆的IT企业，该如何选择？比如中国，传统IT企业几乎都有OpenStack的团队，如红帽、HP、戴尔、IBM、华为等；还有些初创企业如AWcloud 、99cloud等，也是不容忽视的力量。\n     企业自己的OpenStack专业团队还真不多见，现在传统企业还没有合适workload就养一堆OpenStack工程师是罕见的。\n     红帽说自己的优点是，在开源方面具有优势，懂底层的代码，而像HP这样的公司，自己写了Unix代码，比较封闭等。它强调的是开源。\n    红帽就是做开源的，无需强调开源了好么？这也不是红帽的优势。红帽在OpenStack上做的工作和他在RHEL上的工作、和在JBoss，在Ceph，在其他任何产品上做的工作和优势没有任何差异，就是“提供企业支持”，提供长生命周期的企业支持。懂底层代码的人很多很多，红帽其中的一部分。而从公司层面，提供商业化发行版，并且对其发出的每个版本做长生命周期的企业支持和服务，是很少的公司可以做的。这是红帽的优势。作者对开源业务模式欠了解。\n    当然，像华为这种公司也可以强调是软硬件通吃，更能提供整体的解决方案。像联想这种公司，可以强调资金实力和技术实力，以及对行业的理解能力。\n    不评价。\n    都有道理，如果要选择，还是选择资金实力、历史悠久的公司可能靠谱一些。有些初创企业在技术上领先，但它们的首要问题是活下来，才能保障3~5年的服务期。\n    OpenStack的全方位长期的核心级别技术服务是很重要的。\n    运维之后，是否被绑定IT公司？ 企业要上OpenStack，最缺的是技术人，而不是钱、技术等问题。\n    市场上OpenStack人员不少了，真的有岗位出来，肯出钱，从业者不成问题。\n    着重说明的是，OpenStack不是产品，只是架构。所以，在开源社区开发的各类版本，只有在“封装”之后才可以使用。一般的企业不具备这种技术实力，所以需要IT公司帮助实施、运维、开发等工作。\n   封装之后可用是个普遍的错误观点，纯属于界面看着难受不改就不用的想法。选择合适的发行版，附加有能力的公司来做架构设计和实施，虚拟机就可以跑起来了，就可以上线了。不做定制开发就用了的也大有人在。我也问过一个云计算创业的公司，你们用的什么版本？回答是我们选择了一个版本就是部署了，碰到bug我们自己的研发就看代码搞定了。它们关注的事提供虚拟机给客户，这才是业务。\n   极端的情况，假如企业用了A公司提供的某个版本的产品，A公司忽然倒闭或者技术实力跟不上，无法后续运维，B公司接手是否可行？理论上可以，由于代码开源，B公司可以直接读A公司开发过的产品；但实际操作，要看系统规模的大小，以及复杂度。毕竟，当前是推广阶段，这种实施失败的案例极少。\n    要看开发的是什么？有代码就可以维护的。规模大小和复杂是无法接手的因素么？他俩加一起也不能就直接推出接不上手吧？在这种场景下，现实项目的操作实践是，抛弃A公司做的，B公司再从头做一遍。看到的项目案例也是这样。\n    中国企业的贡献有多大？ 如果只从基金会来看，中国企业仍旧没有进入核心层。基金会的白金会员只有8个名额，AT\u0026amp;T、惠普、IBM、Inetl、Rackspace、Red Hat和SUSE等，每年缴纳50万美金的费用。除非有企业退出，否则不可能进入。在最新的Kilo版本中，按照贡献代码数来计算，中国企业贡献最多的几位是华为、99Cloud、Awcloud、Kylin Cloud（为啥都叫Cloud）；尤其是华为，代码贡献是2681，远超其他公司。有嘉宾解释这个排名时说，华为人也太多了，别家都是初创企业，比不了。这种大公司一旦下决心布局，立即显示出整体的优势，举个例子，如联想在2015年1月加入基金会，3月就正式成为企业代码贡献者，以它的战略和技术背景来看，绝对是2015年黑马。当然，初创公司的专注度、贴身的服务能力、快速的反应能力，也是大公司比不了的，各有所长。中国企业在这一轮技术升级中，几乎都抓住了好机会。接下来要比战略和市场行动了，其实是一场长跑。\n     国人对OpenStack的贡献多少？和企业是否用OpenStack也没有必要的联系。OpenStack的出现，也不是给企业IT带来整体升级的机会。现实看OpenStack只是一种基础架构技术而已。它和传统的服务器虚拟化技术是同层面的东西。只是它带有更多的和网络存储技术的相关性；特别是在网络、存储相关的技术上确实颠覆传统技术的势头十足。但是这只是现象。实际变了么？\n     后续问题是什么？ 总体感觉，OpenStack已经过了市场炒作期，完胜其他三个开源架构；但处于普及期，尚未真正进入大规模的应用阶段。有技术原因，也有市场原因，还有厂商推广原因。比如技术，每一个版本的功能是否有较大提升，在新技术之间的快速迭代和平衡问题，怎么做好开源的商业化问题，又不能受控于几家核心的企业？在打包后的产品中，怎么解决各个厂商分化的问题？\n    纠结下一个版本新功能的人，属于根本不知道自己当前需要使用OpenStack什么功能的人。上游大厂的利益划分和最终对用户的影响并不大。各个厂商提供的功能和模块往往是不冲突的，即使是是重叠了，对用户也是好事。OpenStack架构最大的好处就在于，它是分布式架构，任何一个用户不可能用足它的全功能场景。常规跑虚拟机的场景用到了OpenStack的全套功能的很小一部分。当然OpenStack社区虽然没把用户的利益完全放在第一位，对用户来说，用户是由自由选择其中的任何功能组件的，就是搭积木而已。\n    比如市场，对于企业来说，如何选择合适的机会应用，这考量IT企业对OpenStack的全面评估以及对自己业务的评估，而不仅仅站在IT的角度看技术发展。其实，最考验的是IT厂商的交付能力、运维能力以及服务能力，这才是最关键的。没有交付能力的IT厂商，你再吹捧OpenStack的好处，那也是别人家的，也是圈子内的，和你没有一毛钱关系。用户要的是效率，是业务的可靠性和连续性，是IT的扩展性和精简、敏捷、高效，不站在用户角度推广OpenStack的厂商就是耍流氓。\n    红帽本身来讲看的还是发布的发行版是否足够稳定，是否修复了足够的bug，是否在安装部署方面有提升。其它交付和运维等等是周边生态系统公司的范围。红帽对OpenStack社区的重要价值，还在于向社区提交bug修复，这些bug很多都是红帽客户碰到的。一旦提交成功了，未来版本中基本就没有这个问题了。\n    真实情况是，云计算还没有真正普及，怎么谈OpenStack的应用呢？\n     敢问云计算怎么才算是真正普及？OpenStack也不是填饱肚子的最后一个馒头。云计算相关技术发展的还不够快么？君不见容器如日中天么？那天人们谈云计算，不谈OpenStack的可能都有，OpenStack只是云计算发展过程中的一个场景而已。\n     比如推广，要接地气，要说人话，不能自说自话，一厢情愿的说自己好。\n    凡是开这种会，没人说自己不好的对么？\n    在饭桌上听来的段子。在香港OpenStack峰会中，某企业也学其他厂商发帽子，由于企业LOGO是绿色的，它发的竟然是“绿帽子”。还有一家企业，觉得要贴合中国元素，在展台挂上了灯笼。不过是“白灯笼”，不是红灯笼。可想而知，这两排慎人的白灯笼，距离用户有多远就滚多远吧。\n     。。。。。！！！！\n     原文微信：http://mp.weixin.qq.com/s?__biz=MjM5MzYwMTE5OQ==\u0026amp;mid=205642335\u0026amp;idx=1\u0026amp;sn=abc8da56bfa748c895a6f7e61ee70d7c\u0026amp;scene=1\u0026amp;key=1936e2bc22c2ceb550a9ed47d35d37ac6649fc2fd92aedfaeae9a37f83c1bc9a01d8c07369a095226703791790b8081a\u0026amp;ascene=0\u0026amp;uin=ODYyMzEyOTQw\u0026amp;devicetype=iMac+MacBookPro8%2C1+OSX+OSX+10.10.3+build%2814D136%29\u0026amp;version=11020012\u0026amp;pass_ticket=9113SDOfWN%2BqnP3yogS7%2FwP2x2VDHEgF3ksia4%2Bbngq1OKnK1y4ajPkfu8mgg8MO\n",
    "ref": "/2015/05/14/openstack-enterprise-ready/"
  },{
    "title": "Import CloudForms  into rhevm",
    "date": "",
    "description": "",
    "body": "[bash] [root@rhevm03 export]# cat /etc/exports /var/lib/exports/iso *(rw) /export/rhev_import_export_disk *(rw,sync,no_subtree_check,all_squash,anonuid=36,anongid=36) /export/template *(rw,sync,no_subtree_check,all_squash,anonuid=36,anongid=36)\n[root@rhevm03 export]# engine-image-uploader -N cfme5351 -e export-nfs-rhevm -v -m upload /tmp/cfme-rhevm-5.3-51.x86_64.rhevm.ova [/bash]\n然后从Web Console上导入这个模板，创建一个目标规格的虚拟机。\n",
    "ref": "/2015/03/30/import-cloudforms-into-rhevm/"
  },{
    "title": "Practical Linux Infrastructure",
    "date": "",
    "description": "",
    "body": "Practical Linux Infrastructure by Syed Ali Link: http://amzn.com/148420512X\n[gallery size=\u0026ldquo;medium\u0026rdquo; ids=\u0026ldquo;53654,53655\u0026rdquo;]\nThe CI/CD pipeline automates as many tests as possible to gain confidence in the code. In addition, it performs a complete build of the software system and ensures the code that has been checked in does not cause anything to break. Any failure has to be investigated by a developer. There are numerous software products that can help implement a CI/CD pipeline, including the following: Jenkins (http://jenkins-ci.org) CruiseControl (http://cruisecontrol.sourceforge.net) Buildbot (http://buildbot.net) CI/CD要自动化尽可能多的测试案例，从而对代码获得更多的信心。另外，它还要执行一个完整的软件系统的build，并确保checked in的代码并不会搞坏其它东西。任何失败，开发人员都不得不去调查原因。有这样的一些软件可以帮助实施CI/CD的 pipeline：\n[wm_list bullet=\u0026ldquo;icon-linux\u0026rdquo; class=\u0026quot;\u0026quot;]\n   Jenkins (http://jenkins-ci.org)\n   CruiseControl (http://cruisecontrol.sourceforge.net)\n  Buildbot (http://buildbot.net)\n  [/wm_list]\nA public cloud solution can end up being more expensive than a private cloud or less, depending on the size of an enterprise. 公有云解决方案比私有云方案是不是更贵还是便宜，这取决于企业的规模。\n",
    "ref": "/2015/03/29/practical-linux-infrastructure/"
  },{
    "title": "wordpress update",
    "date": "",
    "description": "",
    "body": "在本网站的网页永久链接结构性调整了之后，本以为搜索引擎更新会是一个缓慢的过程，今天去bing和baidu一看，简单翻了若干页之后，发现已经全部更新完毕了。而且搜索 ： site:martinliu.cn 返回结果的顺序也和以前不一样了。貌似旧文章比较靠前，不过顺序无所谓，只要指向的链接完全OK就可以了。\n",
    "ref": "/2015/03/29/wordpress-update/"
  },{
    "title": "服务器虚拟化 RHEV",
    "date": "",
    "description": "",
    "body": "服务器虚拟在我的lab中是必选项，管理控制器端RHEVM安装在主服务的一个虚拟机里面。在主服务器上使用targetcli做了一个iscsi的共享存储。使用这个命令可以方便的实现iscsi设备。把最终的存储文件放在了SSD盘上的一个100GB的瘦制备文件上。 [bash] ╭─root@w540 ~ ╰─$ targetcli targetcli shell version 2.1.fb37 Copyright 2011-2013 by Datera, Inc and others. For help on commands, type \u0026lsquo;help\u0026rsquo;.\n/\u0026gt; ls o- / \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;. [\u0026hellip;] o- backstores \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;.. [\u0026hellip;] | o- block \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;.. [Storage Objects: 0] | o- fileio \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;. [Storage Objects: 1] | | o- iscsi1 \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;. [/root/iscsi01.img (100.0GiB) write-back activated] | o- pscsi \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;.. [Storage Objects: 0] | o- ramdisk \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip; [Storage Objects: 0] o- iscsi \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip; [Targets: 1] | o- iqn.2003-01.org.linux-iscsi.w540.x8664:sn.82939fa1cd49 \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip; [TPGs: 1] | o- tpg1 \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;.. [no-gen-acls, no-auth] | o- acls \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;. [ACLs: 0] | o- luns \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;. [LUNs: 1] | | o- lun0 \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip; [fileio/iscsi1 (/root/iscsi01.img)] | o- portals \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;. [Portals: 1] | o- 0.0.0.0:3260 \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;.. [OK] o- loopback \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip; [Targets: 0] /\u0026gt; [/bash]\n以上iscsi的存储配置参考：https://access.redhat.com/solutions/894163\n如果需要让所有的节点都能无障碍访问iscsi存储，就需要把acl设置为允许所有节点访问。使用下面这个命令\n[bash] /\u0026gt; iscsi/iqn.2003-01.org.setup.lun.test/tpg1/ set attribute authentication=0 demo_mode_write_protect=0 generate_node_acls=1 cache_dynamic_acls=1\nParameter demo_mode_write_protect is now \u0026lsquo;0\u0026rsquo;.\nParameter authentication is now \u0026lsquo;0\u0026rsquo;.\nParameter generate_node_acls is now \u0026lsquo;1\u0026rsquo;.\nParameter cache_dynamic_acls is now \u0026lsquo;1\u0026rsquo;.\n/\u0026gt; ls\no- / \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip; [\u0026hellip;]\no- backstores \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;. [\u0026hellip;]\n| o- block \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;. [Storage Objects: 0]\n| o- fileio \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip; [Storage Objects: 0]\n| o- pscsi \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;. [Storage Objects: 0]\n| o- ramdisk \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;.. [Storage Objects: 1]\n| o- test1 \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;.. [nullio (100.0MiB) activated]\no- iscsi \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;.. [Targets: 1]\n| o- iqn.2003-01.org.setup.lun.test \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;.. [TPGs: 1]\n| o- tpg1 \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;. [gen-acls, no-auth]\n| o- acls \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip; [ACLs: 0]\n| o- luns \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip; [LUNs: 1]\n| | o- lun0 \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;. [ramdisk/test1]\n| o- portals \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip; [Portals: 1]\n| o- 12.12.12.1:3260 \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;.. [iser]\no- loopback \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;.. [Targets: 0]\no- srpt \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip; [Targets: 0]\n/\u0026gt; saveconfig\nLast 10 configs saved in /etc/target/backup.\nConfiguration saved to /etc/target/saveconfig.json\n/\u0026gt; exit\nGlobal pref auto_save_on_exit=true\nLast 10 configs saved in /etc/target/backup.\nConfiguration saved to /etc/target/saveconfig.json [/bash]\nRHEVM的安装过程非常简洁，基本用Satellite配置了一下它所需要的repos，做好视图，然后就推送给了一个kvm虚拟机，使用pxe安装好之后就行了。\nRHEVM需要的repos 和基本的安装命令： [bash]\nsubscription-manager repos \u0026ndash;enable=rhel-6-server-rpms subscription-manager repos \u0026ndash;enable=rhel-6-server-supplementary-rpms subscription-manager repos \u0026ndash;enable=rhel-6-server-rhevm-3.5-rpms subscription-manager repos \u0026ndash;enable=jb-eap-6-for-rhel-6-server-rpms subscription-manager repos \u0026ndash;enable=rhel-6-server-rhevh-rpms yum install rhevm rhevm-dwh rhevm-reports engine-setup [/bash]\n回答完engine-setup的所有问题就可以登录风格统一的黑底色的RHEM界面了。实际上有三个登录界面：用户的，管理员，和报表的。\n\n下面需要安装跑虚拟机的Hypervisor了，RHEV的Hypervisor有两种，一种是精简话的裁剪rhel版本叫做RHEVH（偏向vshpere的做法），还有一种就是rhel的标准版，然后安装Hypervisor相关的包（偏向OpenStack的做法）。下面我会安装第二种做法。目的是：我有两台相同配置的计算节点，我希望把动态的变更他们的功能；一会做RHEV虚拟机的演示，一会做OpenStack nova的演示。\n用了一个组合视图安装了这两个服务器虚拟化节点。组合视图里如下所示：  如上图所示：1）视图1是基础的RHEL操作系统repo；2）视图2是RHEV相关的repos视图，其中包括了安装RHEVM和host的所有需要的repo。考激活秘钥控制每个repo的默认是否开启，它们对安装后的os可见，但是默认并不是开启的，因此，我设置rhevm和jboss为默认关闭的，由于安装rhev host的情况比较多，需要安装rhevm的话，可以手动enable这需要的repos即可。\n安装和配置完存储之后的RHEVM控制台： \n目前由于没有安装OpenStack环境，所以没有Glance服务，因此iso镜像只能暂时放在了dis06的一个服务器虚拟化Hypervisor节点上，目前是临时的方案，回头一定把iso放到Glance服务上host。\n下面上传一个iso之后就可以创建虚拟机了。 [bash] [root@rhevm03 ~]# engine-iso-uploader \u0026ndash;iso-domain=iso-dis06 upload /tmp/turnkey-jenkins-13.0-wheezy-amd64.iso Please provide the REST API password for the admin@internal oVirt Engine user (CTRL+D to abort): Uploading, please wait\u0026hellip; ERROR: mount.nfs: Connection timed out\n[/bash]\n由于这个命令上传不成功，也不想排错了；到目前这个状态其实就可以在Satellite里面使用RHEV的资源提供者的方式来安装虚拟机了，如下图所示：\n\n手动创建RHEV虚拟机1：通过New Host设置相关参数。选择Deploy on 为 rhevm03（rhevm），这个配置让sat6去联系RHEVM，rhevm的配置信息必须提前输入到sat6中。然后还要在sat6中设置虚拟机的三种规格，就是Computer profile中的选项，这个选项确定了cpu，ram，磁盘和网络等信息。剩下的就是最重要的Lifecycle Evn和Puppet Env了，这两个选项确定把系统安装为标准的rhel6的核心最小化安装。当然可以一次性完成某种应用的全套安装和配置。\n\n手动创建RHEV虚拟机2：通过Virtual Machine参数可以看到1，2，3都来自标准的规格配置，如果需要手动修改的话，可以在这里修改，这里可以看到默认的存储是w540-iscsi-lun0这个之前在RHEVM里面配置好的iscsi存储。\n\n手动创建RHEV虚拟机3：点击提交之后，sat6就开始了实时创建rhev虚拟机的过程，sat6使用REST API告诉RHEVM这些信息，然后RHEVM再确定使用哪个Hypervisor来建立并运行虚拟机。\n问题来了：如果需要在RHEV资源池里建立n个相同配置的虚拟机，管理员该如何操作？\n在sat6里面，管理员重复以上操作，当然需要手动操作n次。这样是不是很麻烦，确实很麻烦！！如何解决？这就需要一种能够实现Orchestration功能的工具来做，也就是自动化编排工具。这种工具最好是统一的能够跨异构资源池的，能够满足如下需求：今天企业可能是纯的vshpere的虚拟化环境，接下来企业有可能引入其他服务器虚拟化资源池技术，如：RHEV，Hyper-V；在以后还可能引入OpenStack资源池。那么这种自动化编排工具和底层的类似satellite6的（标准化部署工具）必须形成一个统一的平台来操作所有异构的资源池。也就是说：在Orchestration工具中统一管理异构资源池，并配合标准化部署工具，实现workload的标准化自动化部署。红帽的Orchestration工具是CloudForms。它能够对接业内所有流行的资源池，如下图所示：\n \n上图是Satellite的上层Orchestration的能力，底层必须还有标准化的部署工具支持，也就是Satellite6，它对以上基础架构类型的支持情况，如下图所示：\n\n使用CloudForms做上层Orchestration的调度，必须依赖于底层的workload的标准化，标准化到什么程度，从虚拟机供给的角度可以参考Amazon AWS 的EC2的实际案例。如下图所示：\n\nAWS服务的我曾研究过一点，上图的全图下载点这里 \u0026ndash;\u0026gt; aws-服务-脑图\n以上所有是Martin\u0026rsquo;s Lab的搭建的一部分，下周可能去一个银行客户演示。需要做的优化还很多，请关注后续更新。\n",
    "ref": "/2015/03/27/e69c8de58aa1e599a8e8999ae68b9fe58c96-rhev/"
  },{
    "title": "入手 zsh 和 oh-my-zsh",
    "date": "",
    "description": "",
    "body": "安装zsh在任何系统上几乎都是差不多。Zsh 是一款功能强大的交互式 shell，与 Bash 相比，Zsh 下面几点表现令人印象深刻：\n[wm_list bullet=\u0026ldquo;icon-linux\u0026rdquo; class=\u0026quot;\u0026quot;]\n  自动补全\n  拼写纠错\n  定制性强\n  美观的命令提示符（这点吸引力最大）\n  [/wm_list]\n相信你安装之后，对上面几点会有更加真切的感受！\n下面是RHEL 7 上的安装过程。\n[bash]\n[root@w540]~# yum install git [root@w540]~# curl -L https://github.com/robbyrussell/oh-my-zsh/raw/master/tools/install.sh | sh [root@w540]~# cat .zshrc\nPath to your oh-my-zsh installation. export ZSH=/root/.oh-my-zsh\nSet name of the theme to load. Look in ~/.oh-my-zsh/themes/ Optionally, if you set this to \u0026ldquo;random\u0026rdquo;, it\u0026rsquo;ll load a random theme each time that oh-my-zsh is loaded. #ZSH_THEME=\u0026ldquo;robbyrussell\u0026rdquo; ZSH_THEME=\u0026ldquo;bira\u0026rdquo; # 后面的文字都省略，我就修改了这个文件的这一个参数，bira的提示符感觉比较新颖和实用 [root@w540]~# zsh ╭─root@w540 ~ ╰─$ ls anaconda-ks.cfg Desktop Documents Downloads initial-setup-ks.cfg ist Music Pictures Public Templates Videos ╭─root@w540 ~ ╰─$ [/bash]\n下面是装完之后的截图，以后我的测试机的默认shell应该都是这个样子了：）\n\nzsh的功能还是比较强大的，然后再加上ohmyzsh这套配置参数文件和工具插件，shell下地工作效率应该可以提高了。下面是一下参考网站：\n[wm_list bullet=\u0026ldquo;icon-linux\u0026rdquo; class=\u0026quot;\u0026quot;]\n  oh-my-zsh入手中文参考：http://tuhaihe.com/2013/05/17/oh-my-zsh.html\n  oh-my-zsh 官网（作者认为这是他此生做的最有意义的一件事）：http://ohmyz.sh/\n  zsh 官网：http://www.zsh.org/\n  [/wm_list]\nMac OS X用户则建议实用iTerm2来替换原声的terminal。下载item2在这里：http://iterm2.com/\n\n",
    "ref": "/2015/03/23/e585a5e6898b-zsh-e5928c-oh-my-zsh/"
  },{
    "title": "Impact Mapping",
    "date": "",
    "description": "",
    "body": "这种方法论的东西很久不感冒了，可是这次耐心看了一下，确实有温故而知新的作用，有点意思，特此推荐一下。\n这个方法论的网站在：http://www.impactmapping.org/\n上图是此方法分析的思路。网上搜索了一下，多看到很多介绍敏捷方法的网站在推荐。下图是次方法的宣传海报。\n\n这里还从YouTube上搬运回来一个视频，可以参考一下。\n",
    "ref": "/2015/03/20/impact-mapping/"
  },{
    "title": "如何参与 Project Atomic",
    "date": "",
    "description": "",
    "body": "关于 Project Atomic 项目 \nProject Atomic 项目相关的开源技术组件如下：\n[wm_list bullet=\u0026ldquo;icon-linux\u0026rdquo; class=\u0026quot;\u0026quot;]\n  linux kernel\n  systemd\n  OSTree and rpm-ostree\n  Docker\n  kubernetes\n  Fedora and CentOS\n  [/wm_list]\n该项目的网站在： http://www.projectatomic.io/\n加入 Project Atomic 邮件列表 项目一般性讨论： https://lists.projectatomic.io/mailman/listinfo/atomic\n项目开发者：https://lists.projectatomic.io/mailman/listinfo/atomic-devel\n项目版本发布更新：https://lists.projectatomic.io/mailman/listinfo/atomic-announce\n填写自己的邮箱后，别忘了在邮箱里收信，并且确认。如下图所示：\n\n问 Project Atomic 问题和讨论 http://ask.projectatomic.io/en/questions/ 这里是项目的论坛可以在这里提问和帮助其他人。\n了解 Project Atomic 代码 https://github.com/projectatomic/ 项目的代码在Github网站上可以看到，如果你watch这个项目的话，可以收到所有开发者对该项目的所有代码更新等活动。\n",
    "ref": "/2015/03/19/e5a682e4bd95e58f82e4b88e-project-atomic/"
  },{
    "title": "FY16 Sales SKO Marco",
    "date": "",
    "description": "",
    "body": "FY16 Sales SKO Marco: 正像所有公司做的模式是一样的，红帽的销售启动大会在澳门开始了。澳门是个让人腻味的地方，每天早晨的集体晨跑成了一个亮点。小小的慢跑群正在成长中。\n",
    "ref": "/2015/03/17/fy16-sales-sko-marco/"
  },{
    "title": "Welcome to the age of the industrial internet",
    "date": "",
    "description": "",
    "body": "",
    "ref": "/2015/03/15/welcome-to-the-age-of-the-industrial-internet/"
  },{
    "title": "走进学校分享开源",
    "date": "",
    "description": "",
    "body": "今天走入了天津市大学软件学院，和同学们分享了我对开源软件的一些看法和经历；很多同学对如何成为架构师感兴趣。全程学生们没有玩手机和睡觉的，感觉效果应该还不错。ppt在这里\u0026ndash;\u0026gt;《开源软件之系统架构师篇》可惜对其中一个同学的回答后来想着欠妥 :(\n",
    "ref": "/2015/03/12/e8b5b0e8bf9be5ada6e6a0a1e58886e4baabe5bc80e6ba90/"
  },{
    "title": "对blog做了结构性调整",
    "date": "",
    "description": "",
    "body": "对blog做了结构性调整：把永久网址链接简化到只有文章标题；省略了之前带有复杂的分类层级的部分；之前想更多地加入关键字的想法，目前看真的想太多了。Blog还是要越简单，越简洁越好。就像我目前的Theme一样，除去了浮夸和花哨的修饰，专注内容，专注文章质量。\n",
    "ref": "/2015/03/10/e5afb9bloge5819ae4ba86e7bb93e69e84e680a7e8b083e695b4/"
  },{
    "title": "安全地简化了网页永久链接",
    "date": "",
    "description": "",
    "body": "网页的 永久链接 的配置是在：Settings \u0026ndash;\u0026gt; Permalink Settings； 通过这个设置把Wordpress默认的代码型网页网址 http://martinliu.cn/?p=123 变成了 搜索引擎更友好，而且人也更容易懂的网址。例如我目前的：http://martinliu.cn/文章标题/\n我之前的永久链接其实已经改过好多次了，期间多次是由于更新网站分类结构，还有是由于看了多篇纠结的wordpress SOE文章导致。前几次修改都是很粗暴的直接修改，并没有顾忌到对以前搜索引擎的已经抓取的网页做保护。这次我必须对当前已经纳入搜索引擎的网页做保护了，毕竟文章现在比较多了，非常有必要对搜索引擎用户做保护。\n本次修改主要参考了文章是：A Simple Guide to Changing Your Permalinks Without Breaking Your WordPress Website 此文推荐了一个简洁的方法，使用插件： Simple 301 Redirects\n安装和激活插件后，我的配置过程如下。首先，更新永久链接到新的设置。\n\n然后再去Simple 301 Redirects 的配置做如下修改：(插件有bug，最后配置网址是 /%postname%/ .html 了发现301 重定向不成功。)\n\n最后到搜索引擎里面看下是否所有的已有抓取的网页都可以正常访问。在搜索引擎中搜索： site:martinliu.cn\nbing 搜搜结果点这里 在结果页面上点击任何一个文章，文章应该被正确加载出来了。\n",
    "ref": "/2015/03/10/e5ae89e585a8e79a84e7ae80e58c96e4ba86e7bd91e9a1b5e79a84e6b0b8e4b985e993bee68ea5/"
  },{
    "title": "一下午讲了两场",
    "date": "",
    "description": "",
    "body": "一下午讲了两场：头一场给两个渠道部门和总代的两位老大；后一场讲给曙光的产品经理。讲的我满头汗，感觉思路非常清晰，越来越清晰了，数据中心的基础架构如果转型到开放架构，那么需要的是什么？是一套综合的方案体系。是一套自动化高效的运管体系。\n",
    "ref": "/2015/03/10/e4b880e4b88be58d88e8aeb2e4ba86e4b8a4e59cba/"
  },{
    "title": "天将雄师",
    "date": "",
    "description": "",
    "body": "《天将雄师》豆瓣上评分很低的电影，才6分多；我看到的却很享受，是我不正常，还是世界不正常了：）\n",
    "ref": "/2015/03/10/e5a4a9e5b086e99b84e5b888/"
  },{
    "title": "新MacBook是个怎样的选择 ？",
    "date": "",
    "description": "",
    "body": "MacBook 和Macbook Pro 的$1299相同价位的配置。http://www.apple.com/mac/compare/results/?product1=macbook\u0026amp;product2=macbook-pro-retina-13\n不难看出这两个本子，基本就是针对两种不同类型的人群。选择Macbook意味着纯文档处理类型的人；选择Macbook Pro意味着需要更强处理和运算能力的技术人员。颜色上新增了银灰和土豪金。\n\n看后我觉得我会选择，土豪金的Macbook，哈哈哈哈~需要考察一下实物才能做这个最后的决定。下面是Apple官网上关于MacBook的设计视频广告，我看完后感觉，电脑作为商品来讲，做广告到这个份上，也就快到头了。\n",
    "ref": "/2015/03/10/e696b0macbooke698afe4b8aae6808ee6a0b7e98089e68ba9/"
  },{
    "title": "martin's lab build day 1",
    "date": "",
    "description": "",
    "body": "本来不能算是day1，由于day1早就开始了，不过作为第一个post发布出的记录，还是叫它day1吧，后续会逐步更新我的进展。\n",
    "ref": "/2015/03/08/martins-lab-build-day-1/"
  },{
    "title": "Martin's lab 主服务器搭建",
    "date": "",
    "description": "",
    "body": "上图是红帽产品和技术架构的全貌。来源是：http://www.redhat.com/en/technologies/cloud-computing 这张图我用在了我的首次给公司内部的全体销售培训上。由于我是IT管理背景的，因此我很习惯从云管理层往下看云引擎的各个层面。但是管理层产品，其实是后来整合纳入的。红帽起家的旗舰产品还是在底层的RHEL。总之，我想在一个Lab里面实现以上所有的部分，所谓实现是让其每个部分都能在运行在假象的一个有意义的业务场景里。还好，红帽的产品全都是基于x86平台的，因此我用几个笔记本，再加上我家里的这台HP MicroServer G8服务器应该能够全部部署出来。\n做这样的一个lab还是要一定的规划和设计的，这些初步的规划和设计都在我的本子里手写的，就不在这里敲字了，随后我会抽空上几张图。\n主服务器基本配置 硬件：Lenovo W540 CPU Intel i7, RAM 32 GB, SSD 512GB, HD 1TB\nOS : RHEL 7.1\n订阅是红帽公司的业务模式，也是红帽认为最自豪的部分，红帽相信可以成为开源技术和用户之间的催化剂，它不断参与最优秀的开源技术创新，并为其用户提供最强有利的技术服务和支持。红帽技术员工可以申请一个红帽雇员订阅。我的订阅可以在网上查到如下图所示：\n\n红帽的服务必须是基于订阅的每一个节点（物理、虚拟）都需要有有效的订阅，否则红帽的支持服务不能生效。对于一个已经成功注册到红帽官网，并且状态正常的服务器，应该显示如下的注册状态：\n[bash] [root@w540 ~]# subscription-manager list\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+ 安装的产品状态 +\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+ 产品名称： Red Hat Enterprise Linux Server 产品 ID： 69 版本： 7.0 构架： x86_64 状态： 已订阅 状态详情： 开始： 2014年09月09日 结束： 2015年12月08日 [/bash]\n红帽员工订阅意味着所有红帽产品。\n基本服务配置 KVM KVM的上手还真比我想象的速度要慢一些，起码比我用XenServer的经历更加纠结一些。总之现在可以彻底的忘记其它任何的选项，KVM可以满足我的所有需求了。由于主服务器有512SSD + 32GB RAM + 8 vCPU，所以我打算把产品里的所有管理控制节点VM都部署在这个机器上。预计有10个左右的虚拟机。 安装配置方面这里就不赘述了。只把困扰我许久的几个网络配置贴出来，供参考。\n网桥0的功能是为所有虚拟机提供外网链接，使他们和主机一样直通主机所物理链接的局域网。 [bash] [root@w540 ~]# cat /etc/sysconfig/network-scripts/ifcfg-br0 DEVICE=br0 ONBOOT=yes TYPE=Bridge BOOTPROTO=none STP=on DELAY=0 DNS1=192.168.0.1 DEFROUTE=yes IPV4_FAILURE_FATAL=yes IPV6INIT=no DNS2=4.4.4.4 IPADDR=192.168.0.5 PREFIX=24 GATEWAY=192.168.0.1 NM_CONTROLLED=no [/bash]\n主机原本的一块物理网卡的配置，由于增加了这个网桥，需求更新如下： [bash] [root@w540 ~]# cat /etc/sysconfig/network-scripts/ifcfg-enp0s25 DEVICE=enp0s25 ONBOOT=yes BRIDGE=br0 NM_CONTROLLED=no BOOTPROTO=none [/bash]\nkvm这块处理这个折腾我很久的br0之外，其它的功能看起来还不错，运行在SSD上的虚拟机也启动和运行速度飞快。\nRepo 服务器 Repos是红帽软件仓库的简称。它具体指每个订阅内所有软件频道里面下载出来的软件包目录。下载到的某个软件包频道的repos目录中是一堆的rpm包文件，这样的目录可以制作成本地Repos服务器，能够提供给所有LAN里RHEL OS用来做软件的安装和升级用。 用主服务器上1TB的慢速普通盘来保存这些下载的repos，安装http服务器，把它共享给本lab的lan中。具体的几个参考脚本如下。\n在把本服务器注册到红帽网站之后，他会默认attach一堆可能不需要的repos，因此我的做法是先关闭掉所有的默认开启，然后再开启我所需要并且关注的东西。 [bash] [root@w540 repos]# subscription-manager repos \u0026ndash;disable=\u0026quot;*\u0026quot; [/bash] 以上命令的结果会反问，所有的被关闭的repos。下面许开启我当前需求的repos。 [bash] [root@w540 repos]# cat rhel7-enable.sh subscription-manager repos \u0026ndash;enable=rhel-7-server-extras-rpms subscription-manager repos \u0026ndash;enable=rhel-7-server-satellite-capsule-optional-6.0-rpms subscription-manager repos \u0026ndash;enable=rhel-ha-for-rhel-7-server-rpms subscription-manager repos \u0026ndash;enable=jb-eap-6-for-rhel-7-server-rpms subscription-manager repos \u0026ndash;enable=rhel-7-server-satellite-capsule-6.1-rpms subscription-manager repos \u0026ndash;enable=rhel-7-server-rt-rpms subscription-manager repos \u0026ndash;enable=rhel-7-server-openstack-6.0-rpms subscription-manager repos \u0026ndash;enable=rhel-server-rhscl-7-rpms subscription-manager repos \u0026ndash;enable=rhel-7-server-rhn-tools-rpms subscription-manager repos \u0026ndash;enable=rhel-7-server-satellite-capsule-6.0-rpms subscription-manager repos \u0026ndash;enable=rhel-7-server-openstack-5.0-rpms subscription-manager repos \u0026ndash;enable=rhel-7-server-rhevh-rpms subscription-manager repos \u0026ndash;enable=rhel-atomic-host-rpms subscription-manager repos \u0026ndash;enable=rhel-rs-for-rhel-7-server-rpms subscription-manager repos \u0026ndash;enable=rhel-7-server-satellite-capsule-optional-6.1-rpms subscription-manager repos \u0026ndash;enable=rhel-7-server-rhev-mgmt-agent-rpms subscription-manager repos \u0026ndash;enable=rhel-7-server-openstack-6.0-installer-rpms subscription-manager repos \u0026ndash;enable=rhel-7-server-rh-common-rpms subscription-manager repos \u0026ndash;enable=jb-eap-6.3-for-rhel-7-server-rpms subscription-manager repos \u0026ndash;enable=rhel-7-server-satellite-optional-6.0-rpms subscription-manager repos \u0026ndash;enable=rhel-7-server-rpms subscription-manager repos \u0026ndash;enable=rhel-7-server-satellite-6.1-rpms subscription-manager repos \u0026ndash;enable=rhel-7-server-supplementary-rpms subscription-manager repos \u0026ndash;enable=rhel-7-server-satellite-optional-6.1-rpms subscription-manager repos \u0026ndash;enable=rhel-7-server-optional-rpms subscription-manager repos \u0026ndash;enable=rhel-7-server-satellite-6.0-rpms subscription-manager repos \u0026ndash;enable=jb-ews-2-for-rhel-7-server-rpms [/bash]\n接下来可以用命令来从红帽CDN同步下载每个Repos里面的软件包。 [bash] [root@w540 rhel70]# cat sync.sh reposync \u0026ndash;gpgcheck \u0026ndash;newest-only \u0026ndash;plugins \u0026ndash;downloadcomps \u0026ndash;repoid=rhel-7-server-satellite-6.0-rpms \u0026ndash;download_path=/data/Repos/rhel70/ reposync \u0026ndash;gpgcheck \u0026ndash;newest-only \u0026ndash;plugins \u0026ndash;downloadcomps \u0026ndash;repoid=rhel-7-server-extras-rpms \u0026ndash;download_path=/data/Repos/rhel70/ reposync \u0026ndash;gpgcheck \u0026ndash;newest-only \u0026ndash;plugins \u0026ndash;downloadcomps \u0026ndash;repoid=rhel-7-server-rhevh-rpms \u0026ndash;download_path=/data/Repos/rhel70/ reposync \u0026ndash;gpgcheck \u0026ndash;newest-only \u0026ndash;plugins \u0026ndash;downloadcomps \u0026ndash;repoid=rhel-7-server-satellite-capsule-6.0-rpms \u0026ndash;download_path=/data/Repos/rhel70/ reposync \u0026ndash;gpgcheck \u0026ndash;newest-only \u0026ndash;plugins \u0026ndash;downloadcomps \u0026ndash;repoid=rhel-7-server-openstack-5.0-rpms \u0026ndash;download_path=/data/Repos/rhel70/ reposync \u0026ndash;gpgcheck \u0026ndash;newest-only \u0026ndash;plugins \u0026ndash;downloadcomps \u0026ndash;repoid=rhel-7-server-rhev-mgmt-agent-rpms \u0026ndash;download_path=/data/Repos/rhel70/ reposync \u0026ndash;gpgcheck \u0026ndash;newest-only \u0026ndash;plugins \u0026ndash;downloadcomps \u0026ndash;repoid=rhel-atomic-host-rpms \u0026ndash;download_path=/data/Repos/rhel70/ reposync \u0026ndash;gpgcheck \u0026ndash;newest-only \u0026ndash;plugins \u0026ndash;downloadcomps \u0026ndash;repoid=rhel-7-server-optional-rpms \u0026ndash;download_path=/data/Repos/rhel70/ reposync \u0026ndash;gpgcheck \u0026ndash;newest-only \u0026ndash;plugins \u0026ndash;downloadcomps \u0026ndash;repoid=rhel-7-server-rpms \u0026ndash;download_path=/data/Repos/rhel70/ reposync \u0026ndash;gpgcheck \u0026ndash;newest-only \u0026ndash;plugins \u0026ndash;downloadcomps \u0026ndash;repoid=rhel-rs-for-rhel-7-server-rpms \u0026ndash;download_path=/data/Repos/rhel70/ reposync \u0026ndash;gpgcheck \u0026ndash;newest-only \u0026ndash;plugins \u0026ndash;downloadcomps \u0026ndash;repoid=rhel-7-server-rh-common-rpms \u0026ndash;download_path=/data/Repos/rhel70/ reposync \u0026ndash;gpgcheck \u0026ndash;newest-only \u0026ndash;plugins \u0026ndash;downloadcomps \u0026ndash;repoid=rhel-server-rhscl-7-rpms \u0026ndash;download_path=/data/Repos/rhel70/ reposync \u0026ndash;gpgcheck \u0026ndash;newest-only \u0026ndash;plugins \u0026ndash;downloadcomps \u0026ndash;repoid=rhel-7-server-openstack-6.0-installer-rpms \u0026ndash;download_path=/data/Repos/rhel70/ reposync \u0026ndash;gpgcheck \u0026ndash;newest-only \u0026ndash;plugins \u0026ndash;downloadcomps \u0026ndash;repoid=rhel-7-server-openstack-6.0-rpms \u0026ndash;download_path=/data/Repos/rhel70/ reposync \u0026ndash;gpgcheck \u0026ndash;newest-only \u0026ndash;plugins \u0026ndash;downloadcomps \u0026ndash;repoid=jb-eap-6.3-for-rhel-7-server-rpms \u0026ndash;download_path=/data/Repos/rhel70/ reposync \u0026ndash;gpgcheck \u0026ndash;newest-only \u0026ndash;plugins \u0026ndash;downloadcomps \u0026ndash;repoid=rhel-ha-for-rhel-7-server-rpms \u0026ndash;download_path=/data/Repos/rhel70/ reposync \u0026ndash;gpgcheck \u0026ndash;newest-only \u0026ndash;plugins \u0026ndash;downloadcomps \u0026ndash;repoid=rhel-7-server-supplementary-rpms \u0026ndash;download_path=/data/Repos/rhel70/ [/bash]\n安装httpd的过程就不叙述了，下面就贴一个本机的配置文件。 [bash] Alias /repos \u0026ldquo;/data/repos\u0026rdquo; \u0026lt;Directory \u0026ldquo;/data/repos\u0026rdquo;\u0026gt; Options None AllowOverride None Order allow,deny Allow from all Require all granted\n[/bash]\n最后，在任何需要的机器上本地repos源的配置文件可以类似如下： [bash] [root@sat6-leb yum.repos.d]# ls rhel70.repo [root@sat6-leb yum.repos.d]# cat rhel70.repo [rhel-7-server-rpms] name=rhel-7-server-rpms baseurl=http://192.168.0.5/repos/rhel70/rhel-7-server-rpms/ gpgcheck=0 enable=1\n[/bash]\n当然，我的目标是以后这个lab网内所有的机器都需要受到satellite 6 服务器的管理和控制，并不需要在每个服务器上手动的去安装和管理repos内容和订阅。下面分阶段安装各种控制器节点的时候，在详细说明如何使用satellite 6做种子服务器生出所有的其他节点。这里的repo服务器还是作为最初的种子服务器，它使安装satellite 6 服务器的源。也是作为lab中对于satellite6的一个备份选项。\nNFS服务器 本机的存储空间比较大，可以作为慢速NFS共享存储和ISO镜像文件服务器使用，因此，安装nfs服务器之后，就可以把本地的满速普通硬盘使用nfs的方式共享到lab内网了。配置文件参考如下： [bash] [root@w540 ~]# cat /etc/exports /data/nfs 192.168.0.(rw,async) /data/iso 192.168.0.(rw,async) /home/test 192.168.0.(rw,async) [root@w540 ~]# showmount -e localhost Export list for localhost: /home/test 192.168.0. /data/iso 192.168.0.* /data/nfs 192.168.0.* [root@w540 ~]# [/bash]\nNTP服务器 根据红帽知识库文档，选择本机这个物理服务器作为lab内网的时钟服务器，所有的虚拟机和其他物理机都和他同步时钟。最终的配置还没有确定。随后更新靠谱的可以供参考的配置\n",
    "ref": "/2015/03/08/e4b8bbe69c8de58aa1e599a8e690ade5bbba/"
  },{
    "title": "Flake it till you make it",
    "date": "",
    "description": "",
    "body": "Under what circumstances should we step off a path? When is it essential that we finish what we start? If I bought a bag of peanuts and had an allergic reaction, no one would fault me if I threw it out. If I ended a relationship with a woman who hit me, no one would say that I had a commitment problem. But if I walk away from a seemingly secure route because my soul has other ideas, I am a flake?\nThe truth is that no one else can definitively know the path we are here to walk. It’s tempting to listen—many of us long for the omnipotent other—but unless they are genuine psychic intuitives, they can’t know. All others can know is their own truth, and if they’ve actually done the work to excavate it, they will have the good sense to know that they cannot genuinely know anyone else’s. Only soul knows the path it is here to walk. Since you are the only one living in your temple, only you can know its scriptures and interpretive structure.\nAt the heart of the struggle are two very different ideas of success—survival-driven and soul-driven. For survivalists, success is security, pragmatism, power over others. Success is the absence of material suffering, the nourishing of the soul be damned. It is an odd and ironic thing that most of the material power in our world often resides in the hands of younger souls. Still working in the egoic and material realms, they love the sensations of power and focus most of their energy on accumulation. Older souls tend not to be as materially driven. They have already played the worldly game in previous lives and they search for more subtle shades of meaning in this one—authentication rather than accumulation. They are often ignored by the culture at large, although they really are the truest warriors.\nA soulful notion of success rests on the actualization of our innate image. Success is simply the completion of a soul step, however unsightly it may be. We have finished what we started when the lesson is learned. What a fear-based culture calls a wonderful opportunity may be fruitless and misguided for the soul. Staying in a passionless relationship may satisfy our need for comfort, but it may stifle the soul. Becoming a famous lawyer is only worthwhile if the soul demands it. It is an essential failure if you are called to be a monastic this time around. If you need to explore and abandon ten careers in order to stretch your soul toward its innate image, then so be it. Flake it till you make it.\n",
    "ref": "/blog/flake-it-till-you-make-it/"
  },{
    "title": "你还在为失去服务器感到焦虑？",
    "date": "",
    "description": "",
    "body": "我耐心看了以下这篇文章《AWS Lambda Debuts for Running Code in the Cloud 》。我还没有来得及去测试一下这个服务，我只是对它感到新奇。有了它，业务应用可能就只需要Dev了，而不需要Ops了；更不用提什么DevOps了。当然这个观点稍微有点极端了。它的确实现了：程序代码可以基于事件在AWS的各种服务中运行。看完了那片文章我也没有察觉到它底层到底使用的是什么技术。只是说AWS再次走到了共有云服务的最前端。\n传统的共有云服务里，大家还停留在虚拟机提供，网络隔离的认识阶段。数据库服务、大数据服务、配套的程序部署和管理监控服务，对于一般性的共有云提供商，也不尽完全。曾经和作共有云的人聊过，他们觉得：传统企业数据中心的拥有着和管理这依然有巨大的纠结“失去对服务器的管控，就会有事业的风险”。因此，可见对服务器的管理是多么的重要。但是，如果你拥有了服务器的控制，并坐拥巨大的私有云建设的资金，那么您能如何很快交付出靠谱的云服务呢？说实话，目前私有云的建设很缓慢，也就是作个大批量的服务器虚拟化。IaaS的建设案例还很少，即使有人说他们建成了新一代的云平台，近看一下大多还仅仅是增强版的虚拟机提供。当然这个虚拟机的提供是基本功，做不好这一客其它的云服务也面谈。我们详细观察以下AWS，它大量的服务，像是RDS，LB，Auto Scaling 等等功能，无处不见AWS EC2的扎实功底和无限变化。\n国内的广大用户，已经选择了私有云了；越大的企业，越有条件大赶快上云建设。只是却是道路艰辛，图省事的有钱人，可以上全套V公司的云计算，却是它的吸引力、炫耀力和安慰力都是无法阻挡的。底层上的技术的引用是至关重要的，越省事的套件，等同于越少的弹性和自由度，等同于更少的自由发挥的空间，和更少的创造。AWS是基于Xen的服务器虚拟化技术，和一堆的其他开源技术。入手这条路解决了启动费用高的问题，带来了无限的创新和发展自由空间。他们不需要商业化软件或者产品么，例如，AWS是重要的Citrix netscaler用户。\n",
    "ref": "/2015/02/15/e4bda0e8bf98e59ca8e4b8bae5a4b1e58ebbe69c8de58aa1e599a8e6849fe588b0e784a6e89991efbc9f/"
  },{
    "title": "AWS 服务索引地图",
    "date": "",
    "description": "",
    "body": "以上图片用FreeMind软件生成，下载英文版原图点击这里：aws-service-map.mm\n\n下载中文版PDF全图点击这里：aws-服务-脑图\n\n",
    "ref": "/2015/02/11/aws-e69c8de58aa1e7b4a2e5bc95e59cb0e59bbe/"
  },{
    "title": "2014 Red Hat Summit- Paul Cormier, Red Hat keynote",
    "date": "",
    "description": "",
    "body": "2014 Red Hat Summit- Paul Cormier, Red Hat keynote\n",
    "ref": "/2015/02/09/2014-red-hat-summit-paul-cormier-red-hat-keynote/"
  },{
    "title": "饥饿游戏3：嘲笑鸟(上) The Hunger Games: Mockingjay - Part 1 (2014)",
    "date": "",
    "description": "",
    "body": "\n是我很久没有看电影的原因么，总之看了还是觉得不错的。可是豆瓣的评分颇低，无所谓他人怎么看了，我自己娱乐好了就行。下一部想看的是《unbreak》\n导演: 弗朗西斯·劳伦斯 编剧: 丹尼·斯特朗 / 彼得·克莱格 主演: 詹妮弗·劳伦斯 / 乔什·哈切森 / 利亚姆·海姆斯沃斯 / 伍迪·哈里森 / 唐纳德·萨瑟兰 / 更多\u0026hellip; 类型: 剧情 / 动作 / 科幻 / 冒险 制片国家/地区: 美国 语言: 英语 上映日期: 2015-02-08(中国大陆) / 2014-11-21(美国) 片长: 123分钟 又名: 饥饿游戏：自由幻梦I(台) / 饥饿游戏终极篇：自由幻梦1(港) / 饥饿游戏3：自由幻梦(上) / 饥饿游戏：自由梦幻(上) / 饥饿游戏 第三部(上) / 嘲笑鸟(上) / Seashore IMDb链接: tt1951265\n",
    "ref": "/2015/02/08/e9a5a5e9a5bfe6b8b8e6888f3efbc9ae598b2e7ac91e9b89fe4b88a-hunger-games-mockingjay-part-1-2014/"
  },{
    "title": "2014年AWS服务更新总结",
    "date": "",
    "description": "",
    "body": "有一段时间没有关注AWS了，下面是在 aws-faq.com 发的新贴。顺便梳理了一下过去一年的更新情况，\nhttp://www.aws-faq.com/featured/aws-服务2015年开年有啥更新.html\nAWS在去年新增了6个服务，整体的更新和服务升级的频率是一周一次；也就是说他们发布新版本的频率是每周一次，当然这是有网上发布信息为依推理出来的；感觉一周很可能超过一次。他们的电商也其它业务的发布评论，很可能就更高了。\nAWS的公有云服务的技术成熟度和领先度我感觉是第一名的。它激发和促进了整个行业的发展。对私有云的促进和很明显。OpenStack的更新是半年一个新版本。其参考和兼容AWS服务是很明显的。它可以很大的满足于企业自建云服务的需求。\n",
    "ref": "/2015/02/08/2014e5b9b4awse69c8de58aa1e69bb4e696b0e680bbe7bb93/"
  },{
    "title": "AWS-FAQ post - AWS 一月有什么动态?",
    "date": "",
    "description": "",
    "body": "AWS-FAQ post - AWS 一月有什么动态?\nhttp://www.aws-faq.com/blog/aws-blog/aws-%E4%B8%8A%E5%91%A8%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88-2015-%E5%B9%B41%E6%9C%88.html\n  AWS 邮件服务的推出还是比较有趣，虽然很晚推出这个服务，但是还是推出了\n  __ 总之1月的动静不大\n  ",
    "ref": "/2015/02/07/aws-faq-post-aws-e4b880e69c88e69c89e4bb80e4b988e58aa8e68081/"
  },{
    "title": "提交提交了一个BZ",
    "date": "",
    "description": "",
    "body": "用163邮箱注册了http://bugzilla.redhat.com/ ; 提交了一个satellite的bug。\n",
    "ref": "/2015/02/02/e68f90e4baa4e68f90e4baa4e4ba86e4b880e4b8aabz/"
  },{
    "title": "Fedora 21 Server测试 - Cockpit篇",
    "date": "",
    "description": "",
    "body": "先上几张Fedora 21 server 安装的截图。\n[gallery link=\u0026ldquo;file\u0026rdquo; ids=\u0026ldquo;53424,53425,53426,53427\u0026rdquo;]\n新的配色还是不错的，重点看第三张图，虽然不全，已经基本上看出F21 服务器版的软件包了。\n\n安装之后发现确实Cockpit的界面已经可以登陆了，是黑色的风格。\n\n在继续安装和探索之前，我有装了一个默认选项的f21 server ，想通过这个节点的节目添加后统一管理。\n[gallery columns=\u0026ldquo;1\u0026rdquo; size=\u0026ldquo;large\u0026rdquo; ids=\u0026ldquo;53433,53434,53435,53436,53437,53438,53439,53440,53441,53442,53443,53444,53445,53446,53447,53448\u0026rdquo;]\n我感觉有了这个工具，新手们可以轻松第完成大部分Linux系统的维护工作了。\n如果你点击了启用 docker , eth0的网络配置会丢失，会被docker那走作网桥，给他的image用作网关。这个测试最好是虚拟机多网卡。\n",
    "ref": "/2015/01/27/fedora-21-server-e6b58be8af95-cockpite7af87/"
  },{
    "title": "Fedora 22 有何值得期待",
    "date": "",
    "description": "",
    "body": "我使用这新安装的F21，连接着公司阿姆斯特丹的VPN，流畅的使用Firefox ， Chrome 上网，在没有墙的世界里顺利传行着。重返Linux世界，想起来很久没有用windows桌面了，渐渐适应和熟悉这感觉，且有些怀旧。\n之前Fedora是没有太多的体验，用的最多的是opensuse + kde桌面的组合。目前，看到fedora magazine上很多更新，感觉真的是发展的太快了。 http://fedoramagazine.org/see-whats-coming-in-fedora-22-workstation/ 看了下这个帖子，上面说F22的提升包括：更长的电池寿命、gnome Wayland更多改进、开始应用bundle的开发、更好的第三方应用支持、提升Terminal、改善开发工具等等。查看更多细节：Christian’s blog post\n",
    "ref": "/2015/01/26/fedora-22-e69c89e4bd95e580bce5be97e69c9fe5be85/"
  },{
    "title": "再次入手Linux - Fedora 21",
    "date": "",
    "description": "",
    "body": "再次安装桌面版的Linux操作系统 ，并打算作为主要的工作平台。已经是 fedora 21，需要新贴纸了。\n接下来作的：http://www.linuxidc.com/Linux/2015-01/111481.htm\n剩余没做的是按照搜狗输入法。\n",
    "ref": "/2015/01/25/e5868de6aca1e585a5e6898blinux-fedora-21/"
  },{
    "title": "虚拟机根分区扩容",
    "date": "",
    "description": "",
    "body": "我的Satellite虚拟机下载了所有常用的repo，100GB的磁盘空间都占满了，无奈必须扩容，否则没法用了。\n扩容的前提条件正好满足：根分区在最后一个分区。\n由于是kvm的虚拟机，所以首先需要扩大硬盘文件的大小： qemu-img resize my.img +100G 。\n下面去操作系统里扩容。先要用fdisk删除根分区。记录初始的其实点。然后用n命令新建分区，输入原始其实点位置，回车默认接受结束点的最后一个位置。w存盘。\nreboot系统，起来之后用命令扩容分区： resize2fs /dev/vda2 ； 在线扩容需要等一段时间，100GB的空间初始化在我的普通磁盘上做了5分钟左右。在此reboot机器，起来之后在看 df -kh 发现已经增加了100GB了，接下来再也不用担心类似情况了。\n",
    "ref": "/2015/01/21/e8999ae68b9fe69cbae6a0b9e58886e58cbae689a9e5aeb9/"
  },{
    "title": "RHEL 性能 提升方法和工具",
    "date": "",
    "description": "",
    "body": "RHEL 7 中已经引入了比较完备的性能优化、调整和监控的工具。对于我这个监控背景的人来说，不具体看下，实在忍不住。\n首先，从这篇KB学起来把。https://access.redhat.com/articles/785283\nRHEL 下性能调优的工具有三种。\n  Performance Co-Pilot\n  TUNA\n  Tuned\n  下面依次简单说下这几个工具。\nPerformance Co-Pilot 监控工具 [caption id=\u0026ldquo;attachment_53397\u0026rdquo; align=\u0026ldquo;alignnone\u0026rdquo; width=\u0026ldquo;1000\u0026rdquo;] PCP Charts - Overview View[/caption]\nPCP是一个工具集，它分为两个部分：\n  PCP Collectors ： 性能指标数据采集器，它可以从系统内核或者其他数据源来持续的采集数据。是由几个系统服务组成。 These are the parts of PCP that collect and extract performance data from various sources, e.g. the operating system kernel.\n  PCP Monitors ：性能参数集中查看和监控的图形界面。它可以同时连接多台服务器。These are the parts of PCP that display data collected from hosts (or archives) that have the PCP Collector installed. Many monitor tools are available as part of the core PCP release, whileother (typically graphical) monitoring tools are available separately in the PCP GUI package.\n  极简实施测试方法：\n 安装pcp的相关软件包（在需要被监控的机器上安装pcp即可，在需要使用图形界面查看的机器上安装pcp-gui）  $ yum install pcp pcp-gui\n启用数据收集器的服务（在需要被监控的机器上运行这些服务，在监控的周期完成之后，可以考虑关闭这些服务）  $ chkconfig pmcd on; service pmcd start $ chkconfig pmie on; service pmie start $ chkconfig pmlogger on; service pmlogger start\n查看监控到的图形：    在pcp-gui主机的host文件中加入被监控主机的地址解析\n  在RHEL 7 桌面的程序中，找到并运行 PCP Charts程序\n  它默认就是连接到本机，因此加入我们需要查看的性能参数图形即可。点击open view ，选择overview 视图即可。当然，它内置的监控视图还有很多，当然如果你希望，还可以把远程的服务器性能实时状态（点击新建视图）视图也加入进来。其它视图如下图所示。\n  [caption id=\u0026ldquo;attachment_53396\u0026rdquo; align=\u0026ldquo;alignnone\u0026rdquo; width=\u0026ldquo;520\u0026rdquo;] 内置监控视图[/caption]\n更多信息求助 man PCPIntro documentation.\n主要适用场景：\n  在RHEL下作应用或者操作系统的性能测试或调优，如果不需要或者没有必要使用第三方工具的话，它应该是首选。\n  对生产系统性能做瓶颈定位，用它可以收集和追踪系统一段时间（一天、一周、一个月）的各种性能参数的表现情况，收集下来的数据可以作单点的或者横向的分析。它能够收集的参数还是相当全面的。\n  PCP的目的是了解系统的实时的性能状态，为性能调优找到方向和目标。也可以作为日常性能监控的工具之一，为性能派错提供一臂之力。\nTUNA TUNA 则适合于复杂性能参数的调整，能对很多kernel和网络的性能参数在图形界面中配置，对于一次性要修改n个文件的深度复杂性能调优，它可以是一个提高工作效率的利器。而且，如果是某种性能参模版，可以用它作配置的导入导出。这一便于工程师，面对一对类似系统做重复的手工劳动。\n[gallery size=\u0026ldquo;mobile\u0026rdquo; link=\u0026ldquo;file\u0026rdquo; ids=\u0026ldquo;53398,53399,53400\u0026rdquo;]\n极简实施测试方法：\n  Install the necessary packages: $ yum install tuna\n  Start the tuning application $ tuna\n  For more information, please see the man tuna documentation\n主要适用场景：\n  高效深度调优\n  工作在范围比较大的性能参数上\n  需要保存并且一致地实施这些参数配置到其它机器上\n  希望使用图形界面操作\n  TUNED 写了一堆文字了，现在我才开始我需要作的正事。我的需求是：优化一台物理的测试机的性能。我希望用最少的时间，直接让系统进入针对kvm虚拟机性能优化的基础优化状态（性能优化基线）。目前我还没有时间关心所有的性能参数细节，我只想快速完成这件事。方法如下：\n  安装tuned $ yum install tuned\n  使用 tuned-adm 选择并加载 $ tuned-adm list Available profiles:\n   balanced blog latency-performance powersave sap throughput-performance virtual-guest virtual-host Current active profile: balanced  tuned-adm profile virtual-host // 最重要的就是这个命令，让操作系统优化成虚拟机host服务器的性能优化调整基线\n上面这条命令其实就是我写本文的目的。打完这条命令，我可以洗洗睡了。如果你还睡不着，可以看下下面这个文章。\nRed Hat Enterprise Linux 7.0 - Performance Tuning Guide - 3.7. tuned-adm\n性能 提升方法 性能调优有几个方面需要考量。工具方面，需要选择一个合适的工具集，需要这个工具集能够统一的覆盖所有需要管理和调优的操作系统类型和版本；目的在于能够得到所有系统的基于统一工具的性能快照（当前的状态基线）；流程方面，需要建立性能调优和持续性能改进的流程。它应该和ITIL里的可用性管理和容量管理关联起来。性能提升的流程应该有一下几个活动：\n  目标选择：选择当前环境性能基线快照目标的对象服务器，选择尽可能要典型、全面、量要够。针对采样对象，作统一的性能参数收集，选择必选和候选的性能参数指标。指标要选的有目的和有特点。目标采样对象可能会慢慢的扩大到更多的对象。目标采集的性能参数也需要，每次都review，可以作有必要的调整。\n  性能参数收集：最好在相同的时间段内收集一定时长的性能参数。建议使用一种统一的工具，这样可以更好第做横向对比。实在不行，可以对同一种操作系统使用一种工具。当然采集工具的数量越少越好，越多工作量越大，分析报表的成本越高。这个阶段RHEL上可以使用PCP。\n  建立性能调优目标：每一种业务应用或者某一类系统的基本性能诉求可能是一致的，把收集回来的数据，做分析整理和加工，对比历史的、业内标准的或者同行业的参考数据。得出本次性能参数调整的目标参数集。不同类型的系统，目标调整的参数集应该是不同的。\n  实施性能优化参数：手工的或者用自动化工具来在目标系统中实时系统参数调整。当然，建议提前做测试，保证不会影响业务正常运行，也可以使用分批分拨实施的方法。建议的方法如下，a)使用自动化配置管理工具，如puppet或类似方案，把参数调整模版用puppet 的模块来表达，并持续改进，发布最新的版本到目标host group上去即可。b）使用手工的方式实施，这里可用用到tuna工具。\n  调优结果分析：再次收集一个周期的性能数据。对比这些数据和第二步骤中的数据。分析和记录本次调优的成败和总结。找出提升的部分，无提升的步骤。为下次调优做些后续的注意事项。\n  以上活动应该在IT Service mnager的负责下定期执行。目标就是提升系统性能和效率，确保每个业务都能运行在最高的性能，为系统的容量管理和性能管理给出可靠的参考数据。\n最后，tuned并没有写在上面的流程中，并不是说它没有到。它其实应该被用在每个操作系统实例安装和初始化的阶段。它提供的是红帽为RHEL推荐的最基础的性能调优参数建议，是性能调优基线的基线。实施方法很简单，在系统初始化的post action中加入这个条目，针对不同类型的系统激活一个合适的profile即可。\n性能 提升不是一蹴而就的，而是一个长期的过程。可以使用PDAC的思想，扎实的走好以上建议流程。使用自动化运维工具和必要的数据分析工具加速以上流程。\n",
    "ref": "/2015/01/10/rhel-e680a7e883bd-e68f90e58d87e696b9e6b395e5928ce5b7a5e585b7/"
  },{
    "title": "KVM Virt-Manager  实用参考手册",
    "date": "",
    "description": "",
    "body": "关于 virt manager Virt Manager 是一个不错的kvm虚拟机管理工具，能够方便地管理虚拟机。我的测试机目前已经完全转向RHEL7上跑KVM虚拟机，通过virt-manager去管理的方案。\n\n安装virt-manager：yum install -y virt-* ； 装完之后重新启动机器即可使用。\n建议初始配置 安装完后有几个环境的配置推荐可以做一下。\nStorage Pool ： 一个默认的 + 两个自建的\n  Default ：这是virt-manager安装时默认创建的，它和操作系统在同一个卷上，我的测试机使用SSD卷，因此我所有虚拟机都会使用这个卷，这样速度比较快\n  hd ：这是测试机上普通磁盘的一个目录，目的是把那些不需要快速IO的虚拟机跑着这里，节省SSD的磁盘空间\n  iso ：这是普通磁盘上的iso文件目录，单独挂在这是为了，使用方便\n  虚拟网络 （一个默认+两个新建）\n  default ： 这个是安装了virt-manager + kvm 之后就有的，是用NAT的方式，带dhcp，默认虚拟机可以连接物理机所在的外围\n  virbr1/virbr2 ：是我根据自己的需要建立的，只能和host物理机通讯，无dhcp\n  我最近做OpenStack的实践，OpenStack需要最好隔离的几个网络跑不同的数据，因此virbr1/2正好符合OpenStack的测试需求。另外我在物理机的操作系统上搭建了yum源服务器，因此任何一个虚拟机都可以通过http访问我放在物理机上的repo目录，我只需要更新这些repos目录里面的rpm包的内容，我的lab环境中的所有虚拟机（不管是在何网络）都可以使用到最新的系统更新包和软件包了。这样大大提高了虚拟机里面软件测试的效率，所有虚拟机像是在本地安装rpm软件包一样，再也不需要联网下载，我只需要每周去公司联网同步一下这些目录即可。\n有了以上配置之后，就可以高效工作了，效率感觉比vmware workstation要高，速度快稳定。下面是虚拟机创建的流程，里面有些我的推荐做法。\n本想看下，virt-install 的使用方式，感觉那个参数太多，容易敲错，还是界面比较容易上手，而且出错的机会不高。\n命令行常用操作指南（持续更新中） virt-manager主要操作还是在命令行比较高效，特别是下面的这些操作，在使用过程中，比较多用，用的多了感觉比GUI操作方式效率高多了。\nvirt-manager的命令行功能调用有两种方式：\n  直接 virsh 回车 ，之后就进入了 virsh # 的一个专门的shell，help 就能看的里面支持的所有命令\n  在普通shell下 直接 virsh \u0026lt;操作命令\u0026gt; \u0026lt;参数\u0026gt;，\n  这两个方式的调用没有差异，感觉全凭个人的操作习惯。\n下面是一些常用的虚拟机管理功能命令参数和实例。\n开启一个虚拟机\nvirsh # start server8-a\n查看所有虚拟机(on and off)\nvirsh list \u0026ndash;all\n关闭一个虚拟机\nvirsh # shutdown server8-a\n对一个虚拟机作一个快照\nsnapshot-create-as server8-a flat-os \u0026ldquo;before customization\u0026rdquo;\n查看虚拟的所有快照\nsnapshot-list server8-a\n返回到之前的一个snapshot\nvirsh # snapshot-revert \u0026ndash;domain server8-a flat-os\n克隆一个虚拟机到新文件（用于模板的复制创建新vm，或者vm的备份）\n[root@w540 Desktop]# virt-clone -o rhel70-tmp -n rhel70-tmp-clone -f /data/vm/cloned-new-vm.img\nCloning rhel7-tmp.img | 195 GB 00:00:03 Clone \u0026lsquo;rhel70-tmp-clone\u0026rsquo; created successfully.\n",
    "ref": "/2015/01/06/kvm-virt-manager-e5ae9ee794a8e58f82e88083e6898be5868c/"
  },{
    "title": "wget 下载大文件-断点续传",
    "date": "",
    "description": "",
    "body": "举例如下：\nwget -c -b -t 0 -O CentOS-7.0-1406-x86_64-Everything.iso http://mirrors.sohu.com/centos/7/isos/x86_64/CentOS-7.0-1406-x86_64-Everything.iso -o centos.log\n下载一个7GB的DVD文件，能够断点续传，能够把状态写入centos.log文件中。具体参数说明如下：\n[su_table]\n-c  断点续传   -b  后台下载   -t 0  反复尝试下载，0（零）为不限次数   -O file name  O（大写字母o）下载的文件命名为   -o file name  o（小写字母o）下载的日志保存在文件中   URL  http://mirrors.sohu.com/centos/7/isos/x86_64/CentOS-7.0-1406-x86_64-Everything.iso     [/su_table] 本文参考：http://blog.chinaunix.net/uid-14735472-id-111049.html\n",
    "ref": "/2014/12/24/wget-e4b88be8bdbde5a4a7e69687e4bbb6-e696ade782b9e7bbade4bca0/"
  },{
    "title": "Workshop: Creating a Docker management environment",
    "date": "",
    "description": "",
    "body": "Red Hat APAC Tech Exchange, Macau\nDay 3 - 4 December 2014 \u0026ndash; Track C\nCommand to Run bash \u0026lt;(curl -sSL https://bit.ly/get-fabric8) -k\nDocument to read https://docs.docker.com/installation/\nhttp://fabric8.io/v2/index.html\nhttps://github.com/fabric8io/quickstarts\nMy document: https://access.redhat.com/articles/881893\nBlogs http://rawlingsj.blogspot.com/\nhttp://macstrac.blogspot.co.uk/\n",
    "ref": "/2014/12/04/workshop-creating-docker-management-environment/"
  },{
    "title": "workshop redhat storage and splunk",
    "date": "",
    "description": "",
    "body": "Instance Details Replace userX with your user id. For example, user1 \u0026ndash;\u0026gt; user 30\nInstance  DNS  IP   **Internal**   RHS 01  rhs-01.userX.apac.red  10.100.0.101   RHS 02  rhs-02.userX.apac.red  10.100.0.102   RHS 03  rhs-03.userX.apac.red  10.100.0.103   RHS 04  rhs-04.userX.apac.red  10.100.0.104   Splunk Master  splunkmaster.userX.apac.red  10.100.0.201   Splunk Search  splunksearch.userX.apac.red  10.100.0.202   Splunk Peer 01  splunkpeer-01.userX.apac.red  10.100.0.211   Splunk Peer 01  splunkpeer-02.userX.apac.red  10.100.0.212   Splunk Peer 01  splunkpeer-03.userX.apac.red  10.100.0.213   **Public**   Gateway  gw-userX.apac.red  gw-userX.apac.red   Splunk Master  splunk.userX.apac.red  splunk.userX.apac.red   Splunk Search  search.userX.apac.red  search.userX.apac.red     On your laptop cd ~/.ssh wget https://s3-ap-southeast-1.amazonaws.com/splunk-lab/rhte-splunk-lab wget https://s3-ap-southeast-1.amazonaws.com/splunk-lab/rhte-splunk-lab.pub chmod 600 rhte-splunk-lab chmod 644 rhte-splunk-lab.pub\nssh -i ~/.ssh/rhte-splunk-lab -l ec2-user gw-userX.apac.red\nOn all RHS Nodes sudo su - subscription-manager attach \u0026ndash;pool 8a85f9864675056e014684868378649c subscription-manager repos \u0026ndash;disable=* subscription-manager repos \u0026ndash;enable rhel-6-server-rpms \u0026ndash;enable rhs-3-for-rhel-6-server-rpms \u0026ndash;enable rhel-scalefs-for-rhel-6-server-rpms\nyum -y update\ncat /etc/redhat-* # should say Red Hat Enterprise Linux 6.6 (Santiago) and Red Hat Storage 3.0 Update 2\n/sbin/service glusterd restart\nOn RHS-01 gluster peer probe rhs-02.userX.apac.red gluster peer probe rhs-03.userX.apac.red gluster peer probe rhs-04.userX.apac.red\ngluster pool list\ngluster volume create splunk replica 2 rhs-01.userX.apac.red:/srv/brick1/splunk rhs-02.userX.apac.red:/srv/brick1/splunk rhs-03.userX.apac.red:/srv/brick1/splunk rhs-04.userX.apac.red:/srv/brick1/splunk\ngluster volume set splunk storage.owner-uid 1001 gluster volume set splunk storage.owner-gid 1001 gluster volume set splunk user.nfs disable\ngluster volume start splunk\ngluster volume info gluster volume status\nOn Splunk Master and Splunk Search Nodes subscription-manager attach \u0026ndash;pool 8a85f9864675056e014684868378649c subscription-manager repos \u0026ndash;disable=* subscription-manager repos \u0026ndash;enable rhel-7-server-rpms\nyum -y update\nwget https://s3-ap-southeast-1.amazonaws.com/splunk-lab/splunk-6.2.0-237341-linux-2.6-x86_64.rpm \u0026ndash;no-check-certificate\nOn all Splunk Nodes subscription-manager attach \u0026ndash;pool 8a85f9864675056e014684868378649c subscription-manager repos \u0026ndash;disable=* subscription-manager repos \u0026ndash;enable rhel-7-server-rpms \u0026ndash;enable rhel-7-server-openstack-5.0-rpms \u0026ndash;enable rhel-7-server-rh-common-rpms\nyum -y update\nyum -y install wget lvm2\nwget https://s3-ap-southeast-1.amazonaws.com/splunk-lab/splunk-6.2.0-237341-linux-2.6-x86_64.rpm \u0026ndash;no-check-certificate\n/bin/systemctl start lvm2-lvmetad.service /bin/systemctl start lvm2-monitor.service\npvcreate \u0026ndash;dataalignment 1024k /dev/xvdb1 vgcreate splunkdb /dev/xvdb1 /sbin/lvcreate -a y -l 100%VG -n splunkdb splunkdb mkfs.xfs -i size=512 /dev/mapper/splunkdb-splunkdb\nOn all Splunk Nodes echo -e blkid /dev/mapper/splunkdb-splunkdb | cut -d \u0026quot; \u0026quot; -f 2\u0026quot;\\t/opt/\\txfs\\tdefaults,inode64,noatime\\t0\\t0\u0026quot; \u0026raquo; /etc/fstab mount /opt\nyum -y localinstall splunk-6.2.0-237341-linux-2.6-x86_64.rpm\necho -e \u0026ldquo;splunk\\t\\tsoft\\tnofile\\t10240\u0026rdquo; \u0026raquo; /etc/security/limits.conf echo -e \u0026ldquo;splunk\\t\\thard\\tnofile\\t20480\u0026rdquo; \u0026raquo; /etc/security/limits.conf\nOn Splunk Master and Splunk Search cd /lib/systemd/system wget https://s3-ap-southeast-1.amazonaws.com/splunk-lab/splunkd.service \u0026ndash;no-check-certificate\nsed -i.bak \u0026lsquo;/^After|^Requires/d\u0026rsquo; splunkd.service sed -i.bak \u0026lsquo;/Description/a After=network.target local-fs.target\u0026rsquo; splunkd.service systemctl daemon-reload systemctl enable splunkd.service systemctl start splunkd.service\nrunuser -l splunk -c \u0026lsquo;splunk status\u0026rsquo; q y systemctl restart splunkd.service runuser -l splunk -c \u0026lsquo;splunk status\u0026rsquo;\nOn Splunk Peer Nodes yum install -y glusterfs-fuse python-httplib2 attr\nmkdir /mnt/glusterfs echo -e \u0026ldquo;rhs-01.userX.apac.red:/splunk\\t\\t/mnt/glusterfs\\t\\tglusterfs\\t\\tdefaults,_netdev,backup-volfile-servers=rhs02.userX.apac.red:rhs-03.userX.apac.red:rhs-04.userX.apac.red\\t0\\t0\u0026rdquo; \u0026raquo; /etc/fstab mount /mnt/glusterfs\nrunuser -l splunk -c \u0026lsquo;mkdir -p /opt/splunk/var/lib/splunk/glusterfs\u0026rsquo; runuser -l splunk -c \u0026lsquo;mkdir -p /mnt/glusterfs/$(hostname -s)\u0026rsquo;\ncd /lib/systemd/system wget https://s3-ap-southeast-1.amazonaws.com/splunk-lab/splunkd-pre.service systemctl enable splunkd-pre.service systemctl start splunkd-pre.service\necho OPTIMISTIC_ABOUT_FILE_LOCKING = 1 \u0026raquo; /opt/splunk/etc/splunk-launch.conf\nwget https://s3-ap-southeast-1.amazonaws.com/splunk-lab/splunkd.service systemctl daemon-reload systemctl enable splunkd.service systemctl start splunkd.service runuser -l splunk -c \u0026lsquo;splunk status\u0026rsquo; q y systemctl start splunkd.service runuser -l splunk -c \u0026lsquo;splunk status\u0026rsquo;\ncd /opt/splunk/bin wget https://s3-ap-southeast-1.amazonaws.com/splunk-lab/rhsBucketMover.py wget https://s3-ap-southeast-1.amazonaws.com/splunk-lab/rhsBucketMover.sh wget https://s3-ap-southeast-1.amazonaws.com/splunk-lab/rhsLinkChecker.py\nchown splunk:splunk/rhs*\non gw-userX.apac.red iptables -t nat -A PREROUTING -p tcp \u0026ndash;dport 8001 -j DNAT \u0026ndash;to-destination 10.100.0.211:8000 iptables -t nat -A PREROUTING -p tcp \u0026ndash;dport 8002 -j DNAT \u0026ndash;to-destination 10.100.0.212:8000 iptables -t nat -A PREROUTING -p tcp \u0026ndash;dport 8003 -j DNAT \u0026ndash;to-destination 10.100.0.213:8000\nWeb GUI on Splunk Master (http://splunk.userX.apac.red:8000/) Settings \u0026ndash;\u0026gt; Indexer Clustering Replication Factor 3 Search Factor 2 Enable Clustering - accept until restart and hit ok\non each Web GUI on Splunk Peer 01 (http://gw-userX.apac.red:8001/) Web GUI on Splunk Peer 02 (http://gw-userX.apac.red:8002/) Web GUI on Splunk Peer 03 (http://gw-userX.apac.red:8003/)\nSettings \u0026ndash;\u0026gt; Indexer Clustering Enable Clustering Type - Peer host = https://splunkmaster.userX.apac.red port 8089 replication port 8090\nWeb GUI on Splunk Search (http://search.userX.apac.red:8000/) Settings \u0026ndash;\u0026gt; Indexer Clustering Enable Clustering Type - Search host = https://splunkmaster.userX.apac.red port 8089 replication port 8090\non Splunk Master Node cd /opt/splunk/etc/master-apps/_cluster/local directory wget https://s3-ap-southeast-1.amazonaws.com/splunk-lab/indexes.conf runuser -l splunk -c \u0026lsquo;splunk apply cluster-bundle \u0026ndash;answer-yes\u0026rsquo; admin password runuser -l splunk -c \u0026lsquo;splunk show cluster-bundle-status\u0026rsquo;\nOn each Node runuser -l splunk -c \u0026lsquo;splunk search \u0026ldquo;| rest /services/data/indexes | table title, homePath, coldPath\u0026rdquo;'|grep demo \u0026lt; look for $SPLUNKDB/glusterfs/demo/colddb\non Splunk Master Node su - ec2-user\ncd ~/.ssh wget https://s3-ap-southeast-1.amazonaws.com/splunk-lab/rhte-splunk-lab wget https://s3-ap-southeast-1.amazonaws.com/splunk-lab/rhte-splunk-lab.pub chmod 600 rhte-splunk-lab chmod 644 rhte-splunk-lab.pub\ncd /tmp wget https://s3-ap-southeast-1.amazonaws.com/splunk-lab/eventgen.tar.gz scp -i ~/.ssh/rhte-splunk-lab eventgen.tar.gz splunkpeer-01.userX.apac.red:eventgen.tar.gz scp -i ~/.ssh/rhte-splunk-lab eventgen.tar.gz splunkpeer-02.userX.apac.red:eventgen.tar.gz scp -i ~/.ssh/rhte-splunk-lab eventgen.tar.gz splunkpeer-03.userX.apac.red:eventgen.tar.gz\nOn each Peer Node cd /opt/splunk mv ~ec2-user/eventgen.tar.gz /opt/splunk chown splunk:splunk eventgen.tar.gz runuser -l splunk -c \u0026lsquo;splunk install app /opt/splunk/eventgen.tar.gz\u0026rsquo; runuser -l splunk -c \u0026lsquo;splunk restart\u0026rsquo;\ncd /opt/splunk/etc/apps/eventgen/samples cp sample.tutorial1 demo_data sed -i.bak s/main/demo/g demo_data cd /opt/splunk/etc/apps/eventgen/local cp ../README/eventgen.conf.tutorial1 eventgen.conf sed -i.bak \u0026rsquo;s/main/demo/g;s/sample.tutorial1/demo_data/g\u0026rsquo; eventgen.conf\nrunuser -l splunk -c \u0026lsquo;splunk restart\u0026rsquo;\nLog into WebUI on Splunk Master search \u0026ldquo;index = demo\u0026rdquo; timeframe = realtime \u0026gt; 5 minutes\ncheck /opt/splunk/var/lib/splunk/demo/db\n",
    "ref": "/2014/12/04/workshop-redhat-storage-splunk/"
  },{
    "title": "KK 失控 观后感 之前三章",
    "date": "",
    "description": "",
    "body": "第一章 人造与天生 1.1 新生物文明 生物的工程化和机器的生物化，这个词出现在我脑海中，并且通过描述一个生动的实际的实验。对生物系统的机器化和机器系统的生物化做对比和类比。开篇就乐观的去迎接新生物文明。\n1.2 活系统只胜利 放生学的成果会促进或活系统向更高阶的智能程度进化，使之机器智能具有自我维持的能力\n1.3 学会向我们的创造物低头 用非常感性的方式道出了人造物的未来和前景；人造物终究会具有生物的特性，能自活、有适应力和创造力，最后人们失去对他们的控制，并与之对等相处。\n总体看，第一章在说人造智能的前景和方向，机器和生物特性相互融合是发展的方向。其中也有一丁点环保的意思，人还要保护生态的完整性，人需要想生物界学习的太多了。\n第二章 蜂群思维 2.1 蜜蜂指导：分布式管理 用蜂群的而神秘性和特征，以及人们历史上对他的认识和研究，提出：它是分散和高度统一的矛盾复合体是，是一个非常极端的模式，这种模式可能是人造智能机器最佳的智能神经模式，分布式管理是统一、集中、集权是管理的反面。分布式管理模式是分布式系统的灵魂之一。\n2.2 群氓的集体智慧 群氓其实具有高级智慧的可能性和存在性，证明了群体中，简单个低级交互叠加之后可以产生对群体的复杂控制，这种群策群力的抉择能力是单个个体所无感知的，但是确实发生在整个群体上，并有效地扑朔迷离的控制这超多数量简单个体所组织的庞大蜂群。\n2.3 非均质的看不见的手 本想客观记录，不想在本文中投入任何感性，禁不住还是想表扬一下翻译者；这种神人实在不多，把这些晦涩难懂的跨界巨大的文章，翻译到这个程度真是值得赞赏，从行文和用词上，真非常达意、恰当和易懂。\n涌现这个概念提出了，它使蜂群和蚁群的操控模式的共性；是非线性的存在；不想人、或者高级生物的意识、是按时间连续的，它是蜂群的另外一个，看似无用、无聊和没有意义的特征之一。继续分析蜂群的奥妙中。\n2.4 认知行为的分散记忆 类比人的智慧模式，人也潜在的具有上面的蜂群的那些特征。\n2.5 从量变到质变 简单、相同类事件的大量发生可带来一个必然的结果，这是预测说，也是反馈性控制的根基定律。把它和具有涌现型意识的事物管理在一起后，就形成了智能控制了，也就是，让机器有所为，有所不为的行为控制，这就到了一种高度的自发的智能程度。它是一种自发的智慧，他们积累和叠加后经过质变，就失控了，而这种状态就是更高的智能程度“意识”；现在看到机器能够令人恐惧的一面了。\n2.6 群集的利与弊 群集就是分布式并行的网络结构，或者是内部组成逻辑，或者是机体组织方式。总结分析了具有这种内质的活系统，在理论上应该具有的特点和优势。\n2.7 网络是二十一世纪的目标 蜂群思维的应用不容易，他需要人们的自我否定，而人是很难去颠覆已有的常识；本文用互联网网络证明了蜂群的事实存在性。\n这一章的干货真的不少，其中的活系统是关键词。它应该是本书的精华之一。\n第三章 有心智的机器 3.1 取悦身体的机器 第一遍读，真不理解作者在扯什么无聊的闲篇充篇幅。再一看其实不是，这一章是循序渐进的描述和论证方法，逻辑上有点严谨的。本节说的是那种最弱智的简单人造机器，已经开始讲述智能机器人了，是智能生物的实施和实践。用真实案例证明它的价值。单体的智能机体的生产。\n3.2 快速、廉价、失控 简单躯体和简单思维逻辑的组合，是可以实现出非常游泳的个体，这些个体如果能就具有群体的包容架构特性，他们将可能出自治的可能性，注意是群体上体现出的自治性，如果可以实现群体的自治，这样包容架构的简单机体在整体上，具有了群级别的共享的智能，它可能反过来在控制到群的个体的行为。\n3.3 众愚成智 平行彼此对等关联，上下级结构的相互影响。不同层级上德简单任务群体之间可以按，上下级的方式组合起来。各个群体之间，彼此各异，又相互作用，在这种局面下可以形成“集体层面统一的智慧”。这样的微混沌状态中蕴藏着“群体才具备的统一智慧”；群体\u0026ndash;\u0026gt;个体行为\u0026ndash;\u0026gt;聚合作用\u0026ndash;\u0026gt;混沌态\u0026ndash;\u0026gt;整体统一反应\u0026ndash;\u0026gt;智慧（智慧可能抬高了，可以是智能）\n3.4 嵌套层级的优点 分布模式下的控制理论。自上而下的模式理论上都是行不通的，简单局部的控制能组合出可以运作的系统；用杂耍抛球机器人的实现，证明了这种方式的可行性和价值；这样做出的有意识地控制，就能产生智能的行为，并可自行地正常运作下去。\n3.5 利用现实世界的反馈实现交流 中央大脑的从上之下的控制模式下，让机器去模拟人脑对外界的感知，产生唯一真实地外界参考模型，不断更新修正脑中的外部世界模型，之后有中央大脑决定行为方式，同时保持不同部分的正常控制的思路，非常符合常识。但其实是不可用的模式。颠覆人们的常识好像是KK的习惯。而行的后，根据结果的正确判断，产生出下一步的动作，这种现实反馈得出的控制行为，可以让机器求生成功。也就是机器能够生存了，看到了把，有更进一步了。\n3.6 无躯体则无意识 躯体\u0026ndash;\u0026gt;行为\u0026ndash;\u0026gt;感知\u0026ndash;\u0026gt;基于规则的控制=意识。这个推导出了，意识要依托与躯体存在。行为规则下控制躯体成为意识；基于经验反馈的感知后控制行为，这种是高级的控制模式，是智能。这和我看的另外一本书有相关，《人性论》说道人性的三个层次：1基于意识和经验的知性；2理性；3德性。它也是从物理现实世界到精神道德层面的逐层递进。\n3.7 心智/躯体的黑盲性精神错乱 本书跨界确实大，用医学上的临床案例证明意识和躯体的共存性和非孤立存在性，说明心智和躯体的高度一致性。人的躯体是心智的奴隶，我也有一个例子证明：某人一大神晚上睡不着，说打坐一个小时后，心智平静，方的安睡。心智甚至可以达到自我毁灭、毁灭躯体的地步。智附着于躯体，智能可以人造产生，而且人造智能可以有强大的威力。\n总结 前三章我在分机上一气呵成做完意识读书笔记，感觉它结构式论述万兆；失控后可产生出智慧的控制；失控和意识控制是完美的矛盾统一，是极低智慧个体聚合融合为群体后，简单控制量变到质变之后，产生出人造智能，群体架构分布式处理管理的躯体成了智能机器。从理论上这种机器智能是可以实施的。\n",
    "ref": "/2014/12/02/kk-e5a4b1e68ea7-e8a782e5908ee6849f-e4b98be5898de4b889e7aba0/"
  },{
    "title": "rdo",
    "date": "",
    "description": "",
    "body": "https://openstack.redhat.com/Main_Page\n",
    "ref": "/2014/12/02/rdo/"
  },{
    "title": "明天澳门见",
    "date": "",
    "description": "",
    "body": "[caption id=\u0026ldquo;attachment_53304\u0026rdquo; align=\u0026ldquo;alignnone\u0026rdquo; width=\u0026ldquo;802\u0026rdquo;] If there is anything you need, I won\u0026rsquo;t be far away.[/caption]\n半年了，第一次出差，赶上公司开大会，Apac整个技术部门的人都汇聚一堂，这是一个geek的盛会。期待的看点还是很多的。更有周三超过百人的geek running。周末会绕道香港，在转机去新加坡，在哪有一周的产品培训。这趟洗肺之旅，不知道能够创下多少公里的跑步里程，我已经按耐不住，脚底板发痒了。\n悲催的我明天才能够拿到港澳签注，因此只能乘坐下午4点的航班，到晚上才能到澳门。比其他所有人的到达时间，整整晚了一天。由于签注还没到手，还有一点点忐忑，毕竟我的程三张机票都出好了。但愿明天顺利出发。\n",
    "ref": "/2014/12/01/e6988ee5a4a9e6beb3e997a8e8a781/"
  },{
    "title": "openstack all in one",
    "date": "",
    "description": "",
    "body": "test\n",
    "ref": "/2014/11/25/openstack-one/"
  },{
    "title": "虚拟桌面 之我见",
    "date": "",
    "description": "",
    "body": "虚拟桌面 的业务价值 虚拟应用产生在虚拟桌面之前，虚拟应用是一种和VPN类似的原创访问方法。它其实最初实现的是图形GUI的远程访问，注意不是文字终端。它和VPN具有本质的区别，在于虚拟桌面是“终端不留数据/秘”的；这个它性拜它的传输协议所赐，虚拟桌面传输的主要是图像信息和键鼠指令。它的另外一个特性是“维护渐变”，在终端上维护近似于零（除了安装和配置虚拟桌面连接客户端程序外）；在服务器端应用升级和维护简单，主要是通过升级和更新一堆的Windows操作系统来实现。因此，主要的业务价值有两点：1）数据安全；2）维护简单。基于这些价值取向，它可以很好地胜任一下业务场景： [su_list icon=\u0026ldquo;icon: flag\u0026rdquo;]\n  多网隔离、集中上网、运维/外包/审计人员访问管理\n  前端操作环境和后端业务数据的分离\n  呼叫中心、处理中心和窗口柜员\n  移动办公、BYOD\n  安全研发、协作研发\n  3D虚拟桌面\n  等等等等\n  [/su_list]\n业务价值很精练，业务场景太多这里就不赘述。\n关键技术点 下面是虚拟桌面/应用的基本原理架构图。  通过上图可以对虚拟桌面的技术架构一目了然。虚拟桌面基础架构就是在数据中心里面部署的一堆Windows虚拟机，核心就在于让远程用户可以操作使用这些虚拟机里面的应用或者这些虚拟机桌面。鉴于此，核心技术主要有两个方面：Windows操作系统虚拟机的集中发布更新和管理；远程访问协议和所有终端管控策略。\nWindows虚拟机的发布和更新 Windows的虚拟机有两种：Server和Desktop；虚拟应用技术主要是利用Windows Server操作系统天然的多用户性质，实现一份安装程序的多用户同时使用。虚拟桌面是复制n个预装应用的Desktop桌面操作系统来实现n个用户的使用。\n1）虚拟机克隆 使用服务器虚拟化技术可以方便地从OS模板中克隆出n个虚拟机，它的挑战在于：\n  创建和更新的速度要快，特别是在虚拟机数量大的情况下\n  可否永久保持用户的个人数据，更新操作不会清空旧的个人数据\n  存储空间要节省\n  2）Stream OS 流化操作系统 这种方案是一种古老而容易被人遗忘的技术。就是很久很久以前的无盘工作站的思路。虚拟机或者物理机以网络启动的方法获得一个运行的Windows操作系统。所有的操作系统启动镜像都在服务器端统一管理，一种镜像可以对应启动n可操作系统，这些操作系统目前多以虚拟机的形式存在。它的特点\n  虚拟机对磁盘的消耗非常小，磁盘是写缓存和用户数据。它的大小可以是0或者几个GB。\n  创建的速度快\n  大批量虚拟机启动过程对网络有一定的压力，一般需要使用隔离的万兆网\n  同样有个人数据保持的问题\n  更新速度非常快，所有的操作系统在母盘更新后，需要重启来更新\n  不管用什么方式集中管理虚拟机，总之桌面虚拟化是要同时玩转这几个球水晶球。\n  存储成本和性能\n  操作系统更新和个人数据保持\n  虚拟应用和虚拟桌面的混搭\n  虚拟机发布更新方式的混搭\n  远程访问协议 远程访问协议哪家强，可以公允的说还是Citrix ICA强。本文不是评测访问协议，只是点到为止。远程GUI界面发的虚拟访问方式一共有以下几种：\n[su_list icon=\u0026ldquo;icon: flask\u0026rdquo;]\n  Citrix ICA/ HDX ICA : Citriix的发家的技术，具有网络适应性强可用于广域网，后台管控策略精细，用户体验高等特点。\n  PCoIP ：最早适用于非虚拟桌面领域的，后来和VMWare和Teradici共同研发之后用在了VDI的访问上。\n  RDP ：Windows Server操作系统自带的远程桌面访问协议，不管你用还是不用它就在那里，它的技术日趋成熟，体验越来越好，不容忽视，从MS许可证的角度讲，任何一个虚拟桌面就需要购买微软的虚拟桌面windows许可证。\n  SPICE ：它是一个开源的协议，可以和KVM配合实现Windows和Linux的远程桌面范围，自身的成熟度和完整度都一般。由于代码的开放性，有使之在某些公司手里成为可造之材。\n  其它 ：国内主要的方式是类似于破解RDP的形式，基于RDP做一些改进和优化。\n  [/su_list]\n总之一句话“优秀的访问协议”是好的虚拟桌面的天然基因，但它并不是虚拟桌面的全部。几个核心的考察指标包括：\n  是否支持集中管理：在一个集中的管理服务器上实现对虚拟机、用户、访问终端等等的集中统一管理。\n  管理的颗粒度：你不清楚的话，就到厂商的管理控制台上数数就行\n  带宽消耗：带宽消耗和视觉效果100%是成反比的，节省带宽就以为这降低显示效果，但是还要要求不降低操作灵敏度的情况下，是否支持WAN。这些看似矛盾的因素就是要在一个共同体里同时寻找。\n  客户端设备兼容：是否任何有计算能力有显示输出的设备都可以操作。主要是设备的类型和操作系统。\n  服务器虚拟化技术 没有服务器虚拟化似乎不成虚拟桌面项目。它是运行虚拟机的载体。选择的范围主要几家：vSphere，XenServer、Hyper-V和KVM。可以说他们和虚拟桌面是强相关的有一定的兼容性制约。如果不差钱，那么直接买最贵的。如果非常清晰自己的业务需求，则可以推导出自己合适的技术。\n网络技术 一个完美的虚拟桌面基础架构需要实现数据中心100%的包裹，需要实现外网设备统一的访问入口。说的更形象一点：虚拟桌面平台的虚拟机操作环境可以成为数据中心企业数据的传输终点，所有用户和数据的交互都在这里发生，数据是否能继续它的旅程传输出去，是受到策略的控制。外部客户访问这个入口，入口想一扇门，打开它用户就能够访问到自己的所有的应用和桌面，这扇门对外只开放一个端口，它起到了远程访问协议的代理服务器的功能，它把虚拟桌面基础架构中成百上千的IP地址的访问都终结掉，给防火墙策略的制定减轻了压力，实为容易忽视的关键技术点。\n项目的成败 毫不夸张的讲，能给你把大规模虚拟桌面项目做成功的人才对你有真爱。大规模虚拟桌面项目太复杂，实施难度大，成本高，这是业内的共识。对于大的组织，业务需求的梳理和确认需要有厂商引导，在这个过程中最尖锐的问题会在与：1）应用的兼容性；2）外设的兼容性。目前的Windows应用并非天然能够在虚拟机里面运行的，特别是在有负载外设需要通过远程协议链接的时候，更是如此。让企业修改应用是一个非常头痛的事情；选择修改应用，使之更适用于虚拟化环境，从长远看是明智的选择，并非企业的让步。而逼着厂商来适应一个糟糕的，或者本不该出现在虚拟桌面环境中的应用，即使是花了很大的代价实现了，也是投入和产出及不划算的。\n成本结构的烦恼，宏观的看成本中排名前几位是：存储、服务器、软件许可。也就是说桌面虚拟化厂商玩命的在硬件厂商打工。如何节省存储和服务器成本，方法可以是：减少虚拟机的资源消耗量。注意有些情况下是在不极大降低虚拟的数量上来做的，这就不得不去细看一下虚拟机的制备方法上，各家的优势了。方法也可以是：调整VDI和虚拟应用使用的比例。\n实施的过程不仅是搭建和测试，更要命的时用户的接受程度。在有些地方是需要强推，在某些情况下是要把技术问题留给厂商解决。一切都在于实施成本的平衡，没有一帆风顺的实施。实施的过程也是不断积累运维经验的过程，企业需要做好学习和提高的准备，这个球也不好接住。\n总结 桌面虚拟化和应用虚拟化是两个不同的技术。在一个项目和客户里，可能是两种不同的技术路线，在很多情况下也是混合使用的。它们构成了“企业应用交付基础架构”，这个基础架构在数据中心里地地位和网络设备、服务器、存储、数据库等等是相同的。只是它处在一个比较特殊的位置。很多人可能还不能理解到这一层。\n从ITSM的角度看，它提供了一种IT服务。用户通过它可以安全高效地使用各种企业业务应用和数据。企业可以用应用交付基础架构，轻松地把业务系统部署到任何的工作场所；并得到更好地数据安全性的保证，更快速地交付各种业务（甚至所有内网应用）给最终用户（不管他们身在何处）。\n",
    "ref": "/2014/11/23/e8999ae68b9fe6a18ce99da2-e4b98be68891e8a781/"
  },{
    "title": "偶遇一个不错主题",
    "date": "",
    "description": "",
    "body": "无意中找到一个新的Wordpress主题 Mustang Lite 作者为WebMan。安装完之后觉得非常满意，本来这是一个多用途很复杂的主题现在让我给彻底精简了。感觉比较简洁，简洁的主题是我的最爱。\n\nWordpress也升级到最新版本\n",
    "ref": "/2014/11/22/e581b6e98187e4b880e4b8aae4b88de99499e4b8bbe9a298/"
  },{
    "title": "跑步不能停",
    "date": "",
    "description": "",
    "body": "在最近一段时间里面，兴趣和心情持续承受着巨大的挑战。一边是亘古不变的哪些发愁的思绪，一边是潮水般涌来的新事物；还有不断的适应和调整。总之心神俱疲的感觉越来越重，是该进入正常运行态了，该恢复状态了，跑步不能中断，业精于勤！跑起来！\n",
    "ref": "/2014/11/18/e8b791e6ada5e4b88de883bde5819c/"
  },{
    "title": "硬件就绪可开工了",
    "date": "",
    "description": "",
    "body": "昨天晚上折腾了很晚，结果扩展的8GB内存条死活和系统不兼容，导致ESXi安装卡在内存检查哪里。在京东上直接退货，然后订货HP专用内存条。今天下午新条子火速送达。装上后系统在也卡了。ESXi安装顺利完成。下载了vClient后，导入了几个常用ISO，安装好了RHEL6和7的模板机。接下来可以开始方案的研究了。由于这台服务器有着巨大的折腾的空间，未来的硬件升级whish list包括：\n[su_list icon=\u0026ldquo;icon: heart-o\u0026rdquo;]\n  增加SSD磁盘，加速IO密集的虚拟机\n  增加到16GB内存，可惜不能上32GB，短板，相当的短\n  增加新的硬盘，当前的1TB用完后，还有三个盘位\n  升级CPU到Xeon e1256l v2，据说性能可以提升三倍，逻辑CPU数可以到8颗\n  [/su_list]\n开源的东西还好，基本上都是结构简洁的居多，我可能从配置管理相关的技术开始搞起来，如Formen，Puppet；再到Ceph\u0026amp;gluster等存储应用，再到OpenStack这样较复杂的应用。\n",
    "ref": "/2014/11/18/e7a1ace4bbb6e5b0b1e7bbaae58fafe5bc80e5b7a5e4ba86/"
  },{
    "title": "我的11.11采购",
    "date": "",
    "description": "",
    "body": "难以置信我在11.11这一天也出手了。在过去的一年多里，烧过了跑步装备，烧过了跑步GPS手表之后；在光棍节那天，我毅然开始搭建home lab了。一直不想把家里也搞成工作的场所，但是来自大学时代攒机的冲动在此刻颠覆了我。\n这台主机仅仅是个开端，它只是一个空机箱，只有主板、CPU和2GB内存。以后什么都需要扩展。在网上看了几篇讨论DIY这款机器的帖子之后，果断在京东上下单了。下单的价格是2799，感觉目前这应该是全网最低价。另外还采购的配件有一条8GB的HP服务器用内存条，一块1TB的硬盘。另外，我也单独为lab开了一个页面，点击左侧链接就可以过去，以后关于对它的折腾都会记录在那边。\nTO Do list：\n[su_list icon=\u0026ldquo;icon: check-circle\u0026rdquo;]\n  收货后组装开机\n  购买2.5寸硬盘托架，加装入家里过剩的笔记本硬盘一块，在光驱位置附近。\n  安装vmware EXSi在2.5寸的盘上\n  [/su_list]\n",
    "ref": "/2014/11/13/e68891e79a8411-11e98787e8b4ad/"
  },{
    "title": "迷宫行者 The Maze Runner",
    "date": "",
    "description": "",
    "body": "在没有计划下，在偶然的空闲中，在一个大清早，居然看上电影了，不得不记录一下，为了最近疲惫的身心，为了留下一丁点的记忆和回味，为了首都这宝贵的蓝天。电影比较好看，最近思虑过甚，无力评论，且留下豆瓣链接。\n\n导演: 韦斯·鲍尔 编剧: 诺亚·奥本海姆 / 格兰特·迈尔斯 / T·S·诺林 / 詹姆斯·达什纳 主演: 迪伦·欧布莱恩 / 阿梅尔·艾米恩 / 李基弘 / 布雷克·库珀 / 托马斯·桑斯特 / 威尔·保尔特 / 德克斯特·达登 / 卡雅·斯考达里奥 / 克里斯·谢菲尔德 / 乔·阿德勒 / 亚历山大·弗洛里斯 / 雅各布·拉提摩尔 / 兰德尔·D·坎宁安 / 派翠西娅·克拉克森 / 唐·麦克马纳斯 类型: 动作 / 科幻 / 悬疑 / 惊悚 官方网站: themazerunnermovie.com 制片国家/地区: 美国 / 加拿大 / 英国 语言: 英语 上映日期: 2014-10-28(中国大陆) / 2014-09-19(美国) 片长: 113分钟 又名: 迷宫行者 IMDb链接: tt1790864\n",
    "ref": "/2014/11/05/e8bfb7e5aeabe8a18ce88085-maze-runner/"
  },{
    "title": "备战 北马",
    "date": "",
    "description": "",
    "body": "北马 是我今年的目标，是第一次挑战42.195千米，是第一次搞 全马。备战的训练计划就差一个月的十几次训练，目前的状态，感觉还是“不踏实”。主要有几个方面，目前的两次长距离训练，一次28公里，一次30公里，跑下来，都是咬牙跑完最后的将近10K。问题主要有：越往后感觉体力越不是很足，渐渐的会感到信心的缺失，渐渐的会感到脚底板和脚趾的疲劳和疼痛，这会传导至小腿到膝盖，特别是右膝盖，在15k以后总会感到有点不舒服。貌似右膝盖倒成了我最严重的挑战了，如果它老人家出了问题，就麻烦了。我可不想半途而废，更不想跑完后，让人抬着回家。心中只想着：能5小时内无伤痛顺利完赛。目前确定每天早晨起来锻炼，观察双腿的和膝盖的情况，非训练日在小区快走，一定要磨合出稳定发挥状态的感觉。\n",
    "ref": "/2014/09/21/e5a487e68898-e58c97e9a9ac/"
  },{
    "title": "Start over from RHEL",
    "date": "",
    "description": "",
    "body": "RHEL 7是一个划时代的版本，比6有很多的重大改变，特别是系统底层的管理这块，很多命令集都发生了变化。对我而言需要在一个新的平台上提升linux的技能，还是很凑巧的事情。逐渐感觉到红帽从操作系统层面，向上往云的方向，向下往软件定义的XXX方向，横向直接积压其它服务器虚拟化技术的势头逐渐明显。传统数据中心转型在即，整个技术堆栈需要重新定义和规划；创新型小公司不断挑战传统巨头厂商的地位，市场在重新定义和分化，仿佛这是进入战国时代的节奏。\n天下事，分久必合，合久必分！ ",
    "ref": "/2014/09/21/start-rhel/"
  },{
    "title": "评测 Forerunner 220",
    "date": "",
    "description": "",
    "body": "随着北马的临近，备战的训练也越来越重要，由于始终没有试过30K的距离，逐渐对长距离感到焦虑，因此放弃了My Ascis以距离为目标的训练计划，转投Garmin训练计划中的全马训练计划。Garmin的计划中多是以时间为导向的，以跑步强度为训练内容，例如EasyRun 30 分钟；Threshold Run 6分钟，恢复跑2分钟，重复四次。\nforerunner 220 开箱测试 \n开箱之后，手表本身有70%多的电，上手到公司门口，试试搜星的速度，在原地不动的情况下，由于是首次搜星，而且需要在搜星的过程中同步设置手表时钟。基本上花了大约3~5分钟的时间。公司门口在有十几层高的楼宇，应该会影响大搜星的速度。下面是绕公司楼一周的路线图。\n\n从图中可以看到路线的左下角还是有一定的偏差。\n手表数据上传 Garmin Express Garmin Connect的网站奇慢无比，主要是由于，该网址里使用了google font，由于google的服务被墙，导致页面加载google 字体需要长时间的等待，直到超时之后才会显示页面的内容。\n有了Garmin Express这个客户端程序就可以避免使用网站了。而且它能自动检查手表的链接状态，USB口一旦插上设备，不管手表里面有几条记录，基本上，几秒钟就能够同步完成。\n \n这个应用更是设备软件更新的神器，这个版本比以前的版本好太多了，同步数据在也不用发愁了。\n手机蓝牙同步 Forerunner 220可以和手机通过蓝牙通信，只要手表和手机配对成功之后，手机上的Garmin Connect App立刻开始数据同步。同步到app的数据直接上传到网站上。\n \n这种方式是空前的爽，根本不需要使用电脑，也不需要在链接什么USB联线。上传完毕之后在稍微编辑一下标题、路线和分类，基本上这个记录下次在网页上看就非常有意义了。\n执行网站上的训练计划 首先，需要在Garmin Connect网站里面选择一个训练计划，激活训练计划的时候需要设定开始和结束时间，不管时间长短，它都会按照训练目标，自动设定每天的训练内容。\n\n有了这个计划之后，就可以在日历上看到实际上每天的训练安排了；如果愿意的话应该可以同时安排多个训练计划，训练计划可以一个接一个排满全年。加入一年跑两个全马，或者多个的话，就可以提前一次性安排好一年的训练计划。\n在日历页面里，点击发送到设备，网页就会调用Garmin Express，Garmin Express打开之后，它就会把网站日历上的所有训练计划条目都下载到手表里面。下载完毕之后，就可以在手表的Training - Training Calendar里面上下浏览每天的训练条目了。\n\n执行一项计划的训练内容 按照网站上的安排，我今天的训练内容如下：\nW11D5a-Easy Run 2 Steps\n  Run 30:00\n  Coll Down\n  选中Do Workout，点击红色按键，表滴的一声，并且震动一下，示意可以跑步了。跑步的过程中，屏幕上有四种模式的切换：\n[su_list icon=\u0026ldquo;icon: play\u0026rdquo;]\n  训练屏幕，由于是30分钟的Easy Run，因此屏幕上就项内容，上面是配速，下面是30分钟的倒计时时钟。\n  数据屏幕1 显示的三四条跑步数据自己可以定制。\n  数据屏幕2 显示的三四条跑步数据自己可以定制。\n  默认的电子表时钟屏幕\n  [/su_list]\n三十分钟快到的时候，手表滴滴的在最后5秒倒计时提示，在最后一秒中，手表开始振动一次，示意这个训练内容完成了。然后手表会显示，开始Cool Down，until press lap button。 我在操场里放松走了一圈，倒走了800米后，按lap键，手表就示意本项训练内容完成，示意保存该活动记录。\n跑间歇跑 Intervals 总感觉到跑完上面的30分钟Easy Run不过瘾，随后测试手表中默认带一个间歇表训练：4*1km ； 1：00 rest。点击开始这个计划之后，手表的第一个屏幕显示的是配速和距离，在距离快完成的最后5秒钟，手表开始滴滴的示意，最后一秒钟，手表振动，并且提示Rest 1分钟，接着手表开始一分钟倒计时，就这样，周而复始4次。\n后记 搜星速度没有预想的那么快，但是在操场上确实够快，不过比Rorerunner 10的速度快多了。连接之前买的200多的心率带，没有成功，并不像网上说的：随便那一条就可以配对成功。不过用了一段时间心率带后，现在想想，真的是个鸡肋功能，有一条即可，需要测了，连接手机测几次即可。这也是我下决心买220无心率带版本的原因。分析下来，620比220多的那些数据和功能，都是通过心率分析出来的；由于现在我彻底不关系心率了，因此，所有和心率相关的东西都变得苍白了。就这样我只用了一个小时就下单220了。在天猫Garmin专卖店1390下单，居然不到24小时就收到货了。顺丰真是神速，24小时内就把货从杭州送达。价格方面赶上暑假减价100。http://detail.tmall.com/item.htm?id=37128865969\n\n",
    "ref": "/2014/09/12/got-new-garmin-forerunner-220/"
  },{
    "title": "意外旧机换新机",
    "date": "",
    "description": "",
    "body": "刚发到手的机器是一台无奈的就机器，没想到没有过一周的时间，IT说研发那边居然多出了一台新机木有人用，说可以给我；收到的新机是一个未拆封的纸箱。我热泪盈眶的对IT说“你是一个好人”。\n\n这个机器基本上介于普通笔记本和超基本之间，重量很轻，比较赞赏的地方有两点：240GB的SSD硬盘，安装的fedora20启动速度果断迅速，一般10秒内就可以输入密码了；显示平面的分辨率是1920*1080，看完这个屏幕后，在看我的老款MacBook Pro的低分屏，感觉差距很大。\n",
    "ref": "/2014/09/06/e6848fe5a496e4b8ade697a7e69cbae68da2e696b0e69cba/"
  },{
    "title": "本博客再次更新样式",
    "date": "",
    "description": "",
    "body": "这次把样式更新为 Editor（by Array）。选择这个主题的原因有几点。\n[su_list icon=\u0026ldquo;icon: smile-o\u0026rdquo;]\n  Editor 是一个简约风格的主题，这种轻量级主题即简洁大方，速度快，可谓鱼和熊掌能够兼得。\n  Feature image 是特大的1000*625，最近两年特别喜欢这个样式，而且这个图片既可以在list中现实也可以在single post中显示。\n  目前看和CDN插件不冲突\n  [/su_list]\n这就是使用免费主题的优势，随时更换心情，想换就换。\n",
    "ref": "/2014/09/06/e69cace58d9ae5aea2e5868de6aca1e69bb4e696b0e6a0b7e5bc8f/"
  },{
    "title": "八月份跑步回顾",
    "date": "",
    "description": "",
    "body": "二零一四年八月我跑步距离总计超过一百八十公里，创造个人月跑新纪录！\n这个月多次跑20公里，一次超过10公里也比较多，总跑步天数也多。值得纪念一下。希望今年能够顺利完成一次全马。\n",
    "ref": "/2014/09/06/e585abe69c88e4bbbde8b791e6ada5e59b9ee9a1be/"
  },{
    "title": "避暑 崇礼 海沱 延庆 2 日游",
    "date": "",
    "description": "",
    "body": "3伏天的雾霾让人无奈，只好逃离北京去避暑。第一站崇礼。崇礼的距离不算近，但是最让人感到欲哭无泪的还是拥堵的八达岭高速，堵的真实让人走投无路啊！没有最堵只有更堵，让逃离帝都的人在出京路上非常糟心。交通在出了北京界后，就仿佛进入了另外一个世界，天也是蓝的，路是畅通的。\n\n上图为崇礼聚龙滑雪场的雪道。\n\n上图是草原天路的大风车。\n\n上图是草原天路的草甸，非常多的野花。\n\n上图是草原天路上露营的装备，发挥了重要的作用，让野餐不在面包+香肠。\n\n上图是路过海沱，绵绵高山峡谷景色非常迷人。\n\n延庆柳沟豆腐宴，看着不错，口味一般，可以管饱，哈哈哈！\n\n延庆的色素菊花田本帖子本来可以很长，太忙了，到此为止吧。\n",
    "ref": "/2014/08/04/e981bfe69a91-e5b487e7a4bc-e6b5b7e6b2b1-e5bbb6e5ba86-2-e697a5e6b8b8/"
  },{
    "title": "西安出差",
    "date": "",
    "description": "",
    "body": "周四中午去，晚上加班到12点多；周五下午和CIO会议，晚上回北京到家11：30多，想睡觉，失眠睡不着中。\n",
    "ref": "/2014/07/11/e8a5bfe5ae89e587bae5b7ae/"
  },{
    "title": "运气还能更糟么？",
    "date": "",
    "description": "",
    "body": "去洗车，发现一条轮胎，右后胎，扎了钉子，拆下来仔细看，居然扎了一根六棱大头钉。我开车太糙了。师傅帮忙试水泡，发现却是漏气，号称是明天早晨就没气了。师傅赶紧推向米其林轮胎，建议我一气四条都换了。一条860。我决定换两条，为了平衡；师傅帮我检查剩下的三条旧胎，发现其中一个早就扎了钉子了。看来我换两条的决定无论如何都是正确的。把两条新胎换到前轮上，剩下两条胎，俩师傅玩命得帮我找毛病，看胎上有裂口，就说已经断了，看不出毛病的那个，摸了一圈，说看都起包了。最后我依然决定换两条备奈特的810一条，刷卡走人。\n\n车的麻烦还不止这些，眼看着就要续保险了，这个是我的车的一年的大头，接着要去修一年积累的划痕，接着去做保养，然后交一年积累的罚款和扣分，然后验车。争取8月底前完成这些事情。\n",
    "ref": "/2014/07/09/e8bf90e6b094e8bf98e883bde69bb4e7b39fe4b988/"
  },{
    "title": "周末跑步",
    "date": "",
    "description": "",
    "body": "周六奥森6.22公里，天气太热，没有能坚持到北园一圈。\n周日北工大7.12公里，天气依然很热，空气污染重，坚持了45分钟，\n正式备战北马的节奏么？不是，还是锻炼身体最重要。\n",
    "ref": "/2014/07/06/e591a8e69cabe8b791e6ada5/"
  },{
    "title": "美国骗局 American Hustle (2013)",
    "date": "",
    "description": "",
    "body": "\n导演: 大卫·欧·拉塞尔\n编剧: 埃里克·辛格尔 / 大卫·欧·拉塞尔\n主演: 克里斯蒂安·贝尔 / 布莱德利·库珀 / 艾米·亚当斯 / 杰瑞米·雷纳 / 詹妮弗·劳伦斯 / 路易·C·K/ 杰克·休斯顿 / 迈克尔·佩纳 / 谢伊·惠格姆 / 亚历桑德罗·尼沃拉 / 伊丽莎白·霍尔姆 / 保罗·赫尔曼 / 萨伊德·塔格马奥 / 马修·拉塞尔 / 托马斯·马修\n类型: 剧情 / 犯罪\n官方网站: www.americanhustle-movie.com\n制片国家/地区: 美国\n语言: 英语 / 阿拉伯语\n上映日期: 2014-07-04(中国大陆) / 2013-12-20(美国)\n片长: 103分钟(中国大陆) / 138分钟(美国)\n又名: 瞒天大布局(台) / 骗海豪情(港) / 人人都是骗子 / American Bullshit\nIMDb链接: tt1800241\n[su_quote]观后感：社会题材的东西感觉越来越喜欢了，相信还会看第二遍，情节非常好看，给周末增色不少！[/su_quote]\n",
    "ref": "/2014/07/05/e7be8ee59bbde9aa97e5b180-american-hustle-2013/"
  },{
    "title": "衡水湖 马拉松",
    "date": "",
    "description": "",
    "body": "和同事们在群里面那么一聊，本着以赛代练的方针，备战北马正式开始，报名 衡水湖 马拉松，首次全马居然在衡水湖，想不到啊！想不到！\n",
    "ref": "/2014/07/05/e8a1a1e6b0b4e6b996-e9a9ace68b89e69dbe/"
  },{
    "title": "MacBook Air 这个性价比值得入手了",
    "date": "",
    "description": "",
    "body": "当前的电脑 我现在用的MacBook Pro是3年前买的，更新到8GB内存，500GB 普通硬盘，不得不说，除了充电器两头电线用到掉皮，里面的电线裸露之外，这台电脑还是我用过的做长时间，并且性能和质感保持最佳的电脑。这是一台BYOD的设备。\n想入手的MacBook Air 刚才在苹果香港store看了一下，觉得MacBook Air性价比应该合适入手了：\n[su_list icon=\u0026ldquo;icon: rocket\u0026rdquo;]\n  最吸引我的地方还是超级本的轻薄，背包可以轻很多了。\n  MacBook Pro 还是扩展性和性能更佳的，但是作为日常办公来说，而且越来越不可能在这样的电脑上跑多个虚拟机的重测试环境。但是新版的MacBook还是比air重不少。\n  CPU：双核i7 1.7 说实话，还是比较低的，但是，想到耗电和发热，也必须忍受这个短板。\n  RAM：8GB内存，和我目前的情况一样，按我现在的使用水平，3GB以上的可用内存是常态，因此及时是要做测试，跑三个内存1GB的虚拟机也应该是没有问题的；要是慢的话CPU应该是瓶颈。目前没有试过。\n  存储：256 GB 对于一般用户来说可能不够。可以参考下图我的分析。如果能合理的把多媒体文件导出到家用NAS的话，应该没有问题。\n  [/su_list]\n关于存储 \n我的多媒体文件在整个硬盘上占到将近一半，甚至超过了操作系统和应用软件和数据文件的总和。因此加入我买新本的话，上面应该不会导入这么大批的文件，照片什么的应该会用这台老机器存储。这台机器上的空间，应该至少还能用两年。但是，估计以后就全都导入到云里面了，百度云基本上都是给TB基本的可用空间。\n",
    "ref": "/2014/07/02/macbook-air-e8bf99e4b8aae680a7e4bbb7e6af94e580bce5be97e585a5e6898be4ba86/"
  },{
    "title": "mac mini",
    "date": "",
    "description": "",
    "body": "坐等Mac Mini的最新版本在秋季发布，还需要忍耐一个燥热的夏季，等不急了！这个机器适合用在Lab测试机。\n",
    "ref": "/2014/07/02/mac-mini/"
  },{
    "title": "武昌会议三次慢跑",
    "date": "",
    "description": "",
    "body": "在东湖公园里面跑步绝对是一种享受，跑一圈大约是7公里左右。我这三天的会议跑了三条路线。\n[su_list icon=\u0026ldquo;icon: rocket\u0026rdquo;]\n  东湖宾馆 ，其实是故意跑进去的，虽然入口都是武警站岗，还是从一个工地跑了进去，最后翻墙出来，看到墙头就有摄像头，狂汗~~~\n  武汉大学，正门湖边，路不好，跑了4公里，返回，往返8k。\n  东湖公园，风景优美、跑步的道路舒适、不枉此行，快速跑了6k\n  [/su_list]\n\n",
    "ref": "/2014/07/01/e6ada6e6988ce4bc9ae8aeaee4b889e6aca1e685a2e8b791/"
  },{
    "title": "浸泡式开会",
    "date": "",
    "description": "",
    "body": "武昌会议第二天，两天重复不换台，重复着：起床、跑步、吃饭、开会、吃饭、开会、吃饭。。。。。。。。 手机被上收到会议桌最前方，没有break，不需使用手机。 电脑必须关掉，所有记录只能用纸和笔。\n",
    "ref": "/2014/06/29/e6b5b8e6b3a1e5bc8fe5bc80e4bc9a/"
  },{
    "title": "无奈出差",
    "date": "",
    "description": "",
    "body": "今天是实在不应该出差！！\n",
    "ref": "/2014/06/27/e697a0e5a588e587bae5b7ae/"
  },{
    "title": "武汉 会议",
    "date": "",
    "description": "",
    "body": "今天是非常特殊的一天，发生了一件另外无奈的事情。真是不想在这天也出差，但是还要它是旅程；用了一个半小时才从三环爬到了西站。上车后，高铁4个小时准时的把我送到了武汉。\n到了酒店后，由于这里就在东湖旁边，因此先去跑一圈是最重要的。  跑的过程中才知道，这里是著名的毛泽东下榻过的东湖宾馆。做讨厌的是，湖边被商业包裹着，没法入内。最终从一个工地进入，出来时就麻烦了，不想大摇大摆的，从被卫兵拒绝的门口跑出来，后来翻墙出来了。 洗过澡后，和同时们一起去吃饭了。   这是同事推荐的一家，非常火爆的店，6点半到店，排了一个多小时对，终于可以上桌了。   口味太赞了，性价比超级高，我现在敲键盘的手指还有油闷大虾的香味。吃了很多，喝啤酒聊天，非常完美的一餐。\n",
    "ref": "/2014/06/27/e6ada6e6b189-e4bc9ae8aeae/"
  },{
    "title": "电波表 对时技巧",
    "date": "",
    "description": "",
    "body": "首先，确保自己所在的地点位于接受范围以内。如北京距离河南在距离商丘1000公里以内的范围，因此能够正常接受电波。\n\n如果，出差去到其他国家的话，可以参考下面的电波发射点地图。\n\n然后，就是手动或者自动对时了。手表需要放在非隔离的空间中，不能在一个没有窗户的房间。\n最后，我最近天天晚上1点左右手工对时，电波接收正常。\n",
    "ref": "/2014/06/25/e794b5e6b3a2e8a1a8-e5afb9e697b6e68a80e5b7a7/"
  },{
    "title": "天津 短暂出差",
    "date": "",
    "description": "",
    "body": "昨天中午去天津，下午完事了就会北京。经过天津站前广场，稍微观察了一下，这次发现天津站修的如此的高大上，广场非常的宽敞，河岸的风景也十分的靓丽。就是车站里面的秩序还是不行，售票厅里的自助售票机是坏的，进站派长队等着检查身份证和安检。\n\n\n一位移民海外的长者看了我发的这几个照片，好奇的问道：天朝是不缺高达上的，就是差环境了，等环境治理好了，会考虑回去养老。\n",
    "ref": "/2014/06/25/e5a4a9e6b4a5-e79fade69a82e587bae5b7ae/"
  },{
    "title": "纯美和邪恶的相互转化-Maleficent ",
    "date": "",
    "description": "",
    "body": "\n导演: 罗伯特·斯特罗姆伯格\n编剧: 保罗·迪尼 / 琳达·伍尔芙顿\n主演: 安吉丽娜·朱莉 / 艾尔·范宁 / 沙尔托·科普雷 / 莱丝利·曼维尔 / 伊梅尔达·斯汤顿 / 朱诺·坦普尔 / 萨姆·赖利 / 布伦顿·思韦茨 / 肯内斯·库兰汉姆 / 莎拉·弗林德 / 汉娜·纽 / 伊莎贝尔·莫洛伊 /迈克尔·希金斯 / 艾拉·珀内尔 / 杰克逊·比尤斯\n类型: 动作 / 爱情 / 奇幻 / 冒险\n官方网站: movies.disney.com/maleficent\n制片国家/地区: 美国\n语言: 英语\n上映日期: 2014-06-20(中国大陆) / 2014-05-30(美国)\n片长: 98分钟(中国大陆) / 97分钟(美国)\n又名: 黑魔后：沉睡魔咒(港) / 梅尔菲森特 / 玛琳菲森 / 黑法魔女 / 睡美人外传\nIMDb链接: tt1587310\n[su_quote]怀揣着一颗童心体味一个纯美的童话世界，童话世界中存在这亦正亦邪，存在着邪恶和纯美的动态变化，最终正义战胜了邪恶，世界恢复到美丽的平衡中！我给它7颗星。[/su_quote]\n",
    "ref": "/2014/06/23/e7baafe7be8ee5928ce982aae681b6e79a84e79bb8e4ba92e8bdace58c96-maleficent/"
  },{
    "title": "手动对时成功",
    "date": "",
    "description": "",
    "body": "12点刚过，还是担心表的最有价值功能是否能够正常工作；于是走向阳台，按下D键，几分钟后，出错，对时失败；不甘心，再次按下D键，看信号等级L3，惴惴不安等了几分钟后终于显示：Get 6:22 12:06\n",
    "ref": "/2014/06/21/e6898be58aa8e5afb9e697b6e68890e58a9f/"
  },{
    "title": "CASIO G-SHOCK GW-6900 太阳能六局电波",
    "date": "",
    "description": "",
    "body": "在京东入手 GW-6900 这块6局电波表。主要的吸引我的就是六局电波功能，其它的太阳能、防水等等其它功能都是浮云，可惜的是目前还没有手动接受电波成功过。\nGW-6900 表的样子就是如上图，比较经典的三眼设计。网上评价说：表盘偏大不适合手腕细者、表颜色发亮。到手拆箱试戴后，这两个疑虑都统统打消了。\n\nGW-6900 手动电波对时还没有成功，等待晚上自动对时了。\n总体觉得这块表比较适合生活休闲佩戴，在一些非高大上的工作场合也适合。\n从工作的角度看，它内置的48世界城市时钟也很有用，特别是第二时钟功能，按右上键直接调出最关心的其它时区时间，操作非常方便。要是找其它某个时区的时间，也就多点几就能看到。\n官方介绍：http://www.casio.com.cn/wat/g-shock/GW-6900-1/index.html\n操作手册：http://www.casio.com.cn/resource/files/support/wat/support/book/3179.pdf\n",
    "ref": "/2014/06/21/casio-g-shock-gw-6900e5a4aae998b3e883bde585ade5b180e794b5e6b3a2/"
  },{
    "title": "推荐Podcast - 一个人的书房 ",
    "date": "",
    "description": "",
    "body": "当静下心来读书成为一个奢望，我们还是能通过其它的方式来亲近书籍，感受另外一种听书的方式。推荐下面这个听书Podcast，他们读的书还是挺吸引人的。\n[caption id=\u0026ldquo;attachment_52878\u0026rdquo; align=\u0026ldquo;alignnone\u0026rdquo; width=\u0026ldquo;967\u0026rdquo;]一个人的书房[/caption]\n他们的书单：《搭车去柏林》《巨流河》《断舍离》《流波上的舞》《追风筝的人》《安妮日记》《冬牧场》《生死的幻觉》《梦里花落知多少》\niPhone上收听地址：https://itunes.apple.com/cn/podcast/yi-ge-ren-de-shu-fang/id612325017?mt=2#\n",
    "ref": "/2014/06/16/e68ea8e88d90-e4b880e4b8aae4babae79a84e4b9a6e688bf-podcast/"
  },{
    "title": "第三个马年",
    "date": "",
    "description": "",
    "body": "这是一个特殊的日子，所有的事情高高低低、起起落落；在一波又一波中挫折着，前行着！\n",
    "ref": "/2014/06/16/e7acace4b889e4b8aae9a9ace5b9b4/"
  },{
    "title": "该睡觉了",
    "date": "",
    "description": "",
    "body": "免费主题 The Night Watch + 七牛CDN 给力，最终网页绝大多数能够非常快速打开，今天到为止了。\n",
    "ref": "/2014/06/15/e8afa5e79da1e8a789e4ba86/"
  },{
    "title": "没完没了",
    "date": "",
    "description": "",
    "body": "实践证明我曾经买的所有的blog theme都不适合我，最后还是回到了免费主题上，非商用blog，付费主题慎用，除非你的定力很好，不好折腾。\n",
    "ref": "/2014/06/15/e6b2a1e5ae8ce6b2a1e4ba86/"
  },{
    "title": "回归到最简洁的状态",
    "date": "",
    "description": "",
    "body": "一个bolg要经过多少次折腾和重定义，我已经不记得是第几次晚上换主题换到2点才睡觉了。要说我为什么？我不过是把其它人熬夜看足球的精力用在了一项觉得有意思的事情上。\n本次更新主要是，更改一下此blog的方向，以后发布的内容将不会在有技术帖，原来的技术贴依然欢迎留言和讨论；今后的风格是简洁风格，多以生活内容为主。\n",
    "ref": "/2014/06/15/e59b9ee5bd92e588b0e69c80e7ae80e6b481e79a84e78ab6e68081/"
  },{
    "title": "于Citrix 25周年的故事 Imagination Innovation Growth",
    "date": "",
    "description": "",
    "body": "[video width=\u0026ldquo;640\u0026rdquo; height=\u0026ldquo;360\u0026rdquo; mp4=\u0026ldquo;http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2014/02/The-Citrix-Story-25-Years-of-Imagination-Innovation-and-Growth.mp4\u0026rdquo;][/video]\n以上视频从YouTube转载。是Citrix给自己的拍摄的生日礼物。真正的25岁生日那天在今年四月份。下面是维基百科上对Citrix的介绍。\n**[Citrix Systems](https://en.wikipedia.org/wiki/Citrix), Inc.** is an American [multinational](https://en.wikipedia.org/wiki/Multinational_corporation)[software](https://en.wikipedia.org/wiki/Software) company founded in 1989 that provides server, application and [desktop virtualization](https://en.wikipedia.org/wiki/Desktop_virtualization), networking, [software-as-a-service](https://en.wikipedia.org/wiki/Software-as-a-service) (SaaS), and [cloud computing](https://en.wikipedia.org/wiki/Cloud_computing) technologies, including [Xen](https://en.wikipedia.org/wiki/Xen) open-source products. Citrix currently services around 330,000 organizations worldwide[[2]](https://en.wikipedia.org/wiki/Citrix#cite_note-2) and is based in [Fort Lauderdale](https://en.wikipedia.org/wiki/Fort_Lauderdale,_Florida), [Florida](https://en.wikipedia.org/wiki/Florida), in the [Miami metropolitan area](https://en.wikipedia.org/wiki/Miami_metropolitan_area), with [subsidiary](https://en.wikipedia.org/wiki/Subsidiary)operations in [California](https://en.wikipedia.org/wiki/California) and [Massachusetts](https://en.wikipedia.org/wiki/Massachusetts), and additional development centers in [Australia](https://en.wikipedia.org/wiki/Australia), [India](https://en.wikipedia.org/wiki/India), [Canada](https://en.wikipedia.org/wiki/Canada) and the [United Kingdom](https://en.wikipedia.org/wiki/United_Kingdom). Following the acquisition of XenSource, Inc. in October 2007, Citrix started spearheading the Xen open-source [hypervisor](https://en.wikipedia.org/wiki/Hypervisor) project.[[3]](https://en.wikipedia.org/wiki/Citrix#cite_note-3) 这个短片拍的是挺有意思的，可以让你快速得回顾一下这个公司的历史。\n",
    "ref": "/2014/02/10/e4ba8ecitrix-25e591a8e5b9b4e79a84e69585e4ba8b-imagination-innovation-growth/"
  },{
    "title": "开源服务器的时代真到了？",
    "date": "",
    "description": "",
    "body": "今天广为关注的的新闻末过Facebook的单人管理上万服务器。上网看了一下此新闻的出处：http://www.datacenterknowledge.com/archives/2013/11/20/facebook-ops-staffer-manages-20000-servers/  本文的描述如下：Delfina Eberly, Director of Data Center Operations, Facebook, presented the Tuesday morning keynote about optimizing data center operations. In terms of hardware, Facebook, because it runs such an enormous volume of servers, focuses on serviceability, including starting from the ground up by influencing server design to ensure easiest and least time consuming methods to repair equipment in the data hall.\n她是Facebook公司的数据中心运营总监，在昨天早晨发表了关于如何优化数据中心运维的演讲。从硬件方面看，为了满足它们巨大的用量，她们不得不把精力完全放到硬件的服务提供性上，说白了“黑猫，白猫，能捉到耗子的就是好猫”，因此她们被逼去自己从服务器硬件设计开始构造自己的数据中心神殿。为什么说是被逼的，你可以想象：加入IBM，DELL，HP之流的sales推门进去，告诉她们你们买我们的服务器吧，保证好用！可能在她们也买得起，但是绝对用不起，用不起是由于：服务器的采购，供货，修复，维保，这一切都靠供应商的话，从时间和效率上将Facebook觉得耗不起。一旦依赖了供应商，自己就必然失去了主导权，多了一重羁绊，无法满足facebook这样公司的高速成长。一切创新其实都是被逼出来的。\n这让我感兴趣Mark最近在搞些啥，我简单转发两个我看到并感兴趣的网站。\nInternet.org 汇聚全球合作伙伴，通力合作，使世界上三分之二尚不能上网的人口能够上网。 Internet.org  这个网站上最抢眼的还是首页最上端的那个视频，很可惜国内用户看不到youtub，我在这里把Mark的这个视频在我的网站上转贴一下。\n[video width=\u0026ldquo;640\u0026rdquo; height=\u0026ldquo;360\u0026rdquo; mp4=\u0026ldquo;http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2014/02/Making-the-Internet-Affordable.mp4\u0026rdquo;][/video]\n这个视频主要是Mark亲自现身说法说如何让上网成本更低，争取能做到让全世界更多的人民上网的宏大理想。听完之后，这不能不让我和今天的另外的一个新闻“facebook收购 Onavo”联系起来，表面上看Onavo是他实现这个理想的一种工具；另外一个邪恶的说法，则说：”他想控制这个世界所有人上网的流量“；我们拭目以待，他们是如何改造地球的吧！\n另外一个网站是这个，开源计算机项目网站。我一直对开源的项目尤为感兴趣，甚至于开源的“窗台农庄项目”。但是主要还是开源软件了解的多。这个网站是Facebook主导的一个项目，目的在于开放他们部分服务器硬件和数据中心设计的技术。确实是一个很不错的学习资料。在这里我又看到了类似于QQ和中国移动竞争的类似场景。如果这个项目火了，这让那些买服务器的公司情何以堪啊！但是我因此加深了IBM卖掉PC业务给联想的这个事实。国人一直在接受人家过期的技术和业务，这样值得么？从业务的角度上讲，短期是还是值得的，原因是：国内IT的发展总是滞后于欧美3到5年时间。我感觉滞后的原因主要还是语言和文化的不通。\n如果对Facebook的数据中心感兴趣的话还可以看看这个FAQ, http://www.datacenterknowledge.com/the-facebook-data-center-faq/\n",
    "ref": "/2014/02/08/e5bc80e6ba90e69c8de58aa1e599a8e79a84e697b6e4bba3e79c9fe588b0e4ba86efbc9f/"
  },{
    "title": "优化 WordPress 页面到一秒内",
    "date": "",
    "description": "",
    "body": "本帖系技术贴，目的在于总结一下这次对本站点优化的经历。总之结果很重要，把基本上所有页面都优化到大约0.8秒左右的载入速度。如果你也是在独立LAMP服务器上运行WordPress的话，我想本文可能对你会有所帮助。 Wordpress 服务器配置 服务器是在阿里云上的主机，主机的配置比较低：1vCPU，1GB内存；后台数据库是RDS服务。\n\n服务器的操作系统是Debian，安装的php的情况见 phpinfo.php 的输出。\nWordPresss所安装的插件如下：akismet syntax-highlighter download-monitor update-twitter-php google-sitemap-generator use-google-libraries wordpress-popular-posts wordpress-seo jiathis wp-easyarchives kimili-flash-embed wpjam-qiniu memcached wp-pagenavi nextgen-gallery wp-postviews optimize-db wp-recentcomments regenerate-thumbnails wp-super-cache revslider wp_video-master shortcodes-ultimate yet-another-related-posts-plugin simple-google-analytics\nWordpress 插件：WP Super Cache Super Cache 使用的是： mod_rewrite 缓存模式。 并开启了：使用对象缓存系统来存储缓存文件。 (实验室功能) 这个功能和memcached插件是相关的。在CDN的配置这里，开启了CDN的支持，并把off-site URL指向了 http://martinliu.qiniudn.com 七牛的空间。\n\n现在很多页面查看源码的时候，都可以看到是0.8秒以内的速度，这个速度起码是本站点有史以来的最快速度。不光服务器速度快了，更重要的是所有静态文件也都是用的大陆的本土CDN站点了。\nWordpress 插件：**memcached 和 MemCached服务 **\n这个插件我第一次用，真可谓是神器，它需要和操作系统的memcached服务配合起来使用；这个插件的安装比较反常规：不能在控制台里面启用，根本就启用不了，需要安装插件后，在未激活的状态下，把它的文件手工放到wp-content目录里面即可。操作系统的memcached的服务安装和配置也比较简单，总之运行基本全都靠默认的配置参数即可。另外php的memcached模块也要安装并启用。它们配合起来能够把页面的request次数降低到冰点。我的主页用这个组合之前需要30次左右的request，用了之后就3次了，它主要是靠内存做缓存，从而加速了网站。\n\n上图是本站首页的测试结果，亮点在它只有3个请求，Web服务器只是做了三个响应就完事了，这个页面的内容就全都可以发给浏览器了。减少了20多次请求的处理，这些请求的结果都被memcached给缓存到内存里面了，目前只能够给memcached开80MB的缓存空间，也就这点内存常驻的网站缓存解决了大问题。加速页面的响应速度。不得不说memcached服务还是挺NB的。\n\n上图是一个常规的文章页面，请数量从以前的30左右降到10以内，我什么也不说了。当然上面这连个图里面也能看出本网站的一点问题，这里也不说了。\nWordpress 插件：WPJAM 七牛镜像存储 本次折腾主要冲着这个来的。CDN我是第一次玩，不过用一次之后，感觉也挺简单的。先要找一个免费的CDN服务商开一个空间，之后一般送1GB空间一个月1GB流量，对我的网站来说足够了。配置完之后就拿到了一个二级域名，然后还有几个重要的Key编码。安装了水煮鱼做的这个插件之后，配置完，什么也不用管，网站的哪些静态文件就在首次访问的时候，被自动传到CDN上面了，下次网页再被打开的时候就全都走CDN上下载了，从而把Apache的基本所有静态文件的请求都offload走了，从而降低了服务器的负荷，提升了它对动态内容的反应速度。我的服务器只有1GB内存，用了CDN之后，我也不是很担心内存不够用的问题了。\n未尽事宜 由于时间仓促，有几个活也没有时间做。1）我的域名martinliu.cn的DNS查询的速度有时候挺慢的，快也要500ms，有时候甚至超过一两秒，不知道是DNSPod不给力还是我的服务器自身有问题。2）CDN的正规用法需要在服务器端写一个脚本，把wordpress里面需要CDN加速的文件都上传到自己CDN的空间里面，并且可以编写脚本定期增量传输。由于最近太忙，以后有时间在研究这个问题吧。3)wordpress-popular-posts此插件在每个页面上都占用一定的时间，不知道是否能把它消除到。4）Gravatar头像的加速，否则这些图标在评论多的帖子上从国外站点下载，实在是太慢了。\n",
    "ref": "/2014/02/07/e4bc98e58c96wordpresse9a1b5e99da2e588b0e4b880e7a792e58685/"
  },{
    "title": "天籁之音 五言古诗 蝉",
    "date": "",
    "description": "",
    "body": "[audio m4a=\u0026ldquo;http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2014/01/chan.m4a\u0026rdquo;][/audio]\n\n垂绥饮清露，流响出疏桐。 居高声自远，非是藉秋风。\n\u0026ndash;虞世南【初唐】\n",
    "ref": "/2014/01/08/e5a4a9e7b181e4b98be99fb3-e697a0e8a880e58fa4e8af97-e89d89/"
  },{
    "title": "Garmin  Beijing LSD Club",
    "date": "",
    "description": "",
    "body": "我在Garmin网站上建立了一个”长跑俱乐部群“ Beijing LSD Club ； 欢迎各位爱好者加入。LSD的意思是：Long Slow distance running ； 简单说就是长跑。\n群的地址： http://connect.garmin.com/group/514228 ；\n\n我今天在Garmin Connect上面的群搜索哪里，那么一搜：北京、Beijing；居然什么也没用；我就不信了，北京用Garmin的表的跑友应该也不少，何不大家都聚集起来，互相分享互相激励。热烈欢迎大家参加！\n",
    "ref": "/2014/01/08/garmin-beijing-lsd-club/"
  },{
    "title": "马丁",
    "date": "",
    "description": "",
    "body": "如果你把思考交给了电视剧；把联系和人际圈交给了手机；把双腿和出行都交给了汽车；把健康都交给了补品和药片负责；那么你的生活也许是时尚的，但一定是错误的；也许是习惯的，但一定会为此买单的。 请让书，聚会，跑步，锻炼更多的出现在生活里。—— 马丁\n",
    "ref": "/2014/01/01/e9a9ace4b881/"
  },{
    "title": "著名美国马拉松运动员 Ryan Hall",
    "date": "",
    "description": "",
    "body": "了解一位著名的美国马拉松运动员。非常年轻，非常优秀的跑者。Ryan Hall holds the American records for the half marathon and 20k, and his 2:04:58 marathon time is the fastest ever by an American. Ryan’s wife, Sara, is also a professional runner. Their Hall Steps Foundation urges the running community to help end global poverty.\n  Birthplace: Kirkland, Washington\n  High School: Big Bear High School, Big Bear Lake, California\n  College: Stanford University (Major – Sociology, Class of 2006)\n  Ryan and his wife Sara, currently currently train in Flagstaff, AZ and Palo Alto, CA\n  Personal Bests   1,500m – 3:42.70 (2001)\n  5,000m – 13:16.03 (2005)\n  10,000m – 28:07.93 (2007)\n  20,000m – 57:54 (2006) American Record\n  Half-marathon – 59:43 (2007) American Record\n  Marathon – 2:04:58 (2011) fastest American performance of all time\n  [su_quote]“I run because I believe that God has created me to run. When I run, I feel like I am fulfilling the purpose for which I was created. I know that I may not always run, but that God has used running as a part of my life to lead me down a path that I would not have taken otherwise. If I had never run, I would have never went to Stanford, met Sara, or be doing what I am doing now. I believe that God wants me to run to bring glory to his name and to further his kingdom on earth in some way. Some of my most intimate moments with God have been out in the trails, on the race course, or on the track. This is why I love to run.”[/su_quote]\n[video width=\u0026ldquo;740\u0026rdquo; height=\u0026ldquo;500\u0026rdquo;]http://v.youku.com/v_show/id_XMjk0NzcxMzg4.html[/video]\nRyan Hall是位美國長跑選手，他在2008年的時候贏得了奧運的馬拉松參賽資格，並且在北京奧運馬拉松項目排名第十，他以59分43秒成為美國半馬紀錄保持人，也是美國史上第一位半馬在一個小時內完成的男人。\nRyan的爸爸是曾經被巴爾地摩棒球隊選中，受到父親喜愛棒球的影響，他小時候其實是想要成為一位投手，常常在院子裡用網球做投球練習。雖然那時候的Ryan對跑步還沒產生興趣，但他小時候在體育課的跑步項目已經非常的突出。父親那時就已經看出他的天分，告訴Ryan說：「如果你願意花時間練習，你可以成為世界頂尖的跑者。」\nRyan高中比賽時的照片\n在13歲的某個星期六的一大早，他心中突然湧出想要跑步的強烈慾望，於是繫緊鞋帶，跟著也有鐵人經驗的爸爸出門慢跑。那天，他跑了24公里。他形容他第一次的慢跑經驗：「很痛苦，真的很痛苦。我們必須要休息很多次，我的小腿也是前所未有的疼痛著，每跨出一步我的臉就會痛苦的抽搐，而且當我們終於回到家的時候我直接癱軟在沙發上，一直到中午我都還無法動彈。」高中的時候1500公尺他就跑出3分43秒的成績。\n開始跑步之後他就有個夢想－參加奧運。Ryan甚至在萬聖節的南瓜上雕刻奧運的五環標誌。在2004年的時候他參加了奧運馬拉松選拔賽，可惜並沒有入選。大受打擊的Ryan覺得自己的人生已經毀滅了，他開始懷疑自己的人生價值。幸好他的信仰幫助他走過一切，這是上帝給他的磨練，他應該要從跑步裡得到快樂，而不是向上帝尋求安慰。\n果然，上帝並沒有放棄他，在2006年的時候開始嶄露頭角，打破了許多記錄。在那一年的10月8號 Ryan打破了美國20K的記錄，57分54秒，比上一個記錄快了48秒。2007年，他成為美國跑最快的馬拉松選手，在休士頓馬拉松那場比賽，他跑出了2小時08分24秒的成績，同年的11月，他也獲得了2008年北京奧運馬拉松的參賽資格，這時的他已經是全美國最有名的跑者之一。雖然在北京奧運上他只獲得了第十名的成績(2：12：33)，但是在2012年的時候他又再度獲得了倫敦奧運的參賽資格。他也是美國史上罕見跑過兩次奧運馬拉松的選手。\nRyan：「我一直很想要成為一個超級英雄，但我想這是我唯一最接近的時刻。順帶一提，那位美國先生是我姐夫。」\nRyan Hall每個禮拜的訓練量都超過150公里以上，那到底要怎麼補充能量呢？平常他會大量的補充水果、蔬菜、和適量的碳水化合物、蛋白質和脂肪。同時他也會確保他會獲得足夠的Omega-3脂肪酸，他也吃很多抗氧化劑含量高的天然食物，例如綠茶、莓果類、肉桂等，可以迅速恢復體力的食物像是鳳梨或是乳漿蛋白質(whey protein)和果汁。這樣吃下來有時一天還會吸收超過6000卡的熱量。「在訓練耐力跑的時候，身體會需要很多的食物，當作燃料跟幫助身體恢復。」Ryan說。\nRyan很喜歡吃生魚片噢！\n但是在比賽前Ryan反而會少吃一點含纖維的食物，「上場前一天吃這些食物會不舒服，還會脹氣。」相反的，比賽前一天是可以吃一些簡單的碳水化合物和含有一點點脂肪的瘦肉蛋白(lean proteins with a touch of fat)。另外，他建議在比賽前兩到三小時要200~400卡的食物，這時身體消化得比較慢而且能補充一點體力，重要的是要吃自己習慣並且常吃的食物。\nRyan跟老婆Sara都是美國優秀的選手，兩人在史丹佛認識、相愛，並在2005年結婚，身為基督徒的他們在2009年創立了一個基金會－The Hall Steps Foundation，目的是在於幫助貧困的人脫離貧窮，可愛的是他們也身兼義賣衣服的模特兒，省下請專業模特兒的錢。Ryan跟Sarah的感情也非常的好，在Ryan的Twitter也常常看見他們一起出去釣魚、健身，去哪裡兩個人都會在一起。\n「每天Sara都會讓我覺得很驕傲，但是今天我特別的以她為榮。」Ryan說\nFrom: 把跑步當信仰的男人─Ryan Hall\n美国半马纪录保持者Ryan Hall的跑步教学视频:\n长距离间歇跑训练(快速储备耐力)网页链接\n短距离间歇跑训练(提高速度耐力)网页链接\n高抬腿 训练(激发腿部活力)网页链接\n直曲腿交叉跑(超有效爆发力)网页链接\n动态拉伸训练(提高冲刺动力)网页链接\n",
    "ref": "/2014/01/01/ryan-hall/"
  },{
    "title": "Reviewer’s Guide for Remote 3D  Graphics Apps ",
    "date": "",
    "description": "",
    "body": "有了这3本书我们再也不用担心GPU的测试了。\n[su_button url=\u0026ldquo;http://www.citrix.com/wsdm/restServe/skb/attachments/RDY12010/Reviewer%27s%20Guide%20for%20HDX%203D%20Pro%20-%2001%20XenServer.pdf\u0026rdquo; target=\u0026ldquo;blank\u0026rdquo; style=\u0026ldquo;3d\u0026rdquo; background=\u0026quot;#4e7f22\u0026quot; size=\u0026ldquo;6\u0026rdquo; icon=\u0026ldquo;icon: download\u0026rdquo;]Part 1下载点击这里 Reviewer’s Guide for Remote 3D Graphics Apps [/su_button]\n[su_button url=\u0026ldquo;http://www.citrix.com/wsdm/restServe/skb/attachments/RDY12011/Reviewer%27s%20Guide%20for%20HDX%203D%20Pro%20-%2002%20vDGA.pdf\u0026rdquo; target=\u0026ldquo;blank\u0026rdquo; style=\u0026ldquo;3d\u0026rdquo; background=\u0026quot;#4e7f22\u0026quot; size=\u0026ldquo;6\u0026rdquo; icon=\u0026ldquo;icon: download\u0026rdquo;]Part 2 下载点击这里 Reviewer’s Guide for Remote 3D Graphics Apps [/su_button]\n[su_button url=\u0026ldquo;http://www.citrix.com/wsdm/restServe/skb/attachments/RDY12202/Reviewer%20Guide%20for%20HDX%203D%20Pro%2003%20vGPU%20GA.pdf\u0026rdquo; target=\u0026ldquo;blank\u0026rdquo; style=\u0026ldquo;3d\u0026rdquo; background=\u0026quot;#4e7f22\u0026quot; size=\u0026ldquo;6\u0026rdquo; icon=\u0026ldquo;icon: download\u0026rdquo;]Part3 下载点击这里 Reviewer’s Guide for Remote 3D Graphics Apps [/su_button]\nThis document helps you set up a simplified lab to review hardware-accelerated GPU virtualization for Windows desktop VDI workloads on Citrix XenServer. True GPU virtualization (a.k.a vGPU) on NVIDIA GRID cards is supported since Service Pack 1 of Citrix XenServer 6.2. It extends high-performance GPU sharing capabilities beyond Windows Server RDS workloads, that we cover in part 1 and part 2 of this series of Guides; Part 3 walks through the following topics:\n[su_list icon=\u0026ldquo;icon: comment-o\u0026rdquo; icon_color=\u0026quot;#b920ab\u0026quot;]\n  How to obtain the necessary components for the feature review\n  Install NVIDIA GRID GPU, and configure vGPU in XenServer\n  Assign vGPU to XenDesktop 7.1 Windows Desktop VM’s\n  Install and publish GPU-accelerated Virtual Desktops (VDI) using Studio\n   Access GPU-accelerated Virtual Desktops (VDI) from Citrix Receiver on any device\n   Verify 3D applications on multiple desktops are sharing the same physical GPU\n  [/su_list]\n",
    "ref": "/2013/12/31/reviewers-guide-remote-3d-graphics-apps/"
  },{
    "title": "新加坡签证申请所需要材料",
    "date": "",
    "description": "",
    "body": "虽然是第二次办理签证，是自己 送资料那种，但是还是少复印了一页材料，下面是一点经验总结：\n[su_list icon=\u0026ldquo;icon: check\u0026rdquo;]\n  新加坡签证的办理，必须到新加坡大使馆的网站上看须知，所以网站一定要去看：http://www.mfa.gov.sg/content/mfa/overseasmission/beijing/ch.html 本页下面的内容就是签证办理的注意事项了，最好还是到网站上看，以防止网站上有更新的东西。\n  户口本复印必须要完整，户口本的每一页都需要复印一页\n  签证费是153一个人，自己准备零钱\n  旅游签证是35天有效期，从签发的那天算，35天后，不管你是否入境，签证都作废了，所以不可以提前太早去办理签证\n  通常情况下，北京3个工作日就可以取签证了\n  送资料的时间是周1～5早晨9点到11点，去晚了就关门了\n  [/su_list]\n[su_quote]下面是官网的详细说明，需要逐字逐句的阅读，而且每个字都要理解，并且照做，你的签证材料准备的就妥妥的了！[/su_quote]\n申请签证必须提供以下材料。若有必要, 本馆有权要求申请者提供其他材料。\n  **护照：**护照原件及护照照片页复印件。护照有效期应在六个月以上（从入境日期开始计算），并至少有一张空白签证页。\n  Form 14A **签证申请表格（原件）：**一份用英文填写完整，并有申请者亲笔签名的申请表格。\n  彩色照片：二张（一张贴在表格上，另一张供扫描用）。照片应符合下列要求：\n  * 两寸，彩色，白底 的三个月内的近照； * 正面免冠（如按特殊宗教或风俗要求戴帽或配饰，帽子或配饰不得掩盖申请者面部特征）。   **中国身份证：**原件及复印件。（注：申请商务签证者，只需复印件）\n  **签证费（概不退还）：**人民币153元 (请自备零钱) 。\n  另，申请旅游签证需提供其他材料如下：\n  1. **在职证明：**  申请人若为在职员工，必须提供由就职公司出具的在职证明信原件一份。证明信中需注明公司同意其休假，并详细注明申请者在该公司任职时间、职务及工资。在职证明信必须列有公司及有关联系人的地址、电话和传真号码。信函必须加盖公章。申请人若无工作，则必须提供证明其个人经济状况的文件，如银行存款证明 (原件及复印件)。银行存款证明的金额没有具体要求但银行签发日期必须是签证申请递交日期的1个月内。此证明应能够如实的反映您的经济能力。\n2. **户口簿：**申请者户口簿 (全本，每页：原件及复印件) 。如为集体户口，可在警察局办理户籍证明，并提供原件及复印件。  另，申请商务签证需提供其他材料如下:  1. **[委托书](http://www.mfa.gov.sg/content/dam/mfa/images/om/beijing/form/proxy_authorisation_letter.pdf)：**如本人不能亲自来使馆申请签证，需出具委托书，委托书要注明被委托人的姓名及身份证号码（中英文均可）。被委托人必须携带自己身份证原件并提交复印件。即使是同一个人被委托，请在申请及领取签证时各递交一张委托书。 2. **新加坡公司商业注册简况打印件：**由新加坡会计与企业管理局（[http://www.acra.gov.sg](http://www.acra.gov.sg/)）出具的新加坡公司最新商业注册简况打印件一份，该简况的打印日期距递交日期不得超过6个月。由新加坡政府机构、大学邀请或出席在新加坡召开的展览会、大型会议等的申请者，无需出具V39A表格和新加坡公司商业注册简况。申请者只需递交该机构或组织签发给申请者的**邀请函原件**。邀请函上必须要有该机构或组织邀请人的签名和申请者的名字。 3. **[V39A表格原件（介绍信）](http://www.mfa.gov.sg/content/dam/mfa/images/om/beijing/form/FormV39A.pdf)：**由新加坡注册公司代表人(必须21周岁以上的新加坡公民或新加坡永久居民) 用英文填写完整的原件一份。信上必须注明新加坡公司的地址、电话、传真号码, 公司章和公司代表人的新加坡身份证号码与签名。  签证申请者必须本人亲自来本馆递交申请。以下情况除外:  * 若申请人未满18周岁，可由其父母代办，但必须出具能证明其关系的出生公证书或户口本和父母身份证（原件及复印件）； * 若夫妻关系，可由其配偶代办，但必须出具能证明其关系的结婚证或户口本和配偶身份证（原件及复印件）； * 如申请人已退休或60周岁以上，可委托他人办理，但需提供本人退休证原件、复印件及委托书（注明被委托人的姓名和身份证号码）。被委托人必须携带自己身份证原件并提交复印件； * 如申请人由在华的新加坡公民或新加坡永久居民作介绍，介绍人(必须21周岁以上) 需亲自来本馆递交申请，并提供填好的 **[V39A表格原件（介绍信）](http://www.mfa.gov.sg/content/dam/mfa/images/om/beijing/form/FormV39A.pdf)** 及其新加坡身份证或护照的原件及复印件； * 申请商务签证者。   **签证递交及领取时间：**周一至周五上午9：00至11：00 （只受理材料递交）周一至周五下午4：00至 4：30 （只受理签证领取）\n  **签证办理时间：**一般三个工作日（递交申请日包含在内）\n  **签证咨询:**建议申请者及介绍人请仔细详读此申请内容。若有任何其他问题，可拨签证热线 +86-10-65329380 咨询。\n  重要注意事项\n  未填好的表格、材料不齐或不符合要求有可能导致拒签或推迟受理。\n  签证申请是否被批准，及批准的有效期限都由签证官根据申请者个别情况决定。\n  申请者应在签证批准后再购买机票。凡因提前购买机票而签证未被批准所造成的经济损失，本馆对此不负责任。\n  签证的签发日期一般是签证的申请日，签证一旦被签发其有效期将不再变更。申请者不应过早递交申请材料。若签证已过期，申请者须重新递交申请材料。申请者在领取签证时，应仔细核对签发日期及签证有效期。建议申请者在出国前一至二周递交申请。\n  签证持有者并不一定可以入境新加坡。签证持有人须符合入境规定方可准许入境，如有效护照，足够的资金和往返机票（如需要）。新加坡移民与关卡局官员有权决定其是否可入境。\n  新加坡移民与关卡局官员在签证持有者入境时决定其停留天数。申请者应留意护照的入境章和批准的停留期限 。\n ",
    "ref": "/2013/12/31/e696b0e58aa0e59da1e7adbee8af81e794b3e8afb7e68980e99c80e8a681e69d90e69699/"
  },{
    "title": "Garmin Forerunner TheLongRun",
    "date": "",
    "description": "",
    "body": "http://7bv9gn.com1.z0.glb.clouddn.com/wp-content/uploads/2014/02/Garmin-AD-TheLongRun-Forerunner-220-and-620.mp4\n",
    "ref": "/2013/12/21/garmin-forerunner-thelongrun/"
  },{
    "title": "Garmin FR620 第二块跑步手表目标",
    "date": "",
    "description": "",
    "body": "\nGarmin ForRunner 620\n尺寸: 4.5 x 4.5 x 1.25 cm 重量: 43.6 g 1“ 彩色/触摸式萤幕180x180 续航力: 手表模式6周 / 训练模式10小时. 50m 防水 支援live tracking - 可与手机连线, 将轨迹及时传送出去, 与朋友分享. 支援蓝牙LE 支援Wifi 支援Running Dynamics 支援Recovery Advisor 支援VO2 max estimate\n\nGarmin ForRunner 220\n尺寸: 4.5 x 4.5 x 1.2 cm 重量: 40.7 g 1“ 彩色/非触摸式萤幕180x180 续航力: 手表模式6周 / 训练模式10小时. 50m 防水 支援live tracking - 可与手机连线, 将轨迹及时传送出去, 与朋友分享. 支援蓝牙LE 不支援Wifi 不支援Running Dynamics 不支援Recovery Advisor 不支援VO2 max estimate\n",
    "ref": "/2013/12/21/garmin-fr620-e7acace4ba8ce59d97e8b791e6ada5e6898be8a1a8e79baee6a087/"
  },{
    "title": "2013 Year Of Running",
    "date": "",
    "description": "",
    "body": "跑了一整年了，回顾一下数字：从咕咚运动和Garmin Connect里面记录的总和里程为九百多公里；跑步主要是为了强健体魄和挑战自我。同时也有非常多的其他好处：减压、提振精气神、消除负面情绪等等。每次跑到欲罢不能的时候，都是一种畅快的肉体和精神之旅。跑步所到达的城市有十几个；国外的城市有：新加坡、新奥尔良、洛杉矶、圣地亚哥。下面是所有跑步地点的清单：\n所有跑步地点的地理分布如下：  从跑步成绩方面还取得了一些个人记录： 这些记录是由我的GPS跑步手表记录的。所有的数据都上传到Garmin Connect网站上，数据还算比较准确。  这块表的功能比较简单，能记录跑步的轨迹、速度等等，可以存储最好个人记录，和7个最近的跑步活动。还算是比较实用，带着它我跑完了人生第一个半程马拉松。\n\n让我跑的最爽的几个地方是：北京奥林匹克森林公园、新加坡的Gardon by the bay 温室植物园、崇礼的草原天堂之路、沈阳的浑河畔、新奥尔良密西西比河畔等等。 由于我热衷于晨跑，当你迎着朝阳，挥汗如雨、在吸收正能量的过程中；你能领略到别人无法想象的景色，这些美景都深深的留在了脑海里。\n以上四张图片：\n  上左：沈阳浑河河畔，我从靠近市中心的大桥王东南方向，沿着河边非常专业的骑行道路一气跑下去，已经快到鹭岛附近，跑了15公里。那是在盛夏，北京闷热沈阳比较凉爽，跑出的汗多，但是体温不太高，跑的大汉淋漓，爽透了。\n  上右：北京的春天气候非常好，早晨7点清凉的很。为了备战金鸡湖半程马拉松比赛，周末驱车30多分钟，跑10多公里回家，浑身无伤痛感，无精神压力的奔跑完全可以让任何一个人上瘾\n  下左：崇礼的草原天堂之路，本来是去那里看草原和大风车的，但是下夕阳西下的时候，看到那一眼望不到边的草原，新修的公路就在脚下，顿时脚跟发痒，直接开跑，跑了3公路多山路，主要是为了搜集地点，3公里山路下来，基本上人山合一，完全置身于世外了\n  下右：在美国新奥尔良的密西西比河河畔，和同事们一起跑可谓是人生的一大乐事，其实需要感谢我的所有跑友们，他们是跑步乐趣的催化剂，无限低放大了跑步的乐趣，能给我更多跑步的理由，我们的跑步微信群是大家参与度极高的圈子，每个人的日常跑步作业都在上面实时发布。\n  最开心的还是看着两岁多的宝宝能一天天的长大，跑步是唯一的让我与她拉近时间和空间距离的方法。我已经无法停止跑下去的步伐。 \n",
    "ref": "/2013/12/19/2013-year-running/"
  },{
    "title": "XenServer 添加硬盘做本地存储",
    "date": "",
    "description": "",
    "body": "当您的 XenServer 测试机需要增加硬盘的时候，你需要通过简单的几条指令把新硬盘添加为本地存储。\n下面的实例情况是：\n  测试机有两块硬盘\n  OCZ SSD硬盘一块\n  SATA 不通硬盘一块\n  还有一个U盘插在系统上\n    SATA的硬盘是我需要加载的新硬盘\n  这个新的硬盘希望被处理成XenServer本地的SR\n  添加过程中主要需要使用这样几条指令：\n  查看当前系统上的检查出来并且挂载中的分区： cat /proc/partitions\n  详细查看这些存储和设备对应的情况： ls -l /dev/disk/by-id/\n  创建新的本地SR: xe sr-create content-type=user device-config:device=/dev/disk/by-id/scsi-SATA_ST9320325ASG_5VD7G964 host-uuid=3850317b-d23a-4ed0-87f9-2b27854319e5 name-label=\u0026ldquo;SATA320\u0026rdquo; shared=false type=lvm\n  [bash] [root@XS62 ~]# cat /proc/partitions major minor #blocks name\n7 0 52378 loop0 8 0 250059096 sda 8 1 4193297 sda1 8 2 4193297 sda2 8 3 241669447 sda3 8 16 312571224 sdb 8 17 204800 sdb1 8 18 312235312 sdb2 8 32 4137984 sdc 8 36 4137856 sdc4 252 0 241655808 dm-0\n[root@XS62 ~]# ls /dev/disk/by-id/ scsi-SATA_OCZ-AGILITY4_OCZ-DY4J9LY3615W5MF2 scsi-SATA_OCZ-AGILITY4_OCZ-DY4J9LY3615W5MF2-part3 scsi-SATA_ST9320325ASG_5VD7G964-part2 scsi-SATA_OCZ-AGILITY4_OCZ-DY4J9LY3615W5MF2-part1 scsi-SATA_ST9320325ASG_5VD7G964 usb-Generic_Flash_Disk_4266F915 scsi-SATA_OCZ-AGILITY4_OCZ-DY4J9LY3615W5MF2-part2 scsi-SATA_ST9320325ASG_5VD7G964-part1 usb-Generic_Flash_Disk_4266F915-part4\n[root@XS62 ~]# ll /dev/disk/by-id/ total 0 lrwxrwxrwx 1 root root 9 Nov 22 19:52 scsi-SATA_OCZ-AGILITY4_OCZ-DY4J9LY3615W5MF2 -\u0026gt; ../../sda lrwxrwxrwx 1 root root 10 Nov 22 19:52 scsi-SATA_OCZ-AGILITY4_OCZ-DY4J9LY3615W5MF2-part1 -\u0026gt; ../../sda1 lrwxrwxrwx 1 root root 10 Nov 22 19:52 scsi-SATA_OCZ-AGILITY4_OCZ-DY4J9LY3615W5MF2-part2 -\u0026gt; ../../sda2 lrwxrwxrwx 1 root root 10 Nov 22 19:52 scsi-SATA_OCZ-AGILITY4_OCZ-DY4J9LY3615W5MF2-part3 -\u0026gt; ../../sda3 lrwxrwxrwx 1 root root 9 Nov 22 19:52 scsi-SATA_ST9320325ASG_5VD7G964 -\u0026gt; ../../sdb lrwxrwxrwx 1 root root 10 Nov 22 19:52 scsi-SATA_ST9320325ASG_5VD7G964-part1 -\u0026gt; ../../sdb1 lrwxrwxrwx 1 root root 10 Nov 22 19:52 scsi-SATA_ST9320325ASG_5VD7G964-part2 -\u0026gt; ../../sdb2 lrwxrwxrwx 1 root root 9 Nov 22 19:52 usb-Generic_Flash_Disk_4266F915 -\u0026gt; ../../sdc lrwxrwxrwx 1 root root 10 Nov 22 19:52 usb-Generic_Flash_Disk_4266F915-part4 -\u0026gt; ../../sdc4\n[root@XS62 ~]# xe sr-create content-type=user device-config:device=/dev/disk/by-id/scsi-SATA_ST9320325ASG_5VD7G964 host-uuid=3850317b-d23a-4ed0-87f9-2b27854319e5 name-label=\u0026ldquo;SATA320\u0026rdquo; shared=false type=lvm cf0893c3-9398-d802-0706-66a8699c3a59 [/bash]\n从上面的命令可以看到，最后一条命令完成后，系统返回了新SR的ID;然后在登录XenCenter就可以看到这个存储了，虚拟现在就可以使用这个存储了。\n",
    "ref": "/2013/11/25/xenservere6b7bbe58aa0e7a1ace79b98e5819ae69cace59cb0e5ad98e582a8/"
  },{
    "title": "AWS 免费套餐截止后必须终止",
    "date": "",
    "description": "",
    "body": "对于亚马逊 AWS 的测试用户来说，你要知道你的免费套餐的截止日期，否则预期就会收费了，会计时收费，像叫停车费一样。我今天收到了亚马逊的提醒邮件，被告知，我的免费套餐将在本月截止，然后我不得不终止了该服务器。\n我是去年10月19日开通的这个免费实例，作为一个一年的 AWS 用户来说，深深的体会到了 AWS 的强大，它的管理控制台非常成熟，它的提供的服务非常全面，它的云市场做的相当好。对于任何一个普通人，你可以无痛，无压力的面对一个自己的数据中心，你可以假象你拥有一个世界上最高级的数据中心，你可以给你的应用任意、随时随地的附件任何一种高级的数据中心基础架构服务，你可以具有无限的资源，并且这个资源不限制类型和容量。共有云必将和私有云二分天下，共有云必将赢得所有中小企业用户。\n[caption id=\u0026ldquo;attachment_52574\u0026rdquo; align=\u0026ldquo;aligncenter\u0026rdquo; width=\u0026ldquo;300\u0026rdquo;] EC2_Management_Console[/caption]\n[caption id=\u0026ldquo;attachment_52575\u0026rdquo; align=\u0026ldquo;aligncenter\u0026rdquo; width=\u0026ldquo;300\u0026rdquo;] Try_Cloud_Computing_Free_with_AWS_Free_Tier[/caption]\n",
    "ref": "/2013/09/24/aws-e5858de8b4b9e5a597e9a490e688aae6ada2e5908ee5bf85e9a1bbe7bb88e6ada2/"
  },{
    "title": "CloudStack+Swift 我心中的黄金搭档",
    "date": "",
    "description": "",
    "body": "迪斯尼是一个有魔力的组织，在它的电影里冤家可以变伙伴。甚至CloudStack和OpenStack两大私有云死对头来到迪斯尼这个神奇的地方也可以“在一起”。当迪斯尼决定建设自己的云计算基础设施时，与很多企业一样面临一个艰难的抉择，从众多云计算技术方案和产品中选择一条道路。如今的云计算市场规模已 达数百亿美元，水已经很深，领头的是亚马逊这样的公共云巨头，以及亚马逊的对手们：Rackspace、Google、CloudStack、 Eucalyptus、OpenNebula等多种私有云和公共云技术与服务，每家都有绝活和独到之处。\n\n对于身价上千亿美元的娱乐和媒体巨头迪斯尼来说，业界可供选择的云计算路线太多，到底是走公共云、私有云、混合云还是多重云的路子？\n迪斯尼的选择是走自己的路。（迪斯尼的系统架构师Lopez将9月9日在CloudBeat上介绍其云计算建设经验。）\n在概念验证阶段，迪斯尼更加青睐CloudStack，在私有云领域CloudStack吸引力很多大型用户，如Zynga和诺基亚都选择了 CloudStack。迪斯尼的系统架构师Lopez表示，相比OpenStack，CloudStack的部署和运行速度要快得多。迪斯尼可以在数天能 部署好CloudStack服务，而OpenStack则需要数周。当然，两大私有云服务部署周期相差如此之大的部分原因也与迪斯尼的特殊要求和原有技术 投资有关。\n不管怎样，迪斯尼目前对CloudStack非常满意，但迪斯尼的团队希望在私有云中增加对象存储技术。这一次迪斯尼倾向使用OpenStack阵 营的对象存储工具——Swift。事实上，开源的OpenStack之所以如此流行，与大量参与者提供的丰富功能密不可分，Swift就是一个很好的例 子。\n于是，迪斯尼的团队与Citrix合作，确保OpenStack的Swift技术能够与CloudStack搭建的私有云紧密集成。在迪斯尼这个神奇的地方，OpenStack和CloudStack之间的深沟裂隙被弥合了。\n在迪斯尼的案例中，CIO能够参考的经验是：云计算的实施方案并非黑白分明，非此即彼，随着云计算服务商提供越来越多的相对独立的云计算功能，CIO们可以不受“站队”的局限，从不同阵营选择最好的云计算工具进行整合。\n开源世界里面没有绝对的对手和敌人，只有融合和共荣 --Marti Liu How Disney built a giant cloud by bolting two together 下面这个文章值得读一下。 http://venturebeat.com/2013/08/30/how-disney-built-a-giant-cloud-by-bolting-two-together/\n转帖：迪斯尼云计算之路选择CloudStack 原文链接： 文章来自IT经理网\n",
    "ref": "/2013/09/03/cloudstack-swift/"
  },{
    "title": "XenDesktop + nVIDIA K1/K2 = BEST 3D VDI",
    "date": "",
    "description": "",
    "body": "今天公司到货了K1，K2的GPU卡，这让我不得不学习一下这个产品。\n\n 到货实物如下：\n[gallery link=\u0026ldquo;file\u0026rdquo; ids=\u0026ldquo;52542,52543,52544,52545,52546,52547\u0026rdquo;]\n此卡的简单技术指标如下。\n GRID K1  GRID K2   Number of GPUs  4 x entry Kepler GPUs  2 x high-end Kepler GPUs   Total NVIDIA CUDA cores  768  3072   Total memory size  16 GB DDR3  8 GB GDDR5   Max power  130 W  225 W   Board length  10.5”  10.5”   Board height  4.4”  4.4”   Board width  Dual slot  Dual slot   Display IO  None  None   Aux power  6-pin connector  8-pin connector   PCIe  x16  x16   PCIe generation  Gen3 (Gen2 compatible)  Gen3 (Gen2 compatible)   Cooling solution  Passive  Passive     \n详细 K1 K2 技术参数指标，下载 ；  这个表格清晰的说明了这两种卡的硬件技术参数。重要的是看它软件合作伙伴这一块。硬件在好，没有支持的软件也不行，我们必须还有看看它的软件合作伙伴：http://www.nvidia.com/object/grid-software-partners.html\n首先，是认证的虚拟应用合作伙伴，这里只有Citrix XenApp；只有Citrix可以做3D设计软件的应用虚拟化；其它无人能及，基于Citrix的应用虚拟化可以真正的把一块GPU的共享程度达到最大，能够更加节约支撑的硬件资源。节省每一度电。还要看支持的API的版本号，这个说明了对3D软件的兼容性，如果这个版本号类型少，支持的低，那么这种方案是不可用的；由于3D软件根本就跑不动。\n NVIDIA Driver  API  GRID K1  GRID K2   **Citrix** [XenApp 6.5 with OpenGL 4.3](http://www.nvidia.com/object/xenapp.html)  ![Yes](http://www.nvidia.com/docs/IO/123679/check-mark.png)  NVIDIA CUDA DirectX 9,10,11 OpenGL 4.3  ![Yes](http://www.nvidia.com/docs/IO/123679/check-mark.png)  ![Yes](http://www.nvidia.com/docs/IO/123679/check-mark.png)     其次，要看认证的虚拟桌合作伙伴厂商，这里稍微多点；这里关键看点是NVIDIA Driver这一列。你有可能会说NVIDIA的显卡驱动难道不能装到所有类型的VDI虚拟桌面中么？我我想这个表格就是答案。一个GPU经过服务器虚拟化层之后，只有Citrix的虚拟桌面能够拿到NVIDIA的原生驱动，也就是说只有Citrix的VDI能够通过NVidia的显卡驱动，穿透服务器虚拟化层直接调用到GPU的原生指令进行运算。而VMwere也有NVIDIA的驱动啊！注意，它的驱动是装在那里的，它的驱动是装在hypervistor上的；也就是说虚拟机必须通过这个模拟的驱动程序层使用GPU的运算能力，这个驱动层做的是GPU指令的翻译和仿真，它实在不能让虚拟桌面的虚拟操作系统中的3D软件透过API直接调用GPU的运算指令。这意味这GPU的性能的折损，这意味您花高昂价格采购的服务器虚拟化软件正在浪费您花更贵价格买来的GPU，k1、k2的卡市场价格都3万多的。这样的方案是否值得买，必须考虑一下。最后要看View5.2 with vSGA，两点在vSGA，这个东西对很对3D软件来说是不可用，不可以接受的。甚至于某些专业3D/2D软件在这显示模式下，连安装都成问题。  NVIDIA Driver  API  GRID K1  GRID K2   **Citrix** [XenDesktop FP1 with NVIDIA GRID vGPU](http://www.nvidia.com/object/xendesktop-vgpu.html)  ![Yes](http://www.nvidia.com/docs/IO/123679/check-mark.png)  NVIDIA CUDA DirectX 9,10,11 OpenGL 4.3  ![Yes](http://www.nvidia.com/docs/IO/123679/check-mark.png)  ![Yes](http://www.nvidia.com/docs/IO/123679/check-mark.png)   **Microsoft** [RemoteFX](http://www.nvidia.com/object/quadro-remotefx.html) Windows Server 2012  -  DirectX 9,10,11 OpenGL 1.1  ![Yes](http://www.nvidia.com/docs/IO/123679/check-mark.png)  ![Yes](http://www.nvidia.com/docs/IO/123679/check-mark.png)   **VMware** View 5.2 with vSGA  -  DirectX 9 OpenGL 2.1  ![Yes](http://www.nvidia.com/docs/IO/123679/check-mark.png)  ![Yes](http://www.nvidia.com/docs/IO/123679/check-mark.png)     也可能某些厂商说：我有vGPU技术。这是用CPU模拟GPU的技术。您可以想想，如果这个技术真的存在的话那么我们只需要有一家公司就行了，就是Intel，而不需要另外一家Nvidia了。这个技术说白了也是仿真模拟，专业的3D/2D软件真正消耗越来越多的计算资源，在某些业务场景下模拟GPU是没法完成工作的，你总不能等待一个渲染和处理要等上几周去完成吧？而且设计师的时间是宝贵的，也不能让操作有顿挫和卡顿出现的。下面的视频，解释了在同一种虚拟桌面情况下，有GPU加速和，无GPU加速（CPU模拟）的操作对比。 总之，Citrix + nVIDIA K1 k2 + XenServer （GPU 直通） + HDX 3D Pro = 业内最好的3D虚拟桌面平台方案；而且这个方案里还能具有，其它全部的使用场景，包括：vdi，共享桌面，虚拟应用，流桌面，远程物理桌面等等方式。可以说这是一举多得，面面俱到的解决方案。\n",
    "ref": "/2013/08/16/xendesktop-nvidia-k1-k2-best-3d-vdi/"
  },{
    "title": "XenClient本地虚拟桌面典型应用场景",
    "date": "",
    "description": "",
    "body": "\n  安全加固移动性笔记本电脑\n  桌面级操作系统更新管理\n  分支机构或者远程办公环境计算机管理\n  弹性的在瘦机和PC直接选择\n  有限的网络访问环境\n  成本节约或已有硬件利用\n  XenClient本地虚拟桌面通常是虚拟桌面项目中的一个容易被忽视的环节。其实它的使用场景随处都是。\n",
    "ref": "/2013/08/15/xencliente69cace59cb0e8999ae68b9fe6a18ce99da2e585b8e59e8be5ba94e794a8e59cbae699af/"
  },{
    "title": "XenDesktop 7 HDX 3D Pro",
    "date": "",
    "description": "",
    "body": "http://brightcove.vo.llnwd.net/pd16/media/1485836774/1485836774_2603380124001_3DCar4CitrixTV.mp4\nDescription\nWindows 7 HDX3D Windows Server 2008R2 3D Network Constrained Environment (Simulating 3G speeds) No network constraints Windows Client iPad Client NVidia Demo software utilized is available on NVidia.com Solarwinds Software used for monitoring network traffic\n看点:\n  桌面虚拟化中的高精尖场景，成本高、技术高、效果精益求精\n  Citrix XenDesktop + nVidia = 业内最好3D设计虚拟桌面平台\n  Citrix可以兼顾 VDI+独占GPU和 共享桌面+共享GPU两种模式\n  来源：http://www.citrix.com/tv/#videos/9008\n",
    "ref": "/2013/08/14/xendesktop-7-hdx-3d-pro/"
  },{
    "title": "The Xen Movie, Part 1: The first ten years of open source Xen.",
    "date": "",
    "description": "",
    "body": "http://brightcove.vo.llnwd.net/e1/uds/pd/13639319001/13639319001_2484626552001_Citrix-Open-Source--Public-Version-.mp4\n",
    "ref": "/2013/08/01/the-xen-movie-part-1-the-first-ten-years-of-open-source-xen/"
  },{
    "title": "Citrix XenServer is Now Fully Open Source",
    "date": "",
    "description": "",
    "body": "http://brightcove.vo.llnwd.net/e1/uds/pd/13639319001/13639319001_2488040716001_XenServer-OSS-Richard-Sharp-Final.mp4\nWith the release of Citrix XenServer 6.2, Citrix is pleased to announce that XenServer is now fully open source. In this video, Richard Sharp, Vice President of XenServer Product Development, explains why Citrix open sourced XenServer, what it means to our customers and how it will help the entire XenServer platform.\n",
    "ref": "/2013/08/01/citrix-xenserver-is-now-fully-open-source/"
  },{
    "title": "A new open source strategy for Citrix XenServer",
    "date": "",
    "description": "",
    "body": "http://brightcove.vo.llnwd.net/e1/uds/pd/13639319001/13639319001_2503709704001_Sameer-Dholakia-v3.mp4\nSameer Dholakia, Vice President and General Manager of the Citrix Cloud Division, talks about the full open source strategy for XenServer. Learn why Citrix made XenServer open source and how this will benefit our customers and ecosystem partners.\n",
    "ref": "/2013/08/01/a-new-open-source-strategy-for-citrix-xenserver/"
  },{
    "title": "怎么使您的MP/VP/ATP/DEF都无穷大",
    "date": "",
    "description": "",
    "body": "自学的能力让你的能力变得无穷大。所谓学无止境，能力上能否得到无止境的提升就是个人为题了。你学习的时间？学习的态度？学习的内容？学习的方法？都决定了你的学习效果。基本上要学习一种新的技术或者产品，大多数人一般都止步于如何操作和运用它；能更深入的理解它的架构和特性，甚至做出横向的比对，就是第二个阶段，这样的人很少。\n\n学习Citrix技术的几个途径如下，我们通常都用到那些？请在下面投票。\n[poll id=\u0026ldquo;3\u0026rdquo;]\n什么是您认为学习Citrix技术的好的方式方法？请于本帖留言。\n",
    "ref": "/2013/08/01/e6808ee4b988e4bdbfe682a8e79a84mpvpatpdefe983bde697a0e7a9b7e5a4a7/"
  },{
    "title": "很离谱，很合理，很喜欢",
    "date": "",
    "description": "",
    "body": "今天上苹果网站上发现一个很酷的东西Mac Pro，我觉得它catch my eyes；真的设计的很离谱，很合理，我很喜欢，帖几张图共同赏析一下。\n[gallery link=\u0026ldquo;file\u0026rdquo; ids=\u0026ldquo;52469,52473,52470,52471,52472,52476,52478,52479,52474,52481\u0026rdquo;]\n连接详情，访问apple官网：http://www.apple.com.cn/mac-pro/\n",
    "ref": "/2013/07/19/mac-pro-e5be88e7a6bbe8b0b1-e5be88e59088e79086-e5be88e5969ce6aca2/"
  },{
    "title": "七章节细讲Citrix虚拟桌面基础架构搭建",
    "date": "",
    "description": "",
    "body": "Citrix项目实施秘籍文档慢慢泄露中。点击本文标题直达Citrix-Book.org 最佳实践网站\n",
    "ref": "/2013/07/09/e4b883e7aba0e88a82e7bb86e8aeb2citrixe8999ae68b9fe6a18ce99da2e59fbae7a180e69eb6e69e84e690ade5bbba/"
  },{
    "title": "XenDesktop 7 抢鲜测试",
    "date": "",
    "description": "",
    "body": "[gallery link=\u0026ldquo;file\u0026rdquo; ids=\u0026ldquo;52454,52455,52456\u0026rdquo;]\nXenDesktop 7 问世以来，目前处于市场初级推广阶段；虽然还没有大范围的推广，如果业内的合作伙伴们如果还没有尝试过，那么你们就Out了。为了更好的指导大家的测试工作，这里介绍两篇文档：\n  XenDesktop7快速安装手册\n  XenDesktop7安装和配置手册 from yandong\n  另外隆重推荐的是这个开放维基百科网站“Citrix-book.org Citrix最佳实践”；退出这个网站的原因是我看到，目前网络资源过于纷乱，大多数技术大拿们都有自己的bolg和微博；但是干活资源过于分散；这个网站本着开放自由的出发点，鼓励和欢迎所有的大难能到这里集中和上传你的干活技术资料。投稿方式为自由注册，自行在线新建和编辑文档；也可以根据网站指引投稿。\n",
    "ref": "/2013/07/08/xendesktop-7-e68aa2e9b29ce6b58be8af95/"
  },{
    "title": "A Post with a Video",
    "date": "",
    "description": "",
    "body": " Video embeds are responsive and scale with the width of the main content block with the help of FitVids.\n\u0026lt;iframe width=\u0026#34;560\u0026#34; height=\u0026#34;315\u0026#34; src=\u0026#34;//www.youtube.com/embed/SU3kYxJmWuQ\u0026#34; frameborder=\u0026#34;0\u0026#34;\u0026gt;\u0026lt;/iframe\u0026gt; ",
    "ref": "/2013/06/25/video-post/"
  },{
    "title": "Microserver Lenovo ThinkCenter M92/M92p Tiny",
    "date": "",
    "description": "",
    "body": "刚刚入手了一台 Lenovo ThinkCenter M92/M92p Tiny测试机，虽然配置不高但是出于geek习惯，还是要动动螺丝刀的。下面是拆机过程，供参考。 [gallery columns=\u0026ldquo;2\u0026rdquo; link=\u0026ldquo;file\u0026rdquo; ids=\u0026ldquo;52429,52430,52431,52432,52433,52434,52435\u0026rdquo;]\n这款机器目前在国内好像还没有正式买，起码联想中国官网上连技术指标也查不到。美国网站上是有这个机器的介绍。\n[caption id=\u0026quot;\u0026quot; align=\u0026ldquo;alignnone\u0026rdquo; width=\u0026ldquo;960\u0026rdquo;] ThinkCenter M92P[/caption]\nAt a Glance   Up to 3rd generation Intel® Core™ i7\n  Up to Windows 8 Pro\n  Up to 1TB HDD, Up to 128GB SSD\n  Up to 32GB memory (4x8GB)\n  M92/M92p Tower Tech Specs\n  M92/M92p Tiny Tech Specs\n  我所测试的是M92 Tiny型。改机默认安装的Win8操作系统。如果把它改装为跑Hypervisor的服务器的话，它应该属于 Microserver的范畴。\n微服务器定义：A micro server (may also be written as microserver or MicroServer) is a small server appliance that works like a server. Micro servers are off-the-shelf appliances that are designed for ease of installation and maintenance. A micro server will come with the operating system, hardware and software preinstalled and configured by the manufacturer. Some configuration functions of the micro server may be performed by the end-user through a touch panel and access to the server appliance is through a Web browser. A micro server is a popular choice for small- to medium-sized businesses that need a server but do not need a full-scale rack or tower server. Micro servers are also used by corporations that operate with minimal IT staff at local or branch offices. A micro server may also be called a server appliance. 接下来，我准备在这个机器上做些改动和测试。\n  如果有可能的话，更换硬盘为SSD硬盘，升级内存到最大两条8GB，共16GB\n  安装和测试XenClient：使用集中管理器，来更新本地硬盘的Widnows虚拟机操作系统\n  安装和测试XenServer：在上面跑XenDesktop的虚拟机，看看做多能达到多少个用户的密度，分别测试共享桌面和VDI桌面，看看共享桌面的密度会在这个机器上比VDI高几倍？\n  测试跑CloudStack的计算节点，试想如果实验室里面有一摞16个机器，都做在一个群集上，跑跑大数据Hadoop 应用，应该也是很好的使用场景\n  ",
    "ref": "/2013/05/24/microserver-lenovo-thinkcenter-m92m92p-tiny/"
  },{
    "title": "你的体重标准么？",
    "date": "",
    "description": "",
    "body": "[caption id=\u0026ldquo;attachment_52426\u0026rdquo; align=\u0026ldquo;aligncenter\u0026rdquo; width=\u0026ldquo;640\u0026rdquo;] 成人理想体重范围[/caption]\n【成人理想体重范围对照表】图中BMI指数，全名叫身体质量指数，是体重公斤数除以身高米数平方得出的数字，是目前国际上常用的衡量人体胖瘦程度以及是否健康的一个标准。你在哪个区域？（MSN健康） 终于为我的体重找到了依据，我的体重目前开来很标准。跑步则是保持体重，提高体质的基础。\n",
    "ref": "/2013/05/23/e4bda0e79a84e4bd93e9878de6a087e58786e4b988efbc9f/"
  },{
    "title": "我想跑遍全世界",
    "date": "",
    "description": "",
    "body": "我说的是跑步的跑：）\n__\n目前的情况是，我的足迹分布在国内6个城市。还有很多国内城市没跑过，也还有很多外国城市没有跑过，好在还有很多年的时间来丰富这张跑步地图。\n",
    "ref": "/2013/05/21/e68891e683b3e8b791e9818de585a8e4b896e7958c/"
  },{
    "title": "XenDesktop虚拟桌面精品书籍导读(中文版)",
    "date": "",
    "description": "",
    "body": "[box color=\u0026ldquo;orange\u0026rdquo; icon=\u0026ldquo;flag\u0026rdquo;] 感谢 Eric Yao 的供稿，@老树皮Eric [/box]\n英文版：《Citrix Virtual Desktop Handbook》\n中文版：[download id=\u0026ldquo;20\u0026rdquo;]\n本书是XD虚拟桌面实施工程师的必备读物，请相关人员仔细阅读。\n",
    "ref": "/2013/05/14/xendesktope8999ae68b9fe6a18ce99da2e7b2bee59381e4b9a6e7b18de5afbce8afbbe4b8ade69687e78988/"
  },{
    "title": "隐藏Windows  Explorer中的各种东西",
    "date": "",
    "description": "",
    "body": "XenApp实施工具，隐藏Windows Explorer中的各种东西。\nHideLibraries Hide libraries icon in the navigation pane of Windows Explorer. HideFavorites Hide favorites icon in the navigation pane of Windows Explorer. HideNetwork Hide network icon in the navigation pane of Windows Explorer. HideComputer Hide computer icon in the navigation pane of Windows Explorer. HideHomeGroup Hide home group icon in the navigation pane of Windows Explorer ShowLibraries Show libraries icon in the navigation pane of Windows Explorer. ShowFavorites Show favorites icon in the navigation pane of Windows Explorer. ShowNetwork Show network icon in the navigation pane of Windows Explorer. ShowComputer Show computer icon in the navigation pane of Windows Explorer ShowHomeGroup Show home group icon in the navigation pane of Windows Explorer Logoff In order to changes take effect the explorer shell process needs to be restarted. Specifying the option causes your windows session to logoff immediately. Reboot In order to changes take effect the explorer shell process needs to be restarted. Specifying the option causes the computer to reboot immediately. Help Displays this usage information.\n点此处下载： [download id=\u0026ldquo;19\u0026rdquo;]\n几乎是做XenApp共享桌面的必备工具。\n",
    "ref": "/2013/05/14/hide-windows-explorer-items/"
  },{
    "title": "XenDesktop虚拟桌面精品书籍导读(part5)",
    "date": "",
    "description": "",
    "body": "[box color=\u0026ldquo;orange\u0026rdquo; icon=\u0026ldquo;flag\u0026rdquo;] 感谢 Eric Yao 的供稿，@老树皮Eric [/box]\n今天是《Citrix Virtual Desktop Handbook》第二讲的最后一期，专门论述一下PVS的设计。在本期之后我会把所有以往的内容整合在一个完整的白皮书中，稍等几日。。。\n请期待基于本系列5篇文章的完整版中文白皮书下载。\nCitrix桌面虚拟化实施部署白皮书 第二讲之第五期：PVS的设计\n Provisioning Services  Citrix Provisioning Services（PVS）使用流化的技术简化了虚拟桌面和物理桌面的部署。计算机从一个单个的共享磁盘镜像上被实时制备（Provisioned），管理员完全不需要去管理或者是给每个单独的用户操作系统打补丁。\n1) 决断：Farm（场）的数量\n一个Provisioning Services的场代表着Provisioning Services基础架构的最高层级。所有在一个场的Provisioning Servers（服务器）都共享同一个SQL 数据库哦Citrix License服务器。当确定需要多少个Provisioning Services的场时，我们一般需要考虑以下几个因素：\nl **网络：**Provisioning Servers会始终和场数据库通信以获取系统配置信息。因此，一般来说每个target devices聚集的地理位置应该部署一个独立的场，当然，如果异地之间的网速足够快，理论上也可以只建立一个Provisioning Services场。\nl **重要程度：**管理者应该决定它可以容仍什么样的风险。尽管可能性非常的低，但是Provisioning Services场如果出问题还是会影响整个组织架构的使用。如果一个公司需要非常高等级的可用性，那么多个场的搭建就可以避免这个问题。\nl **可管理性：**管理者可能需要在基于组织架构划分的基础上，例如国家、地区，又或者是不同部门之间，来进行单独的系统管理。尽管听起来这会增加管理的复杂程度，但是实际上只会增加有限多的配置、桌面创建过程，以及操作系统镜像更新。\n2) 决断：站点（Sites）的数量\n每个Provisioning Services的场都包含一个或者多个的站点。一个Provisioning Services的站点是一个逻辑的实体组成部分，包含了Provisioning Servers（服务器）、vDisk pools，以及target devices的集合。多个站点共享同一个数据库。Target devices可以在同一个站点中容错到其他的Provisioning Servers上。在以下的情况下我们建议创建多个站点：\nl **网络：**站点用来控制Provisioning Services的流数据量。例如，一个站点可以根据站点、rack、或者是刀箱来创建，以确保流数据始终保持在本地而不变成一个网络瓶颈。\nl **组织架构：**另外一个需要创建多个站点的实际理由是企业组织架构的改变。例如，两个公司通过收购合并了，但是有需要在企业整合过程中保持资源的独立。\n3) 决断：数据库的配置\nProvisioning Services的数据库存储有所有一个场内的的系统配置信息。Provisioning Services 6.X版本支持一下版本的SQL数据库，包括Express、标准版、企业版的SQL Server 2005、2008R2以及2012版。选择哪一个SQL版本其实是取决于你需要哪一个级别的容错水平。以下的表格是一个SQL 2008R2版本的示例：\nProvisioning Services场的数据库的大小很少会超过250M容量，即使在大型环境下也不会。所以，在测试环境下Express版本是最佳选择，因为不需要容错功能。\n下面的公式是用来计算Provisioning Services的数据库的容量大小：\n4) 决断：数据库；离线模式\n如果到Provisioning Services场的数据库的连接断开，已经连接到Provisioning Servers的target devices仍然可以正常工作，但是新的target devices将会无法启动。\n支持离线数据库功能可以让Provisioning Services在失去连接到数据库后仍然可以保持正常操作。在服务器启动时会对数据库做个快照，然后定期保持同步。如果连接丢失，Stream Services会使用最新的一个快照以获取场的配置信息。一旦数据库连接建立起来了，Stream过程会把断线期间的变化同步到数据库中。\n需要注意的是，离线数据库功能默认下是关闭状态的，而且也仅仅是在生产环境下的稳定的场环境下推荐使用。评估环境下不推荐使用\n5) 决断：服务帐号\nStream和SOAP服务会和其他许多不同的Provisioning Services基础架构中的组件进行通信，如下图所示：\n6) 决断：设备集合\n设备集合是用来创建和管理target devices逻辑组。创建设备集合可以简化设备管理，因为将来的操作可以不用基于target device级别，而是基于集合这个级别。\n设备集合可以基于物理地理位置、子网范围、组织架构中不同的部门来设计。也可以考虑基于vDisk的分配来创建不同的设备集合，这样所有分配到一个特定vDisk的所有的target devices就能被快速的定位。\n7) 决断：Provisioning Server（服务器）的内存\n运行Provisioning Services的Windows操作系统会把vDisk的部分内容缓存在内存（系统缓存）中以降低从存储中读取的操作。从存储中读取数据的速度是显著低于从内存中读取数据的，所以，正确计算Provisioning Servers的内存是非常关键的。请参见以下的公式：\n简单地说，就是给每个vDisk分配2G左右的内存。\n8) 决断：Scale Up还是****Scale Out\n题外话：首先对这两个词进行一下解释：\nScale Out(向外扩展)：就是指企业可以根据需求增加不同的服务器应用，依靠多部服务器协同运算，借负载平衡及容错等功能来提高运算能力及可靠度。\nScale Up(向上扩展)：指企业后端大型服务器以增加处理器等运算资源进行升级以获得对应用性能的要求。\n随着Farm场的增长，管理员需要作出决定以判断是不是需要给Provisioning Server增加更高的资源，也可以是在场中增加更加多的Provisioning Servers，一下了可以是考虑因素：\nl **冗余：**将用户符合扩展到其他负荷不重的服务器上会有助于降低当Provisioning Servers宕机情况下爱所影响的用户数量。如果公司无法接受单点高性能服务器宕机所造成的损失，那就考虑Scaling Out，就是我们说的向外扩展（既增加多台服务器）。\nl **容错时间：**在一个单台的Provisioning Server上所连接的Target Devices越多，在服务器宕机后所需要的恢复时间也就越多。Citrix的内部测试显示在Provisioning Services 5.6 SP2版本下，1500台Target Devices需要大约8分钟恢复生产能力；\nl **数据中心容量：**数据中心一般都是只有有限的空间、电源、冷却能力，此时，可以考虑Scaling Up，即向上扩展（增加单台服务器的处理能力）。\nl **硬件成本：**刚开始时，可能Scale Up会有更高的性价比，但是继续往后可能Scale Out会开始更具性价比，应该做一个成本分析；\n9) 决断：vDisk的存储位置\n一个场可以包含一个或者多个的vDisk存储。一般来说有两个主要的选择：\nl 本地存储或者是DAS**：**DAS可以是本地的，或者是基于Block的存储类型，Provisioning Server可以直接访问，例如SATA、SCSI、iSCSI，以及光纤。本地的vDisk就只能被本地的Provisioning Server所反问，因此，vDisk应当被手动或者自动的复制到其他的vDisk存储位置上。\n注意：将vDisk__部署在本地存储上并不会造成单点故障，因为Provisioning Service__的负载均衡技术可以让target devices__自动的在其他Provisioning Servers__之间做容错动作。\nl NAS**：**NAS是一种基于文件级存储的solution。NAS协议包括CIFS和NFS。NAS vDisk可以被多个Provisioning Server同时所访问。NAS由于不需要vDisk复制功能所以能保证vDisk在一个场内的多台Provisioning Server之间保持连续性。\n注意：NAS__反而会造成单点故障，如果网络共享功能不可用，所有从这个vDisk__上Streamed__的target device__都会变得不可用了。\n10) 决断：评估存储容量\n一个vDisk包含了一个VHD基础镜像文件、一个properties文件（.pvd），也可以能包含了一个链条VHD差异磁盘（.avhd）。每当一个vDisk被Provisioning Services versioing所更新时，一个新的差异磁盘就会被创建。\n一个vDisk所占空间的评估因素大致有以下几点：\nl **vDisk****的总容量：**顾名思义\nl **vDisk chain****的最大版本数：**vDisk versioning简化了vDisk升级以及管理的负担，他能够更加灵活和健壮的管理vDisks。\n备注：太多的差异磁盘会显著降低Provisioning Services__的性能，建议不要超过5-7__个的版本数。\nl **vDisk****版本变化百分比：**差异磁盘的大小是随着对vDisk的改动多少而随着变化的。改得越多，差异磁盘的大小就越大。以下的计算公式可以用于计算vDisk容量：\n举例如下：\n比如你计划部署三个vDisk：\n Windows 7 (x64) image = 40GB\n Windows 7 (x86) image = 35GB\n Windows XP image = 20GB\n每个vDisk都不会超过5个差异磁盘。预计一个差异磁盘大致是20%的主vDisk镜像文件大小，那么估计Provisioning Services存储所需要的空间如下：\n11) 决断：RAID级别\n存储子系统的RAID级别会对应用程序和用户的工作负荷产生直接的影响。RAID 0、1以及10对读操作是最优，而RAID 5和6是对写操作是最优。对于Provisioning Services来说，不同的RAID级别有如下推荐配置：\nProvisioning Services中vDisk主要是读操作，而对Write Cache来说主要是写操作。所以：\nl Write Cache**：**推荐RAID 0、1、10因为这几种RAID的写惩罚较低\nl **vDisk ****存储：**推荐RAID 0、1、5、10，它可以让读操作分配到RAID中的其他磁盘中；\n如果可能，建议将vDisk放在RAID5上，而写缓存放在RAID10上。如果vDisk和写缓存一定要放在一起，那么建议采用RAID10。\n12) 决断：写缓存的位置\n写缓存可以有以下位置：\nl **缓存在Target Device**的硬盘上：由于Provisioning Servers不用处理写请求，放在这里会减轻Provisioning Servers的资源消耗。尽管没有放在内存中这么快，这种方式的读写都是在本地，还是能提供快速的响应时间；\nl **缓存在Target Device****的硬盘上永久保存：**和第一种方式类似，区别在于用户重启之后存储永久保存。该功能目前还是测试阶段，仅在Windows 2008 R2和windows 7上支持。\nl **缓存在Target Device****的内存中：**尽管这种方式在性能上是最优的，但是如果RAM别耗尽了也会印象系统的稳定性；\nl **缓存在Provisioning Server****的磁盘上：**缓存在Provisioning Server的磁盘上作为临时文件存储。所有的写操作均发生在Provisioning Server服务器上。这样配置当然会增加Provisioning Server的磁盘IO操作和网络负担。配置上这种方式最为简单，不过这种方式下target device由于所有的到写缓存的读写请求都必须经过网络，target device的性能会受到较大影响。这种方式仅在POC阶段推荐！\nl **缓存在Provisioning Server****的磁盘上永久保存：**和上一种方式基本类似，区别在于用户重启之后存储永久保存。这种方式的好处在于target device能够保存对vDisk所做的改变，在重启之后也仍然保留。任何对vDisk的改变都会将缓存文件强制标记为失效状态。例如，如果vDisk被设置为Private Image Mode，一下所有的操作都会导致缓存文件被标记为失效状态：\nn o Placing a vDisk in Maintenance mode\nn o Mapping the drive from the console\nn o Changing the location of the write cache file\nn o Using Automatic update\n写缓存包含了target device的MAC地址和磁盘识别符，他能独一无二的区分出每一台target device。一个target device可以被分配多个vDisk，因此，也可以关联多个缓存文件。\n将写缓存部署在target device上是最为推荐的配置方法，因为既不用消耗而外的RAM内存，又不会减少Provisioning Servers的扩展性。\n13) 决断：写缓存的大小\n写缓存的大小取决于很多隐私，一般来说都是基于评估和典型的用户配置文件大小。一般来说应当能够存储一下数据：\nn Temporary application data\nn User profile temp files\nn Windows Event Logs\nn Citrix Logs\nn Antivirus pattern files\nn Citrix Application Streaming/Microsoft App-V Cache\n备注：启用了用户配置文件重定向操作能减少写缓存所需要的大小。\n写缓存的大小极大程度上取决于安装或者是Streamed到vDisk上的应用程序的大小以及用户配置文件的大小。推荐配置的起点是2GB。对于大部分虚拟桌面来说，我们有如下推荐配置：\n此外，Windows的pagefile也会写入和写缓存同样的磁盘中，所以：\n例如，如果Windows 7的vDisk设计是1.5GB的pagefile，那么写缓存的一个安全的评估数据应该是：\n不过由于Hypervisor都不能将磁盘精确到小数点后，我们姑且分配4GB的空间吧。\n14) 决断：vDisk的格式\nProvisioning Services支持固定磁盘以及动态磁盘格式。\nl **固定磁盘格式：**对于私有模式（private mode）的vDisk，固定尺寸大小的vDisk可以对存储vDisk磁盘上进行的磁盘碎片整理操作，这对写操作的性能提升会有帮助。不过在私有模式下，访问vDisk受限于一个target device，我们说仅当对vDisk进行维护模式时才有实际意义。\nl **动态磁盘：**相比较而言他需要更少的磁盘空间，但是在写操作上性能会显著降低。尽管在共享模式下（Shared Mode）的vDisk不会对vDisk执行写操作，不过对完成vDisk合并时所要花费的时间会增加许多。\n15) 决断：vDisk的大小\nvDisk的大小主要取决于操作系统以及安装在操作系统上的应用程序的多少，我们预估的大小如下表所示：\nvDisk的大小如果设置的太小或者是太大，日后我们还可以在Provisioning Services中调整。为了精确的评估vDisk的大小，请遵循以下的准则：\nl **Target Device**的空间：确认目前作为主target device服务的计算机所正在使用的磁盘空间大小；\nl **应用程序大小：**当应用程序安装时，所需要的空间也在增长。计划大25%的增长\n16) 决断：vDisk复制\n如果vDisk是存储在DAS上就需要在他自己有变化的时候复制到其他DAS上。Provisioning Services支持vDisk从本地复制到Provisioning Servers上，也可以支持在使用共享存储时跨越多个站点之间的复制。复制可以是手动或者是自动：\nl **手动复制：**简单，但是更耗时；\nl **自动复制：**大型环境下自动复制更快。一些自动化工具，例如Microsoft DFS-R还支持带宽控制。唯一缺点是如果复制出错，管理员还不支持，除非复制平台支持复制重传。\n17) 决断：微软****Volume Licensing\nProvisioning Services支持Microsoft Key Management Service (KMS)和Multiple Activation Key (MAK) volume licensing。\nl KMS Volume Licensing**：**可以在用户的本地网络上激活，无需连接到微软的网站。一台KMS服务器支持不受限的JMS客户端。微软公司推荐部署两台KMS服务器。****\nn Office 2010的部署只支持KSM激活方式；\nl MAK Volume Licensing**：**MS的一次性激活方式。\n18) 决断：高可用\nProvisioning Services是虚拟桌面基础架构中最重要的组成部分，因此为了避免单点故障，需要考虑一下推荐步骤：\nl MAK Volume Licensing**：**MS的一次性激活方式。\nl **数据库：**Provisioning Services支持两种数据库的高可用方式：\nn 离线的数据库；\nn 镜像数据库\nl Provisioning Servers**（PVS****服务器）：**所有在一个站点之间的Provisioning Servers都能够被配置为向target device提供同一个vDisk。每个站点最少部署两台PVS服务器。\nn Provisioning Services启动文件应当配置为高可用。在启动文件中可以配置高达4台PVS服务器的列表。Target Device会按照顺序连接这些PVS服务器。后续所响应的服务器可以不是当初提供Streaming服务的服务器。当然，我们也可以配置负载均衡。\nl **vDisk****和存储：**对于DAS上存储的vDisk，应当做好同步操作。对于NAS上的vDisk，NAS存储必须提供一条高可用的网络共享连接；\nl **网络：**Provisioning Servers（PVS服务器）的网卡应当配置为Teamed。\n19) 决断：带宽需求\n带宽评估对于整体性能是有至关重要的，特别是当Target Device启动的时候。带宽是随着操作系统的不同而有所区别的。Target Device启动所需要的时间可以参考下面的公式：\n例如，500个Windows 7的Target Devices在1G以太网下需要40M启动：\n1. 1 GB Ethernet = 125MB/s\n2. 500 targets x 40 MB = 20GB\n3. 20GB/125MBs = 160 seconds\n下面的表格列举了在10GB网络下启动500台不同操作系统的Target Device时大致的带宽和启动加载时间：\n备注：防火墙会增加网络延迟，同时也会造成网络瓶颈，如果可能，最好禁用防火墙，如果实在不能避免，最好能开放一下端口的完全访问能力：\n20) 决断：网络配置\n为PVS服务器提供10Gbps网络能提供最够需要的带宽，如果做不到的话，1Gbps也可以提供足够的带宽，但是有可能会成为PVS服务器的瓶颈。将多块网卡做Teaming处理能提供更高的吞吐量，增加网络性能，也能阻止网络的单点故障。下表列出了PVS服务器的网络配置属性，从最大容量到最小：\n以下的NIC属性应当正确配置在PVS服务器以及Target Devices的NIC上：\n简单地说，就是禁用Checksum Offloading属性；关闭Auto Negotiation，使用强制配置；启用Jumbo Frame。\n21) 决断：交换机配置\n用于PVS服务器和Target Devices的网络交换机应当做一下优化：\nl 生成树协议（Spanning Tree Protocol**）/PortFast****：**禁用生成树协议，启用PortFast；\nl 风暴控制 Storm Control**：**在Cisco Catalyst交换机上将Unicast流量值设置大一些，或者是禁用Unicast Filtering。\nl Broadcast Helper**：**启用之，这样可以转发PXE和TFTP流量；\n22) 决断：Bootstrap交付\n在一个Target Device开始启动过程的时候，他会首先加载一个bootstrap程序，该程序会初始化Target Device和PVS服务器之间的流化会话过程。有三种方法让Target Device能收到bootstrap程序：\nl Broadcast Helper**：**启用之，这样可以转发PXE和TFTP流量；\nl 使用带有DHCP选项的PXE方式；\nl 使用不带有DHCP选项的PXE方式；\nl 使用Boot Device Manager**；**\n在企业无法提供PXE或者是TFTP服务的情况下，或者是无法对DHCP Scope选项修改的情况下，可以考虑使用Boot Device Management工具通过一个ISO文件来提供bootstrap文件。\n23) 决断：审计\n默认下审计功能是禁用的，管理员可以将将其打开。打开后该工具可以记录在Provisioning Services场内组件所做的配置修改记录，并将结果记录至数据库中。\n24) 决断：防病毒\n大部分的防病毒软件都会是扫描所有的文件和系统进程，对性能影响很大。所以在PVS环境下必须优化防病毒软件的配置。请参见CTX124185 - Provisioning Services Antivirus Best Practices。\n",
    "ref": "/2013/05/07/xendesktope8999ae68b9fe6a18ce99da2e7b2bee59381e4b9a6e7b18de5afbce8afbbpart5/"
  },{
    "title": "Top10全球排名前十的云计算公司",
    "date": "",
    "description": "",
    "body": "来自 http://www.intelligenthq.com/uncategorized/top-10-cloud-computing-companies/\nCitrix榜上有名排名第三，这就是我看好CloudStack一年多的回报，国内CloudStack目前看还没有什么生机，希望能早点发展起来。\nWe all know change is constant, especially in technology. Look at Toshiba, a world leader and innovator in high technology. This week, the company made an interesting move and announced the opening of Toshiba’s first datacenter in Europe, located in France.\nToshiba Cloud \u0026amp; Solutions Division is directed at professional markets, public and private-sector companies, and entities within the Toshiba Group. The creation of this datacenter is in line with the Group’s goal of accompanying its clients right from the design of IT products and solutions through to hosting related services tailored to specific needs.\nThe datacenter also hosts firms located in other regions, illustrating Toshiba’s broader ambitions. \n“Developing this first datacenter in Rhône-Alpes highlights the importance of the Grand Lyon project for Toshiba and embodies the group’s investment in the development of its Cloud offering,” explains Philippe Hartmanshenn, Managing Director of Toshiba Systèmes France’s Cloud \u0026amp; Solutions Division.\n“This allows us to move both internal and external client resources and services offsite to our high-security servers – located in France. We also plan to use the datacenter to develop and integrate business solutions for our clients from every sector.”\n__I felt the need to highlight this as it shows the importance of the cloud, as an important tool to innovation regardless of industry.\n\nSo who are the Top 10 players of cloud computing services that has been making waves recently?\n1. Google\nGoogle Cloud is the approach of Google to provide enterprise solutions to companies. Google Cloud Platform allows you to build applications and websites, store and analyze data on Google’s infrastructure. Companies can build websites, applications and service on this platform. Apart from these Google also offers Google Apps for businesses, which is now growing. Google has recently unveiled a “patent pledge” that it hopes will shield cloud software and big data developers from litigation. The pledge, which is like a non-aggression pact, covers ten patents related to Google’s MapReduce technology.\n2. Microsoft\nThe foundations of the Cloud OS are Windows Server and Windows Azure, complemented by the full breadth of our technology solutions, such as SQL Server, System Center and Visual Studio. Together, these technologies provide one consistent platform for infrastructure, apps and data that can span your datacenter, service provider datacenters, and the Microsoft public cloud.\n3. Citrix\nCitrix Cloud Platform provides the latest and most advanced open source software platform to build highly scalable and reliable cloud computing environments. Citrix offers three form of cloud computing – Hosted public cloud, Hosted private cloud and On-premise private cloud; Recently as per Info-Tech Research Group, Citrix Cloud platform is announced the Champion in Cloud Management Vendor Landscape. Citrix recently announced the availability of CloudPortal™ Business Manager 2.0, a cloud services delivery platform that enables enterprises and service providers to unify the commerce, user management, provisioning and operational aspects of a cloud into a single cloud interface for delivering anything as a service (XaaS).\n**4. Joyent ** San Francisco infrastructure-as-a-service provider, Joyent is the high-performance cloud infrastructure company, offering the only solution specifically built to power real-time web and mobile applications. Recently with the combined efforts of Joyent and Xeround (a cloud database company), Joyent customers can now access free and highly available with zero management MYSQL database. Xeround relational database is only available for Joyent Cloud platform.\n**5. CenturyLink ** CenturyLink, 3rd largest telecommunication company in USA and an established leader in providing networking solutions and cloud hosting services. CenturyLink recently announced that it’s providing 100 Gigabyte per sec (Gbps) networking solutions and will continue to provide best cloud infrastructure and IT hosting solutions. Savvis, a subsidiary of CenturyLink has collaborated with VMware Cloud Applications Marketplace to provide wide variety of applications packages to its clients from various software and hardware vendors.\n6. Amazon\nAmazon EC2 is an Infrastructure as a Service Cloud Computing Platform provided by Amazon Web Services (AWS), which allows users to provision or deletion of virtual computers. Amazon is one of the true innovators in Web-based computing, offering pay-as-you-go access to virtual servers and data storage space. Recently Amazon announced AWS CloudHSM, a new service enabling customers to increase data security and meet compliance requirements by using dedicated Hardware Security Module (HSM) appliances within the AWS Cloud. The CloudHSM service allows customers to securely generate, store and manage cryptographic keys used for data encryption in a way that keys are accessible only by the customer.\n7. IBM\nIBM Smart Cloud – IBM’s enterprise-class public cloud infrastructure-as-a-service (IaaS)delivers secure and scalable hosted IT infrastructure with on-demand access to virtual server and storage resources. BM recently announced global availability for its cloud service on five continents—plus a new center opening in Spain—based on its industry-leading sourcing business to host SAP applications and other core operations. Now clients can turn to cloud computing for enterprise applications while reducing the overall cost of IT and at the same time, expanding online access and investing in innovative analytics, social business and mobile computing.\n8. Salesforce\nSalesforce.com’s CRM solution is broken down into several broad categories: Sales Cloud, Service Cloud, Data Cloud, Collaboration Cloud and Custom Cloud. Saleforce is aiming be the first cloud computing company to hit the $4 billion annual revenue by 2014 and you can assume this from its 3rd quarter earnings. Salesforce will concentrate on social media, mobile computing and real time in a project it refers to as Cloud 2.\n9. Rackspace\nRackspace, an open cloud company is delivering enterprise-level hosting services to businesses of all sizes and kinds around the world since 1998 and have grown to serve more than 190,000 customers. Rackspace integrates the industry’s best technologies for each customer’s specific need and delivers it as a service via its commitment to fanatical support. Rackspace recently opened the doors to its Open Cloud Academy by launching a pilot training program. The Open Cloud Academy is an educational program designed to provide students with affordable IT certifications, specifically around open cloud technologies.\n10. Verizon Terremark\nVerizon started its cloud computing services as a part of its enterprise solutions. Its infrastructure services have helped many of the world’s top enterprises improve IT performance and evolve business processes. Verizon Terremark sets the standard for IT deployments with advanced infrastructure and managed service offerings that deliver the scale, security, and reliability necessary to meet the demanding requirements of enterprises and governments around the world. Terremark launched its Enterprise Cloud Private Edition a single-tenant environment and its OS- and network-agnostic strategy shows the telco cloud understands the value of accessibility and integration.\n",
    "ref": "/2013/05/07/top10e585a8e79083e68e92e5908de5898de58d81e79a84e4ba91e8aea1e7ae97e585ace58fb8/"
  },{
    "title": "XenDesktop虚拟桌面精品书籍导读(part4)",
    "date": "",
    "description": "",
    "body": "[su_box color=\u0026ldquo;orange\u0026rdquo; icon=\u0026ldquo;flag\u0026rdquo;] 感谢 Eric Yao 的供稿，@老树皮Eric [/su_box]\n桌面虚拟化项目的实施白皮书 《Citrix Virtual Desktop Handbook 5.x》，点击下载。\n四、 控制层 Control Layer 控制层是设计架构的第四层。在上面有关用户的三个层面我们所做的决定都会汇总起来到控制层。\n 访问控制器  访问控制器子层的职责是给每个用户提供予以支持访问控制层的基础架构组件。这么说可能比较绕口，那就换个说法吧，访问控制器一般包括例如Web Interface、StoreFront，以及NetScaler Access Gateway；\n1) 远程访问架构\n如果有用户需要远程或者是离线的移动访问能力，那么就要设计远程访问基础架构了。\n **A. **决断：拓扑  网络拓扑的设计对远程访问架构能够支撑功能性、性能以及安全性至关重要。远程访问架构应当和安全团队一起合作以确保符合企业的安全规范。以下三种主要的拓扑结构我们在设计师可以考虑，每种的安全性逐渐递增：\nl 1-Arm (Normal Security**，单臂模式)****：**在这种架构下，Access Gateway使用一个物理的或者是逻辑的Bonded的网络接口，再加上VLAN和IP子网的设计，来传递用户和后台虚拟桌面的流量。\nl 2-Arm (High Security 双臂模式)：在双臂模式下，Access Gateway利用两张或者更多的物理或者逻辑Bonded的网络接口卡，再加上VLAN和IP子网的设计，来传递用户和后台虚拟桌面的流量。前段用户的流量被导向这些网络接口卡的第一张网卡上，前后端的流量是被分离设计的，就是说说后端虚拟桌面架构服务器的流量是被定向到第二张网卡上的。通过这样的设计我们就可以DMZ区来分离前后端的流量，同时还可以定制防火墙策略和流量监控策略。\nl **Double-Hop DMZ (Very High Security): **这种模式既利用了双臂拓扑下的特性，又使用了两个单独的Access Gateway设备。有一些企业使用了三个物理的/逻辑的防火墙结构来保护他们的内部网络。这三个防火墙将DMZ区划分为两个区域来提供额外的内部网络安全。\n在第一个DMZ区的Access Gateway设备处理用户的连接，完成SSL VPN的安全功能。这个Access Gateway设备加密客户端连接，判断用户的认证方式，控制能够访问的内部网络服务器；\n第二个DMZ区域的Access Gateway设备充当与一个代理设备角色。这个Access Gateway设备启用ICA协议将客户端连接穿越第二个DMZ区到后端的服务器场。在第一个DMZ区的Access Gateway设备和内部网络的Secure　Ticket　Authority（STA）也是通过第二个DMZ区的Access Gateway设备来进行代理的。\n **B. **决断：平台  在Access Gateway部分，我们曾经讨论过只要是涉及到远程访问，我们都会考虑NetScaler Access　Gateway设备。问了确定合适的NetScaler平台来满足项目需求，必须确定一些关键资源。由于所有的远程访问流量都是通过SSL（安全套接层）来加密，再通过HTTPs的HTTP（超文本协议）协议来传输。所以有两种资源metric需要确认：\nl **SSL****吞吐量：**SSL吞吐量是定义为每秒钟能处理的GB SSL流量；\nl **SSL每秒交易量（TPS）：**TPS metric定义在每秒每个应用程序交付控制器（ADC）能处理的SSL交易数量\n关于这两个参数的更详细解释，可以参考：Best Practices for implementing 2048-bit SSL\n平均的SSL带宽开销在和虚拟桌面的开销比较起来时经常忽略。但是SSL带宽的计算将会有助于确定总带宽是否足够。固定带宽加上数据包头开销常常随着加密算法的不同而变化，总带宽开销也常常随着数据包尺寸大小的变化而不同。理想状态下，开销数字应当通过POC或者是Pilot来实际测试得来，但是在没有这些数据的情况下，在工作负荷带宽基础上加上2%是一个合理的数字。因此，在确定NetScaler平台的时候，SSL的吞吐量常常是最大并发带宽乘以1.02，即：\nSSL吞吐量 = 最大并发带宽 × 1.02\n例如：假设128M是最大的并发带宽，那么最合适的NetScaler模型应当计算为：\n约130Mbps = 128M × 1.02\nNetScaler有三种平台，每种都提供了大量的不同的扩展性：\nl VPX**：**VPX平台的NetScaler和硬件的NetScaler提供完全一致的功能，不过他只适合于小型的测试环境使用。****\nl MDX**：**NetScaler MDX是NetScaler设备的硬件版本。他能支持大型网络可扩展环境；****\nl SDX**：**NetScaler SDX设备是在物理NetScaler设备和虚拟NetScaler设备之间的一个桥梁。一个SDX设备能够划分为多个虚拟的NetScaler设备。****\n2) StoreFront\nCitrix StoreFront是Web Interface的下一代产品，它验证用户连接到后台的XenDesktop站点、XenApp场，以及AppController（SaaS应用），然后枚举或者是聚合可用的桌面和应用程序到商店以便让用户通过不同操作系统平台上的Receiver来访问，包括安卓、iOS、Linux、Windows、Win8/RT以及Web站点。\n C. 决断：Web Interface还是StoreFront  Web Interface和StoreFront是两种不同的解决方案，在一些功能方面有重叠。所以我们要认真评估我们的需求。一般来说，新的方案应该使用StoreFront，因为Web Interface已经不再有新功能添加了。可以参考下面的链接了解Citrix 桌面产品的生命周期：Lifecycle Milestones for Citrix XenDesktop\n下面的表格也示例了在何种情况下该使用什么产品：\n下面的表格对两种产品在未来功能的开发目标上进行了一个对比，Web Interface已经不再会有革命性的功能添加了：\n下面的表格是功能对比：\n有一些Web Interface有的功能也会被完全整合到未来的StoreFront新版本中去：\n **A. ****决断：Web **服务的高可用  如果StoreFront服务器不可用，或者是其他对应的Web服务不可用了，那么用户就不能连接到新的会话，例如打开新的虚拟桌面，无法打开应用程序等操作，因此，至少需要规划两台StoreFront来预防单点故障问题。我们可以考虑的方案包括：\nl DNS Round Robin**：**在多个服务器之间提供基本的负载均衡功能，无法做到是否可用性的检查；在服务器宕机时，部分用户会受到影响。****\nl Windows NLB**：**是Windows的一个服务。可以做一些基本的检查来判断服务器是否可用，但是无法判断单个服务的状态。\nl Citrix NetScaler**：**智能硬件设备，能检查StoreFront服务的状态，根据用户请求主动激活负载均衡状态。\n **B. **决断：应用程序订阅数据库的高可用  StoreFront的配置数据都存储在每一台StoreFront服务器的本地，然后被复制到服务器组中的其他的系统中。对比之下，用户应用程序订阅信息存储在应用程序订阅数据库中，该数据库可以是本地的StoreFront服务器，也可以是推荐的一个专门的Microsoft SQL Server。\n如果应用程序订阅数据库不可用，以下功能将不可用：\nl 用户不能在管理他们的应用程序订阅；\nl 无法登陆至Web 方式的Reciever，但是已经建立起来的会话可以继续正常工作；\n为了防止应用程序订阅数据库成为单点故障点，Citrix推荐SQL的高可用方案：\nl **自动容错的SQL**镜像：数据库镜像提供了一种比数据库Clustering更简单的快速容错方法。数据库镜像技术在每一个镜像点上需要一个标准的SQL标准版服务器License，在加上一个witness服务器的SQL Express License即可。更多细节可以参考文档：Configuring StoreFront using the Configuration Files.\nl SQl Clustering: 微软的技术，不过老实说，相比较Mirroring技术配置太复杂，此外，自动容错的过程也更慢。在License上，每个Cluster节点都需要一个企业版的SQL license。\nl **Hypervisor****高可用：**数据库部署在一台虚拟机上，通过Hypervisor的高可用来实现。这个技术比镜像或者是clustering都要便宜，因为只需要一个SQl Express License和一台SQL Server（需要一个具备HA功能的Hypervisor License）。不过，这个技术容错过程较慢，也仅仅是当SQl Server的操作系统宕机时才能启动容错机制。如果数据库服务出现错误是无法被Hypervisor层检测到的。\n注意：未来的StoreFront__版本将不会再使用应用程序订阅数据库（Application Subscription Database_），相反，预订信息会自动的在StoreFront__服务器组中的StoreFront__服务器中自动复制。_\n **C. **决断：容量规划  基于扩展性的测试，单个StoreFront服务器可以支持的用户数是无限制的，受限制的是在这个服务器上每小时之内用户同时操作的动作。这是因为仅仅当用户执行一个动作的时候，例如在Receiver中订阅一个应用程序是，StoreFront才被使用。当用户连接到所发布的资源时，StoreFront实际上是idle状态的。因此，下面的表格所展示的内容介绍的是没鸟的请求时，或者是每小时的请求数。我们建立了一个前提条件是每用户在每小时之内启动了五个应用程序，订阅了2个应用程序，取消订阅了一个应用程序，总共每小时是8个操作量。\n注意：上述数字是在仿真环境下测试得来：基于SSL的XenApp6.5，发布了100+个应用程序，每个用户在5秒钟之内完成操作的。\nStoreFront对CPU的数量更敏感，也就是说对CPU的消耗更大，而不是对内存消耗更大。推荐的企业StoreFront服务器是4个vCPU和4GB RAM。\n **D. ****但服务器扩展性 – **应用程序订阅数据库  应用程序订阅数据库包含了每个用户订阅的一系列资源列表情况。基于测试环境下，推荐的一个储存应用程序订阅数据库独立SQL服务器的配置是4vCPU和4GB RAM。\n数据库的增长速度大约是每个订阅10KB空间消耗：\n数据库大小 = （用户数 × 每用户的订阅数） × 10KB\n1个订阅 = 1个用户订阅一个应用程序，例如，1000个用户订阅10个应用程序就是100MB。\n 桌面控制器  这部分内容主要是介绍XenClient部分，请大家自行参见原始文档。\n下期预告：下一期我们介绍最后的部分：Provisioning Services\n",
    "ref": "/2013/05/02/xendesktope8999ae68b9fe6a18ce99da2e7b2bee59381e4b9a6e7b18de5afbce8afbbpart4/"
  },{
    "title": "Ask the Architect 推荐Citrix虚拟化大师一名",
    "date": "",
    "description": "",
    "body": "http://virtualfeller.com/\n",
    "ref": "/2013/05/02/ask-the-architect-e68ea8e88d90citrixe8999ae68b9fe58c96e5a4a7e5b888e4b880e5908d/"
  },{
    "title": "我的第一次半程马拉松比赛",
    "date": "",
    "description": "",
    "body": "[nggallery id=18]\n第一次的半程马拉松比赛，跑的非常艰苦，鞋子和脚趾出现严重的状况，中途已经痛的我呲牙咧嘴；烈日艳艳的高温，让整个人都快从脚底板燃烧起来了。到了终点，一个大约坑爹的1公里折返跑彻底让人筋疲力尽。\n比赛就是比赛，一旦开始就没有退出，只有坚持到底的人才能收获成绩。\n",
    "ref": "/2013/04/23/e68891e79a84e7acace4b880e6aca1e58d8ae7a88be9a9ace68b89e69dbee6af94e8b59b/"
  },{
    "title": "bad thing will pass",
    "date": "",
    "description": "",
    "body": "\n",
    "ref": "/2013/04/23/bad-thing-will-pass/"
  },{
    "title": "让Xen Project回家",
    "date": "",
    "description": "",
    "body": "\n首先我们来回顾一下历史： \n上周Citrix把经营和支持多年的开源项目Xen Project加入到了inux Foundation，可以说是Xen Project 的一个新家。可能您还不太了解“Linux Foundation”；访问 FAQ 可获得它的一些基本知识。到目前为止Linux Foundation总共支持了8个开源软件项目。\n[![OpenDaylight](http://www.linuxfoundation.org/sites/main/files/logo_od_small_0.jpg)](http://www.opendaylight.org/)  [![](http://www.linuxfoundation.org/sites/main/files/wlogo_caf.jpg)](https://www.codeaurora.org/)  [![](https://www.linuxfoundation.org/sites/main/files/wlogo_omam.jpg)](http://www.openmama.org)  [![](https://www.linuxfoundation.org/sites/main/files/wlogo_tize_0.jpg)](http://www.tizen.org)   [![](https://www.linuxfoundation.org/sites/main/files/wlogo_meeg.jpg)](http://www.meego.com)  [![](https://www.linuxfoundation.org/sites/main/files/wlogo_yoct.jpg)](http://yoctoproject.org/)  [![](http://www.linuxfoundation.org/sites/main/files/xen_project_unicolor_0.jpg)](http://xenproject.org)  [![](https://www.linuxfoundation.org/sites/main/files/wlogo_fbaz.jpg)](http://fossbazaar.org/)     那么Linux foundation能给这些开源软件提供怎么呢？ With ten years of experience managing open source projects and support services, The Linux Foundation can provide the back-office, technical infrastructure and legal framework to get your collaborative project off the ground quickly and efficiently. 想加入Linux fondation的项目还必须满足如下两个标准：\n  The use of open source governance best practices including license and contribution agreement choices in keeping with the ideals of Linux\n  The project must have the potential to fuel innovation in an industry through collaborative software development\n  我个人认为，这对于Xen Project和Citrix双方来说都是一个好事，Xen Project可以获得跟光明的发展前景，Citrix的商业产品XenServer也基本上可以直接从中受益。对Xen的处理，Citrix的做法和处理CloudStack是相同的，只是CloudStack交给了Apache组织。在国外这是一种成熟和成功的商业模式，开源软件项目周边发展出的是生机盎然的生态系统。\nCitrix的官方新闻 ：Citrix and Industry Leaders Usher in New Era for Open Source Xen //Strong Industry Support Drives Need for Independent Xen Project Initiative Xen Project官网新闻：Xen is now a Linux Foundation Collaborative Project Linux Foundation 新闻：Xen to Become Linux Foundation Collaborative Project Jim Zemlin （Executive Director of Linux Foundation）欢迎Xen的加入： Welcome Xen as a Linux Foundation Collaborative Project 对Xen Project做持续贡献的厂商么是这么反馈的： 查看 Xen Project的旧家：http://www.xen.org/ Xen Project 的新家：http://xenproject.org/ 请记住Xen的标志物，功夫熊猫：[gallery ids=\u0026ldquo;52363,52365,52366\u0026rdquo;]\nZDNet 的评论： Xen, Citrix\u0026rsquo;s popular open-source hypervisor, is becoming a Linux Foundation Collaborative Project with the backing of such major technology powers such as Amazon Web Services, Google, and Intel.\narstechnica.comd的评论：Linux Foundation takes over Xen, enlists Amazon in war to rule the cloud ///Xen virtualization gains support from Amazon, Cisco, Google, Intel, and more.\n",
    "ref": "/2013/04/23/xen-is-now-a-linux-foundation-collaborative-project/"
  },{
    "title": "XenDesktop虚拟桌面精品书籍导读(part3)",
    "date": "",
    "description": "",
    "body": "[box color=\u0026ldquo;orange\u0026rdquo; icon=\u0026ldquo;flag\u0026rdquo;] 感谢 Eric Yao 的供稿，@老树皮Eric [/box]\n桌面虚拟化项目的实施白皮书 《Citrix Virtual Desktop Handbook 5.x》，点击下载。\n智慧的积累靠一蹴而就很难实现，慢慢积累和温故而知新往往是最佳的手段。让我们继续开始《Citrix桌面虚拟化实施部署白皮书》，这晚我们开讲第二部分的第三单元：桌面层。\n四、 桌面层 Desktop Layer\n设计思想的第三层，也是和用户相关的最后一层，就是桌面层。用户是否能接受桌面虚拟化很多程度上就是在这一层实现的，例如包括个性化、应用程序，以及后台操作系统镜像文件的设计。\n 应用程序交付  选择正确的应用程序交付方法会对整个系统设计的可扩展性、可管理性，以及用户感受起到非常大的帮助。基于我们在前几章节的“四、 应用程序数据搜集”，我们可以考虑以下几种交付方法：\nl 直接安装在操作系统镜像文件上：应用程序是基础操作系统镜像文件的一部分；\nl 安装在Personal vDisk上：物理是分离的，但是逻辑上是直接安装在基础操作系统镜像文件中；\nl 流化（Streaming）：应用程序被profiled（XenApp组件）后通过网络交付到桌面上。应用程序的文件和注册表键值在虚拟桌面的一个容器中保存，但是和基础操作系统镜像文件是分离的。\nl Hosted：应用程序安装在XenApp服务器上，用户通过Citrix HDX协议远程访问。\n 决断：应用程序交付方法  系统架构师应该在基于用户需求、应用程序兼容性，以及其他通过在前几章（“四、 应用程序数据搜集”）搜集上来的应用程序因素基础之上决定采用何种方法来进行应用程序的交付。通常单一的方法是无法满足用户全部的需求的，所以多种方法组合才是最佳答案。但是不管用什么方法，这些交付手段都应当对整个项目的交付复杂程度和后续跟进步骤与以最小的影响。\n下面的表格就是不同的交付方法对系统不同层面的影响：\n除了应用程序交付方法对系统不同层面的应用之外，系统架构师还应该考虑应用程序在不同交付手段上的适用性。下面的表格就是不同应用程序所推荐的部署方法示例：\n上表中需要注意的是最后一种应用程序，我们往往会觉得这种复杂安装和配置的应用程序最好是安装在操作系统镜像文件中，但是最佳实践告诉我们应该安装在XenApp Server上，通过Hosted的方法发布给用户。\n兼容性  任何一个桌面虚拟化项目都会对一个公司的应用程序交付方法产生巨大的应用。举例来说，许多公司都希望通过在桌面虚拟化中使用流化的应用程序交付或者是XenApp交付应用程序来降低升级用户的桌面操作系统的劳动负荷以及提高管理效率。所以在设计阶段我们就要做很多兼容性测试以确定最正确的应用程序交付方法。最重要需要考虑的兼容性需求一般来说包括以下几点：\nl 桌面操作系统的版本：如果操作系统是通过流化安装或者是直接安装在操作系统中，那么应用程序需要考虑和操作系统的兼容性问题；\nl 服务器操作系统的版本：有一些应用程序可能会更合适通过XenApp的方式来交付，所以，应用程序是否能安装在服务器版本的操作系统平台上是要考虑的因素；\nl 应用程序本身的架构：应用程序本身的开发平台有可能是16位的，32位的，也可能是64位的。16位的应用程序就不能运行在64位的操作系统平台上，例如Windows 2008Server　R2、Windows XP 64bits等；\nl 互操作性：有一些应用程序如果和某些版本的操作系统共存是会有兼容性问题，例如注册表冲突、DLL冲突，或者是ini冲突。\nl 应用程序流化：应用程序流化到桌面虽然可以简化管理，因为操作系统上不用安装那么多的应用程序了，但是记住有些带有设备驱动程序，或者是使用了COM+等应用程序就不适合了\n在做应用程序兼容性测试时的三种主要技术手段有：\nl 手动：不言而喻这种方法最消耗时间，每种交付方法都要测试，每种操作系统版本、不同操作系统语言包等也都要验证。手动模式下想要的出应用程序所有方面的测试结果是非常困难的，对应用程序互操作性的测试是几乎测不出来的。而且更多的测试结果是现场使用人员发现的，而不是测试时发现的。\nl 预验证的应用程序：很多应用程序的开发商都会提供该应用程序的兼容性文档和最佳安装方式的文档。参考这些文档会有直接的帮助。此外，Citrix Community Verified的网站上也有一整系列的由Citrix的客户和合作伙伴验证过包括采用流化方法/XenApp/Xendesktop兼容的应用程序列表。微软公司也提供了类似的应用程序列表：Microsoft Windows 7 Application Compatibility List for IT Professionals；\nl 自动化的工具：Citrix AppDNA可以快速而且准确的对应用程序的兼容性做出精确的测试，包括测试不同的操作系统平台，测试不同的交付手段，例如Windows XP、Windows 7、Citrix XenApp、Microsoft App-V，以及Citrix Streaming流化交付方式等。应用程序被导入到AppDNA时，它会被和数千种应用程序进行兼容性的匹配验证以判断是否有互操作性问题。当发现问题时，AppDNA会告知问题出自何处，可能的解决办法，以及估计解决的时间。\n上述每种方法的优点和缺点都列在下表中：\n测试做完之后，兼容性的结果就应该填入到之前的应用程序评估表各种以便我们的后续分析：\nl 预运行环境：许多程序都有运行环境的要求，例如Java、.Net环境，或者是数据库要求；\nl 程序之间的依赖：例如，需要以pdf格式呈现信息的应用程序就需要电脑上安装了pdf的阅读器；\nl 16位的代码：应用程序评估也应该判断是否应用程序包含有16位的代码，因为16位的代码是不能运行在64位的操作系统平台上；\nl Windows XP：确认应用程序是否能通过Windows XP的兼容性测试；\nl Windows 7：确认应用程序是否能通过Windows 7的兼容性测试；\nl XenApp 6.5：确认应用程序是否能通过XenApp 6.5的兼容性测试；\nl Application Streaming 应用程序流化安装：确认应用程序是否能通过流化程序安装的兼容性测试；\n用户分类  通常不是所有用户都需要所有的应用程序，有些程序可能就只有很小一部分用户用的上。所以系统架构师应该做好这个工作，例如如果一个部门的用户都需要的应用程序列表组，我们可以单独做一个操作系统镜像文件。如果只有少部门用户需要使用，那我们建议采用Personal vDisk或者是Streaming的方式交付应用程序。\n业务特点  l IT经验：如果IT部门已经对某种应用程序交付方式有经验，或者是基础架构已经Ready了，那么这种交付模式可能就是合适的方式。例如，如果公司内部已经通过Microsoft App-V平台部署过Streaming的应用程序，那么XenApp Streaming 应用程序就应当优先被考虑。\nl 管理需求：应用程序交付的方法很可能严重依赖于应用程序的拥有着。如果应用程序是公司拥有的程序，那么IT部门就有责任和义务来维护该应用程序，包括XenApp发布或者是XenApp流化。如果程序的拥有者是某个下级部门，那么IT部门就不方便集中管理，这种情况下应用程序可能就建议安装在Personal vDisk上，让部门自己来管理该应用程序。\nl 升级频率：应用程序的升级所需要花费的时间和部门协调也对交付模式的选择有很大影响。如果应用程序经常升级，那么系统架构师就应当选择安装数量最少的交付模式，这样可以减少升级的应用程序数量，以及降低升级的复杂程度。这种情况西XenApp交付方式最为合适；\nl 产品Licensing：如果应用程序没有License要求，例如和软件厂商签订了Site License，那么我们可以将该程序发布给所有的用户也不会产生其他任何成本，将该程序直接安装在操作系统模板里面也能降低交付的复杂性。如果应用程序对License很敏感，系统架构师就需要考虑采用一种能够遵守应用程序软件提供商要求的License模型。\n技术特点  l 资源使用：如果应用程序对资源要求很高，可能会更合适于直接在虚拟桌面里面直接运行；\nl 技术难点：如果一个应用程序的安装都很复杂，例如需要专门的配置，脚本的运行，或者对其他应用程序有很多要求，我们称之为技术难点。这种情况下，安装在XenApp Server上能减少操作系统镜像文件制作的复杂性。\n",
    "ref": "/2013/04/16/xendesktope8999ae68b9fe6a18ce99da2e7b2bee59381e4b9a6e7b18de5afbce8afbbpart3/"
  },{
    "title": "什么是真的云？",
    "date": "",
    "description": "",
    "body": "[su_box ] 最近有一篇比较热的文章，中文标题《Forrester：70%的“私有云”根本不是云》；你如果稍微搜索一下，你发现它几乎被转载烂了，但是我看了几篇，真心的担心读者们是否都能正确的理解。写本文，全当是给您的一个阅读帮助。 [/su_box]\n中文版网页点这里 英文版网页点这里\n中文翻译的质量有限，有些概念和逻辑错误，我做了一点点的修订，从而避免误解。\n**【基于CNW.com.cn译稿】**如果企业数据中心拥有高度虚拟化的环境，有一个Web门户供商业用户申请和访问虚机，再有一种方法可以跟踪有多少资源被使用了……拥有这一切并不能叫做有了一个私有云。\n假如有足够大的容量可以为员工提供他们所需要的任意数量的计算资源，并能够动态地上下扩展或收缩容量，但仍然需要IT人员制备好系统的话，那么这仍然不能叫私有云。\n虚拟化和私有云之间的界限是比较模糊的，根据Forrester的最新报告，在企业的IT高管们所自诩的私有云中，高达70%的IT环境其实并非私有云。“这是个严重的问题。实际上是在做云洗白而已。”Forrester的云专家James Staten如此说。\n为什么说这个问题非常重要? Staten认为，如果将一个高度虚拟化的环境称为云环境，但它又不具备私有云的一项或多项关键特征，那么IT部门就给了用户一个不切实际的期望。假如用户们发现这个环境不能自配置，或者没有弹性资源池而感到不满时，他们就有可能因此而气馁。那么当下一次用户需要实时运行一个虚机时，他们会选择在哪里运行呢? 是IT部门给他们的伪私有云? 还是亚马逊的AWS? 如此一来，IT部门就无法控制事态了。\n大多数云专家已经对云计算(公有云或私有云)的定义有了普遍的共识，这就是NIST提出的五个关键特征。这些特征包括：\n● 用户可按需索取、自服务\n● 泛在的网络接入\n● 共享资源池\n● 弹性扩展资源的能力\n● 拥有可计量的服务\n如果没有这五大特征，那从技术上说就不能叫云。和某些人的想法相悖的是，虚拟化并不是私有云。它只是为云提供动力的一个基本要素，但只依靠它是创建不出一个云的。VMware的营销经理Mike Adams说，私有云必须在虚拟化环境之上综合更多复杂的管理功能，方能满足NIST的定义要求。\nCA的战略解决方案副总裁兼云专家Andi Mann给这场讨论踩了一脚刹车。“如果你不符合所有这五大特征，那么你就陷入了语义学纠结中。”他认为真正的问题并不是说符合这五个复选标记的东西就叫做云，而是在于IT能否为用户提供适当的服务。“有时候，80%的云都已足够好了，”他说。“用户真正在意的是业务服务。谁会在意你的环境叫什么。你要关心的就是客户，就是业务用户是不是得到了他们需要的资源。”\n也许企业并不需要弹性扩展，因为原本就是静态工作负载。即便不需要弹性的资源扩展能力，它仍然还可以需要云的其他特征——自服务、计费、泛在网络接入和共享资源池。但它在技术上可能并不符合NIST的定义。“所以，如果你要想技术上也说得过去，也可以将其称为：高效率的虚拟环境，”Mann说。\n那么，所有这些云洗白来自哪里? Staten认为，IT管理人员基本上对云都抱有恐惧心理。企业内的虚拟化专家通常都处于支配地位; 在需要资源时，他们可以去制备相应的资源容量。而云被视为一种赋予用户自服务和动态扩展资源权力的模式，对IT是一种威胁。如果用户可以自己开通了，那还要他们这些虚拟化专家干什么呢?\nStaten认为，这样想上述问题是错误的。即便有了云，IT管理人员还是有大量的工作可做，比如需要设置和确保云服务有一个可供用户选择的服务目录，需要完成安全访问协议配置，提供资源可用性和虚拟化组件等。管理人员必须接受这样一个理念：如果他们不这么做，那么用户不论如何还是需要访问和使用他们所需要的资源，这样还是会陷入可怕的“影子IT”的局面。(Martin修订)\n我想先对以上的几个关键点和名词做一些解释，从而能让我们更好的理解原文作者的意图。\n  \u0026ldquo;cloud-washing\u0026rdquo; \u0026ndash; “云洗白” 这个比喻是说：本来根本什么云都不是！但是还是要狡辩和伪装为私有云。真像是：纯虚拟化环境不等于云\n   \u0026ldquo;shadow IT.\u0026rdquo; \u0026ndash; “影子IT” 这个比喻是说：IT部门是业务部门挥之不去的阴霾，他们跟没发赶上业务部门需求变化请求的脚本，业务部门的人从来不管你是用的是神马云，你们这帮人根本没有按时的交付过任何东西，甚至于每当想起需要IT部门来配合做什么东西，就感到没有指望，啥都需要漫长的等待。\n  IT部门真的是技术不行么？IT部门真的是干活的人不够么？这个比喻后背后真是的故事：特别是大规模的企业，业务部门所需要的任何IT资源和变更都必须通过IT自动、半自动或者手工配置实现；小的到开通一个邮箱，重置一次密码；大到新的业务系统的升级和上线；往往IT或者业务用户发频繁和密集地发起种种请求时，没有任何一家传统企业的IT部门（亚马逊、谷歌这种公司除外，因为它们已经是云计算公司了）能够很有自信地、充分让业务部门满意地完成被要求完成的所有工作。它们为什么完成不了呢？这个就走入了IT管理的经典理论，这就是我之前十年工作经验中天天和用户沟通的东西：“保持IT系统的稳定，还是接受变化”；为了既能响应业务部门不断的变化请求和IT用户的日常需求，IT部门想到了很好的流程来加以解决，这个流程是什么？它叫“变更管理流程”。举个例子，大型的商业银行一般一周或者两周有一次系统变更日；所有的对IT系统的配置和改变，必须提前计划安排好工作顺序，只能在变更日当晚的固定时间窗口中完成，例如晚上11点到凌晨5点；如果在这个时间段某个工作没有完成怎么办？对不起！没有完成的变更叫做失败变更，你还必须在变更窗前前就把系统回退到未变更前的状态！你现在发现了么？对生产系统是多么严肃的事情！如果你在变更前，没有万无一失的备份计划，你但失误，你就歇菜了；或者你觉得是顺利完成变更了，但是营业厅一开门，IT的投诉热线就被打爆了，这也不行；变更一但导致生产系统的宕机，轻则IT部门的领导引咎辞职，重则数据中心的大领导乌纱帽不保。\n以上讲述的故事可以说是我的亲身经历，就是中国的国情；那么这个文章的出处毕竟是国外的，这几个发话的大佬们都是何方神圣？\nForrester的云专家 James Staten ：BIO 从Bio上看，他好像是Forrester的头牌云分析师之一，有20年的IT从业经验。\nVMware的营销经理Mike Adams ：网上查不到它的Bio，在VMWare网站搜索，也只能看到他是http://blogs.vmware.com/vsphere/ 的负责人。网上并没有关于此人的详细介绍，但是我们从vsphere的blog上在读一下这个产品的定位“BEGIN THE JOURNEY TO A PRIVATE CLOUD WITH DATACENTER VIRTUALIZATION”；这个说法和此大师在文章中说的一样：vsphere是数据中心虚拟化的一个技术组建，数据中心虚拟化技术是私有云建设的起点。但是它是起点，不是私有云。纯种的服务器虚拟化项目也不是那天就能进化成私有云了。\nCA的战略解决方案副总裁兼云专家Andi Mann ：BIO 从Bio上可以看出，这大叔才是练家子，人家84年从IT管理员出身干起；感觉它说的话比较在点子上，并没有去忽悠云；而是从云的本质，也就是IT的本质去看，去分析的。也就是“IT是提供服务和支持的，为的是让用户能够操作和使用业务系统去完成业务工作。” 如果这句话抽象，我可以举个例子：领导需要阅读邮件，他关心的是IT能否让我安全的在设备上查邮箱，浏览和回复邮件；当然你能让他在任何设备、任何网络上、任何时间都能完成以上动作，那就再好不过了。银行的储蓄业务柜员需要的是完成一个存、取钱、开销户等相关操作，他关心的是IT系统能够正常快速的相应，让客户快速的离开柜台；她根本不关心，网线后面连接的系统是啥做的。\n言归正传：把焦点放到“云”的概念上一点意义都没有！倒不如把心思放在云的价值上；把心思放在私/公有云的建设方案上！我试图从云计算的基础特征上来解读一下云计算对云企业的价值：\n  用户可按需索取、自服务：让用户能够更方便的访问（请求、开通和使用）IT资源和服务，用户无需等待，资源召之即来\n  泛在的网络接入：个人觉得这个应该翻译为高速度高带宽的网络接入，这个是外界访问到计算资源的必要条件之一；如果你资源再多，但是出口太窄也没有意义；如果翻译成这样也凑合如果能理解为，在个中网络条件下都能够正常安全的加入到云所提供的IT服务上也可以。\n  共享资源池： 这个可以提高IT资源的利用率，利用率高了，投资就减少了，浪费了低了\n  弹性扩展资源的能力：这个可以应付突发的大批量用户访问请求，并且能够自动资源回收，最重要的是这些扩展和收缩的发生都是云系统自动完成的，不需要管理员手工操作\n  拥有可计量的服务 ： 这个对于IT部门需要向用户收钱的实在是重要；或者对服务提供商更重要，如果国内的用户实在没有这个需求也可以不强求。\n  那么，我们清楚了云的标准和价值后，我们需要判断的是什么？我认为是，我们为什么要建云？你在建云的时候，必须要有一个原因；有了这个原因了才有云的价值取向，才能谈到云的需求，才能谈到云的方案。当然，云就是以云的方案和设计理念去建设的，不存在伪云计算最终能进化或者发展成云计算这一说，就像是，猴子长的年纪在大也无法开口讲话一样。厂商也要不要故意误导，用户也不要片面理解。\n在引申一下：云计算和虚拟化究竟有啥关系？我斗胆从云的经典分类上来说Iaas\\PaaS\\SaaS；从技术上讲，只有IaaS和服务器虚拟化有必然联系，其它两种PaaS和SaaS可以和虚拟化一点必然关系都没有，但是如果他们需要的话，可能可以利用到虚拟化技术的某些优势，但是用非虚拟化技术的架构实现这两种云计算一点问题都没有。网上盛传的“虚拟化是云计算的基石”根本就是一种误解；不过虚拟化的确能帮你做很多事，能帮助你交付很多种的IT服务。如果你一定要把他们挂上钩，那么你需要回答的是，你是否要建设IaaS云？你的IaaS云管理平台是什么，要关注在IaaS云计算管理平台的功能和能力上来，看你的IaaS是否需要管理多种类型的Hypersior？是否需要管理到分布在各地的成千上万个服务器？等等。。。从这些需求中才会细化出IaaS云管理平台对服务器虚拟化平台的需求。云计算建设是自顶向下的过程，从清晰的概念和建设思路出发，切勿本末倒置，切勿舍本逐末。\n",
    "ref": "/2013/04/15/forrester-private-clouds-what-is-cloud-computing/"
  },{
    "title": "XenDesktop虚拟桌面精品书籍导读(part2)",
    "date": "",
    "description": "",
    "body": "[box color=\u0026ldquo;orange\u0026rdquo; icon=\u0026ldquo;flag\u0026rdquo;] 感谢 Eric Yao 的供稿，@老树皮Eric [/box]\n桌面虚拟化项目的实施白皮书 《Citrix Virtual Desktop Handbook 5.x》，点击下载。\n上周一我们介绍了《Citrix桌面虚拟化实施部署白皮书》的第二部分《设计篇 Design》的第一单元：用户层。今天我们继续往前进，开讲第二单元：访问层的部分。\n三、 访问层 Access Layer\n访问层的设计主要是基于每个用户组和终端设备的移动性需求。\n 决断：认证点  让用户在什么地点做认证是管理员的决定，一般而言，有四个认证点：\na) Web Interface：给XA和XD提供安全访问；\nb) StoreFront：为Receiver交付认证能力和资源；\nc) Secure Gateway (Web Interface): Secure Gateway是一个Windows的应用程序，她和WI配合工作；\nd) Access Gateway: 硬件\n具体采用哪种方式认证由用户组的移动需求来决定，推荐方案如下：\n决断：预认证策略  如果我们使用的是Access Gateway，我们就可以选择是否采用预认证策略，这些策略可以是确定终端是否满足某种接入网络前的扫描条件。\n我们可以配置的策略包括测试防病毒软件、防火墙软件、操作系统，甚至是注册表键值。XA和XD可以利用这些策略的检查结果确认后续的动作，包括剪贴板是否开启，打印机映射，甚至是否开启特定的应用程序访问权限。例如，如果用户没有安装防病毒软件，可以配置策略隐藏敏感的应用程序。\n下面的图标从流程上示例策略配置是如何流转的：\n决断：认证策略  l Web Interface, Secure Gateway (Web Interface), or StoreFront: StoreFront是未来的方向，而Web Interface已经是行将就木，所以下面的策略主要是用在StoreFront上，当然也适用于Web Interface\nn 用户名/密码\nn Domain Pass-Through：允许从用户设备上透传Domain登录信息，用户登录到加入域的电脑后自动登录到Store；\nn Access Gateway Pass-Through：用户登录到Access Gateway后自动登录到Store\nl Access Gateway：NetScaler支持几种不同的认证手段。下面分别列出了几种主要的认证方法，每种方法都可以单独使用，但是在实践中，我们进场组合起来以提供多因素认证。\nn LDAP：轻型目录访问协议是我们最为熟悉的认证方法了，它是一种基于TCP协议的目录访问服务，例如MS的活动目录就是其中一种实现形式。\nn Radius（aka Token）：Radius全名是Remote Authentication Dial In User Service，这是一种基于UDP传输协议的安全认证协议。除了认证外，它还提供授权和计费功能。Access Gateway转发用户输入的用户名和密码给Radius服务器，Radius服务器可以立即检查用户名和密码，也可以转发给目录服务器。\nn 客户端证书：用户登录到Access Gateway虚拟服务器后，可以通过本地的客户端证书的属性来做认证。客户端证书通常在用户端的形式是智能卡，或者是Common Access Cards (CACs)的形式，再通过客户端本地的读卡器来读取信息。\n采用什么认证形式通常都是取决于安全的需求，以及使用什么认证点。下表给出了一个基于安全需求级别的示例：\n决断：会话策略  采用Access Gateway作为认证点的用户必须有对应的会话策略来定义用户体验。会话策略的制定是基于Receiver在设计阶段制定的。一般而言，首先我们会将设备分为非移动设备和移动设备两种：\nl 移动设备：表达式定义为：“REQ.HTTP.HEADER User-Agent CONTAINS CitrixReceiver”，该语句将移动设备设置为比非移动设备更高优先级以保证移动设备的匹配性。\nl 非移动设备：表达式定义为：“ns_true”，即所有流量。\n更多信息，可以参考Citrix公开电子文档：Receiver and Plug-ins\nBTW，另外一种会话策略是采用终端的扫描方法。\n决断：会话Profile（Session Profile）  每个会话策略（Session Policy）都必须定义一个对应的Session Profile（姑且翻译成会话配置文件）。这个会话配置文件定义了用户去访问资源时的访问细节。有两种定义到虚拟桌面环境的访问方式的会话配置文件的形式：\nl SSL VPN：传统的VPN方式，将网络全部打通。这种方式并不一定十分安全，因为这能导致客户端到内网服务器的攻击访问。\n另外一种办法是考虑是否在SSL VPN中开辟一条给客户端网络流量的单独通道。这样通过receiver的流量智慧限制在指定的端口，只能访问指定的服务器资源等。\n上述两种方式各有利弊，第一种方式虽然安全性差了，但是可以做客户端流量可以被企业的网络过滤设备，例如入侵检测设备做监视和控制。\nl HDX Proxy：在HDX 代理方式下，用户是通过Access Gateway连接到他们的虚拟桌面和虚拟应用。这种方式下完全没有将内部资源暴露到公网上，此时Access Gateway充当了一个微型VPN的作用，它仅处理HDX的流量。其他的流量，例如电子邮件，又或者是使用者上网的流量都不经过Access Gateway。\n决断：访问带宽  最后的访问层决断就是要决定虚拟桌面所需要的最大并发网络带宽。其中很重要的一个关键环节就是决定采用NetScaler Access Gateway的哪一个平台。\n每个用户所需要的带宽关键还是要看计算的需求。一个时不时才用一下电脑的ERP使用者和一个在电脑前屁股都不挪窝的OA用户肯定带宽要求是不同的，如果是CAD画图的用户那就更不用说了。\n理想情况下带宽的使用情况是通过带宽分析工具来给出来，不过我们还是可以给出一些经验值：\n总带宽的的计算公式可以这样来定义：\n总带宽 = 平均带宽 × 最大并发用户值\n更多细节，可以参考Citrix的知识库文章：\nXenDesktop Planning Guide: User Bandwidth Requirements ： XenDesktop Planning Guide: User Bandwidth Requirements\n",
    "ref": "/2013/04/15/xendesktope8999ae68b9fe6a18ce99da2e7b2bee59381e4b9a6e7b18de5afbce8afbbpart2/"
  },{
    "title": "XenDesktop中如何重定向USB设备",
    "date": "",
    "description": "",
    "body": "原文出处：http://support.citrix.com/article/CTX136751 这篇文章你还不会，你就out了！\n概要\n本文描述如何映射默认下被禁用的USB设备。\n要求\n当重定向USB设备，终端用户必须首先识别USB设备，将其映射到会话中。假如设备需要特殊驱动，则驱动必须同时安装在客户机和虚拟桌面代理（VDA）上。如果终端识别驱动，设备在没有驱动的情况下仍可映射，但是VDA上需安装驱动以确保工作正常。\n背景\n特定USB Class默认下被禁用因为它们主要用于本地工作站，例如智能卡阅读器。\n步骤\n注意!这个修复需改变注册表。错误使用注册表编辑器可能产生严重问题，导致你需要重装操作系统。Citrix不承诺解决错误使用注册表编辑器的问题。使用注册表编辑器存在风险。确保修改前备份注册表。\n完成以下步骤查找设备的Class ID和Hardware ID：\n 打开终端客户机的设备管理器，查找需要重定向的USB设备。   右击设备选择属性。注意在Details面板上，显示如下图的Hardware ID 和 Class ID。   在Citrix Desktop Studio \u0026gt; HDX 策略 \u0026gt; 用户中，点击新建USB 设备重定向策略。   点击下一步，类别中选择USB设备 \u0026gt; 客户端USB设备重定向，点击添加，选择允许后确定。  然后，类别中选择USB设备 \u0026gt; 客户端USB设备重定向规则，点击添加\n点击新建添加允许的Hardware ID：\n确定后点击下一步，最后应用此策略。\n 在终端设备，查看注册表HKLM\\Software_WOW6432Node_\\Citrix\\Ica Client\\GenericUSB，设置_DeviceRules_值为‘Allow: VID=0911 PID=1844’  你可以删除_deny class rule_以使能此class的所有设备。但是，为防止非法重定向，增加Allow规则方法更优。\n注意：当增加Allow规则，确保它置于规则列表顶部，使它比规则Deny优先级更高。\n此时在Desktop Viewer 上可见对应USB设备。\n 假如点击设备仍不能映射至会话中，尝试手动在VDA的注册表中添加允许标记： HKLM\\Software\\Policies\\Citrix\\ICA_Client\\USB\\DeviceRules。  更多信息\n默认值存储于VDA注册表的HKLM\\SOFTWARE\\Citrix\\PortICA\\GenericUSB Type=String Name=\u0026ldquo;DeviceRules\u0026rdquo;，但是，不建议修改此值，因为当VDA自检，它首先查看HKLM\\Software\\Policies\\Citrix\\ICA_Client\\USB\\DeviceRules，再查看本地路径。优选修改规则方法是使用组管理对象（GPO）模板。\n**注意：**你必须修改终端客户机注册表以允许对应的USB class。\n查看更多: http://support.citrix.com/proddocs/topic/xendesktop-rho/ps-ref-policies-usb-devices.html\n",
    "ref": "/2013/04/15/xendesktope4b8ade5a682e4bd95e9878de5ae9ae59091usbe8aebee5a487/"
  },{
    "title": "XenDesktop虚拟桌面精品书籍导读(part1)",
    "date": "",
    "description": "",
    "body": "[box color=\u0026ldquo;orange\u0026rdquo; icon=\u0026ldquo;flag\u0026rdquo;] 感谢 Eric Yao 的供稿，@老树皮Eric [/box]\n桌面虚拟化项目的实施白皮书 《Citrix Virtual Desktop Handbook 5.x》，点击下载。该文档是由Citrix全球顶级Consultant系统架构师Daniel Feller, Thomas Berger, Rich Meesters, Matt Brooks, Ed Duncan 以及 Roger LaMarca等大牛合作完成，它介绍了桌面虚拟化架构设计、方法论、经验总结以及最佳实践等知识，更是包含了一步一步指导手册、真实案例分析以及模板手册等。\n序言：关于方法论 一、 Access 二、 Design 三、 Deploy 四、 Manitain 五、 项目计划\n第一部分：Access 一、 业务驱动力 二、 数据搜集 三、 用户数据搜集 四、 应用程序数据搜集 五、 用户分类\n FlexCast模型比较 FlexCast模型选择 六、 应用程序评估 七、 项目管理 Roadmap 项目团队 a) 业务角色 b) 技术角色  第二部分：Design 一、 概况 二、 用户层 User Layer\n 终端类型的选择 Receiver的选择 资源需求 三、 访问层 Access Layer  序言：关于方法论\nCitrix Virtual Desktop handbook会紧密遵循Citrix顾问实施方法论，即如下图所示：\n一、 Access\nAccess阶段主要提供Design阶段所需要的信息，包括：\n  业务驱动力；\n  数据搜集：包括用户、应用程序、设备以及基础架构；\n  用户的分类：用户要根据需要的分类而分成不同的组别，随之应对着不同的FlexCast方法论；\n  应用程序分类：旧的应用程序应该被删除、应用程序版本应该标准化、非公司程序应该删除，等等这些构成了应用程序的标准化和合理化；\n  计划：每个用户组都要根据对业务的影响程度指定不同的实施时间优先级，优先级实施进度结果应该随时更新项目进度和计划。\n  二、 Design\n设计阶段主要聚焦在五层的一个方法论上：\n  用户层：描述推荐的终端以及所需要的用户功能体验；\n  访问层：描述用户层是如何连接到他们的桌面，例如本地桌面是直接连接StoreFront，而外界用户往往要通过Firewall层才能进来，这就涉及到了FW、VPN等技术；\n  桌面层：主要指用户的虚拟桌面实现技术，即FlexCast技术，主要好汉三个主要成分，分别是镜像文件、应用程序，以及个性化内容；\n  控制层：如何管理和维护其他层，又分为访问控制、桌面控制，以及基础架构控制；\n  硬件层：致力于支撑整个解决方案的硬件物理设备，包括了服务器、CPU、内存、存储设备等；\n  三、 Deploy\n按照第二部分设计好的FlexCast方式实施。\n四、 Manitain\n主要包含三种不同的活动：\n  监控：在虚拟桌面环境设计和实施到生产环境以后，持续的监控是必需的。\n  技术支持；\n  测试和变更管理：以后会遇到不断的软件和产品更新；\n  五、 项目计划\n一个设计详尽的项目计划对项目成功的实施时至关重要的。项目经理要通过项目计划来监控成本、管理项目组成员、跟进项目实施进度等。同时项目进度要及时通告项目组所有成员让大家都知道项目的进度。\n在项目的初期一般只需要做Access阶段的计划，这个时段需要多FlexCast模式、容量、用户分组等有更多的交接，所以无需做Design的计划。如下图所示就是一个计划表：\n第一部分：Access\n一、 业务驱动力\n桌面虚拟化项目的第一步应该是去了解对公司所造成的影响，并且将这些影响定一下来，然后对之以优先级排序。有了这些文字描述管理层和项目管理组才能制定出项目成功实施的标准，设计阶段才能有正确的方法论和架构设计。\n下图就定义了一个业务驱动力的优先级示例：\n二、 数据搜集\n数据搜集阶段负责搜集关键信息数据，包括用户、设备、应用程序，以及基础架构等在下一阶段需要使用的数据。\n有三种方法来搜集数据：\n 手动搜集  小型企业有可能通过访问每台终端，或者是远程连接凡是来搜集数据。\n中大型企业一般般都有了ESD（Enterprise Software Deployment），例如微软的SCCM等。可以通过这些平台去搜集应用程序的使用情况等信息。但是ESD一般都不能提供应用程序性能需求和实际使用的信息。\n调查表  这也是一个好办法，可以通过管理层去通过行政命令来执行。也可以通过面对面的会议或者是电话沟通来进行；这种方式比手动搜集要显著减少了所花费的时间，但是完成率不高也是一个缺点，不够精确反应实际情况也是一个缺点。\n自动化搜集  这样的工具有很多，一般都能自动化生成报表。Citrix公司为了帮助用户节省实施成本，和LanDesk公司合作，为Project Accelerator用户提供了一个60天免费试用的LanDesk FastTack 软件License。LanDesk FastTack 软件是一个专门为Citrix实施方法论开发设计的一个专业信息搜集工具。\n上述三种方法的优势和劣势如下表所示：\n三、 用户数据搜集\n信息搜集表可以参考示例表格：Citrix Virtual Desktop Handbook - Assess Workbook.xlsx\n 业务特性  业务特性必须通过业务层的管理人员来手动搜集，无法自动化搜集。包括\nA. 身份\na) 用户名\nb) 部门；\nc) 角色\nd) 业务经理\ne) 所分配的用户组；\nB. 业务\na) 主要的数据中心\nb) 移动性，下表是示例分类\nc) 个性化\nd) 安全性\ne) 关键性\n技术特性  a) 工作负荷\n用户环境  a) 用户Profile\ni. Profile类型：包括本地、漫游、强制、第三方、未知\nii. Profile版本：Windows XP和Windows Vista/7\niii. Profile位置：文件服务器在哪里\niv. 大小：用户Profile的大小\nb) 用户数据主目录\ni. 主目录位置\nii. 大小\n客户端硬件，包括以下需要搜集的信息：  o Number of CPUs/Cores\no CPU Speed (GHz)\no Memory (GB)\no Disk Size (GB)\no Operating System\no Age of the System (years)\no Peripherals\n本地资源映射，包括以下需要搜集的信息：  o Local Drives\no Printing\no Clipboard\no Audio\no COM Port\no USB\no LPT\n四、 应用程序数据搜集\n信息搜集表可以参考示例表格：Citrix Virtual Desktop Handbook - Assess Workbook.xlsx\n 身份信息  a) 应用程序名称和版本\nb) 应用程序所有者\nc) 状态\n应用程序技术特性  a) 分配\ni. 使用者数量\nii. 部门信息\niii. 个别用户\nb) 工作负荷\nc) 业务特性\nd) 兼容性\n五、 用户分类\n一旦数据搜集工作完成之后，我们就可以开始准备将用户分成不同的组了，这个时候就要按照FlexCast模型的要求去分配不同的实现方式给不同的用户组了。\n我们一般都是按照人物性工作者、分支机构办公人员、移动工作者等方式去区分用户，但是实际上用户的分类远不止这几类，更有甚者，很多用户组都是同时属于上述几个组的。\n最快区分用户的方法就是按照用户的需求不同来分组，一旦将用户的需求区分之后，就可以将这些数据填入Citrix Virtual Desktop Handbook - Assess Workbook.xlsx 了。\n FlexCast模型比较    Hosted Shared\n  Hosted VDI，又可以细分为\n  a) Pooled-Random/Streaming\nb) Pooled-Static\nc) Pooled/Streamed with Personal vDisk\nd) Dedicated\ne) Existing\nf) Psysical/Remote PC\n Steamed VHD\n  Local VM\n  On-Demand Apps\n  下表是关于FlexCast整体技术的一个概览：\nFlexCast模型选择  在XenApp和XenDesktop之间有很多技术上的区别，但是他们都是通过HDX来提供的最佳用户体验。他们的区别如下：\n六、 应用程序评估\n在用户分组完成之后，我们已经有了根据需求不同确定下来的不同的用户组，下一步就是向用户提供他们工作需要的应用程序。下面是建议的三部曲：\n  Rationalization 合理化\n  Business Characteristics 业务特性\n  兼容性\n  七、 项目管理\n  Roadmap\n  项目团队\n  下面的表格示例告诉我们在一个虚拟桌面项目中可以建议的业务角色和技术角色分类。虽然角色有很多种，但是很多角色的存在时间都很短，同时很多角色都由一个人同时完成。项目经理和Citrix架构师自然是贯穿整个项目的角色，其他就不一定了。\na) 业务角色\nb) 技术角色\n",
    "ref": "/2013/04/09/xendesktope8999ae68b9fe6a18ce99da2e7b2bee59381e4b9a6e7b18de5afbce8afbb-p1/"
  },{
    "title": "解决XenServer tools not installed",
    "date": "",
    "description": "",
    "body": "[box color=\u0026ldquo;orange\u0026rdquo; icon=\u0026ldquo;flag\u0026rdquo;] 鸣谢：Michael Zhang的经验分享，有需要的请收藏备用。 [/box]\n刚刚搞定了POC环境中一个很诡异的问题。把过程写出来以供大家参考。建议可以把这个设置放到POC的实施手册中。 刚开始做POC时，我们安装了XP的模板，并且安装了同版本的XenTools，此时XenCenter面板上显示虚机的IP地址没有问题。但是跑了一段时间后发现，所有的虚机的IP地址都显示不出来了，并且XenCenter面板上显示XenServer tools not installed，虚机的内存信息，Disk IO等信息，都没有显示： \n\n后来重装了模板，重新发布了虚机，一切就OK了，此时我认为是原先的模板有问题，所以导致了这个issue。 但是后来跑了几天，某台虚机又出现了类似的症状，此时我意识到应该不是模板的问题了。然后我就检查了这台虚机的Service，发现：\n\n这个Service就是XenTool的Service，因为没有启动，所以导致了上述的问题。 但是当我用手工试图重启该Service的时候，系统报改Service启动时停止，没有给出任何原因。Windows Event Log里也没看到任何报错。 后来上网查了下，原来是Windows Event Log的Application类的log满了以后，会导致该Service启动异常。 看了下XP的Windows Event Log的Application类日志的属性，默认只有64K：\n\n我把上面的日志文件大小阀值改成了1024K，清空Application类的log，重启上面的Service, 成功，问题解决。\n \n\n上述类似的问题我记得也有兄弟曾经遇到过，发邮件出来问过，当时怀疑是XenServer跟VDA的时间不同步造成，现在感觉也许跟这个原因有关。\n[box color=\u0026ldquo;gray\u0026rdquo; icon=\u0026ldquo;order-check\u0026rdquo;] 欢迎投稿，请发邮件到： liuzh66@gmail.com [/box]\n",
    "ref": "/2013/04/07/xenserver-tools-not-installed/"
  },{
    "title": "思杰行业解决方案视频放量推荐",
    "date": "",
    "description": "",
    "body": "[button type=\u0026ldquo;big\u0026rdquo; icon=\u0026ldquo;sign-in\u0026rdquo; url=\u0026ldquo;http://i.youku.com/u/UMzU2OTI4MzY0/videos\u0026rdquo;]点击本按钮，直达优酷视频专辑[/button] [line]\n  汽车行业解决方案\n  思杰制造行业解决方案\n  金融行业解决方案\n  呼叫中心场景Citrix桌面云解决方案\n  教育行业解决方案\n  思杰政府行业解决方案\n  医疗行业解决方案\n  营业厅场景解决方案\n  Citrix集中运维监控解决方案\n  OA解决方案\n  思杰虚拟化助力翠微中学教育信息化建设\n  思杰虚拟化为遍布全美的学校师生提供便\n  [line] [box color=\u0026ldquo;red\u0026rdquo;] 合作伙伴们必看视频，你们不得不懂这些内容，否则跟不上形势：) [/box]\n  PoC标准流程\n  2013-03-29 14.02 Citrix MDM solution\n  搞定虚拟环境下的USB设备\n  自由灵活办公【Work Shifting】\n  企业统一应用门户 【Unified Storefron\n  高管移动办公　【Executive Mobility】\n  企业云网络【Enterprise Cloud Network\n  桌面虚拟化 【Desktop Virtualization\n  云融合【Cloud Convergence 】\n  BYOD　工作生活最潮方式\n  Citrix Personal vDisk 技术讲座\n  Citrix Remote PC \n  采用TriScale技术的Citrix NetScaler 1\n  为什么选择思杰？实现安全移动办公和云\n  Citrix 桌面虚拟化之网络解决方案\n  Citrix 桌面虚拟化XenDesktop _FlexCast\n  Citrix-VDI-in-a-Box For SMB \n  Citrix CloudGateway Citrix Receiver\n  粉笔画动画为您解释Citrix XenApp的工作\n  演示思杰TaaS（Tools as a Service）解释\n  ",
    "ref": "/2013/04/07/e6809de69db0e8a18ce4b89ae8a7a3e586b3e696b9e6a188e8a786e9a291e694bee9878fe68ea8e88d90/"
  },{
    "title": "NetScaler Insight Center 虚拟桌面和应用监控利器",
    "date": "",
    "description": "",
    "body": "NetScaler Insight Center with HDX insight and Web Insight overcomes the limitations of traditional methods and technologies to fully address the application visibility challenges facing today’s enterprises. Featuring an approach that leverages NetScaler ADCs, Insight Center combines network-based instrumentation – that is both network and application-aware – with an efficient and powerful management system capable of transforming raw data into actionable information.\n在Citrix TV 栏目搜索 NetScaler Insight ；查询更多的相关资源。\n简单的讲NetScaler Insight能做到的是使用业内的专业协议AppFlow来监控所有经过NetScaler设备的流量。它是一个虚机，能够接收来自多个NetScaler的监控数据，实际上在NetScaler上打开了Insight功能后，它会对ICA协议做必要的拆包和封包动作，这样就能够更加详细的看到用户会话的详细信息，能够实时的了解到用户的体验，从而为主动的问题解决和排错打下了好的基础。注意：这个动作只有NetScaler设备能做哦！其它厂商看不到ICA会话参数。它有两个模块：1)ICA HDX insight ; 2) Web insight；这两个模块能够基本上把所有过NetScaler设备的流量截获、分析和报表；未来能够和XD/XA的管理工具做直接集成。并且它也能够把分析数据发给其它第三方支持AppFlow分析的系统，例如splunkd等。\n其它相关资源： http://blogs.citrix.com/2013/03/19/netscaler-insight-center/\nhttp://blog.itvce.com/?p=3101\nhttp://blog.itvce.com/?p=3167\nhttp://blogs.citrix.com/2012/12/07/netscaler-insight-1-0-ga-unleashed/\nhttp://support.citrix.com/proddocs/topic/ni-netscaler-insight-01-map/ni-wrapper-con.html\n",
    "ref": "/2013/03/28/netscaler-insight-center-e8999ae68b9fe6a18ce99da2e5928ce5ba94e794a8e79b91e68ea7e588a9e599a8/"
  },{
    "title": "破两项个人记录",
    "date": "",
    "description": "",
    "body": "前面三四公里总是跑的太猛，最快到了4：25；跑的速度不太匀。老实说这次是有点太野心了，想创造一万米50分钟的个人记录。但是后半程还是没法坚持下来；坚持不下来可能有这样几个原因所知：1）阳光强烈，太晒，太热了；2）后半程爬坡上升海拔的路程有一段。下次试着逆时针方向绕湖跑，让提高海拔的路程放到体力充足的前半程。\n",
    "ref": "/2013/03/28/two-records-xuanhu-lake-10km/"
  },{
    "title": "XenApp5补丁清单",
    "date": "",
    "description": "",
    "body": "对于XenApp5的用户来说你至少需要知道下面两件事情：\n  EOF的时间是2013-3-31\n  关键补丁清单如下\n  这意味着，你只能获得越来越有限的支持在这个版本；最好的办法是升级你的应用到XenApp6.5版本。如果实在要用，请起码打全了这些补丁。\nHotfix PSE450R07W2K3006 (http://support.citrix.com/article/CTX130483)\nHotfix PSE450R07W2K3027 (http://support.citrix.com/article/CTX131874)\nHotfix PSE450R07W2K3043 (http://support.citrix.com/article/CTX132765)\nLIMITED RELEASE - Hotfix PSE450R07W2K3003 (http://support.citrix.com/article/CTX130466)\nLIMITED RELEASE - Hotfix PSE450R07W2K3004 (http://support.citrix.com/article/CTX130497)\nLIMITED RELEASE - Hotfix PSE450R07W2K3009 (http://support.citrix.com/article/CTX130587)\nLIMITED RELEASE - Hotfix PSE450R07W2K3017 (http://support.citrix.com/article/CTX131022)\nLIMITED RELEASE - Hotfix PSE450R07W2K3029 (http://support.citrix.com/article/CTX132174)\nLIMITED RELEASE - Hotfix PSE450R07W2K3033 (http://support.citrix.com/article/CTX132196)\nLIMITED RELEASE - Hotfix PSE450R07W2K3034 (http://support.citrix.com/article/CTX132245)\nLIMITED RELEASE - Hotfix PSE450R07W2K3037 (http://support.citrix.com/article/CTX132403)\nLIMITED RELEASE - Hotfix PSE450R07W2K3038 (http://support.citrix.com/article/CTX132494)\nLIMITED RELEASE - Hotfix PSE450R07W2K3045 (http://support.citrix.com/article/CTX132809\nLIMITED RELEASE - Hotfix PSE450R07W2K3051 (http://support.citrix.com/article/CTX133221)\nLIMITED RELEASE - Hotfix PSE450R07W2K3052 (http://support.citrix.com/article/CTX133249)\nLIMITED RELEASE - Hotfix PSE450R07W2K3054 (http://support.citrix.com/article/CTX133421 )\nLIMITED RELEASE - Hotfix PSE450R07W2K3056 (http://support.citrix.com/article/CTX133679)\nLIMITED RELEASE - Hotfix PSE450R07W2K3057 (http://support.citrix.com/article/CTX133762\nLIMITED RELEASE - Hotfix PSE450R07W2K3058 (http://support.citrix.com/article/CTX133828)\nLIMITED RELEASE - Hotfix PSE450R07W2K3060 (http://support.citrix.com/article/CTX134027)\nLIMITED RELEASE - Hotfix PSE450R07W2K3062 (http://support.citrix.com/article/CTX134577)\nLIMITED RELEASE - Hotfix PSE450R07W2K3063 (http://support.citrix.com/article/CTX134799)\nLIMITED RELEASE - Hotfix PSE450R07W2K3064 (http://support.citrix.com/article/CTX134829)\nLIMITED RELEASE - Hotfix PSE450R07W2K3065 (http://support.citrix.com/article/CTX135883)\nLIMITED RELEASE - Hotfix PSE450R07W2K3067 (http://support.citrix.com/article/CTX135443)\nLIMITED RELEASE - Hotfix PSE450R07W2K3068 (http://support.citrix.com/article/CTX135887)\nLIMITED RELEASE - Hotfix PSE450R07W2K3069 (http://support.citrix.com/article/CTX135993)\nLIMITED RELEASE - Hotfix PSE450R07W2K3071 (http://support.citrix.com/article/CTX136531)\nLIMITED RELEASE - HDX MediaStream Hotfix HDXFlash110WX86007 (http://support.citrix.com/article/CTX135404)\nLIMITED RELEASE - Delivery Services Console 4.7.3 (http://support.citrix.com/article/CTX132683)\nCitrix产品生命周期查询一览表：\nhttp://www.citrix.com/support/product-lifecycle/product-matrix.html\n",
    "ref": "/2013/03/20/xenapp5e8a1a5e4b881e6b885e58d95/"
  },{
    "title": "My first half marathon",
    "date": "",
    "description": "",
    "body": "[caption id=\u0026ldquo;attachment_52283\u0026rdquo; align=\u0026ldquo;aligncenter\u0026rdquo; width=\u0026ldquo;720\u0026rdquo;] My first half marathon record[/caption]\n本周一，在南京出差，周二一大早，我5点就醒了，常识跑一次半马。这是第一次尝试跑两个小时的时间，第一次尝试跑半马的距离。其实前10公里还是可以，后十公里还是有点疲劳的，中途休息了四次，每次走大约1分分钟左右。很惊喜的看到大部分的路程都在配速5分左右，和我设定的五分二十秒目标配速很接近。本次试跑证明了，我身体的耐力跑半马还是可以。打算在半马的基础上提高成绩，争取能把半马跑好再说。下个月四月十四日在苏州的半马比赛很期待，比赛前抽空好好准备争取能轻松完成。跑完后，这几天没有发现身体任何不适，今天早晨跑5公里，发现加速比以前有力，似乎经过这次拉练后，身体的体能有所提高。最重要的是：我在没有伤痛的情况下即感受到了体育竞技的乐趣，又达到了强身健体的目的。\n",
    "ref": "/2013/03/14/my-first-half-marathon/"
  },{
    "title": "Do you challenge yourself?",
    "date": "",
    "description": "",
    "body": "[caption id=\u0026ldquo;attachment_52275\u0026rdquo; align=\u0026ldquo;aligncenter\u0026rdquo; width=\u0026ldquo;723\u0026rdquo;] personal records May/1st/13[/caption]\nI will create my records as more as I could before I am die.\n",
    "ref": "/2013/03/01/do-you-challenge-yourself/"
  },{
    "title": "NetApp技术学习",
    "date": "",
    "description": "",
    "body": "[caption id=\u0026ldquo;attachment_52271\u0026rdquo; align=\u0026ldquo;aligncenter\u0026rdquo; width=\u0026ldquo;300\u0026rdquo;] sales-ilt-se-asap-rev07[/caption]\n今天参加了NetApp Accredited Storage Architect Professional Workshop。这个课程偏售前，讲的还是不错，一共3天，明天开始做Lab，实验练习的环境就是在ONTAP操作系统中的各种命令；使用官方的模拟器可以很方便的搭建测试环境，模拟器下载地址：https://communities.netapp.com/docs/DOC-1034\n[caption id=\u0026ldquo;attachment_52269\u0026rdquo; align=\u0026ldquo;aligncenter\u0026rdquo; width=\u0026ldquo;300\u0026rdquo;] NetApp模拟器Web访问[/caption]\nNetApp University : http://www.netapp.com/us/services/university/ 更多免费课程还可以在这里注册得到。课程的质量还不错。\n[caption id=\u0026ldquo;attachment_52270\u0026rdquo; align=\u0026ldquo;aligncenter\u0026rdquo; width=\u0026ldquo;300\u0026rdquo;] NetApp在线免费课程[/caption]\n",
    "ref": "/2013/02/26/netappe68a80e69cafe5ada6e4b9a0/"
  },{
    "title": "TIPS install XenServer on Mac Mini 6.1 ",
    "date": "",
    "description": "",
    "body": "[caption id=\u0026ldquo;attachment_52258\u0026rdquo; align=\u0026ldquo;aligncenter\u0026rdquo; width=\u0026ldquo;640\u0026rdquo;]mac-mini-2012-with-XenServer[/caption]\n今天尝试在Mac Mini上安装XenServer，下面把经验共享一下。我遇到的问题有两个：\n  网卡无法识别：使用默认安装盘安装，提示没有检测到网卡，安装无法继续\n  网卡驱动植入失败：在按了F9加载驱动的时候，没有发现驱动程序，无法继续安装\n  安装完毕之后，重启，屏幕上显示一个带问号的文件夹，一闪一闪无法正常启动XenServer\n  经过一番折腾，发现这些点主意一下，应该就没有问题。\n[caption id=\u0026ldquo;attachment_52255\u0026rdquo; align=\u0026ldquo;aligncenter\u0026rdquo; width=\u0026ldquo;300\u0026rdquo;] 启动Macmini[/caption]\n在启动Mac Mini的时候，在“咚”的一声之前，就按住ALT键，否则没法出现上面的屏幕，我用的是USB盘启动，所以要选择右侧的图标。\n[caption id=\u0026ldquo;attachment_52256\u0026rdquo; align=\u0026ldquo;aligncenter\u0026rdquo; width=\u0026ldquo;300\u0026rdquo;] 进入menu.c32菜单[/caption]\n我遵循前人的经验，乖乖到此来禁止gpt；首先在这里要迅速输入menu.c32，输入完了就过了，就必须重新关机，重启mac mini。\n[caption id=\u0026ldquo;attachment_52257\u0026rdquo; align=\u0026ldquo;aligncenter\u0026rdquo; width=\u0026ldquo;300\u0026rdquo;] 输入disable-gpt参数[/caption]\n进入这个屏幕了，要快速按TAB键，否则启动参数无法编辑，输入disable-gpt参数的机会就失去了。编辑启动参数的时候，把参数加载第二个\u0026mdash;（三个短横线）前即可，上图我为了拍照在参数之前加了很多空格，其实这个参数和前后要至少一个空格就够了。\n在进入安装的屏幕后，如果是XenServer6.0.201的源安装盘，还必须下载tg3的网卡驱动，并且用工具打入iso文件，这样安装的时候，就可以选择到加载网卡启动，否则6.0.201的安装盘即不自带此网卡驱动，也无法正常识别附加的驱动。网卡驱动下载地址为：http://support.citrix.com/article/CTX135328 要把加压后的iso文件，再次加压到对应的目录里才行，直接把解压后的几个文件放入目录，安装程序是无法识别到网卡驱动的。如果能正常识别的话，会出现选择框，让你选择 Broadcom tg3。如果是XenServer6.1的安装盘，就不需要折腾驱动了，原盘自带了Broadcom tg3网卡驱动。下面有两张截图，供必须要使用XenServer 6.0.201的人参考。\n[caption id=\u0026ldquo;attachment_52250\u0026rdquo; align=\u0026ldquo;aligncenter\u0026rdquo; width=\u0026ldquo;300\u0026rdquo;] XenServer 6.0.201 with driver[/caption]\n[caption id=\u0026ldquo;attachment_52251\u0026rdquo; align=\u0026ldquo;aligncenter\u0026rdquo; width=\u0026ldquo;300\u0026rdquo;] xs-repository-list 实例[/caption]\n即使你不是安装XenServer6.0.201，也推荐使用UltraISO来把iso文件写入一个USB盘来安装，因为Mac Mini没有光驱，而且这样不用刻盘，更加环保一点。\n最后一个Tips：这个可能是解决问题3的技巧，在安装的最后一个屏幕上，安装程序提示移除Mac Mini上的其他所有截至，然后点击回车完成安装。在这个屏幕上要识时务的把安装U盘从机器上拔除，然后点击回车来重启Mac Mini。经过我的验证，拔出U盘后好像没有在遇到过闪烁文件夹的重启不了的问题。建议都使用自带Broadcom tg3网卡驱动的6.1来安装，否则6.0.201安装完成之后，一旦打了补丁，还需要下载for这个补丁的新版本的网卡驱动，在重新手工打上该驱动，否则网卡会起不起来。\n",
    "ref": "/2013/02/21/tips-install-xenserver-on-mac-mini-6-1/"
  },{
    "title": "2012 Hadoop与大数据技术大会PPT下载",
    "date": "",
    "description": "",
    "body": "http://hbtc2012.hadooper.cn/download.html\n",
    "ref": "/2013/01/09/2012-hadoope4b88ee5a4a7e695b0e68daee68a80e69cafe5a4a7e4bc9appte4b88be8bdbd/"
  },{
    "title": "冬练三九-晒晒我三周的成果",
    "date": "",
    "description": "",
    "body": "运动总成绩 总距离 79.8公里 总时长 9.5小时 共燃烧 5516.4大卡\n\n",
    "ref": "/2012/12/26/e586ace7bb83e4b889e4b99d-e69992e69992e68891e4b889e591a8e79a84e68890e69e9c/"
  },{
    "title": "Open Source Software: The Mega List",
    "date": "",
    "description": "",
    "body": "马克备用。\n",
    "ref": "/2012/12/23/open-source-software-the-mega-list/"
  },{
    "title": "2013年的云计算，您准备好了么？",
    "date": "",
    "description": "",
    "body": "\nGetting Ready for Cloud Computing 2013\n[dc]看[/dc]到篇不错的文章，值得分享一下。在最近的三四年里面，厂商都忙着炒作概念，用似云非云的各种虚拟化来对付用户，实际上云计算并没有那么简单，我一直不敢给客户讲，也讲不好的东西就是：对于一个特定的用户，告诉它什么是云？他应该怎么怎么过渡到云？先从那里做起？大致的路径是怎么样的？一旦对应到具体的用户环境里面，以上每个用户的答案都是不同的，感觉没有十足实践经验的人，根本无法和用户达成共鸣和一致。这个和我以前做ITSM/ITIL完全不同，在那块领域里面，讲究的是管理的思路和理念，等你做了一些项目之后，你从项目中的总结和提炼，就成了你的炮弹，用在其它新用户身上，用不好，也用不错；管理的学问往往是殊途同归的。而云计算，目前国内真的还属于初级阶段，就像是在2002年左右的时候，我们给银行做ITIL做服务台一样，对无论是用户和厂商的人来说，还不夸张的说，都是雾里看花。\n[tab label=\u0026ldquo;云计算七大注意事项\u0026rdquo; first=\u0026ldquo;yes\u0026rdquo;]\n[list icon=\u0026ldquo;star\u0026rdquo;]\n   检查和评估您的网络 : 如果数据中心不做网络架构的巨大调整，给云平台配置足够强大的带宽资源，上云计算，基本上就是让用户和运维人员都痛苦不堪，不会有啥好结果。    建立鼓励员工进谏的机制 : 识别、评估、选择和实施云计算方案的流程需要提前设计好。在每个阶段和过程里让最终用户、开发人员和管理层都充分的参与意见。    聚焦在立竿见影的运维痛点和功能差距上: 瞄准那些影响最终用户生产力和新上面的应用部署项目上。让云计算的高效和灵活等优势小试牛刀一下，从而验证需求点的准确性和方案的靠谱性。    先尝后买 : 云计算是最着急投胎的，没有必要大干快上，对于数据中心来说也是一个渐进的温和的改良的过程。选定一个足够小的范围，先尝后买，分区分配扩容，放大项目范围。    承载应用（App hosting）和SaaS应用不能划等号 : 这根本就是个误解，无须多说。    监控利用率和满意度 : 不管云做的大小，资源都要物尽其用，跟踪最终用户和领导大满意度，与同行用户横向比较数据，找出自己的所处位置和程度。实施反馈机制，让用户驱动云的需求和建设方向。    眼观六路，站足先机 : 市场风云莫测，业务模式层出不穷，这些都不断催熟这云方案。所以广泛关注，收集跟多信息，为云计算建立多个选项，多种选择总是好事。    [/list] [/tab]\n[tab label=\u0026ldquo;英文原文\u0026rdquo;]\nIf you’ve been holding back about moving to the ‘Cloud’, it is time to get onboard the Cloud Computing express.\nNot only has every major research firm published market forecasts indicating that Cloud services are growing exponentially, but we see multiplying customer success stories that clearly illustrate the immediate and measurable business benefits of moving to the Cloud.\nHere are some simple rules you should follow to help you move ahead in the coming year and successfully leverage today’s rapidly evolving Cloud alternatives:\n1. Check your networks: Adopting Cloud solutions doesn’t make sense if you don’t have sufficient bandwidth capabilities. Without adequate connectivity, accessing Cloud services will be like stepping back in time and only frustrate your end-users and executives.\n2. Establish policies that encourage employee input: Develop straightforward procedures for identifying, evaluating, selecting and implementing Cloud solutions. Your end-users, developers and executives are being exposed to Software-as-a-Service (SaaS) applications, Platform-as-a-Service (PaaS) solutions and Infrastructure-as-a-Service (IaaS) alternatives every day. Invite them to recommend those they like.\n3. Focus on your immediate pain-points and functional gaps: Don’t rip out existing applications that work and cost little to maintain. Instead, target those cumbersome old applications that get in the way of end-user productivity and new applications to fill immediate needs.\n4. Start small and try before you buy: One of the greatest advantages of today’s Cloud solutions is that they mitigate many of the risks associated with traditional, legacy applications. Rather than paying for a perpetual license upfront without having an opportunity to test how it will meet your needs, many of today’s Cloud solutions allow you to try them out before you subscribe to them. And, you can start with a small group of users, or a single department, before you roll out the solution across your organization.\n5. Recognize that application hosting doesn’t equal Software-as-a-Service (SaaS): There is a growing number of legacy, on-premise software vendors who are offering hosted versions of their applications on a subscription pricing basis and calling them “SaaS” solutions. Although these hosted applications alleviate some of the operational hassles and reduce the upfront cost associated with traditional software deployment, they still fall short of the fundamental benefits of true ‘multitenant’ SaaS solutions, such as ongoing enhancements and aggregated benchmarks. In addition, the legacy software vendors can’t scale their hosted services if their customers are using varying versions of the hosted application.\n6. Monitor utilization and measure satisfaction: Track how your end-users and executives are using the SaaS apps and other Cloud services. Be sure the utilization levels justify the current subscription fees to prevent overspending. Investigate how your utilization levels compare with other organizations by requesting benchmark information from SaaS/Cloud vendors. Implement feedback mechanisms to ensure satisfaction and generate new ideas. Use data to determine future service requirements.\n7. Stay informed to stay ahead: The Cloud marketplace is changing rapidly from a technological perspective and maturing quickly from a business model point of view. Keeping up on the latest developments may be a challenge, but is also essential to take full advantage of the increasingly powerful solutions being delivered via the Cloud. Maintain an ‘open door’ policy and utilize social networking tools to invite your end-users, executives and others to share information about new services and best practices. [/tab]\n",
    "ref": "/2012/12/18/2013e5b9b4e79a84e4ba91e8aea1e7ae97e682a8e58786e5a487e5a5bde4ba86e4b988/"
  },{
    "title": "Top 10 things Ubuntu is doing right",
    "date": "",
    "description": "",
    "body": "http://www.datamation.com/open-source/top-10-things-ubuntu-is-doing-right.html\n",
    "ref": "/2012/12/18/top-10-things-ubuntu-is-doing-right/"
  },{
    "title": "What's new in Windows 8 VDI licensing: Free ride for Windows RT",
    "date": "",
    "description": "",
    "body": "http://searchvirtualdesktop.techtarget.com/tip/Whats-new-in-Windows-8-VDI-licensing-Free-ride-for-Windows-RT?utm_medium=EM\u0026amp;asrc;=EM_ERU_19908957\u0026amp;utm;_campaign=20121212_ERU%20Transmission%20for%2012/12/2012%20%28UserUniverse:%20635116%29_myka-reports@techtarget.com\u0026amp;utm;_source=ERU\u0026amp;src;=5093920\n",
    "ref": "/2012/12/13/whats-new-in-windows-8-vdi-licensing-free-ride-for-windows-rt/"
  },{
    "title": "三亚半山半岛洲际酒店5公里",
    "date": "",
    "description": "",
    "body": "[gallery link=\u0026ldquo;file\u0026rdquo; ids=\u0026ldquo;52210,52209,52207,52208,52211,52199\u0026rdquo;]\n三亚住着全国各地来度假的人，有在这里旅游的，有在这里度假的，有在这里修养的。洲际酒店是我一直喜欢的酒店，这次赶巧有下榻于此；这里在鹿回头景区旁边，是一个探入大海的鹿头，酒店就坐落在鹿头的脖子部分，所有酒店的两侧都能看到大海，而左右被两座山包夹着。大海一天之中变化着不同的颜色，今天晴空万里，空气好的不得了！想起北京的PM值，我都不想回去了，精心准备的ppt，希望再次打动用户。明天的两大目标：跑5公里；打动用户一个都不能少。\n查看大图\n",
    "ref": "/2012/12/13/e4b889e4ba9ae58d8ae5b1b1e58d8ae5b29be6b4b2e99985e98592e5ba975e585ace9878c/"
  },{
    "title": "印度",
    "date": "",
    "description": "",
    "body": "今天在印度同事的帮助下，又解决掉我一个棘手的问题。这个哥们是个developer，解决问题很给力。每当他帮忙找出一个原因后，我就感慨，为什么我没有想到？开发人员的思维方式和我们是不同的，他们能找到基础的基础，从哪里开始入手分析问题，往往我们都太聪明了，总是试图找捷径/替代方法/或者绕开问题。\n中国人谈到印度，往往有不屑的态度，可是我真的想不出能有什么理由这么想。看看我们现在如此浮华和虚荣腐败的国家，到处是利益驱动下的虚假繁荣，任凭胡主席和温总理在鞠躬尽瘁地视察民情和整治社会，社会还是依旧那样。环境还在被污染，食品还是一样有毒，物价还是一样的上涨，货币还是依旧的贬值，税赋还是依旧的增加，社保和服务还是不能够的到位，道路还是越来越堵，中石油茅台洋酒还是照样的喝，舆论依然的禁锢愚人，互联网还是那么的和谐\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\n回到印度的话题，我突然到一个问题：现在还有什么软件不是在印度开发的？但从我的公司看，它以平均每年收购两家公司的速度并购，十之八九的被收购的公司的研发工作被部分转移印度做。任凭国内的developer你们怎么的叫喊比印度人更聪明，我们的软件业还是照旧，既没有走出去多少，也没进来多少。大多数企业的终极目标也就是去美国上市。即使是国内在大的公司，也偶尔给我们上演一下3Q大战的闹剧。无疑印度的软件也在某种程度上是超越国内的。\n",
    "ref": "/2011/05/10/india/"
  },{
    "title": "让Remedy飞一会",
    "date": "",
    "description": "",
    "body": "Remedy应用的性能优化是一个在系统建设过程中需要长期关注的问题，而不是在上线的前一天晚上去解决的问题，我也碰到过很棘手的性能问题，它确实爆发了，而且恰好在上线前夕爆发；之后感觉除了点背之外，感觉比较遗憾的是：为啥这个性能问题不早点爆发！\n那么如何持续改进Remedy的性能？首先是硬件环境的准备情况，是否能在项目开始的第一天，就把开发，测试，生产环境统一装好。而不是到上线的前夕才去动生产环境。甚至于有条件的情况下，可不可以直接在生产环境上做开发，这样做的好处：让生产环境上性能优化的时间周期和机会尽可能的多，尽可能的长。当然这种机会毕竟不多，那么是否可以做到生产环境和开发环境的尽早的同步，也就是说：在开发到了一个小的阶段的时候，生产环境就可能就绪，就可以使用，这样把未成型的系统先部署上去，以便有机会做多次的生产系统性能调优。比较生产系统的性能最优化是项目的一大目标，不能等到最后才去仓促应战。曾经听说某行流程平台上线的第二天就挂了一次，这都是血淋淋的教训。总结一下：尽早的建设生产系统，优化生产系统，把开发好的那部分程序尽早迁移到生产上，长期的追逐系统性能，甚至于在生产环境上对此系统做压力测试。这些工作如果能够做的话，我想在上线日我们一定不会紧张。\n如何追逐测试系统的性能。可以使用Web profiling工具如Fiddler。使用这种工具对某些特定操作持续的测试，把每次的测试结果保存下来，把时间记录到一个表格中。可以考虑测试如下内容：用户登录、打开事件控制台、创建一个事件单、搜索事件单等等，其他流程也类似。保证每次点击的次数都相同。其实从Fildder的分析数据中也可能得到很有价值的数据，如：那个Web调用的时间消耗最长，那些Web资源的请求出错。找出时间消耗做多的调用，就可以有针对性的优化应用了。总之：使用一种工具，在开发的整个过程中持续测试和优化，记录所有测试结果，这样在上线前对系统的性就能有客观参考依据。\n另外要注意Remedy系统是一个标准的3层架构应用，你需要在系统调优的时候，有这样几种人的帮助：压力测试工具高手、JVM调优专家、数据库调优专家和Remed性能调优专家。还需要参考下列的参数配置。\nMid-tier优化参数建议 关于Mid-tier的一点建议，目前普通使用的Java应用服务器都是Tomcat，我一向是开源软件的粉丝，但是，还是建议如果有条件的话，还是上商业的产品，如Weblogic或者Websphere。这样可以获得能多一点的支持。 鉴于大多数系统还都是用的BMC的产品自带的Tomcat，下面是一些建议的参数配置。\n1-HTTP keep-alive Keep-alive count: infinite (minimum 5000) Connection timeout:90000 ms (minimum 60000 ms)\n2-JVM settings JVM heap：-Xms1024m –Xmx1024m MaxPermSize：-XX:MaxPermSize=256m 以Windows系统为例，可以使用Tomcat的配置界面工具，配置这两个参数。\n3-Threads configuration of the application server hosting the mid tier maxThreads：500 acceptCount：100\n关于1和3的 参数文件：tomcat dir/conf/sever.xml 的实例代码： [xml]\n\u0026lt;Connector URIEncoding=\u0026ldquo;UTF-8\u0026rdquo; acceptCount=\u0026ldquo;100\u0026rdquo; connectionTimeout=\u0026ldquo;90000\u0026rdquo;\nmaxHttpHeaderSize=\u0026ldquo;8192\u0026rdquo; maxKeepAliveRequests=\u0026quot;-1\u0026quot; maxThreads=\u0026ldquo;500\u0026rdquo;\nport=\u0026ldquo;80\u0026rdquo; protocol=\u0026ldquo;HTTP/1.1\u0026rdquo; redirectPort=\u0026ldquo;8443\u0026rdquo;/\u0026gt;\n[/xml]\n以上参数配置并不是万能的，只是给出一个优化配置的基础，以此为起点调起来可能会更靠谱。\nFine tuning the mid tier Mid tier parameter or service： Recommended value Enable Cache Persistence：Always on for a production environment Prefetch or preload service： Use prefetch only when a specific set of AR System forms are known. Otherwise, use preload (recommended). Recommended preload procedure： 1.Turn on Enable Cache Persistence. 2.Turn on preload. 3.Allow preload to finish preloading all user facing AR System forms. 4.Turn off preload (allowing statistical service to take over). **arsystem.formhtmljs_expiry_interval **和 arsystem.resource_expiry_interval： Set both parameters to the same value to reflect how often you want the browser to check with the mid tier for updates. In a deployment environment where the AR System applications are not modified, set to 604800 (1 week) or higher. The minimum recommended value is 86400 (1 day). For the new values to take effect, restart the mid tier. Definition Change Check Interval： In a deployment environment where the AR System applications are not modified, turn this off. Otherwise, map this to the frequency of your AR System application modification. For example, if you push changes out every Sunday, set this frequency to 604800 (1 week). arsystem.log_level： Severe. This can also be set through the Mid Tier Configuration Tool\nARS优化参数建议 打开ar.cfg参考一下参数，修改后重启ARS服务。\nDelay-Recache-Time:300 ** Max-Entries-Per-Query:2000** ** Next-ID-Block-Size:100** ** Server-Side-Table-Chunk-Size:1000** ** Allow-Unqual-Queries:F** ** Cache-Mode:0** ** Debug-mode:0** ** Submitter-Mode:1** ** CMDB-Cache-Refresh-Interval:600**\n数据库优化参数建议 数据库方面一定要依靠有经验的DBA，靠他们帮你搞定下面这两条： • Configuring your AR System database server for optimal performance • Diagnosing and resolving issues. 另外如果你是Oracle11g的数据库，可以自己动手搞定下面这一条： Oracle 10g/11g database settings are recommended: Cursor_sharing = FORCE 在数据库上做如下操作： [sql] alter system set cursor_sharing=FORCE scope=both; [/sql] 然后在ar.cfg里面加入这个参数。 Oracle-Cursor-Sharing: FORCE 然后重启ARS服务即可。\n以上参数配置部分参考了BMC的官方文档《BMC Remedy AR System Server 7.6 Performance Tuning for Business Service Management 199037.pdf》，感兴趣的话可以去官方站点的文档下载里下载，该文章对以上参数有详细的解释。\n",
    "ref": "/2011/05/07/let-remedy-ars-fly-2/"
  },{
    "title": "Remedy ITSM 7.6.04 套件快速安装",
    "date": "",
    "description": "",
    "body": "自从Remedy ITSM 7.6.03版本发布以后，Remedy ITSM套件有了一种全新的安装方式“预配置堆栈式安装”，这种安装方法简化了以前从ARS开始一个部件罗一个部件的安装方法，它将ITSM套件中的所有组件一次性的安装上去。下面讲具体该如何操作。\n什么情况下使用这个安装方式？ A）POC的情况下 B）客户的生产环境满足下面的需求： • Microsoft Windows Server 2008 (64-bit) (Standard, Enterprise, or Datacenter) with Microsoft SQL Server 2008 (64-bit) (Standard or Enterprise) • Oracle Solaris 10 with Oracle 11g (64-bit) (Standard, Enterprise, or RAC) • Red Hat Enterprise Linux 5 (Update 5) (64-bit) with Oracle 11g (64-bit) (Standard, Enterprise, or RAC) • Microsoft Windows Server 2008 (64-bit) (Standard, Enterprise, or Datacenter) with Oracle 11g (64-bit) (Standard or Enterprise) Note: The BMC Remedy ITSM Suite Precon gured Stack installer supports only Unicode database servers\n这种方式安装了什么组件？ BMC Remedy AR System server version 7.6.04 AREA LDAP Directory Service Authentication ARDBC LDAP Directory Service Data Access Web Services Plugin Simple Network Management Protocol (SNMP) Configuration Full Text Search (FTS) Configuration Approval Server Assignment Engine Email Engine Flashboards Mid-Tier BMC Remedy AR System clients BMC Remedy User BMC Remedy Alert BMC Remedy Developer Studio BMC Remedy Data Import BMC Remedy Migrator Crystal Reports ODBC BMC Atrium Core BMC Atrium CMDB version 7.6.04 Product Catalog version 7.6.04 Atrium Impact Simulator version 7.6.04 BMC Remedy ITSM Suite BMC Remedy Asset Management version 7.6.04 BMC Remedy Change Management version 7.6.04 BMC Remedy Incident Management version 7.6.04 BMC Remedy Problem Management version 7.6.04 BMC Remedy Service Desk 7.6.04 BMC Service Level Management version 7.6.04 BMC Remedy Knowledge Management version 7.6.0 如果你真的不需要安装以上所有组件，请不要使用此安装方法。\n需要什么硬件？ System requirements for Microsoft Windows and UNIX®: • Minimum 12 GB free disk space for the installation directory • Minimum 8 GB free space for local database and remote database • (For Red Hat Enterprise Linux® only) Minimum of 2.5 GB free space in the /tmp directory or /tmp file system. • (For Oracle® Solaris only) Minimum of 2.5 GB free space in the /var/tmp directory or the file system. • 3 GHz dual processor • Minimum 3 GB RAM during installation; 8 GB RAM during runtime; 8 GB main memory for optimal performance • (When 6 GB UNIX systems are used) Make sure that a minimum of 6 GB Swap Space is configured within the system. 如果您的硬件真的低于以上需要，请不要使用此安装方法，否则安装完之后系统可能不能正常运行。\n需要什么人参与？ 需要操作系统管理员和数据库管理员参与 以Linux+Oracle为例，可能需要如下环境变量 [bash] export ORACLE_BASE=/u01/app/oracle export ORACLE_SID=remedy export ORACLE_HOME=/u01/app/oracle/product/11.2.0/dbhome_1 export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$ORACLE_HOME/lib export NLS_LANG=en_US.UTF8 export LANG=en_US.utf8 export PATH=$PATH:$ORACLE_HOME/bin [/bash]\n需要什么安装文件？ 以Linux+Oracle的安装为例，需要如下文件：\nlinux.x64_11gR2_database_1of2.zip linux.x64_11gR2_database_2of2.zip jdk-6u25-ea-bin-b03-linux-amd64-27_feb_2011.bin BMCRemedyITSMSuitePreconfiguredStack7.6.04.Linux.tar.gz\n需要安装多长时间？ 大约1.5个小时左右，是的没有夸张，这个时间是在一个DELL E6400（64位，8GB内存）的笔记本上测得的，如果你有更好的硬件，相信可以更快，这应该是史上最快的Remedy ITSM套件安装速度，如果你也成功通过此方式安装，请留下评论留下下你的安装时间和系统配置情况。\n参考以下操作步骤 安装之前需要根据网卡的MAC地址先申请一个Lic，接着基本上都是点Next，即可完成安装 [imagebrowser id=8]\n",
    "ref": "/2011/05/04/remedy-itsm-7-6-04-quick-install-guide/"
  },{
    "title": "让Ubuntu飞一会儿",
    "date": "",
    "description": "",
    "body": "很久以前我一直使用的rpm based Linux，原因很简单，我只要手握一张最新的DVD，就可以走遍天下都不怕，特别是对SuSE Linux的yast很依赖，因为它可以帮我解决rpm包之间的依赖性。这样工作起来就很简单，基本上是搜索到软件包之后，点击安装既可以搞定所有的软件安装工作。\n来到Ubuntu世界的我并不很满意，最近一次的apt-get update，以失败告终，险些把家里的PC的一块硬盘给搞丢了，因为升级失败导致分区表失效了，Win操作系统不认了。直接崩溃，好在那Live Cd模式进入还能勉强看得那个盘里的东西，恢复到移动硬盘，重新格式化该分区，才把文件恢复了。着实让我虚惊一场。\n我比较喜欢一些小的LAMP堆栈式安装的Linux，如TurnkeyLinux。安装可以在10分钟内搞定系统安装。今年家里的宽度升级到2MB了，因此带宽上逐渐能满足Ubuntu这种从网上升级的需求。下面就是找国内的升级的源了，进过几个月的使用，最近觉得在北京的联通固定宽带的用户，使用163的镜像站点速度还是不错的。再次感谢国内的这样的无私奉献的公司，使得在国内的开源用户可以更快更方便。废话说了一堆：）哈哈下面也就是这几条命了的事情。\n第一步，当然要选择近水楼台的163了，来参考http://mirrors.163.com/.help/ubuntu.html 的帮助文档，根据你操作系统的版本，更新/etc/apt/sources.list 文件即可，之后你的Ubuntu就是从国内的较快的站点上下载包了\n第二步，安装多线程apt下载加速工具apt-fast\n[bash] root@lamp ~# apt-get install python-software-properties root@lamp ~# add-apt-repository ppa:tldm217/tahutek.net root@lamp ~# apt-get update root@lamp ~# apt-get install apt-fast root@lamp ~# apt-fast -v apt 0.7.25.3ubuntu9.3 for i386 compiled on Sep 9 2010 22:22:02 Supported modules: *Ver: Standard .deb *Pkg: Debian dpkg interface (Priority 30) S.L: \u0026lsquo;deb\u0026rsquo; Standard Debian binary tree S.L: \u0026lsquo;deb-src\u0026rsquo; Standard Debian source tree Idx: Debian Source Index Idx: Debian Package Index Idx: Debian Translation Index Idx: Debian dpkg status file [/bash]\n以后你在安装软件包就是用apt-fast install了，而不是apt-get install，至于apt-get么，不管你用还是不用，它就在哪里~~~~ 最后一步（可选），如果你还经常要以cpan的方式安装perl的包的话，那么163上不管你用还是不用，他就在哪里，你也可以选择163最为perl的安装源。安装步骤如下：\n[bash] root@lamp perl/CPAN# pwd /etc/perl/CPAN root@lamp perl/CPAN# cp Config.pm Config.pm.bk root@lamp perl/CPAN# ls Config.pm Config.pm.bk Config.pm~ root@lamp perl/CPAN# vi Config.pm [/bash]\n修改Config.pm文件中的urllist值，修改成如下即可：\n'urllist' =\u0026gt; [q[http://mirrors.163.com/cpan/]], 接下来就可以测试一下了： [bash] root@lamp perl/CPAN# cpan -i XML::Entities [/bash]\n如果你有其他让Ubuntu加速的方法，请留言：）\n",
    "ref": "/2011/04/10/let-ubuntu-fly/"
  },{
    "title": "ARS启动故障修复案例",
    "date": "",
    "description": "",
    "body": "ARS版本 7.6.04 数据库 Oracle11G 和ARS在同一台服务器上\n错误现象： ARS服务不能正常启动 arerror.log报 390600 : SQL 数据库不可用 \u0026ndash; 将重试连接 (ARNOTE 590) Sat Apr 02 20:27:41 2011 : Action Request System(R) 服务器 x64 版本 7.6.04 Build 002 201101141059 (c) Copyright 1991-2010 BMC Software, Inc. Sat Apr 02 20:29:51 2011 390600 : SQL 数据库不可用 \u0026ndash; 将重试连接 (ARNOTE 590) Sat Apr 02 20:29:51 2011 ORA-12170: TNS:Connect timeout occurred\n排错步骤： 使用sqlplus测试登录，返回TNS超时错误 [powershell] C:\\Users\\martin\u0026gt;sqlplus ARAdmin/AR#Admin#@ars SQL*Plus: Release 11.2.0.1.0 Production on Sat Apr 2 20:48:35 2011 Copyright (c) 1982, 2010, Oracle. All rights reserved. ERROR: ORA-12170: TNS:Connect timeout occurred [/powershell] 使用tnsping ars 测试也不成功 ping本机主机名 [powershell] ping arsserver Pinging arsserver [fe80::c123:5921:b71b:64fd%13] with 32 bytes of data: Reply from fe80::c123:5921:b71b:64fd%13: time\u0026lt;1ms Reply from fe80::c123:5921:b71b:64fd%13: time\u0026lt;1ms Reply from fe80::c123:5921:b71b:64fd%13: time\u0026lt;1ms Reply from fe80::c123:5921:b71b:64fd%13: time\u0026lt;1ms Ping statistics for fe80::c123:5921:b71b:64fd%13: Packets: Sent = 4, Received = 4, Lost = 0 (0% loss), Approximate round trip times in milli-seconds: Minimum = 0ms, Maximum = 0ms, Average = 0ms [/powershell] 貌似找到原因，修改host文件，加入主机名到127.0.0.1 后面，在测试ping主机名成功。 重启Oracle监听器服务，再次测试tnsping 和sqlplus ，测试都获得成功。 重新启动ARS服务，服务被正常启动\n",
    "ref": "/2011/04/02/ars-start-issue-on-oracle/"
  },{
    "title": "How to configure statusnet default language",
    "date": "",
    "description": "",
    "body": "If you are playing with statusnet, I bet you could not change default language; English language just shows every where. So I\u0026rsquo;d like to write a quick guide to show you how to change perferred langguage as zh_cn. I have a Ubuntu server with only English language pack. [bash] root@lamp www/statusnet# locale -a C POSIX en_GB [/bash]\nI searched and install Chinese language pack by aptitide [bash] root@lamp www/statusnet# aptitude search language-pack-zh p language-pack-zh - translations for language Chinese (dummy package) p language-pack-zh-base - translations for language Chinese (dummy package) P language-pack-zh-hans - translation updates for language Simplified Chinese P language-pack-zh-hans-base - translations for language Simplified Chinese p language-pack-zh-hant - translation updates for language Traditional Chinese p language-pack-zh-hant-base - translations for language Traditional Chinese root@lamp www/statusnet# aptitude install language-pack-zh-hans-base [/bash]\nThen I checked it again [bash] root@lamp www/statusnet# locale -a C POSIX en_GB zh_CN.utf8 zh_SG.utf8 [/bash]\nUbuntu OS has translations for language Simplified Chinese right, then I go ahead to configure statusnet config.php file. It only needs one more line as below, you can use your own language. [php] $config[\u0026lsquo;site\u0026rsquo;][\u0026lsquo;language\u0026rsquo;] = \u0026lsquo;zh_CN\u0026rsquo;; [/php]\nThe final step, you login statusnet as administrator and go to /admin/site. Then you will select your language from dropdown list. I spend a few days to fix this problem. Just today, I realized my problem is Ubuntu linux server does not have Chinese Language pack yet. Show you my art as below :) \n如何在Ubuntu上配置statusnet默认为中文界面 1）安装中文语言包 2）配置config.php的默认语言 3）statusnet管理员配置站点的默认语言\n",
    "ref": "/2011/03/29/how-to-configure-statusnet-default-language/"
  },{
    "title": "既要开源，也要环保",
    "date": "",
    "description": "",
    "body": "今天看到了我保存的一摞Linux光盘，这基本上也记录了我所关注和安装过的所有Linux的种类。品种繁多。如下：\n  CentOS 4.4\n  Ubuntu 8.4 server\n  Ubuntu 8.4 desktop\n  Opensolaris\n  Debian 4.0\n  SuSe Enterprise 10.1\n  Redhat Enterprise Server 3\n  SuSe Linux 10\n  Mandriva 2008\n  CentOS 4.2\n  SuSe 10.0 Eval DVD\n  Mandrake 10.0\n  Redhat 7.1\n  Derbain 3.0\n  FreeBSD 5.2\n  Suse 9\n  SuSe enterprise linux 9.0\n  Fedora 4\n  Redhat 9\n  Solaris 10 x86\n  Ubuntu 10.10 Desktop\n  SLES 10 sp2\n  ![CD fire](http://martinliu.cn/wp-content/gallery/fatureimage/thumbs/thumbs_Crstal (12).png)总共50多张碟片既有CD也有DVD。Linux这东西最大的特点是更新发展的快，之前硬盘都小，为了安装Linux刻盘是最方便的方式，而且多年以前机器还不支持USB启动。这么多光盘真的是一大堆的白色垃圾，一直在想废弃光盘该怎么处理的为题，目前好像还没有即能实现废物利用，有环保的处理方法。上周为了在家里的PC上安装Ubuntu 10.10 Desktop，又刻了一张盘，希望这是最后一张Linux CD，以后考虑USB启动安装Linux的形式。使用工具软件把Linux ISO文件灌注到U盘里，在用U盘来装。\n推荐两种工具：\n  Universal USB Installer\n  LinuxLive USB Creator\n  减少光盘刻录量，做到既开源又环保！ [](http://martinliu.cn/wp-content/gallery/fatureimage/Crstal (12).png)\n",
    "ref": "/2011/03/24/usb-linux/"
  },{
    "title": "My baby girl, my angel",
    "date": "",
    "description": "",
    "body": "I am so exciting, and so happy!\n\n",
    "ref": "/2011/03/16/my-baby-girl-my-angel/"
  },{
    "title": "Remedy ARS 开源工具知多少",
    "date": "",
    "description": "",
    "body": "Remedy ARS是全球最大市场份额的产品，是为业内广泛接受的成熟产品套件；虽然他始终是私有的软件产品，但是围绕其周围，还是不断有新的开源工具出现。下面就介绍几种这样的软件。\nARInside is a free open-source utility to create a static html documentation of your AR-Server. If you need something to quickly browse through your workflow, ARInside might be worth a try. ARInside 3.0.2 has some new features, lots of bugfixes and other improvements. Just to name a few:\n documentation improvements 64-bit platform support experimental support for Solaris and AIX basic ARS 7.6.x support huge performance plus on big installations  这是一个ARS服务器扫描的工具，可以形成一个静态的文档，能够作为一个状态的参考极限，这样方便你对当前的服务器上的所有对象和工作流有个全面的了解。最大的好处是能够统计和技术，而且不用登陆Dev Studio了。一图胜千言，下面大家看后就明白它能做什么。\n看后还闲着干嘛，赶紧去下载使用吧。\n其他的关于Remedy ARS 开源的项目我也在sf.net里面大致搜索了一下，下面是个简单的参考清单。\nRemedy Outlook Integration Updated 2006-09-08 The Remedy Integration for Outlook (ROI) synchronizes tickets from any Remedy AR System application to your Outlook task list or calendar.\nRemedy ARAPI PHP extension Updated 2009-07-19 Extension to PHP for integration to Remedy Action Request System. First release will be focused on reading and manipulating data. Later version will give access to arapi-application structure functions.\nJasper Reports data provider for Remedy Updated 2006-08-16 jaspars provides a Jasper Reports custom data source (JRDataSource) compatible with the Remedy AR System. See http://www.mypathworks.com/arslist/Public?id=8ae4b6940c259f32010c3707fbae01bf for more information and usage instructions.\nARSperl Updated 2008-05-06 ARSperl is an integration kit for Perl5 and Remedy ARSystem API. It provides a large subset of the functionality found in the ARS C API\nAR Cache Purge Updated 2009-05-27 AR Cache Purge automates the process of clearing BMC Remedy user cache on client machines. It first checks the registry for the Home folders(s) and then removes the .arf and .arv files. It handles multiple users and home folders on a single machine.\npyARS Updated 2010-12-20 The pyARS python module allows developers to use BMC\u0026rsquo;s ARSystem (Remedy ARS) and Atrium CMDB functions from within Python. Using Python\u0026rsquo;s interactive shell, it is extremely easy to retrieve and modify data entries as well as workflow objects.\nCOM Objects for the AR System Updated 2006-01-10 Coarse (COM Objects for the AR System), provides an automation compatible COM API to the AR System (Remedy only provides a C API and a Java API). It is compatible with VB6, VBA, VBScript, and JScript. Based on the RTL Sourceforge project.\n",
    "ref": "/2011/03/01/remedy-ars-open-source-tool/"
  },{
    "title": "ITIL V3中级认证培训-服务生命周期模块",
    "date": "",
    "description": "",
    "body": "培训针已获得Foundation认证的学员，讲授ITIL V3服务生命周期模块的五门中级课程， 包括服务战略、服务设计、服务转换、服务运营、持续服务改进。 课程介绍了服务生命周期各阶段的术语、流程、结构、角色、职能和活动，结合ITIL的最佳实践，帮助学员掌握如何提升用户的日常IT服务。 课程中还将结合BMC的IT管理领域领导者优势，向学员介绍ITIL的自动化解决方案、以及基于ITIL的云计算生命周期管理。帮助广大学员迅速走向管理云端。课程详情\n\n认证考试： 每门课程学时三天，并包含随堂认证考试。五门成绩均及格即可获得5个中级认证以及考取高级认证的资格。\n培训价格（含认证）： 单门课程10000元/人 五门课程优惠价格共32000元/人\n特别赠送：\n报名五门课程的学员，将获赠云计算网络培训一次。课程介绍 没有通过考试的学员，每门提供一次免费重考。 培训时间： 服务战略：3月21-23日 服务设计：3月24-26日 服务转换：4月11-13日 服务运营：4月14-16日 持续改进：5月18-20日\n培训地点: BMC上海培训教室（浦东花园石桥路33号花旗大厦） 咨询和报名:010-85183688-1883 yuan_yuan@bmc.com Yunlong_jin_cw@bmc.com\n",
    "ref": "/2011/02/21/itil-v3-bmc-training/"
  },{
    "title": "在Oracle上备份和恢复 Remedy ARS数据库",
    "date": "",
    "description": "",
    "body": "Why ARS system need full backup and restore 众所周知_Remedy ARS_上运行的所有程序代码都是在数据库中存储的，几乎所有的程序代码和相关数据都是存储在后端的数据库里的。基于这种特性，我们可以很方便地从数据库层面实现对ARS系统的备份和恢复。所谓基于数据库的备份和恢复就是指数据库的全库导入和导出。在这方面_Oracle_做的很好，他所提供的imp和exp命令行工具能很好的完成此项任务。 When you may backup BMC Remedy ARS system Database _Remedy ARS_系统数据库全备份可能会发生在下面的几个时间点：\n   在安装过程中，_Remedy ITSM_套件的安装都是从ARS开始一个模块一个模块增加安装的，可以在安装每个新模块之前，做一个数据库备份，用于安装失败情况下的现场恢复   在系统上线前，当系统需要做升级/代码更新等等大规模操作之前可以考虑做一次数据库的导出备份   在做系统迁移的情况下，我们甚至可以生产库迁移到开发机上进行问题的重现，或者代码的修改，或者测试，完成之后再导回生产系统（如果生产系统再次期间处于维护状态的话） How-to 下面是我总结的相关操作步骤参考。\n备份_ARSystem_数据库 exp aradmin/ar#admin@itil file=c:\\before-patch7.dmp log=c:\\exp.log compress=n statistics=none\n参数解释： aradmin/ar#admin 是ARS系统默认的用户名和口令 @itil 是ARSystem数据库所在的数据库实例名 file=c:\\before-patch7.dmp log=c:\\exp.log 是导出的数据库文件和日志文件路径\n删除ARAdmin用户数据 drop user aradmin cascade;\n创建和授权ARAdmin用户 CREATE USER ARADMIN IDENTIFIED BY ar#admin# DEFAULT TABLESPACE ARSYSTEM TEMPORARY TABLESPACE ARTMPSPC PROFILE DEFAULT ACCOUNT UNLOCK;\nGRANT ARADMINROLE TO ARADMIN; ALTER USER ARADMIN DEFAULT ROLE ALL; ALTER USER ARADMIN QUOTA UNLIMITED ON ARSYSTEM;\n导入备份的数据文件 imp ARAdmin/AR#Admin@ars file=c:\\CMDB2010-12-13_13.dmp log=c:\\imp.log fromuser=ARAdmin touser=ARAdmin ignore=y\nCredit to：以上操作步骤由_神州太岳_工程师_李成旗_协助编写和测试.\n",
    "ref": "/2011/02/14/backup-restore-remedy-ars-oracle-db/"
  },{
    "title": "图书推荐《服务建模：原理与应用》",
    "date": "",
    "description": "",
    "body": "Learn how to use service modelling to streamline and optimize processes!\nInformation about customer needs, the technical composition of services, and service performance are fundamental to effective service management. Service modelling is a structured approach to utilizing this information to improve the way services are delivered. Consistent application of service modelling provides the automation of processes and timely access to information.\n[caption id=\u0026ldquo;attachment_50942\u0026rdquo; align=\u0026ldquo;alignleft\u0026rdquo; width=\u0026ldquo;201\u0026rdquo; caption=\u0026ldquo;Service Modelling: Principles and Applications \u0026ldquo;][/caption]\nService Modelling presents a comprehensive, up-to-date overview of the topic, presented in the context both of business processes, and of requirements stemming from the need to manage network resources. Vilho Räisänen delivers a justification for service modelling, and explains state-of-the-art concepts, frameworks and standards in detail.\nService Modelling:\n  Provides a complete and illustrated overview of state-of-the-art concepts for service modelling, covering requirements and frameworks.\n  Includes industry initiatives, conceptual frameworks, and the work of standardisation bodies.\n  Discusses different modelling approaches, and the positioning of modelling of services in service management and in the wider operational context.\n  Sets the modelling framework in the context of business drivers and modelling paradigms.\n  Illustrates principles with real-world use cases, providing both fixed Internet and mobile network examples.\n  Relates concepts to the work of TeleManagement Forum, giving practical examples throughout.\n  Service Modelling: Principles and Applications is an invaluable guide to service modelling for telecommunications and data communications professionals, including vendors, operators, consultants, training organizations, service and content providers, system architects and engineers for IP-based services. Educational organizations, advanced undergraduate and graduate students on telecommunications and networking courses will also find this text invaluable.本书的已经翻译为中文版本，本书中包含了针对电信行业的实例模型和介绍，图书内容介绍如下：\n《服务建模:原理与应用》主要内容简介：服务技术的发展，不仅彻底改变了人们原有的生活方式，更从本质上促进了当代社会经济发展方式的转变。《服务建模: 原理与应用》以服务建模为主题，共分4部分：第1部分介绍了服务建模所需解决的问题，第2部分分析了实际应用中的服务建模框架，第3部分列举了使用服务建模的案例，第4部分则对《服务建模:原理与应用》的中心内容进行了总结，并提出了未来服务建模值得研究的一些领域。 《服务建模:原理与应用》可作为高校信息技术、管理和经济类相关学科电子服务方向的教学用书。也可以作为现代服务企业进行服务建模方面研究的工具书或参考书。\n",
    "ref": "/2011/02/12/book-service-modelling/"
  },{
    "title": "在64位Windows上安装ARS7.5",
    "date": "",
    "description": "",
    "body": "刚才终于把ARS装上了。费了我两天的力气终于搞定了。错误其实很简单的，现象很多人都见过，ARS在安装完所有的文件后，在系统中建完ARS的服务以后，会继续启动服务，才能做最后的程序文件导入的相关操作。\n错误的现象是：在启动服务的时，安装程序一直停止在“Starting Remedy ARS services\u0026hellip;.”的屏幕，去arerror日志里面可以看到无法连接到SQL数据库的错误。\n我的安装错误的原因其实很简单：\n  如果是64为的Windows操作系统，默认的安装路径是C:\\Program Files (x86)\\目录\n  Oracle客户端没有正确的安装\n  解决的方法如下：\n  修改ars默认的安装路径，尽量把它放在一个较短的而且没有特殊字符的路径里，如D:\\bmc\\\n  ARS 7.5 sp6支持的Oracle客户端是32位的，如果你在64位OS上安装的是64位的Oracle数据+客户端（sqlplus），那么默认的这个64为的客户端是不能用的，需要安装一个62位的客户端，而且需要时10g的，此版本也不支持11g的客户端；另外在安装32位的oracle客户端的时候最好也不要在路径中有特殊字符如符号和下划线之类的\n  ARS7.5本身是32位的可支持程序，所以它所需要的JDK和Oracle都需要是32位的版本。如果你安装的是7.6.04，就不需要考虑32位的问题，由于它本身就是64位的程序了，所以JDK和Oracle都需要使用相应的64为的程序。\n",
    "ref": "/2011/02/10/64-windows-ars-75-install-tips/"
  },{
    "title": "BMC Atrium CMDB CI数据迁移",
    "date": "",
    "description": "",
    "body": "在不同的CMDB服务器之间做数据迁移之前一定要注意两点：1）保持两边的CDM相同；2）先导入CI数据在导入CI相关的关系数据。另外就是每个类导入完毕之后要做数据完整性和正确性的抽检。以下使用的工具是cmdbdriver，该命令初始化和一般性的参数介绍请参考相关文档。\nCI数据导出示例\nCommand: xexpdt XEXPORT DATA Export instance data from all classes? (F): Classes to export data from: Class and its subclasses, From namespace (1,2) (1): Namespace (): BMC.CORE Class name (): BMC_ComputerSystem Dataset ID (): BMC.ASSET Filename for exported data: C:\\DEMO\\cs-ci Exporting Class BMC_ComputerSystem i=0: namespaceName = BMC.CORE, className = BMC_ComputerSystemExported without errorsExporting Class BMC_MainframeExporti ng Class BMC_PrinterExporting Class BMC_StorageSubsystem CMDBExportData results ReturnCode: OK Status List : 0 items\n到相应目录下面找到导出的文件，导出的结果至少是两个文件一个是META_FILE其他的才是CI数据文件。\n关系数据导出示例\nCommand: xexpdt XEXPORT DATA Export instance data from all classes? (F): Classes to export data from: Class and its subclasses, From namespace (1,2) (1): Namespace (): BMC.CORE Class name (): BMC_Dependency Dataset ID (): BMC.ASSET Filename for exported data: C:\\DEMO\\REL-DEP.XML Exporting Class BMC_Dependency i=0: namespaceName = BMC.CORE, className = BMC_DependencyExported without errorsExporting Class BMC_AccountOnSystemExpor ting Class BMC_HostedAccessPointExporting Class BMC_HostedServiceExporting Class BMC_InventoryBulkItemsExporting Class B MC_InventoryComputerSystemsExporting Class BMC_InventoryEquipmentExporting Class BMC_InventorySystemComponents CMDBExportData results ReturnCode: OK Status List : 0 items\n到相应目录下面找到导出的文件，导出的结果至少是两个文件一个是META_FILE其他的才是CI数据文件。\n导入数据示例\nCommand: impdt IMPORT INSTANCE DATA Handle duplicate Instance Ids: (Error/New ID for Dup/Merge/New ID for All) (1-4) (1): 3 Filename containing import data: c:\\demo\\cs-ci_0_0 (导入包含CI数据的文件)\nCMDBImportData results ReturnCode: OK Status List : 0 items Total items Processed : 2 Items Imported successfully : 2 Items for which Import failed : 0\nCommand: impdt IMPORT INSTANCE DATA Handle duplicate Instance Ids: (Error/New ID for Dup/Merge/New ID for All) (1-4) (1): 3 Filename containing import data: c:\\demo\\REL-DEP.XML_0_0 (导入包含关系数据的文件)\nCMDBImportData results ReturnCode: OK Status List : 0 items Total items Processed : 1 Items Imported successfully : 1 Items for which Import failed : 0\n导入完毕之后使用Remedy User到相应的表格中查找，确认导入的数据是否正确。\n",
    "ref": "/2011/01/12/bmc-atrium-cmdb-ci/"
  },{
    "title": "BMC Atrium CMDB 类定义迁移",
    "date": "",
    "description": "",
    "body": "当对CDM做了定制，并且要在不同的服务器直接做类的迁移的时候，需要把定制过的类都导出，然后在目标机上导入。可以使用的CMDB自带的命令行cmdbdriver工具。\ncmdbdriver.exe能支持的参数\nOptions: -u -a -p -l -s -x\u0026lt;INPUTFILE_FULLPATH\u0026gt; -t\u0026lt;PORT_NUMBER\u0026gt; -q\u0026lt;QUIET_MODE_NUMBER\u0026gt;\n登录CMDBdriver 实例： cmdbdriver -u Demo -p bmc@XXX -s atriumcmdb -t 9988\n登录之后在运行另外用于初始化的两个命令 init 和log\nCommand: init INITIALIZATION\nCMDBInitialization results ReturnCode: OK Status List : 0 items\nCommand: log Control record: Authentication string () : User name () : Demo Password () : ********** Locale[.charSet] () : TimeZone () : Server () : atriumcmdb\n导出类定义的方法实例 Command: xexpdf XEXPORT DEFINITION Export all classes? (F): Classes to export: Class and its subclasses, From namespace (1,2) (1): Namespace (): BMC.CORE Class name (): BMC_ComputerSystem Export all attributes with classes? (T): Filename for exported data: c:\\demo\\BMC_ComputerSystem.xml\nCMDBXExportDef results ReturnCode: OK Status List : 0 items\n使用文本编辑器查看c:\\demo\\BMC_ComputerSystem.xml的导出结果\n导入类定义的方法： Command: impdf DEFINITION IMPORT Import Item List: Number of import items (0): Import option : Create/Overwrite (1-2) (1): 2 Filename containing import data: c:\\demo\\cs.xml\nCMDBImportDef results ReturnCode: OK Status List : 0 items\n使用Remedy User，用Demo登录，把语言切换到英文，然后在查BMC_ComputerSystem表达，在custom 2 ～n的tab页面里面查看哪些导入的属性。或者使用class manager查看确认导入是否成功。\n",
    "ref": "/2011/01/12/bmc-atrium-cmdb-sync-cdm-class/"
  },{
    "title": "Fiddler Timers ",
    "date": "",
    "description": "",
    "body": "Fiddler is a Web Debugging Proxy which logs all HTTP(S) traffic between your computer and the Internet. Fiddler allows you to inspect all HTTP(S) traffic, set breakpoints, and \u0026ldquo;fiddle\u0026rdquo; with incoming or outgoing data. Fiddler includes a powerful event-based scripting subsystem, and can be extended using any .NET language.Fiddler is freeware and can debug traffic from virtually any application, including Internet Explorer, Mozilla Firefox, Opera, and thousands more.\n  ClientConnected- Exact time that the client browser made a TCP/IP connection to Fiddler.\n  ClientBeginRequest– Time at which this HTTP request began. May be much later than ClientConnected due to client connection reuse.\n  ClientDoneRequest - Exact time that the client browser finished sending the HTTP request to Fiddler.\n  DNSTime - # milliseconds Fiddler spent in DNS looking up the server\u0026rsquo;s IP address.\n  GatewayDeterminationTime - # milliseconds Fiddler spent determining the upstream gateway proxy to use (e.g. processing autoproxy script). Mutually exclusive to DNSTime.\n  TCPConnectTime - # milliseconds Fiddler spent TCP/IP connecting to that server\u0026rsquo;s IP address.\n  HTTPSHandshakeTime – Amount of time spent in HTTPS handshake\n  ServerConnected – Time at which this connection to the server was made. May be much earlier than ClientConnected due to server connection reuse.\n  FiddlerBeginRequest – The time at which Fiddler began sending the HTTP request to the server.\n  ServerGotRequest - Exact time that Fiddler finished (re)sending the HTTP request to the server.\n  ServerBeginResponse - Exact time that Fiddler got the first bytes of the server\u0026rsquo;s HTTP response.\n  ServerDoneResponse - Exact time that Fiddler got the last bytes of the server\u0026rsquo;s HTTP response.\n  ClientBeginResponse - Exact time that Fiddler began transmitting the HTTP response to the client browser.\n  ClientDoneResponse- Exact time that Fiddler finished transmitting the HTTP response to the client browser.\n  Can i find out how long the server needs to process my request ? (ServerBeginResponse - ServerGotRequest) is probably what you want.\nCan i find out how long the request needs to pass through the network? I\u0026rsquo;m not sure that\u0026rsquo;s what you really want to know, but it would be:\n(ServerGotRequest - ClientDoneRequest) - (DNSTime + TCPConnectTime)\n",
    "ref": "/2010/12/22/fiddler-timers/"
  },{
    "title": "[ZT]ITIL V3 服务转换篇 之 资产和配置管理",
    "date": "",
    "description": "",
    "body": "为了定义和控制服务和基础设施组件。维持当前计划中、历史的服务和基础设施状况配置信息的准确性 **一、先介绍几个基本概念 **1、配置项（CI） 配置项是正在或将要在配置管理控制下的资产、服务组件或其他。配置项在复杂性、大小、种类有很大不同，从整个服务或系统包括硬件、软件、文档、支持人员到单独软件模块或硬件组件。配置项可以集中或分组管理。配置项可以选择使用既定的选择标准、分组、分类和识别方式在整个生命周期中管理和追溯。其包括： A) 服务CI项：服务能力资产、服务资源资产、服务模式、服务包、发布包、验收标准等 B) 组织CI项 C) 内部CI项 D) 外部CI项：包括外部客户需求和协议、供应商发布、分包商及对外服务。 E) 接口CI项：端到端的服务，跨越服务提供者的接口 2、配置管理系统（CMS） 为了管理大型复杂的IT服务和基础设施，资产和配置管理需要使用配置管理系统CMS。在指定范围内CMS掌握着所有配置项信息。CMS为所有服务组件与相关事故、问题、已知错误、变更发布、文档、公司数据、供应商、客户信息做关联。 在数据层面CMS能使数据库存在多个物理CMDB中而后共同组成一个联合的CMDB。其他数据来源也可以加入CMS中。 3、配置管理数据库(CMDB) 所有配置项的信息都包括在配置管理数据库(CMDB)中。配置管理数据库(CMDB)对所有IT 组件、组件的不同版本和状态以及组件之间的相互关系进行跟踪。在其最基本的形式下，配置管理数据库(CMDB)可能仅由一些纸质表格或一套电子表格 (Spreadsheets)组成。 4、最终介质库(DML) DML是用来存储和保护所有已授权的被确认版本介质配置项。 他们存储经过质检的主拷贝版本。这个库可以有一个或多个软件库或存放区来存放开发、测试和实时存储文件。他们包含组织所有软件的主拷贝、购买软件的副本及 受控文件的电子版。DML包含物理的拷贝存储，DML是发布管理的基础。\n**二、配置管理的目的： ** 1. 确定、控制、记录、报告、审计、验证服务资产和配置项包括版本、基线、组成成分、属性和相关关系。 2.通过服务生命周期管理保护资产完整、配置项等账户。确保只有已授权的组件被使用和已授权变更被执行。 3.通过服务生命周期保护服务资产、配置项的完整性。为了建立和维持一个准确和完整的配置管理系统，确保资产和控制服务、IT基础设施的配置需求的完整性。\n三、资产、配置管理的活动\n\n1、规划 2、识别 配置项识别过程： A) 定义和制定标准文件来选择配置项和他们的组件构成 B) 依据标准选择配置项及其组件并记录他们 C) 给配置项分配唯一的标识符 D) 指定每个配置项相关属性 E) 确认每个配置项是受配置项管理来管理 F) 确定每个配置项的责任人 3、控制 必须有效控制信息以维持配置管理数据库(CMDB)的及时更新。一旦某项活动改变了配置项已记录的特征或配置项之间的关系，则必须在配置管理数据库 (CMDB)中记录该项变动。需注意的是：只有变更管理才有权批准对配置项的特征进行变动，事件管理只能改变某个现有的配置项的状态来反映现实状况。 配置管理负责控制组织接收到的所有IT 组件并需确保这些组件被记录在系统中。硬件可在其已订购或已交付时进行记录，而软件则通常在其被纳入DML时进行记录。 4、记录 组件的生命周期可被划分成多个阶段，每个阶段都可以分配一个状态代码，但具体分成几个阶段则取决于公希望记录IT 基础设施的哪些特征。保持对每次状态变化日期的记录可以提供关于一个产品的生命周期的有用信息，如订购时间、安装时间以及所需的维护和支持。组件的状态决 定了可以对其进行操作的余地。 5、审核和报告 执行审计是为了核实配置管理数据库(CMDB)中记录的信息是否仍然反映了当前的现实状况。这些信息可用来检查和更新配置管理数据库(CMDB)。 在下列情形下需要执行审计： A) 在建立了新的配置管理数据库(CMDB)之后； B) 建立配置管理数据库(CMDB)一段时间之后； C) 重大变更之前或之后； D) 灾难恢复之后； E) 其他任何方便的时候。 审计也可以随机地或在配置经理认为配置管理数据库(CMDB)中的信息不正确时进行。如果配置管理系统与审计工具之间存在关联，则可以每天生成针对某个相 关领域的审计报告。在发现差异时，不应该允许审计工具自动更新配置管理数据库(CMDB)。所有的差异都表明变更管理流程可能被忽视了，所以应该对这些差 异进行调查并通过变更管理对这些差异进行追溯性处理。 三、配置管理管理报告 配置管理流程的管理报告可能包括下列信息： a) 有关流程质量的信息； b) 在审计中发现的记录与实际情形不符的次数； c) 发现未经批准的配置的次数； d) 出现已记录的配置不能被找到情形的次数； e) 审计中发现的有关配置项属性详细程度方面的差异； f) 处理信息记录请求所需的时间； g) 超过给定事件或变更次数的配置项的列表； h) 有关 IT 基础设施的结构和组成的统计信息； i) 有关 IT 基础设施发展情况及其他方面的信息； j) 有关改进措施的总结、报告和建议，例如，针对由于业务、技术、市场价格和其他相关变化所导致的配置管理追踪记录的配置项的范围和详细程度的变更所提出建议； k) 有关实施流程所耗费的人力成本的清单。\n四、配置管理的绩效指标指标 a) 闲置许可数量; b) CMDB错误导致变更失败的数量; c) 未授权配置数量; d) 配置项文档错误导致变更失败所引起的事故数量; e) 因为CMDB错误导致违反SLA的数量; f) 无相应配置项刷新的变更请求数量; g) 不精确配置项百分比; h) 客户满意度 ;\n五、与其他流程的关系\n转帖学习一下。\nFrom http://blog.amteam.org/standard/A1159174.html\n",
    "ref": "/2010/12/20/itil-v3-asset-configuration/"
  },{
    "title": "如何阻止员工上班时间聊QQ的免费解决方案",
    "date": "",
    "description": "",
    "body": "最近听说有些公司的IT部门已经发文，要求公司员工所使用的电脑必须尽快安装360软件。嗯，这还真是一个法子，值得推广哈哈哈\n",
    "ref": "/2010/11/06/qq-v-360/"
  },{
    "title": "八月十五月儿圆，我和兄弟们装AR",
    "date": "",
    "description": "",
    "body": "经过几天的奋战，我们终于在中秋月圆之夜，在黑山扈的百望山脚下为客户成功地安装了Remedy ITSM 7.6.03 每当安装程序一次次挂死、安装程序界面不正常显示、安装不完全、安装失败，都让在场的人达到抓狂的后期，无语~~ 这里总结一下这几天的失败安装的血泪史，供后来人参考学习。\n版本的确认：所有操作系统，JVM，JDK，数据库，数据库客户端，和以上软件的位数都需要查明，都需要在Remedy的兼容文档中一一确认。\nAIX操作系统的字符集：需要同时安装中英文的UTF8字符集。安装方法smitty，需要有操作系统的安装盘，安装完成之后，locale -a ，需要能看到 ZH_CN, ZH_CN.UTF-8,EN_US, EN_US.UTF-8 这四种字符集缺一不可。否则无法以中文方式安装成功，也无法让操作系统已中文utf8来启动AR服务。\nXManager需要安装在于AR同一网段的Windows服务器上，例如Mid-tier可能安装在Windows上，并与AR在同以网段，那么安装程序最好在该服务器的Xmanager的客户端中安装，从哪里连接AIX服务器并运行安装程序。如果不在同一个网段，安装程序很有可能安装了一半或者无名的消失，安装进程会立刻中断，需要把系统推到重来。\nAIX系统上font server的安装：使用netstat -na|grep 7100， 如果没有结果则需要从AIX的光盘中在AIX的服务器上安装font server和相关的包，并且启动它。如果不装的话，remedy安装程序可能界面显示不正常，或者不显示。\nOracle上众多僵尸进程：如果在安装CMDB或者ITSM套件的时候，安装界面挂死或者消失，这会是Oracle服务器上产生上百个僵尸进程，这些进程会吃光Oracle服务器的所有物理内存。我们的oracle服务器的16GB内存被吃光之后，ITSM安装界面几乎停止，20~30分钟才能安装完一个定义文件。解决方法是：随时监控Oracle服务器的内存使用情况，当出现内存被僵尸进程吃光的情况，可以考虑使用IT行里无人不知的无敌重启方案，重启Oracle服务器的操作系统，从启动Oracle数据库实例，重启ARS服务，然后再次安装Remedy ITSM。\nRemedy安装之备份：如果是在AIX+Oracle的数据库上安装。Remedy还是非常绿色的软件，需要在安装完AR，CMDB，ITSM套件后各做一个Remedy安装文件目录的备份，在AIX上可以把这个文件夹tar起来备用。Oracle数据库还是非常容易备份的，使用imp和exp命了就可以搞定，具体语句咨询DBA。切忌在安装CMDB和ITSM之前一定要对Remedy系统的安装文件和数据库做备份，一旦安装失败，可以恢复文件，恢复数据库，排错后重新再来。\n",
    "ref": "/2010/09/22/install-remedy-ars-itsm-on-aix-oracle/"
  },{
    "title": "[ZT] Old BSM is dead",
    "date": "",
    "description": "",
    "body": "随着云计算和虚拟化的来临，IT架构愈加复杂，老一套的IT管理方案只能监控静态的基础架构。老一套的CMDB和BSM给运维无法带来实质性的帮助，需要能够具有自适应、自学习IT环境的能力，管理工具需要对IT环境的变化有感知，有学习功能，否则无法对业务故障的处理给予应有的支持。转帖自学一下这个文章，老外从IT架构的历史讲起，横跨跨服务保证和CMDB等领域，讲的还是很不错的。 The Significance of the VMware Integrien Acquisition While it may seem that with Integrien VMware has acquired yet one more piece of the puzzle (a puzzle whose final form no one knows), this acquisition is perhaps one of the most significant if not the most significant that VMware has done. To understand the significance of this acquisition, one has to step back and examine a bit of history in the Systems Management business.\nFor as long as there have been computers, operating systems and business critical applications, there has been monitoring of these items to make sure they were working (available) and performing well for their constituents. In the early days of the computer industry (through about 1982) computer systems were vertical monoliths where a customer would buy “an accounting system” and that purchase would include hardware, systems software, and applications software. All of this usually came from one vendor so there was one throat to choke when it did not work.\nStarting with the delivery of the PC, then Ethernet LAN’s and Novel Netware, and finally Windows Servers and the Internet, the industry reorganized along horizontal dimensions. A computer system was now a multi-layer cake and you could buy each cake from one of many vendors whose products were largely interchangeable with each other, and compatible with adjacent layers. So you could buy an Intel based server from one of N vendors, put either Linux or Windows on it, but a Java applications server from one of N vendors on that and then buy applications from thousands of different vendors.\nThis horizontal layering of the industry was heavily promoted by Microsoft and Intel (who “owned” two key layers of the cake), and also ushered in the tremendous innovation and price competition that continues to drive our industry today. Moore’s Law says that microprocessor performance doubles roughly every 18 months or so, and with those increases in price/performance come the more for less mentality that we have all become accustomed to.\nWith this freedom of choice at every layer of the cake however came problems. The first problem was complexity. There were now too many cooks in the kitchen which meant that there were both too many and not one single throat for the CIO to choke when something went wrong. The management software industry reacted to this by inventing a marketecture, Business Service Management (BSM). The idea behind BSM was to identify the key business services that applications or combinations of applications delivered to users (the ability to enter and order and ship the resulting product is a business service as is the ability of a consumer to transfer funds from one banking account to another), and to then map all of the software and hardware infrastructure that this business service depended upon and to manage that collection of linked resources as an entity.\nWhile Business Service Management sounded like a great idea, it in fact ended up as a miserable failure. The reasons were:\n  There were many applications for which it was just too hard to measure their performance (in response time terms). Web applications turned out to be pretty easy, but fat client Win32 applications written to proprietary client/server protocols turned out to be very hard. It turned out that for most enterprises, more than half of the business critical applications were in the hard pile (fat client/Win32) and less than half were the easy web applications.\n  Many BSM frameworks relied upon scripts and synthetic transactions to measure response time and end user experience. However this approach failed for many enterprises due to the large number of applications that comprised a business service and how rapidly these applications were changing. For example if synthetic transactions were used to measure the performance of a set of transactions, and a company had 500 business critical applications (not a very high number – some companies have thousands), and each application was updated once a year, then that would translate into 10 updates a week for the monitoring scripts.\n  The same is true for most passive monitoring approaches that rely upon templates to identify transactions in applications protocols. There are many products that can measure the response time of transactions from the perspective of the web server by attaching physical or virtual appliance to a span port on the switch that services the web server. However all such products require configuration to understand what set of granular http request/responses combine to create a transaction of interest. Maintaining these configurations across hundreds of applications and thousands of transactions proved to be a major impediment to instrumenting their service level in any kind of a broad and systematic manner.\n  It turned out to be a nightmare to identify the hardware and software that supported each business service. This gave rise to the need for Configuration Management Databases (CMDB’s) that were supposed to get populated with the hardware and software assets and their relationships to each other. The effort to put in place a CMDB and to maintain it turned out to doom the CMDB projects and the associated BSM projects at many companies.\n  The BSM vendors were unable to evolve their products at the same rate as the innovation of the vendors who contributed products to the layers in the cake. New devices (laptops that were not always connected), new protocols (ICA, VOIP), new operating systems (Linux), new languages (Java, C#), and new user interfaces (first the browser and then rich Internet applications) all occurred at a pace that no one vendor could keep up with.\n  When the BSM vendors got overwhelmed by innovation, vendors of point monitoring solutions stepped in to monitor the newest layer or item in a layer. This lead to a proliferation of monitoring tools which were not integrated with each other.\n  When a problem occurred even if one had a BSM product and a CMDB it still horribly difficult to know exactly what path the failed transaction took through the entire hardware and software infrastructure. The BSM tools were rarely aware of every element of the stack and the tactical monitors that had been bought to fill in the cracks were not integrated with the BSM tools nor each other.\n  In summary we entered the age of virtualization and the cloud with both BSM and their supporting CMDB’s having failed at monitoring and managing a static infrastructure where applications and services largely stayed on dedicated hardware. In other words, before virtualization and the dynamic data center it was impossible for anyone in IT to see a problem and get told in a deterministic manner exactly where the problem was and how to fix it.\nThe Impact of Virtualization and the Cloud\nSince holistic end-to-end monitoring of business services was essentially broken (or not attainable) before virtualization, it is reasonable to assume that virtualization and the cloud will only make this problem worse. This will occur for the following reasons:\n  Virtualization increases workload density and the dynamic operation of workloads. This will require both continuous mapping of application to infrastructure dependencies and more more frequent (near real time) collection of performance data. Just the requirements for real time mapping and real time data completely overwhelm existing monitoring systems. Hyperic has a good blog on this point here.\n  Inferring application performance from resource utilization statistics becomes impossible. This was possible on physical hardware, but on hardware that is shared via virtualization it no longers works. Hence the need for Infrastructure Performance Management solutions that measure Infrastructure Response Time. We expect Infrastructure Performance Management solutions from vendors like Akorri, CA Technologies (CA Virtual Assurance), Virtual Instruments, and Xangati to form the foundation layer of whatever will replace BSM.\n  Application will now get moved from cluster to cluster and ultimately from data center to data center (private cloud – hybrid cloud – public cloud). APM solutions will need to track the applications no matter where they go, and seamlessly work across different IP networks. Leading virtualization aware APM solutions like those from AppDynamics, BlueStripe, and New Relic meet these needs today and will likely form the APM layer of whatever replaces BSM.\n  All of the above together combine to create one new result for Systems Management. That new result is that in the general case it will be impossible to deterministically do root cause in a dynamic environment. This was explored in detail in this post.\nThe Significance of the Integrien Acquisition\nThe Integrien acquisition by VMware is significant because it means that VMware has recognized that only a dynamic, statistical, self-configuring, and self-learning approach can keep up with the rate of change in these new dynamic IT environments. The self-learning approach simply means that you feed the system the metrics that get collected about the system and it figures out which ones are important, how the metrics are related to each other, and lets you know when anomalies have occurred.\nThis acquisition is all the more significant because this is not garden variety technology. There have only ever been three companies this this space. ProactiveNet was acquired by BMC a few years ago. Netuitive has been around since the late 1990′s and it took the company until the mid 2000′s before the product had matured into something that really just worked when you plugged it in. Integrien is a fairly recent entry in this field and is now part of VMware – which leaves Netuitive as the only remaining independent player.\nThe New Dynamic BSM – Service Assurance\nSince the old BSM is dead due to a brittle and difficult to update technology approach it is reasonable to ask what will replace it. The answer is most likely a set of Infrastructure Performance Management tools (Akorri, CA Virtual Assurance, Virtual Instruments, Xangati) integrated with a set of next generation APM tools (AppDynamics, BlueStripe, New Relic) vis these self learning technologies. When this occurs, we will have a system that adapts on its own to changing conditions in the environment leaving IT staff available to interpret results (and not raw monitoring data). We will also have taken an important step towards dynamic service assurance which was discussed in detail in this post.\nUnderstanding and Evaluating these Technologies\nFor most IT professionals either they or someone on their staff can digg in and understand how the technologies that they use work. However unless you have an advanced degree in statistics and/or mathematics you are not going to be able to dig an and decide for yourself based upon how these products work which one you should choose. Rather what you should do is apply the following criteria in making your selection:\n  Decide exactly what you want the product to do for you. These products are extremely flexible. You can feed them every alarm that is generated by all of your monitoring solutions and let them sort out the good ones from the bad ones. Or you can feed them revenue per minute for one key business application and let them figure what causes degradations in revenue per minute.\n  Make sure that the product has connectors to what you already use to collect metrics from your systems. These products are not in the data collection business (with some exceptions). They rely upon other products to collect data from them. They must therefore be interfaced with your existing monitoring solutions.\n  How hands off and plug and play will the product be in practice? This is the key criteria to the long term value of such a solution to your enterprise. Previous attempts at statistical approaches (neural nets) failed because the product had to be “retrained” every time conditions changed. Make sure that the product you select can automatically select and weight the inputs that it bases decisions off of and these these decisions are automatically updated over time. Self-learning needs to be a continuous thing, not just a one time or periodic thing.\n  Make sure that the product can handle time based (time series) as well as event based data. Performance metrics tend to be time based, but many performance problems are caused by configuration changes which are events. Make sure that the product can cross-correlate configuration change events with performance degradations.\n  Carefully assess the scale of the solution. This means how many inputs can the solution take per unit of time. Right now most of these solutions operate at 15 minute or 5 minute intervals. Monitoring a dynamic system may require intervals of 10 or even 5 seconds (or perhaps even real time continuous streams of monitoring data).\n  Summary\nSelf-learning performance management solutions like Integrien and Netuitive are going to be absolutely an essential part of the migration to dynamic data centers and IT as a Service. Once these dynamic data centers scale out to the thousands of applications in a typical enterprise, and scale up to address the most performance critical applications, the rate of change in the environment will be too high for legacy tools and manual administration to be able to keep. up. These automated self-learning approaches will be the only way in which IT Operations will be able to stay on top of these new environments while staying within staffing and budget constraints.\n",
    "ref": "/2010/09/17/zt-bsm-dead/"
  },{
    "title": "Open source software box dot net launch",
    "date": "",
    "description": "",
    "body": "\nMy another new domain name ossbox.net is launching. This site will move into as soon as martinliu.cn could be finally blocked due to IDC domain registration process failed.\nI am almost giving up this blog sometimes, just because .cn domain name is hopeless. I am done with this game. For the past few months, I did everything that I could do for keeping this domain alive. But, martinliu.cn is still under the risk; you could not reach this site for any moment.\nossbox.net means open source software box network. I\u0026rsquo;d like to package oss as a physical machine or virtual appliance. A quick start guide will go with it to jump start a new user for using oss. Installation and configuration work is painful for people are not a oss guru. I call this is the last mile problem for adapting open source software. If you have oss specialty and are interesting in this kind of work, please drop me a email. I\u0026rsquo;d like to involve anyone who has same idea.\n",
    "ref": "/2010/09/15/open-source-software-box-dot-net-lunch/"
  },{
    "title": "Remedy Server Group及负载均衡配置参考步骤",
    "date": "",
    "description": "",
    "body": "上图为大型用户环境下Remedy ITSM的部署架构，作为本安装步骤参考模型。所不同的是，如下配置步骤只应用了一个最上面的负载均衡器，每个Web对应连接一个ARS服务器，简化掉了中间放在ARS前的负载均衡器。\n第一步 安装前的准备工作。 确定Remedy ARS的服务别名，例如“AtriumCMDB”。在所有的Web服务器（Mid-tier所安装的服务器）的host文件中加入一条Ip地址解析，例如：\n192.168.10.11 AtriumCMDB 此ARS服务别名指向的是该Web服务器所对应的ARS服务器，例如：Web1中AtriumCMDB对应的ip为ARS1，Web2对应ARS2，Web3对应ARS3，以此类推。\n第二步安装第一台ARS服务器 默认所有的ARS都安装了数据库客户端程序，如果是Oracle数据库，ARS上的客户端程序的大小版本号必须和远程数据库的大小版本号完全一致。Windows平台的Oracle客户端只支持32位的程序。在所有ARS服务器的host文件中加入一条Ip地址解析，例如：\n192.168.10.11 AtriumCMDB 此IP地址为每台ARS自己的对外提供ARS服务的IP。ARS上安装完JDK之后，开始安装ARS，安装过程中服务器别名输入AtriumCMDB，其他的选项都按需要配置，所有有关服务器端组件、服务端口、密码、安装路径的信息都要做详细记录，用来安装Server Group中其他成员使用。安装完第一台服务器的ARS之后，申请Remedy License，打License，包括其他所有CMDB、ITSM相关应用模块的License，打完License后导出成文件备用。ARS安装成功之后，顺序安装其他应用，顺序时CMDB 》ITSM 其他。安装完毕后，通过Remedy User来确认所有应用功能是否正常。\n**第三步 **配置第一台ARS服务器为Server Group中的管理服务器 配置方法参照，ARS Configuration Guide中的Server Group的相关章节。配置完毕之后打开Server Group的Log，从启动ARS服务之后，查看该Log看Server Group工作是否正常。\n第四步 安装Server Group中的成员ARS服务器 准备工作参考第一台ARS服务器。运行ARS安装程序，选择Server Group，选择输入AtriumCMDB别名，选择共享的数据库，其他参数与第一台保持一致。安装完毕之后。使用ARS自带的Sample应用新增一个city，在ARS1上查询ARS2上新增的记录。同样参考的Server Group的相关章节，对ARS2进行配置。在ARS2上查看Server Group的日志，确认该ARS已经加入了以第一台ARS为管理服务器的群集中。为第二台ARS服务器打License。在确认第二台ARS服务器成功加入之后，安装CMDB应用。安装完毕之后，在第二台ARS服务器上，使用Remedy User客户端，打开CMDB的相关表单进行新增和查询操作；然后在ARS1上检查操作结果，保证两边一致。安装ITSM：直接把第一台ARS服务器的ar.cfg文件覆盖到第二台ARS的ar.cfg上，一定要修改第一台ARS服务器主机名的哪一行，把它修改为第二台ARS的主机名。复制第一台ARS的ITSM安装目录到第二台ARS的相同路径中，重启ARS服务。查看arerror.log文件看看ARS启动的是否正常。在第二台ARS上使用Remedy User确认ITSM应用是否工作正常，如果一切工作正常，则第二台ARS服务器安装完毕。按照相同的方式安装其他的ARS服务器。\n第五步 配置每台ARS的ranking 按照ARS Configuration Guide中的Server Group的相关章节配置每台ARS服务器处理不同后台工作流的ranking。\n第六步 安装配置所有Web服务器的Remedy Mid-tier 安装Remedy Mid-tier软件，都指向相同的ARS服务别名AtriumCMDB，当然该别名被解析为它所对应的ARS服务器的IP地址。使用浏览器测试每台Web服务器，保证Remedy Mid-tier都能正常工作。\n第七步 配置F5负载均衡 配置F5的分发策略，按不同ARS服务器的用途，来分别不同的用户请求。考虑管理和接口功能的ARS负担少量的用户交互。开发一个jsp的程序部署在Mid-tier的shared目录中，用它来判断Web所对应的ARS的可用性，以此作为唯一判断条件来分发用户请求给可用的web服务器。\n",
    "ref": "/2010/08/09/remedy-lb-midtier-server-group-configure/"
  },{
    "title": "OTRS 3.0.0 beta1 发布",
    "date": "",
    "description": "",
    "body": "这个产品被重命名为OTRS Help Desk，从名字上看出它变的更加成熟，更加符合ITIL了。OTRS界面是很土的，比RT3差很多，一直以来我都被它完善的ITIL概念所吸引而无暇顾及它丑陋的界面，这个版本将在界面和新的功能上给我们更多惊喜。下面是3.0时代的第一个release notes，偷懒一下，英翻中的工作让google代劳了。\nRN原文：http://lists.otrs.org/pipermail/announce/2010/000133.html\n时间已经到了 一个全新的欢迎开放源码OTRS的世界领先的新一代帮助台解决方案。新的OTRS的帮助台3.0主要版本附带了一个全新的图形用户界面上完全重新设计信息的基 础 架构。您将受益于更快获取相关信息，具有较高的透明度和增加在日常工作效率。 OTRS的帮助台3.0设计的基础 上与来自不同行业的电力用户访问种类繁多以及在与用户体验领先的专业机构密切合作。今天我们很自豪地介绍美妙的结果：\n最值得关注的新功能如下：\n（1）用户为中心的图形用户界面，在一个戏剧 性的转变从结果重新设计一个全面的，但一个更强大的静态和动态的应用程序使用的，类似的Ajax，XHTML和优化的最先进的技术状态的CSS。\n（2）新工单和文章指示器 - 这一新的功能已被两票和文章一级执行。它允许在一个表面上是为代理人在 票或任何更新的文章水平检查，以检查新的和未读文章。您将受益于增加透明度和减少响应时间。\n（3）优化全 文搜索 - 新的搜索功能，您可以灵活定制的方式来浏览信息库。选择新的搜索功能提供了从单一的搜索字符串的搜索范围，复杂的多字符串布尔搜索行动，包括 各经营者。您受益于完全可定制的搜索根据您的需要。\n（4）工单缩放视图 - 关于Ajax技术让代理商来显示实时链接的信息结构复杂，同时让代理商目前的工作环境为基础的重新设计。这些公司会受益于增加的方向，提高工 作流程效率。\n（5）全局工单一览 - 知名的OTRS2.4全局工单概述已经得到了优化，以达到增加跨活动。根据不同的使用情况和您的代理人的喜好，他们可以轻松地更改机票概览布局根据自己的特殊需要。期权是小型，中型和大型，每个细节提供了不同程度的信息。\n（6）可用性 - 包括重新设计的共同普及标准条WCAG和炜也让弱能ARIA的用户能够更好地互动与OTRS的服务台。美国康复法案第508条已经实现。\n（7）新客户界面 - 客户网络前端可集成到您的组织机构内部网，并充分考虑重新设计的桌面帮助系统集成。\n（8）存档功能 - OTRS的3.0现在提供一个新的归档功能。有了你分开存档受益于搜索，并增加结果显示花了时间却缩短。\nGoogle的翻译效果不佳，请直接看官方发布说明。另外此版本为beta版本，OTRS并不建议用于生产环境。\n",
    "ref": "/2010/08/03/otrs-300-beta1/"
  },{
    "title": "BMC课程通知: BMC Remedy AR 7.5 管理员培训",
    "date": "",
    "description": "",
    "body": "\n课程适用于Remedy AR管理员和开发人员，讲授AR系统的功能、架构、日常运维和创建应用。 学员可以选择课后参加上机考试，获得BMC Certified Administrator: BMC Remedy AR System 7.5认证。不参加考试的学员将会获得结课证书 点 击查看详情\n课程目标\n认识AR System 7.5 的用途和优势 认识AR System 7.5的架构 使用Remedy User和Web浏览器创建和查询请求 使用Remedy User和Web浏览器创建AR系统报告 使用BMC Remedy Alert 和Web接收通知 描述BMC Remedy Administrator工具的基本维护任务 了解AR系统的访问控制概念 了解不同的AR System角色 理解 AR System 的系统架构 了解AR System 的开发工具 权限管理和 AR System许可管理 使用Administration Console执行统一的管理任务. 使用Developer Studio 创建AR System 对象 创建AR System 表单, 控件和 菜单来满足业务需求 创建AR System active links 创建AR System filters 创建基于时间的 escalations 定制一个web的应用 使用log日志来评估性能和识别性能问题 了解AR System 最佳实践\n参加前提：无 授课语言: 中文 培训价格: 7500元/人 （BMC合作伙伴价格5250元/人） 认证考试价格：3500元/人 （可选）\n日程： 北京：8月16日- 20日 上海：8月23日- 27日\n联系我们: 010-85183688-1883 Yuan_yuan@bmc.com AP_education@bmc.com\n",
    "ref": "/2010/07/30/bmc-training-schedule01/"
  },{
    "title": "ITIL v3 MindMap脑图",
    "date": "",
    "description": "",
    "body": "\n下载ITIL v3核心概念介绍，脑图版：http://www.box.net/shared/fve6vvasvt\n这份资料对于新手学习，或者ITILv3老手做参考都比较适合。为了为一些朋友突破一下语言的障碍，我把它翻译成了简体中文版，使用开源软件FindMind进行的翻译。\n文档下载 正在翻译中，稍后提供中文完整版本。翻译状态：\n  服务策略 100%\n  服务设计 100%\n  服务转换 0%\n  服务运往 0%\n  服务持续性改进 0%\n  ",
    "ref": "/2010/07/29/itil-v3-mindmap/"
  },{
    "title": "Make Cacti more easier",
    "date": "",
    "description": "",
    "body": "Cacti是我最喜爱的一个网管软件之一。网站http://cactiez.cactiusers.org/ ；该网站的主人吧Cacti嵌入到了Linux的安装光盘中，实现了Cacti的一键式安装，这正是我所关注的关于开源应用的重要的一个步骤。我称之这是在解决开源软件应用的“last mile”问题。开源软件的潜在用户往往有这样几个特点：\n  技术力量弱，有些可能根本就不知道什么是Linux，什么是open source\n  需求相对明确和简单\n  无法获得中文的技术支持和培训\n  CactiEz让人能在30分钟之内上手开始使用Cacti，从根本上解决了整套软件的安装和配置工作。\n英文版下载地址：http://cactiez.cactiusers.org/\n中文版下载地址：http://linux.chinaunix.net/bbs/thread-1049886-1-1.html\n",
    "ref": "/2010/07/23/cacti-easier/"
  },{
    "title": "规划CMDB数据填充-003",
    "date": "",
    "description": "",
    "body": "From 《Step by step to build a CMDB》步骤17-规划CMDB数据填充\n本文描述填充过程的任务3到任务4：\n任务3 映射CI和数据源 现在拿出您的CI清单，并把每一类CI与具有相关信息的数据源映射起来。一个简单的电子数据表格，像图17.2一样的就足够了。有更复杂数据需求的大一点的企业可能需要多个数据页或者通过CI分类来连接到不同的数据页。\n这项工作的最终目标不仅是识别用以填充CMDB数据源，而且还识别了流程和平台的接触点，有些平台对数据填充是有影响的。这项工作也是至关重要，用来定义数据调和规则，定义数据优先度，这些会在下面的步骤，任务7“建立调和规则”中用的。 工具映射如下图17.2所示，包括了每一个CI类，相关的属性，相关的关系数据，和数据源。 图17.2 Ci和数据源之间的对照关系图样例 您可能会发现一些s数据源之间的重叠，特别是CI库存清单的属性数据。这些数据通常包括唯一物理特性和CI的地点的说明 ，例如：型号、序列号、地点和所有者。此信息可能被存储在其他多个地方，它们也可用于CI数据填充的来源和日常维护的来源。 多种的资产和库存清单数据来源可能包括如下：\n  审计（资产清单或者配置发现数据库；无代理和有代理方式）\n  资产管理系统\n  采购系统和许可证管理\n  财会系统（采购或者收货）\n  合同管理系统\n  变更管理系统\n  其他财务应用和系统\n  任务4 访问数据源环境 为了确保数据质量，你应该访问所有的数据源环境，而不仅仅只是CMDB，还包括连接工具和相关技术，要逐一访问查看每一个数据源。在这里，“进来的是垃圾，出去的就是垃圾”这个俗语是适用的。CMDB项目的成功可能依赖于对系统或者基础架构的更新，以适应网络流量和数据量，还依赖于确保每一个数据源的数据质量。\n当你规划CMDB数据填充的时候，要自问这样几个问题，是有关外部映射数据源质量的：\n  现在那些信息在那里、怎样被存储的？ \u0026ndash;数据库、电子表格、Word文档？\n  当前环境中有没有审计（发现）工具、软件分发、配置管理或者采购系统，用来自动的跟踪和存储这些信息？ 或者数据时被手工地收集和更新的？\n  这些系统是基于开放标准还是私有技术的？\n  这些系统的厂商有没有标准化的工具？或者CMDB厂商？\n  需要被继承的数据源的物理位置在那里？\n  在CMDB和数据源之间，通讯的方式是双向的还是单向的？\n  还要考虑有关映射数据源性能相关的问题：\n  就当前的数据源来说，现实的性能、容量和可靠性是怎样的？\n  系统上当前的活动状况怎样？\n  活动用户数\n  其他并发继承此数据源的工具\n  备份、病毒扫描、报表或者数据挖掘的日程\n  审计工具（配置发现或者库存清单）扫描或者排队日程\n  其他任何将影响性能的事情\n  硬件和当前环境是不是能完全满足今后数据迁移所需要的附加工作量和空间需求？以及满足对于以后的日常数据同步？有没有对今后几年里增长率有做过计算？\n  是不是需要考虑要满足什么约束或者特殊权限？\n  厂商是否在与他们数据库集成方面有建议的最佳实践？（使用热备的生产机来降低作业压力）\n  CMDB周边的数据集和连接技术是什么？\n  网络环境中物理的限制（带宽、距离等）是否会有影响？\n  当前的版本是多少？在以后的六个月或者一年里是否有升级的计划？有哪些好处？\n  为当前的解决方案是否得到了足够的资料来负责架构、排错以及连接系统的维护？\n  通过尽早的回答这些问题，就可以避免后续可能出现的性能问题，那些问题会影响项目的成功。如果数据源不太可靠，而且数据质量和性能方面是有问题的，这个时候，可以回到这些数据的关键利益相关者那里，与他们讨论，并确定这是否会影响到使用方面的关键需求。如果没有，需要把这部分数据需求从CMDB项目计划的第一阶段中展示放弃。这里最重要的是第一阶段的合理部署，实施结果能够获得用户全面的适应。然而，如果这些数据依然是比较关键的需求，那么需要与数据所有者，和收益者各方进行沟通，并引起各方的高度重视，共同确定一个解决方案。\n",
    "ref": "/2010/07/20/cmdb003/"
  },{
    "title": "规划CMDB数据填充-002",
    "date": "",
    "description": "",
    "body": "From 《Step by step to build a CMDB》步骤17-规划CMDB数据填充\n本文描述填充过程的任务1到任务2：\n任务1 再次回顾CMDB范围 现在进行现实检验。你能否确实交付在第2阶段即“定义需求和创建IT服务模型蓝图”中定义的CI范围涉及的相关数据？你在CI数据一旦交付以后，能否有足够的资源来维护整个系统和所有数据？这些都是重要的问题，因为您所选择的CMDB解决方案，可能很容易地就超越了您需要的范围，超出了你可以能容易维护的程度。\n在规划CMDB数据填充时，您的思想应该是“少即是多“。先学会走再跑。让CMDB的首次推广得到充分验证后在考虑扩大范围。您需要帮助保持 CMDB的团队和CMDB数据用户的积极性。同时避免项目范围的蔓延，否则可能破坏的实施的效果，以及用户对新的解决方案的接受度。\n请谨记这样几个考虑因素，从而来帮助您始终专注于那些核心需求上，并能对关键的限制作出反应：\n 成本 – 每个人都必须面对业务现实，包括预算和费用的现实。因此，在您的CMDB项目预算范围里，对主要需求排列优先级。如果出现新的想法，那么也只是在新的预算来下了以后才考虑。 时间 \u0026ndash; 您可能需要在给定的时间内实施CMDB，来使您企业在此方面的业务需求得到满足，如 Sarbanes-Oxley 法规，或支持一个非常关键的新流程。当您计划了CI数据填充的顺序后（后面介绍的这一步），不仅要对CI数据排优先级，而且还要明确时间的限制。 实用性 – 如果没有足够的资源用来实施和维持CMDB，以满足CMDB要求，那么您可能需要缩小实施范围，以便您可以在您实际有限的资源里运作项目。你还可以考虑分两个阶段进行实施，把非关键的要求放到第二个阶段中。 外部强加的优先事项 – 有些业务的运作，例如企业治理、数据保护和信息自由，可能会影响您既定的优先次序。您可以通过分阶段实施CMDB数据填充来减少外部因素的影响。如果你没有从一开始就计划足够的时间来达成最后期限，那么你可以尝试投入更多的资源来克服时间上的限制。然而，还要意识到，以后你要申请更多的资源，没有资源的保证，你可能无法充分管理好项目。 所有权 – 有时IT资产的负责人并不属于IT组织。如果资产所有者决定不参与的CMDB，这会严重限制了CI数据内容的提供。您可以提供CMDB部分功能的有限的访问给他们，用来消除他们顾虑，并参与进来。 地区 – 地理区域上的边界，可能会限制建立企业范围的CMDB。由于地理或行政上可能的边界，我们可能听过“最好再也不要从总部传来这样神经质数据库方案”。最好预防这种情况的办法是，尽可能早的让所有地区的相关人员参与到CMDB项目里来。 组织架构 – 很多企业把IT划分成为清晰地、各自为政的独立部门，通过这种方式来对CMDB里的不同范围负责。例如：通信部门的人可能是一个单独的组织结构，他们可能拒绝参与到项目中来，因为他们觉得这超出了他们的控制范围。这时候就要让其他的IT组织参与其中，让每个人都知道谁是项目负责人。  当你计划你的CMDB数据填充的时候，越能专注于关键受益人的需求，就越能够达成项目的业务目标，就越能让您的项目顺利。您需要就已经确定的 CMDB范围，与所有的利益方沟通它可能的影响和效果。收集他们的反馈，并对有必要方面做进一步讨论。\n任务2 识别CI 使用在第15步即“设计IT服务模型蓝图”中设计的IT服务模型蓝图为基础，来生成用于CMDB数据填充的CI以及相关属性和关系数据的清单。这个清单的细节应该到数据字段级别，以便，你能够识别并且映射一个或者多个数据源到特定的CI数据。 例如，如果你把一个实际的服务器CI的属性和关系数据都列出清单，你就可以找出一些现有的能提供属性数据的数据源，可能包括库存管理的数据库和发现或者网络管理工具。但是另外一些数据字段可能没有现成的数据源。你将在第18步“选择自动化CMDB数据填充工具”中用到以上差距分析。或者您可能决定使用手工的方式来填充和更新这个字段，这里还需要仔细的考虑到数据的负责人，和在21步“建立CI生命周期管理流程”中需要支持的流程。 至此，你需要专注于用来满足项目目标的要求。在步骤11到14，你定义了与其他流程的结合点，明确的CI需求。专注于那些能直接对流程收益人产生直接影响的CI数据。\n",
    "ref": "/2010/07/20/plan-cmdb-population-002/"
  },{
    "title": "RT3 Request Tacker或让你摆脱束缚",
    "date": "",
    "description": "",
    "body": " What\u0026rsquo;s new in 3.8+?\n  清晰易用的图形界面\n  仪表板Dashboards\n  流程单关系图 Ticket relationship graphs\n  与PGPemail无缝集成 Seamless PGP support for email\n  富文本编辑 Richtext editing (WYSIWYG)\n  预定义用户首选项 Per-user preferences for common options\n  单据按日历feed：Calendar feeds for ticket due dates\n  标记单据 Bookmarking tickets\n  新的邮件设置 New email delivery settings\n  更容易的升级工具 Easier upgrade tools\n  性能提高 Loads of performance improvements and bug fixes\n  发现RT比OTRS的界面好的太多了。不过这俩比较起来，OTRS更正式，更符合ITIL，主要是它有ITSM模块，这个模块里面内置了IM，PM，CM和SLA管理，值得一提的是它也包括配置管理模块。不过OTRS的界面和RT比起来就不是难看一点了。初步体验了RT一下，主要感觉是，界面太直观了，所有方便操作近在咫尺，系统的易用性降低了使用和配置的复杂性。对于不追求ITIL的中小企业，应该很值得试试RT。\n",
    "ref": "/2010/07/18/rt3-request-tracker/"
  },{
    "title": "OCS inventory NG 两三事",
    "date": "",
    "description": "",
    "body": "头等大事是有关于OCSNG很快就要出UTF8多语言支持版的Windows采集代理程序。新闻如下： ** 新版windows采集代理被彻底重写，它将包括下面的新特性：**\n 全Unicode代理，多语言UTF-8支持 Native 32 and 64 bits agent BIOS AssetTag 收集 硬盘序列号收集 部署返回码收集 全 HTTPS 支持 Socks 4 、5 HTTP 代理支持 FTP, FTPS 和SMB 包部署支持 二进制插件支持  另外，是一本新书的发布，这是我见到的第一本系统介绍OCSNG的图书。可能是由于我写过一些相关的post，该书的出版社发邮件给我，想请我review，并写写书评。处于对OCSNG和GLPI的喜爱，忍不住诱惑，就答应了。很快的我得到了这本书的电子版。虽然没有时间看完，浏览了几章后，还是可以说这本书写的是非常实用。特别是对系统的安装、配置、部署和使用都从系统管理员的角度写的非常到位。书上没什么废话，文字写的比较随意，很易懂的随意。可喜的是该书还捎带着把GLPI也给介绍了，包括如何与OCSNG做集成配置，以及GLPI的主要功能说明。对于这种偏门的开源软件系统能有如此细致使用的介绍实属难得，更何况我对OCSNG和GLPI的网站文档本身就不敢恭维。这里提供一个样章供参考 \u0026ldquo;Introduction to IT Inventory and Resource Management\u0026rdquo;\n最后，还是期待新版OCSNG的Window采集代理程序能早点发布吧。期望它发布之时我有时间做这样一个虚机，以便分享给各位感兴趣的人。规划如下：\n  基于Fedora 10\n  安装OCSNG_UNIX_SERVER-1.3.2. + glpi-0.78-RC2\n  做一定系统的基本优化，配置OCSNG和GPLI的集成\n  期望该虚机能应用于实际的网络环境中\n  ",
    "ref": "/2010/07/16/ocs-inventory-ng/"
  },{
    "title": "Upgraded to Wordpress 3.0",
    "date": "",
    "description": "",
    "body": "\n期待多时的3.0版本终于出现了，刚刚升级上来，还没有体验到她的新功能，先换上了最新的皮肤，看上去字体和布局都非常舒服。简单就是美，希望WordPress能够越来越好。它真可谓用户体验的典范之作！\n",
    "ref": "/2010/06/20/upgraded-wordpress-30/"
  },{
    "title": "BMC提供ITSM洋快餐",
    "date": "",
    "description": "",
    "body": "还有很多企业依然在寻找IT服务管理的方法论 还有很多企业依然在让内部开发团队打造ITSM流程平台 也还有很多企业在购买的成熟的ITSM管理平台套件上大搞研发和定制 也还有很多外国企业在拼命保持使用ITSM产品开箱即用的功能来减少开支和加快投资回报 也还有一些外国企业在尝试ITSM的KFC，BMC Remedy OnDemand，连系统也不建设了，直接拿标准的就来用吧。 回顾国内的ITSM用户，往往在探索期里花的时间和金钱成本太大，推广标准化ITSM的理念需和ITSM系统平台建设同行；目前国外的工具和ITIL标准已经够标准、成熟和进化了，我们的标准化理念也争取迎头赶上吧 Reduce Service Support Costs Quickly with BMC Remedy OnDemand\nView Full Screen\n",
    "ref": "/2010/06/07/bmc-remedy-ondemand/"
  },{
    "title": "规划CMDB数据填充-001",
    "date": "",
    "description": "",
    "body": "From 《Step by step to build a CMDB》步骤17-规划CMDB数据填充\n目标\n在这一CMDB关键的步骤中，会为CMDB的初始化CI数据填充，做精细的计划。需要考虑到所有CI数据，把不同CI类型对应到不同的数据集中，安排正确的顺序将这些数据集CMDB。其中定义对应的规则来调和重复数据是很重要的，不仅在CMDB初始化数据填充阶段重要，在以后的日常维护过程中也是非常重要的。做出了本阶段的详细规划后，这样在第18步即“选择自动化CMDB填充工具”时，就能考虑需要什么样的配置发现和自动化工具了。\n实际上，把数据填充到CMDB中是非常基础的工作，必须事前做好充分的数据范围和类型的分析。对于一个典型的CMDB数据填过程来说，将需要做如下工作：\n  建立里项目程碑和高阶项目计划，以及配套的支撑数据库和操作流程。\n  安排项目启动会议，单周或者双周的项目进度沟通会。\n  识别子项目（每个数据集分为一个子项目），建立每个子项目的目标和需求清单。识别和制定项目工作活动内容，确定项目的工作流程，并且按照项目计划排程所有活动。包括： \u0026mdash;并行开展项目（用户界面定制，DSL数据填充）； \u0026mdash;串行开展项目（发现工具，数据调和，等等）\n  为每个子项目分配项目负责人，让他们来负责汇报项目的进展、问题升级和下一步的工作。\n  为所有项目参与人员建立一个开放的沟通平台，包括所有内部、外部人员（邮件组方式，数据库、通报）\n  为可能出现的紧急事件预留至少10%的时间和预算的缓冲。\n  自动配置采集工具是一种很好的数据填充和数据维护方式，您也会在某种发现工具的诱惑下，在很短的时间里，就采集到了大量的数据。可是您还是需要注意：一个被填充了大量数据的CMDB并不意味着是一个好CMDB。一旦您建立和填充了CMDB，您就将需要对它进行积极地维护。如果CMDB中存储着很多超出用户需求的数据，即使在最好的情况下，您也是对这些无用的数据做大量无谓创建和维护工作，这是一个巨大的浪费且没有意义的事。而在最糟的情况下，如果你所填充入CMDB的数据，在后来是没有被及时更新和维护的，那么当用户使用到这些质量低和不精确的数据数据后，就会对CMDB失去信心，这样也对 CMDB在企业里的推广和应用造成一定阻碍。\n按照您在第二步-“定义需求和创建IT服务模型蓝图”中的需求，来设计和部署CMDB。从你的服务模型蓝图出发，来识别CI，把他们分组到各个数据集中。识别每个数据集应该对应的数据源，把每个CI类型和相关数据源对应起来。并且按照既定的CMDB数据导入的工作顺序，来规划不同数据源中数据。最后，把以上所有规划和设计用文档记录下来，包括识别重复数据的调和规则等。\n在这一步里，您必须专注于CMDB所需要的范围，交付可实现的东西，而非可能的东西。在敲定最终的规划之前，你需要组织分析会议进行仔细地计划。\n",
    "ref": "/2010/06/04/plan-cmdb-population-001/"
  },{
    "title": "ITSM实施精要-只讲2分钟",
    "date": "",
    "description": "",
    "body": "下面是我在过去ITSM项目实施中的一些经验和体会：\nITSM_implement best practice\n下载\nCredit：本ppt的原版为《the 60 second guide to Enterprise Innovation》\n",
    "ref": "/2010/06/01/itsm-implement-best-practice/"
  },{
    "title": "联邦的CMDB–神话/现实/需求/还是策略？",
    "date": "",
    "description": "",
    "body": "来自：Jonathan Markworth（CompuCom Systems有限公司管理顾问，探讨联邦数据库的优点）\n使用一个具有单一的、全知的、万能的和自维护功能的工具，来管理IT基础架的方方面面信息，是否是最好的方案呢？使用一个能做所有工作的全集成平台，来替换您积累下来的所有管理工具是否是最佳方式？现实情况是，大多数组织都已经实施了几十种应用程序、工具、实用程序、数据存储、硬件平台和管理框架，它们一起运行着一个或更多的IT服务管理功能。它们中的每一个应用都有自己的数据库，对当前环境中的一些关键管理功能提供信息支持。在CMDB应用场景中，这些工具相关的数据库中，其实也包含了大量关键的CI属性，这些属性可以用于识别CI之间的关系。重要的问题是，如何利用现有的投资和资源来建立一个底层共享的数据库，比如一个CMDB。\n一种方法是“集中存储和管理”，从这些数据源中导出CI的唯一标识、属性、以及关系，然后都整合到一个数据库中。但在经过了一段很长的时间后，这种方案所产生的数据将很难维护，因为伴随着数据源数量的增长，整套系统的维护会变的愈来愈复杂。\n另一种方法是“建立联邦的CMDB”，建立一个核心CMDB，用来整合所有配置项的唯一标识、核心属性和关系数据，为所有需要它的IT流程随时提供配置数据，而不需要对所有数据进行集中式地复制。用联邦的模式，让CMDB持有所有CI及其核心属性数据，然后再连接到其他相关的数据源；如服务台事件单、服务水平协议、甚至其他监控的管理控制台界面。通过正确地部署，联邦模式可以使得企业的CMDB能横跨所有的个IT组织，如果需要的话可以对既有的相关系统进行分阶段的实施，这样不仅可以让IT组织能够继续日常业务，还不会带来什么干扰。\n摘自BMC软件公司公布的VIEWPOINT “CMDB的潜力—驾驭新的IT现实”，CMDB为主题的文章。\n",
    "ref": "/2010/05/31/federation-cmdb/"
  },{
    "title": "CMDB配置采集工具部署之4大挑战",
    "date": "",
    "description": "",
    "body": "[singlepic id=84 w=320 h=240 mode=watermark float=left] 挑战1：沟通成本大 项目的参与沟通方可能很多，最多的情况下，可能包括：网络部门、系统部门、安全部门和各个业务部门。沟通的内容主要是配置采集的实施技术方式。其中采集的安全性，风险分析是最重要的部分；在部门多的情况下，面对多种选择的时候，逐一给项目各方说清所有方案，特别是讲清楚利弊是非常耗时的。在充分沟通了所有技术可能性之后，才能做出倾向性选择。逐一这是第一轮沟通，搞清楚了倾向性而已。\n挑战2：决策成本大 特别是银行等金融企业，安全性要求特别高。安全风险方面的建议往往是最重要的，他们的建议对配置采集工具的实施具有决定性意义。在各方都充分理解了配置采集工具的架构和安全性之后，就是拍板定夺了。这种逐级的审批和决策是需要较长的周期。\n挑战3：前导时间成本太大 在前导时间里，可能还没有部署正式的ADDM采集服务器。在这个阶段里，要配置网络，让以后的采集服务器能够处于能够扫描到所有目标服务器设备。还可能需要在每台服务器上配置相关的准备工作，主要是坚持主机的操作系统的账户、采集协议和安全配置等是否满足配置采集工具的要求。这写工作是一个群众性运动，需要让所有的系统管理员配合。此项工作的设计人员设备多，最好能尽早的开始。\n挑战4：用户的期望太大 用户对配置工具的期望主要是集中在深度和细度方面。其实这也不为过，只是在实施的过程中，最好还能把发现工具的一下特有的功能和特殊推广给用户。如软件和硬件的EOL信息，一些开合即用的报表和图形化展示功能，全文搜索等等功能其实都可以给客户带去意想不到的价值 。\n",
    "ref": "/2010/04/26/cmdb-addm-tool-implement-good-practice/"
  },{
    "title": "Naya-猫-周末",
    "date": "",
    "description": "",
    "body": "厦门持续的阴雨，这样的天气已经持续很久了，看来清明和谷雨前后没有什么好天气了，说实话不太适应南方这种鬼天气，比较怀念上周6北京的大晴天。今天的心情同天气一样，郁闷原因不说了。\n匆忙吃过早饭，乘船来到岛上来寻找一处安静的地方，目的很简单啊，无聊出差的周末工作，还能做什么？今天感觉除了工作就是发呆了。在岛上七拐八拐的稍微溜达了一下，稍微逛了两个小店。想找一个地方能够提供舒适的桌椅、户外的环境，当然还有咖啡和午饭了。最后还是落脚在Naya，院落里有只有墙边的两个桌不淋雨，其他的都被雨水浇的稀里哗啦的。点上一杯咖啡，打开电脑开始工作吧。背后桌上的猫引来一些游客的观赏和拍照，烦！难得找个清静的地方，带上耳机，许巍熟悉的老歌旋即缭绕耳畔。趁没有人惹猫咪，我对它咪咪了几声，它没反应，我继续。过了一会我发现它走到我的长椅上，蹲在那里，正在看我，这猫看来也很无聊，需要人的陪伴，它也让我想到了某人。我摸了几下它的头，它很享受的眯上眼；这又让我想起了，小时候我样的那只大猫，比它颜色白。它坐的位置正好在我搭在椅背上的衣服后面，游客这下彻底看不到它了，我也可以安心地继续了。发文感谢一下这只猫义务陪伴我可爱的MIMI。今天主要的工作内容是CMDB解决方案需要和差距分析。\n",
    "ref": "/2010/04/18/naya_cat_weekend/"
  },{
    "title": "21世纪最缺的是什么？",
    "date": "",
    "description": "",
    "body": "21世纪最缺的是人才，在ITIL项目中更是重要。特别是CMDB项目，项目团队人员构成是呈金字塔型。\n最顶端的人是Project Executive Board“项目执行委员会”，简称PEB，它就像是一个公司董事会；它对CMDB项目的目标、预算、工期、项目变更等负责。PEB人员数量应愈少愈好，不过下面的个角色也是缺一不可。首先，要请至少一个C level的人加入，比如数据中心的CIO。其次，关键利益干系人，它们是CMDB的价值的主要承载者，叫好和批评项目成果的都会是它们。然后是CMS/CMDB系统的负责人，它们对CMDB的规划、维护和之后的发展最重要。最后是项目实施资源的主要提供方领导，说白了他就是出人出力的部门，今后项目的执行和实施都靠他们。所以PEB的人数在4人左右。他们是相关部门的领导。我在最近的项目实施中，也遇到了几个问题，需要去找客户的老板来拍，也就是找到PEB的人决策。其实之前也听到其他同事在项目过程中，曾经感慨道“客户的领导还真辛苦，大事小情都需要替下面做决策，他们的脑袋真禁拍！”。国内的管理者的确挺辛苦的，毕竟所带领的团队都还比较的年轻，这也是国内IT管理的成熟度低的一个体现。\n金字塔下面的人就是都是我们的天天加班、做牛做马的辛劳工作的实施人员了。没有规矩不能成方圆，实施团队的技术素质和构成、团队沟通等都是至关重要的。对项目的质量，项目工期都有非常重要的影响。金字塔下面的兄弟姐妹都是一条船上的人，大家要互相配合才能完成项目的各项工作；在这个过程中没有一个船老大也是不行的，船老大就是项目经理。对CMDB的项目经理的要求可不低，重要有以下几点：\n  Planning skills\n  IT service management background\n  Previous involvement in building a database\n  ITIL Manager’s certification\n  Ability to make decisions\n  Capabilities to motivate staff\n  Ability to blend a team\n  Strength of character to lead a team\n  Capacity to present results and status of project to sponsors and stakeholders\n  Self-motivation\n  Ability to communicate instructions to the project team (from step by step to build a cmdb)\n  项目实施工程应该具备很多的必要素质。CMDB产品是一个复杂的应用系统，必须有人对它的技术细节非常熟悉，包括应用安装、配置和客户化。这个技能应该是核心中的核心，对产品利用的好，就能减少二次开发的工作量，就能最大发挥产品的原本功能，从而规避项目风险。产品的二次开发技能也是另一个必要因素，这是由于中国用户的特点决定的，对于任何一个大型的ITSM项目，国内没有不对产品做二次开发的。程序开发技能也很重要，Java/JSP开发人员是必须的，他们还需要懂得html、xml、sql等技术。如果能在有操作系统和数据库专家就在好不过了，在系统出现性能故障，系统需要全面备份和恢复的时候，数据库专家和系统专家的参与能让事情经行的更高效，更快，不至于由于系统不可用导致的窝工。系统能更安全，能更放心的使用和开发。下面的一些技能是充分条件，包括ITIL认证、ITSM流程的知识背景和项目经验。\nCMDB项目对实施人员的要求是很高的，实施前要选合适的人；想要追求高品质的项目质量，就需要网络业内的专业的实施专家顾问、有经验的项目经理和合格的项目实施工程师。从这个角度上讲，21世纪ITSM项目最缺的可见是CMDB人才；呵呵这纯粹是我的笑谈，不过您要组建一个CMDB项目团队的话，挑选人员的时候请务必擦亮眼睛。\n",
    "ref": "/2010/04/15/cmdb-project-need-talents/"
  },{
    "title": "Alice in Wonderland",
    "date": "",
    "description": "",
    "body": "今天在厦门看了一次电影，是3D版的，总的来说影片非常好看，可谓是老少皆宜的佳品制作。可惜3D眼镜还是太沉了，脖子看完了很痛。红色皇后的真残酷，还有白色皇后的真伪善，还有很多卡通角色的搞笑，包括最后于怪龙的决斗。整个片子内容饱满而有趣，丝毫不觉得拖沓和无聊。让我又一次的回到童年的感觉。清明节前后真不是出游的好季节，厦门整日阴沉着天，只能当是休息了。\n",
    "ref": "/2010/04/04/alice-wonderland/"
  },{
    "title": "项目实施之鬼见愁@需求变更@",
    "date": "",
    "description": "",
    "body": "[singlepic id=34 w=320 h=240 mode=watermark float=right]不经意间听到的让我深思的一段对话。 甲：咦，这个功能是什么时候加的？ 乙：哦，我也不知道还有这个功能 丙：那是我加的 甲：需求是谁提的？ 丙：他们那天给我打了一个电话说需要这个功能\n都说ITSM项目是非常难实施的项目，成功率低；特别是CMDB项目，实施难度大，失败案例比比皆是。首先我觉得ITSM项目的实施有它的特殊性，特殊在于实施顾问对客户需求的理解，在于实施顾问对ITIL最佳实践的经验，在于对产品工具的把握。其中任何一个环节拿捏不准都会到导致需求的泛滥、需求混乱、需求的飘忽不定。\n可见需求管理是项目实施和执行的灵魂，失去了对灵魂的掌控，需求讨论会就将可能进入走火入魔的地步，需求各方争执不下，整个会议室炸开了锅，每个人都争抢着发言，我的脑也几乎要眩晕；我说的这一点也不夸张，没见过只能是你的幸运。\n需求管理包括需求的分析和整理，应该是有层次的，在不同的层次里讲不同的语言，达成共识的讨论结果。层次可以分为这样三层\n  业务需求\n  用户需求\n  功能需求\n  所谓业务需求是说站在公司的高度，从最high level角度描述需求之所在。它的语言像是项目使命的宣言，指出为什么要做这个项目，项目的价值点落在哪里。最概况的项目范围。业务需求告诉我们：为什么会有这些需求。\n用户需求是指从项目利益相关人的角度出发。逐一描述各个业务操作环节，这些业务操作由每个可独立执行的条目为单位，每个业务操作中说明业务规则、输入和结果。切忌在这一阶段就进入详细的功能界面或者功能操作上细节的任何讨论。原因很简单：我们在这里还没有进入技术实现环节，依然在以客户或者系统使用者的角度来描述它的需求。系统用户和客户是不需要理解每一个页面跳转和鼠标点击的意义的。在我的经验看来客户在这里最容易陷入技术细节讨论的泥沼，反而可能浪费需求讨论的时间，可能导致项目的延期，需求点难以确定。用户需求告诉我们：用户的需要什么。\n功能需求则需要告诉我们：为了能满足用户需求，我们的系统是怎么做的。这里将用技术的语言，进入系统层面说明系统应该怎么做。功能需求最终将导出概要设计和详细设计。\n业务需求的满足=用户需求的满足+功能需求的满足；用户需求是能推倒出功能需求的，用户需求和功能需求可以是一对一、一对多和多对多的关系。\n以上三个需求是有层次的并与客户递进沟通的产物，既然是沟通，那么在每个层次上都伴随着矛盾、争论、妥协。在任一层次上理不出头绪时，一定要追溯到上一层，通过上一层来指导解决。但是这往往也是很难把握和执行的，最终最可能的结果是在以上三个沟通层次中都伴随着需求的变化、需求的扩大、需求的混乱。甚至于进入了测试阶段还能产生出新的需求和理解的偏差，谁人能不说“需求变更”是项目实施的鬼见愁呢？\n如何解决这个“鬼见愁”？一方面需要时刻对项目预算和时间资源保持清醒的头脑，项目实施比较是那时间和金钱换需求。还有就是通过项目变更委员会来控制需求变更。\n",
    "ref": "/2010/04/02/project-failed-by-requirements-change/"
  },{
    "title": "掀起CMDB的盖头来",
    "date": "",
    "description": "",
    "body": "今天是项目计划提交后的第二天，客户方项目经理对项目的推迟表示感到非常吃惊，期望能让我们给出一个合理的解释。其实这也同样的超出了我的预料，难道软件项目管理和运作都是所谓的人月神话么？\n[singlepic id=22 w=320 h=240 mode=watermark float=left]在我看来CMDB项目的实施和运作有是有可能分阶段、逐步地交付项目成果的。简单的来说首先交付的当然是CMDB和配套发现工具系统本身，丑媳妇不要怕见公婆，把这个不加粉饰的原型系统拿出来，让项目各方包括最终用户来试用和评估。接着按照CMDB配置数据的来源的不同，把数据顺序的导入CMDB，并且开展数据的调和工作，完成基础数据的初始化。在基础数据的基础上，需要对CMDB服务模型加以验证，选取重点的系统来验证，让系统经理和CMDB相关用户也参与进来，用事实和数据讲话，对模型和工具做最终的确认。这个其实是一个小范围内的推广，它的经验可以直接应用于下一个阶段。接下来是对其他所有被采集对象的普遍扫描和CI数据同步，在这个阶段里还需要实现CMDB和所有ITIL流程的集成，ITIL流程是CMDB的主要消费者 ，这个集成往往是两家不同的产品，这种情况下，如果集成的效果欠佳，CMDB的实施成果也会打折扣。最后结尾的交付物可以是CMDB的审核和报表等产品。\n正如ITIL的实施一样，没有两个国内公司的ITSM实施是相似的，就像国内不存在两片相同的树叶一样。那么国外的树叶又如何呢？从ITSM实施方面来看，相同的树叶在国外还是非常多的。相同的原因在于，往往用户选择了相同的产品如Remedy ITSM套件，往往由于定制化的人力成本很多用户也在尽量避免对产品的定制，如果通过配置可以实现的需求，绝不定制或者开发。我们也应该多走工业化标准生产的道路，少以中国特色为借口来实施个性化二次开发。\n",
    "ref": "/2010/03/30/phase-roll-out-cmdb-implement/"
  },{
    "title": "CMDB需求分析之最佳实践",
    "date": "",
    "description": "",
    "body": "[singlepic id=4 w=320 h=240 mode=watermark float=right]今天终于移师厦门开发中心，这意味着我所经历的史上最长CMDB需求分析基本告一阶段，也意味着CMDB的构建、集成、定制和 测试工作也徐徐拉开了大幕。\n回忆前三个月所做的的需求分析工作，虽然各项调研和讨论工作进行的缓慢，不过细致的工作最终还是换回了令人满意的成果，起码我是这么认为。\n需求分析的过程是对需求的重新整理、重新定义和梳理。项目的立项并不意味着项目目标树立的精准，项目范围控制的合理。实际需求可以在实施的初期阶段来重定义，从新分析，着觉得不是浪费时间。而且这一点对于中国用户至关重要。国内很多项目都是资金或者预算驱动的，先有需求，通过需求推到出项目的价值，在通过项目的投资回报率申报项目预算的过程在国内是很少见得。国内的项目往往是有多少钱需要花，那么大家在来看，如何把需求花到极致，达到最大的产出。这也是很多需求分析做的贪多、贪大、求全的根源，这样做的好处是在一个项目周期内就把需求实现的尽善尽美（愿望是这样），坏处是：可能导致厂商和服务商的服务成本超支，从而造成的项目质量降低，从用户角度来说一次性接受一大堆的系统功能，负担重，接受度低，同时客户满意度低，项目满意度差。\n我认为较好的最佳实践还要抓项目的主要目标，抓需要实现的主要价值点，抓重点放弃那些可做可不做的功能。懂得放弃的人才懂得获得。把所有的功能需求做成能够分批、分期上线的成果；确保让系统用户能buy in每一个阶段性成果，不要奢望给用户带来革命性的提高，由于那样也意味着，你对他们当前工作方式的影响是巨大的，没有用户愿意接受巨变。\n需求分析时，从技术上讲，对会议组织人要求很高。需要此人能非常熟悉CMDB项目实施的方法论，需要此人能够非常熟悉产品的各个功能点，需要引导有效的需求分析会议。在白板上尽可能多的画图，用Visio或者ppt等工具尽量多的讲解各种架构图、功能图、流程图具有事半功倍的效果。不管会议上您可能收到怎样的抱怨、抵制、反对；stakeholder的反馈将是你最宝贵的收获。没有互动和反馈的需求分析会是相当无聊和浪费时间的。切忌在大型的企业中，要慎重地计划每一次需求分析会，理由也很简单，企业组织越大，沟通的成本也越高。需求分析沟通的效率和成功完全取决于CMDB项目执行的方法论，取决于分析引导人的各种项目背景经验，还取决于对客户状况了解和上手的速度。\n",
    "ref": "/2010/03/29/cmdb-requirement-analysis-practice/"
  },{
    "title": "OpenNMS 1.6.1 to 1.6.10",
    "date": "",
    "description": "",
    "body": "[singlepic id=35 w=320 h=240 float=left]在最近的一年里，我基本上忙于CMDB的工作，没有什么业余时间来看看OpenNMS的情况。其实OpenNMS是最初引入我深入了解开源软件世界的东东。时隔1年之久，我上一篇关于opennms的文章是它是1.6.1版本，刚才查了一下，它最新的稳定版本是1.6.10.\n看似它这一年里发展的比较慢，这让我感到些许地失望，大概地看一下一堆相关的release notes。功能性的变化如下：\n  新增和增强了一些monitor的和功能，主要有http，dns，ldap，ssh，jmx等，从最初的snmp采集，都这些采集功能；采集能力的增强是它这样的无代理监控程序永远的话题\n  UI的功能的增强了一些\n  SNMP采集仍然是他的主要能力，在这方面也有了一些改进\n  新增了一些网络设备品牌的支持\n  阀值配置也有改进\n  总的来说，作为一款能够采集各种snmp mib信息，能够出好看的性能报表，能够作为统一的告警事件平台，能够有简单易用的UI，OpenNMS做的显然是非常不错的。至今还行它还没有提出什么云计算相关的话题，可见他们还是一般比较稳健发展，不爱赶时髦的人。希望他们能做的更好。\n对于我的这个blog来说，之前写的OpenNMS和网管相关的东西比较多，以后可能会越来越少，就此和OpenNMS做一个总结。以后本blog可能会和目前做的cmdb和itsm相关这些内容为主了。\n",
    "ref": "/2010/03/28/opennms-161-1610/"
  },{
    "title": "重整旗鼓",
    "date": "",
    "description": "",
    "body": "还是不能下决心把blog彻底迁移到国内的免费blog，所以在此选择新的地方来安置它。最后决定这次把它放到美国的一个收费空间中。之前使用免费空间的时候，多是美国的免费空间。这次也走上了收费空间之路。不过昨晚和一个博友聊了一下，觉得.cn域名真的是个没有前途的域名。所以我也不知道martinliu.cn能走多远，所以我还是秉持着一颗平常心，不烦不燥，翻墙并快乐着。毕竟blog是以娱乐为主，能看到martinliu.cn在线一天，也是个乐子。\n",
    "ref": "/2010/03/27/martinliucnblog/"
  },{
    "title": "Pick a car",
    "date": "",
    "description": "",
    "body": "我是个慢性子，上个驾校，考个驾驶本也让我耗了将近一个初中的时间，前后历时三年，我在驾校2年有效期的最后一周内考完实际道路，本周最后一次去驾校领取到了驾驶本。\n拿到驾驶本后，接下来的事情需要考虑的事情是买一辆什么样的车了。目前有三个候选出现在我的选择范围内：速腾、明锐和高尔夫6。本人不是什么车迷或者玩家，为的是能够买车作为代步工具，增加生活的方便性，和出行舒适度。\n在车论坛上面也初步看了一下最终还是没有能确定究竟该选哪个车。很显然这三个车都是大众车系。下面是我对这三款车优缺点的分析。\n首先是“明锐”，它是我最初了解的车型。优点为：该车的口碑较好，主要是周边有一些开明锐朋友都对它比较认可，有的是明锐的第一批车主，他们说第一批车不该做的太差否则对比起观众。我也去店里看过样车，在先入为主的心理驱使下，逐渐认为该车确实还是不错的。主要是外形稳重大气、车内空间和后掀式后备箱的空间都比较大、6档手自一体的发动机也不错，总体看来性价比非常好。缺点：全系列车没有ESP、地盘离地间隙太小。\n其次是“速腾”，选择速腾的理由主要在于，该车的舒适度和空间都还不错，用户基础大。缺点：技术太老了，08年的车一直买到如今还这么火，真有点让我丈二和尚。性价比低于明锐。\n最后，也是我最纠结的车型“高尔夫6”，高6一出，在各大车论坛中，高6板卡就成为热点，从大家对它的热情来看，高6有很多魅力。我比较看重的有，该车所采用的发动机和离合的技术是大众最新的技术。该车的安全性装备较前两车稍优一些。我去南三环的4s店看过，那做工真是没说的。缺点也是比较致命的：空间小，预定等车需要5~6各月。\n在选车同时，最要紧的是约陪练练习，然后租车练习。总的来说对车并没有太大热情，不过能尽早的开上自己的车也是目前的头等大事。\n",
    "ref": "/2010/03/27/pick-car/"
  },{
    "title": "AVATAR",
    "date": "",
    "description": "",
    "body": "观后感：开发一个世界时，切勿牺牲另一个世界，原来地球人比外星人还狠。\nWe don't need to sacrifice any world for anything; E.T. should watch out the Earthling !!! ",
    "ref": "/2010/01/09/avatar/"
  },{
    "title": "图文阐释-DAS-NAS-SAN",
    "date": "",
    "description": "",
    "body": "转帖自学. 目前磁盘存储市场上，存储分类（如下表一）根据服务器类型分为：封闭系统的存储和开放系统的存储，封闭系统主要指大型机，AS400等服务器， 开放系统指基于包括Windows、UNIX、Linux等操作系统的服务器；开放系统的存储分为：内置存储和外挂存储；开放系统的外挂存储根据连接的方 式分为：直连式存储（Direct-Attached Storage，简称DAS）和网络化存储（Fabric-Attached Storage，简称FAS）；开放系统的网络化存储根据传输协议又分为：网络接入存储（Network-Attached Storage，简称NAS）和存储区域网络（Storage Area Network，简称SAN）。由于目前绝大部分用户采用的是开放系统，其外挂存储占有目前磁盘存储市场的70%以上，因此本文主要针对开放系统的外挂存 储进行论述说明。 表一：\n[singlepic id=97 w=570 h=250 float=]\n今天的存储解决方案主要为：直连式存储（DAS）、存储区域网络（SAN）、网络接入存储（NAS）。如下表二：\n[singlepic id=98 w=533 h=352 float=]\n开放系统的直连式存储（Direct-Attached Storage，简称DAS）已经有近四十年的使用历史，随着用户数据的不断增长，尤其是数百GB以上时，其在备份、恢复、扩展、灾备等方面的问题变得日益困扰系统管理员。 主要问题和不足为：\n直连式存储依赖服务器主机操作系统进行数据的IO读写和存储维护管理，数据备份和恢复要求占用服务器主机资源（包括CPU、系统IO等），数据流需要回流 主机再到服务器连接着的磁带机（库），数据备份通常占用服务器主机资源20-30%，因此许多企业用户的日常数据备份常常在深夜或业务系统不繁忙时进行， 以免影响正常业务系统的运行。直连式存储的数据量越大，备份和恢复的时间就越长，对服务器硬件的依赖性和影响就越大。 直连式存储与服务器主机之间的连接通道通常采用SCSI连接，带宽为10MB/s、20MB/s、40MB/s、80MB/s等，随着服务器CPU的处理 能力越来越强，存储硬盘空间越来越大，阵列的硬盘数量越来越多，SCSI通道将会成为IO瓶颈；服务器主机SCSI ID资源有限，能够建立的SCSI通道连接有限。 无论直连式存储还是服务器主机的扩展，从一台服务器扩展为多台服务器组成的群集(Cluster)，或存储阵列容量的扩展，都会造成业务系统的停机，从而 给企业带来经济损失，对于银行、电信、传媒等行业7×24小时服务的关键业务系统，这是不可接受的。并且直连式存储或服务器主机的升级扩展，只能由原设备 厂商提供，往往受原设备厂商限制。 存储区域网络（Storage Area Network，简称SAN）采用光纤通道（Fibre Channel）技术，通过光纤通道交换机连接存储阵列和服务器主机，建立专用于数据存储的区域网络。SAN经过十多年历史的发展，已经相当成熟，成为业 界的事实标准（但各个厂商的光纤交换技术不完全相同，其服务器和SAN存储有兼容性的要求）。SAN娲⒉捎玫拇?宽??00MB/s、200MB/s，发 展到目前的1Gbps、2Gbps。 网络接入存储（Network-Attached Storage，简称NAS）采用网络（TCP/IP、ATM、FDDI）技术，通过网络交换机连接存储系统和服务器主机，建立专用于数据存储的存储私 网。随着IP网络技术的发展，网络接入存储（NAS）技术发生质的飞跃。早期80年代末到90年代初的10Mbps带宽，网络接入存储作为文件服务器存 储，性能受带宽影响；后来快速以太网（100Mbps）、VLAN虚网、Trunk(Ethernet Channel) 以太网通道的出现，网络接入存储的读写性能得到改善；1998年千兆以太网（1000Mbps）的出现和投入商用，为网络接入存储（NAS）带来质的变化 和市场广泛认可。由于网络接入存储采用TCP/IP网络进行数据交换，TCP/IP是IT业界的标准协议，不同厂商的产品（服务器、交换机、NAS存储） 只要满足协议标准就能够实现互连互通，无兼容性的要求；并且2002年万兆以太网（10000Mbps）的出现和投入商用，存储网络带宽将大大提高NAS 存储的性能。NAS需求旺盛已经成为事实。首先NAS几乎继承了磁盘列阵的所有优点，可以将设备通过标准的网络拓扑结构连接，摆脱了服务器和异构化构架的 桎梏；其次，在企业数据量飞速膨胀中，SAN、大型磁带库、磁盘柜等产品虽然都是很好的存储解决方案，但他们那高贵的身份和复杂的操作是资金和技术实力有 限的中小企业无论如何也不能接受的。NAS正是满足这种需求的产品，在解决足够的存储和扩展空间的同时，还提供极高的性价比。因此，无论是从适用性还是 TCO的角度来说，NAS自然成为多数企业，尤其是大中小企业的最佳选择。 NAS与SAN的分析与比较 针对I/O是整个网络系统效率低下的瓶颈问题，专家们提出了许多种解决办法。其中抓住症结并经过实践检验为最有效的办法是：将数据从通用的应用服务器中分离出来以简化存储管理。\n[singlepic id=99 w=410 h=220 float=]\n由图1可知原来存在的问题：每个新的应用服务器都要有它自己的存储器。这样造成数据处理复杂，随着应用服务器的不断增加，网络系统效率会急剧下降。 图 2\n[singlepic id=100 w=398 h=168 float=]\n从图2可看出：将存储器从应用服务器中分离出来，进行集中管理。这就是所说的存储网络（Storage Networks）。 使用存储网络的好处： 统一性：形散神不散，在逻辑上是完全一体的。 实现数据集中管理，因为它们才是企业真正的命脉。 容易扩充，即收缩性很强。 具有容错功能，整个网络无单点故障。 专家们针对这一办法又采取了两种不同的实现手段，即NAS（Network Attached Storage）网络接入存储和SAN(Storage Area Networks)存储区域网络。 NAS：用户通过TCP/IP协议访问数据，采用业界标准文件共享协议如：NFS、HTTP、CIFS实现共享。 SAN：通过专用光纤通道交换机访问数据，采用SCSI、FC-AL接口。\n什么是NAS和SAN的根本不同点？ NAS和SAN最本质的不同就是文件管理系统在哪里。如图：\n[singlepic id=101 w=455 h=223 float=]\n由图3可以看出，SAN结构中，文件管理系统（FS）还是分别在每一个应用服务器上；而NAS则是每个应用服务器通过网络共享协议（如：NFS、CIFS）使用同一个文件管理系统。换句话说：NAS和SAN存储系统的区别是NAS有自己的文件系统管理。 NAS是将目光集中在应用、用户和文件以及它们共享的数据上。SAN是将目光集中在磁盘、磁带以及联接它们的可靠的基础结构。将来从桌面系统到数据集中管理到存储设备的全面解决方案将是NAS加SAN。\n",
    "ref": "/2010/01/07/what-is-das-nas-san/"
  },{
    "title": "CMDB Value Points 价值点",
    "date": "",
    "description": "",
    "body": "\nCMDB的价值点分为两类：硬收益和软收益。从硬收益的角度，CMDB的用户可能会让你来描述CMDB对他们的价值点。下面的几个轶事可以作为收集CMDB可能为你的企业带来价值点的几个方向：\n\n 把IT环境的可视化带到更高程度 \u0026ndash;一领先的制热和冷却系统供应商指出，他们始终无法很好的理解一个计划外停机时间对用户所造成影响。例如，当只有25个用户受到了网络中断问题的影响，IT部门必须通知用户群中的全部100个用户。这会导致一个客户满意度低的反馈。CMDB使该公司能够理解配置项之间的关系，并确切地知道在任何确定时刻什么用户会受到影响。现在用户间可信的沟通能够来自于各个IT部门，并且使IT成为业务不可分割的一部分。  按业务目标来安排系统变更的优先度\u0026ndash;大型设备制造商不得不关闭了其所有的系统，后来发现不知道哪些服务器应该先启动。CMDB使公司能区分关键业务元素的优先度，确保减少计划外的停机时间，无形中降低了收入损失的风险。  减少软件许可证的费用的同时确保用户和服务器能整体的满足许可证遵从性 \u0026ndash; -的半导体制造商开展了一个审计，结果另他们感到震惊：该公司支持在为大量已经报废的服务器支付支持和维护费用。实际上，该公司关于报废资产的数量已经长期和实际不符了。CMDB有助于该公司发现这一问题，并重新分配预算资金，以更好地支持现有的基础设施。  为加快服务器整合提供更深层次的资产和关系信息 \u0026ndash; 一大型的金融服务提供商注意到，在其行业的公司通常在一个较短的时间内，会进行几次成功并购和整合。对于如何整合所有的IT部门是一个重大挑战（有时是次要的），他们往往是停留在相互隔离的工作状态下。然而，使用CMDB的公司就能够有效地集成新的收购，从而节省资金和为公司内部建立统一的IT业务形象。 IT要实现CMDB的硬收益，一般通过降低以下对象的相关成本来实现：人、第三方服务、软件、硬件和设施。这些方面的价值点可以通过财务方面的分析报表来反映出来。\n  CMDB能够实现的价值还包括哪些很难衡量的方面，例如下面的例子解释了这些软价值：\n 服务台 \u0026ndash; CMDB可以从提高事件和问题处理和解决效率和效果的方面来体现出硬利益的成效。还可以认为，CMDB使这种改善更可行，往往服务台技术员从尖锐的客户那里来收集信息是一项非常不快的工作，CMDB可能会提高支持人员支持客户的效率，提高客户满意度。另外，通过为服务团队提供更好的信息，你可能使用较低技术水平的工作人员来完成的相同水平的服务工作，降低在工资成本上的成本。  变更管理 \u0026ndash; 通过CMDB这个流程得到了很大的提升，更完善的风险评估，提供更多的信息来评价类似类型CI在过去时间里的变更成功率，并能更好的理解变更CI与其上游和下游其他基础设施组件的依存关系。其结果可能是使企业用户对IT所提供给他们的服务感到更满意，但这是难以像硬效益一样的量化的。  连续性管理 \u0026ndash; CMDB的变成了持续管理的记录源泉。拥有了能准确的、更新的描述IT环境状况的信息后，灾难恢复被大大地简化了，这提高了整个组织的信心。这是一个明确的好处，但也不是那么容易量化。  与业务的影响与和谐 \u0026ndash; CMDB使CI依赖关系能被更深入的了解。这种理解大大简化了连接CI到依赖于IT基础设施的业务流程或者服务的过程。使IT与业务更紧密的和谐是至关重要的，例如提升响应速度和让业务具有更好的竞争优势，但对比硬利益它也可能是难以量化。 以上内容参考了BMC出版的\u0026laquo;step by step to build a cmdb\u0026raquo;;以上软效益对于不同的企业而言可能是不同的，总的来说前两条是显而易见的，你也可能有更好的关于硬效益和软效益的总结和期望。如果有的话一定需要在项目建设前，或者初期阶段中，与CMDB项目相关的利益人和用户做细致的价值点讨论和确认是非常关键的。更进一步价值点的确认也更进一步的指导了CMDB项目实施的方案。BMC Atrium CMDB通过其完备的功能，以及那些以CMDB为核心而建立的ITSM流程应用，能很好的为企业用户实现以上的相关效益。 ",
    "ref": "/2010/01/01/cmdb-value-points/"
  },{
    "title": "At end of 2009",
    "date": "",
    "description": "",
    "body": "Martin Liu\u0026rsquo;s blog move to 72pines. I will see how long I could still here. Let\u0026rsquo;s say 6 months.\n[fergcorp_cdt_single date=\u0026ldquo;1 June 2010\u0026rdquo;]\nTo do list\n[add] I\u0026rsquo;d like to blog more about C-Bank CMDB project implement.\n[add] I hope I could have sometime for playing with open source software, like opennms, zenoss, otrs, etc\u0026hellip;\n[del] All of duplicate blog post will be deleted from some of my old blog site, including blogspot, chinaunix, msn space etc\u0026hellip;\nTo be continued\u0026hellip;.\n",
    "ref": "/2009/12/31/at-end-of-2009/"
  },{
    "title": "垃圾网站的殉葬品-个人博客",
    "date": "",
    "description": "",
    "body": "如果拥有个人博客，并且拥有个人域名，正在租用一个小服务商的虚拟机，那么你的网站可能已经无法访问，由于域名为注册被封，或者由于服务商的机器干 脆被连窝端而无法访问。如果你是我的blog的读者的话，我想你已经发现，我的blog已经无法访问两天了。我已经可以想象今天的国内互联网上，国内的自 由博主们，已经是哀鸿遍地了！！！\n更有甚者成，我国之互联网正进入全球最大的局域网时代。对垃圾网站的严打可以，但是打到这个程度，究竟打击了谁，我相信那些害群只马一定会转移到国 外，继续他们的活动。所以，倒霉的还是很多自由博主，还是那些提供小型博客服务的小服务商。我想新浪、搜狐、百度他们的blog的注册量这几天肯定在节节 攀升吧~那就透着乐吧，我想他们肯定在唱“我们的生活充满了阳光~~~~”国内博客的行业亟待实名制管理，自由博主们也需要阳光。我的博客还无法还原两个 月的内容丢失，阴霾笼罩着我。\n",
    "ref": "/2009/12/30/e59e83e59cbee7bd91e7ab99e79a84e6ae89e891ace59381-e4b8aae4babae58d9ae5aea2/"
  },{
    "title": "十月围城",
    "date": "",
    "description": "",
    "body": "港片也能这么拍的如此严肃，港人爱国，武打片打到这么痛楚，普通人普通情感才感人，师徒，父子，领袖和革命党，朋友，夫妻，宏大的历史背景下，平常市井生活里，对最关心的人，关心到底有多少，想爱趁早多一点！\n",
    "ref": "/2009/12/24/e58d81e69c88e59bb4e59f8e/"
  },{
    "title": "老美真的很扯，一个职位的帖子被顶了22次",
    "date": "",
    "description": "",
    "body": "Remedy的开发人员或许熟悉这个邮件列表，ARSlist.org；如果没注册的话，一定需要注册一下啊，不为别的，学学英语，看看其他人都聊什么，有什么问题总是不错的。下面这个段子就是最近我看过的最扯的讨论。关键词：Remedy, 职位， OH州，辛辛那提，Developer，伊拉克，ARS 6.3, ARS 7.5, ITSM 7.5, 巴格达， AK 47，武器，活动链，过滤器，阿富汗，薪水，简历，顾问\u0026hellip;\u0026hellip;. engoy！！！！\n\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\nJob: Permanent - Lead Remedy Developer - Cincinnati, OH\nDear List,\n\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;1\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-\nMerry Christmas!\nTitle: Lead Remedy Developer\nLocation: Cincinnati, OH\nDuration: Permanent (Relocation is offered)\nStart Date: 2-4 Weeks\nMust haves:\n- 5+ Years experience with Remedy\n- Experience with 7.x\n- Stable Resume (No Consultant Resume’s) (Client does not like job hoppers and will reject)\nsubtitle: As a senior developer, the individual will create, design, develop, test and implement Remedy applications and workflow enhancements from business requirements, in accordance with the corporate procedures and standards. This individual may also serve as a business analyst or project manager on select projects and may train Remedy users as required.\nAdditionally, the individual will be responsible for the daily administration, maintenance, monitoring and support of all Remedy applications, servers and reporting in a high-available 24x7 environment. The individual is expected to evaluate Remedy application patches, enhancements and new releases as necessary.\nITIL certification\nCMDB design\nProject Management and SDLC experience\nBusiness requirements gathering\nRemedy Integration with other technologies and systems\nRespectfully,\nJoshua Kitchen\nSenior Recruiter\nKforce Federal\n937.449.1749 office\njkitchen@kforce.com\nhttp://www.govtrecruiter.com\nGreat People = Great Results®\n\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;2\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\n\n- Stable Resume (No Consultant Resume’s) (Client does not like job hoppers and will reject)\nMy 2 cent\nHaving been a Consultant for 8+ years (Remedy Developer for 13+ years), and then taking a Full Time Remedy position with a local company, the value I bring to the organization is huge. As I have seen a lot, traveled the world, assisted a wealth of customers with numerous ITSM and bespoke applications, have a breath of experience that most “Stable” Remedy developers do not have. If there is a seasoned Developer/Consultant that is ready to settle down and eliminate traveling, your client should really rethink their definition of “Stable”, because a Consultant is not a “Job Hopper”\nDoug\n\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;3\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\nJoshua,\n\n- Stable Resume (No Consultant Resume’s) (Client does not like job hoppers and will reject)\nReally! What planet is your client from? I would think most consultants would be glad to MILK a project for ALL its worth. But that would be bad business for the employer. So projects tend to adhere to budgeting constraints.\nIt is not the consultant’s fault that many Remedy projects end on or ahead of schedule. Unless he/she has worked TOO hard. Apparently your client does not want THAT GUY.\n\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;4\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\nAs my last \u0026ldquo;Permanent\u0026rdquo; job was for an \u0026ldquo;UNStable\u0026rdquo; company that Disappeared one month end of last year,\nI couldn\u0026rsquo;t have said it better myself\u0026hellip;spot on Doug!\nHappy Holidays To You and Yours!\n\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;5\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\nRead between the lines dudes :-)\nWe need a Lead Remedy developer who has the experience of a junior/trainee Remedy Administrator, and who is willing to work at the wages of a gas station attendant.. No expenses paid. Must be willing to work late hours - no overtime.. Must have had his first job as a gas service attendant for at least 5 years..\n;-)\nJoe\n\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;6\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\nYou guys give ol Josh a break, he is just relaying what his customer wants… If any consultants want to apply for that position I bet you can send an updated resume to accommodate getting to the interview. I think that it’s funny though that some employers do not realize anything about this product or the way that it is developed or administered. But I guess that is what recruiters are actually for right?\n\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;7\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\nHey Tommy,\nWe just like to have harmless fun sometimes :-) We know (at least most of us) Josh for a while as well as the fact that recruiters / employers sometimes have no clue what they are talking about. Time and again I have come across employing interviewers question me about the implementation of ITIL as if it were a physical product. Its nothing new.\nYes not so hard to update a resume to make it like you were on a \u0026lsquo;stable\u0026rsquo; job and not a \u0026lsquo;job hopper\u0026rsquo;. Technically if I were to do that, it would look like I worked for just 2 companies over the 12 years I have worked with Remedy. I had to do just quite the opposite when I started looking for consulting gigs, and name every customer my old company had as a different project so that it would look more like a \u0026lsquo;job hoppers\u0026rsquo; resume.\nIts just a wrapping paper. At the end of the day you are the real stuff - what you know or do not, and can do or cannot, makes the difference to a smart employer (if they exist).\nJoe\n\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-8\u0026mdash;\u0026mdash;\u0026ndash;\nDid you notice the slight jab at the end of the note? I just wanted to get in a shot. It drives me crazy that there is such a disconnect between the hiring manager and the HR team in most companies.\nOne of my favorite job adverts had the perfect candidate as being aged 21 – 25, Bachelors degree and 6+ years experience in a corporate environment. The math just didn’t add up unless you started your degree plan at before you were 13.\n\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;9\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-\nAs recruiters who have filled numerous Remedy positions in IRAQ and elsewhere we have tried to always be responsive to the needs of the client and the realities of the talent pool. The external recruiter\u0026rsquo;s role does not stop with the resume.\nWith respect to the current thread, there is a real clue re the client\u0026rsquo;s mind set and/or lack thereof, when they use the word \u0026ldquo;Permanent\u0026rdquo; in their job description. How do you spell \u0026ldquo;law suit?\u0026quot;\nThere are no \u0026ldquo;permanent\u0026rdquo; jobs out there.\n* Contract positions or\n* Employee positions\u0026hellip;\nTime for a reality check. We expect to be looking for \u0026ldquo;Senior Remedy Engineers\u0026rdquo; for both Afghanistan and Iraq\u0026hellip;Anyone interested?\nHappy Holidays\nSincerely,\nJeff Glaser\nINVIZCORP\n703-729-3382\n\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;10\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-\nDo the Afgan and Iraq positions come with weapons training? Haven’t fired a Mark 19 in a while but I’m sure the mechanism hasn’t changed would love to renew the qualification though lol\n\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;11\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-\nSomeone actually mentioned age as a desirable quality in a job posting? That would be discriminatory.\n\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;12\u0026mdash;\u0026mdash;\u0026ndash;\nIf you had issues with the weapon.. would you check active links or filters to see why it’s not firing?\n\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;13\u0026mdash;\u0026mdash;\u0026mdash;-\nLol Is it Friday already?!?! That was a pretty good one.\n\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;14\u0026mdash;\u0026mdash;\u0026mdash;-\nActive links, since the trigger is executed by the user action.\nRick\n\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;15\u0026mdash;\u0026mdash;\u0026mdash;-\nBut that weapon is an automatic so you would need to check filters as well if the first round went off but then misfired on the next firing order. Maybe even check API logging of the belt stopped feeding correctly.\n\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;16\u0026mdash;\u0026ndash;\nI would have an escalation throw out a grenade every 5 minutes. RUNIF: weapon jams.. J\nI’d stick around Tommy since you already had weapons training… unless, of course, you trained with Dick Cheney.\n.\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;TTTT_\u0026mdash;\u0026ndash;_______\n/''''''''''(______O] \u0026mdash;\u0026mdash;\u0026mdash;-____ ______/]_\n__\u0026hellip;\u0026mdash;'\u0026quot;\u0026quot;\u0026quot;_ \u0026ndash;'' Q ___________@\n|''' ._ _______________=\u0026mdash;\u0026mdash;\u0026mdash;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\u0026quot;\n| ..\u0026ndash;''| l L |_l |\n| ..\u0026ndash;'' . /-___j ' \u0026lsquo;\n| ..\u0026ndash;\u0026rsquo;' / , ' \u0026lsquo;\n|\u0026ndash;\u0026rsquo;' / ` \u0026lt;br /\u0026gt;|__' \\ -\n- \u0026lsquo;-.\n\u0026rsquo;. /\n'-./\n\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;17\u0026mdash;\u0026ndash;\nYou could also add in an exclusion in the Runif clause just to be on the safe side If $USER$ != “dchene1”\nNice AK. You know I think that symbol art is coming back en vogue,\n\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;18\u0026mdash;\u0026ndash;\nWhat would be the client type? Unknown?\n\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;19\u0026mdash;\u0026ndash;\nClient type would be terrorist or freedom fighter depending on who was holding the UI.\nEscalations would be no good unless you happened to be testing something when the enemy was in line with the weapon that was firing at the given time or interval!\nFilters would be no good because of the network lag between the client and the server by the time the result computed fire, the target had moved out of the kill zone!\nSorry guys and girls but always ends up with some grunt holding the weapon and firing the trigger.\nRob\n\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;20\u0026mdash;\u0026ndash;\nYour right Rob. The \u0026ldquo;grunt\u0026rdquo; part.\nAs it turns out Joe was spot on about the position \u0026ldquo;gas station attendant\u0026rdquo;.\nI haven\u0026rsquo;t see the wage that was offered, since I worked with the old UNIX client.\nRemember\u0026hellip; that was before we had Active Links\u0026hellip;\n\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;21\u0026mdash;\u0026ndash;\nYou could have actions like Change Fields (of fire), Open Window (for grenades), and Call Guide (for arty).\nRick\n\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;22\u0026mdash;\u0026ndash;\nDon\u0026rsquo;t forget to include an active link guide for autofire.\n\u0026lsquo;threats\u0026rsquo; \u0026gt; 1 AND \u0026lsquo;LastThreatEliminated\u0026rsquo; != \u0026ldquo;Yes\u0026rdquo;\nSQL Statement Set Field\nSELECT MIN(TargetDistance) FROM CURRENT_BATTLEFIELD.FIELD_OF_FIRE WHERE TARGET_STATUS=\u0026lsquo;ALIVE\u0026rsquo;\nSET FIELD \u0026lsquo;ThreatDistance\u0026rsquo; = $1$\nIf \u0026lsquo;threats\u0026rsquo; \u0026gt; 1\nPERFORM-ACTION-PULL-TRIGGER \u0026ldquo;\u0026lsquo;ThreatDistance\u0026rsquo;\u0026quot;\nOn a serious note. If you\u0026rsquo;re looking for a contract, go for Iraq before Afghan. They\u0026rsquo;re trying to pay people the same amount of money for both places. Left Iraq 6 weeks ago. No way I\u0026rsquo;d go to Afghan for the same pay. (Living conditions are worse, more time off to sit around and do nothing(very boring), and we got almost no incoming at Victory in Baghdad.)\nAs far as the Iraq posting. It says ARS 6.3 but that description is 4 years old. It\u0026rsquo;s 7.1, ITSM 7.0.3. 7.5 is probably never going to happen there. But if you you\u0026rsquo;re looking for a new contract and want to get paid pretty good to learn ITSM 7 and get some experience with 7.1 (that\u0026rsquo;s why I went) then send Jeff Glasser your resume.\nJason Bess\nRemedy Developer/Consultant\nBess Development Corporation\n(My position is the one they\u0026rsquo;re back-filling in Iraq right now. I won\u0026rsquo;t lie, it sucked being there. But the $95k tax exclusion, massive paychecks, and experience were unbeatable.)\n\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;The End\u0026ndash;\n请问16楼贴出的是何物？哈哈:)\n",
    "ref": "/2009/12/24/is-that-a-joke-of-remedy-developer/"
  },{
    "title": "资产CI的一生",
    "date": "",
    "description": "",
    "body": "在ITIL v3以后，配置管理进化为“服务资产和配置管理SACM”，换句话说，资产和配置管理不分家。两个流程应该是融合的。从微观上看资产管理设计到CI的所有生命周期状态，而这个服务资产在CMDB中出现的状态为整个生命周期中的一部分。\n\n最好能通过资产管理为统一入口，来完成对CMDB中资产的生命周期管理。例如：一台服务器在到货以后，完成资产入库后，就应该在CMDB中自动创建CI，在上架部署了软件后，有配置资产自动采集工具，采集回详细配置信息后，资产状态就自动变为“部署”，当在运行维护中服务器宕机或者维护时，在资产管理中也能看到更新的信息。下面是建议的服务资产的生命周期状态:\n编号 \n状态名称 \n状态描述 \n\n1 \n到货 \n表示为CI的物品在采购以后，被相关部门签收。 \n\n2 \n组装 \n设备的组件在被组装的过程中 \n\n3 \n维护 \n该设备处于宕机后的维护状态 \n\n4 \n宕机 \n该设备处于宕机状态，还未对其进行维护 \n\n5 \n终止 \n不在处于被部署的状态 \n\n6 \n转移 \n该设备正在被转移到其它的地点或者机房途中 \n\n7 \n删除 \n配置项被标记为删除状态 \n\n8 \n库存 \n设备处于库存中，还没有被部署 \n\n9 \n借出 \n已被其他单位或者部门借走 \n\n10 \n处理 \n该设备已经被拆卸，其本身已经不可用 \n\n11 \n保留 \n该设备已经被某单位或者部门预订，已经不再库存中了 \n\n12 \n返厂 \n由于设备已经被损坏或者过保，必须被退回厂商 \n\n13 \n部署 \nCI的默认状态，表示设备处于正常的生产运行状态 \n\n14 \n订购 \n该设备已经被订购，还未到货，仍然不可用 \n\n\n配置项管理和资产管理的联系和区别。\nService Asset and Configuration Management (SACM) = Configuration Management + Asset Management\nConfiguration Management\n@The Process responsible for maintaining information about Configuration Items required to deliver an IT Service, including their Relationships\n@This information is managed throughout the Lifecycle of the CI\nAsset Management\n@Asset Management is the Process responsible for tracking and reporting the value and ownership of financial Assets throughout their Lifecycle. ",
    "ref": "/2009/12/13/service-asset-ci-life-cycle/"
  },{
    "title": "Remedy ITSM 7.6 installation Tips",
    "date": "",
    "description": "",
    "body": "自从7.6发布和以后一直没有时间安装，通过最近的几次安装，积累了一些经验，供大家参考。在安装开始之前请一定查看ARS_7500_Comp_Matrixv1001.pdf文档，保证操作系统、数据库、中间件和JDK的版本都符合要求。如果是安装生产系统的话，建议把数据库和应用服务器分开，硬件配置也一定参考Remedy ITSM安装手册中的建议硬件配置要求。\n最近在Linux的虚拟机上做了一次安装，相关细节如下:\n  Suse Linux Enterprise server 10 sp2 64 bit\n  Oracle 10G 64bit (10201_database_linux_x86_64.cpio.gz)\n  JDK 1.6(jdk-6u6-linux-i586.bin)\n  在Suse Linux上安装Oracle还是比较容易的，可以参考这个安装手册进行，下载。数据库安最好按照成utf8字符集，如下图所示：\n\nRemedy ITSM套件的安装分为三个步骤：1）ARS 7.5 SP3 的安装；2）Atrium CMDB7.6安装；3）ITSM 7.6安装；其中第一步是最重要的，第二步骤如果安装产品目录数据的话时间花费比正常多一点。Remedy ARS 7.5是最新的补丁包，它修复了sp2的很多bug；是Remedy ITSM 7.6安装的必须版本。在安装ARS的时候需要准确的导出相关的环境变量，如果环境变量没有或者不够的话，安装程序则无法正确地连接数据库，下面的例子可以参考一下。\n\n每一步安装完成之后都需要详细查看相关的日志，确保每一步都安装完全正确。在安装完ARS之后一定要为服务器添加所有相关License。\n",
    "ref": "/2009/11/28/remedy-itsm-76-installation-tips/"
  },{
    "title": "2012",
    "date": "",
    "description": "",
    "body": "妹妹问：那么2012年的奥运会还办不办了？无语\u0026hellip;..这个电影中有很多情节与中国相关，特效不错，这可能是吸引人去电影院看的原因吧。\n这个电影倒是让人对玛雅文化产生了兴趣，有空可以看看。\n",
    "ref": "/2009/11/23/2012/"
  },{
    "title": "What's Google Chrome OS",
    "date": "",
    "description": "",
    "body": "看完这个视频之后，还是没搞清楚：它到是一个快速的浏览器，还是一个快速启动的OS加浏览器，如果它仍然需要OS的话，那么它不过是一个Redesigned的OS+操作系统。说白了就是瘦客户端加肥浏览器的组合吧！\n您用Google的浏览器么？我用了一次就删除了，至今没有尝试装Google的操作系统。\n",
    "ref": "/2009/11/23/whats-google-chrome-os/"
  },{
    "title": "CMDB选型解密",
    "date": "",
    "description": "",
    "body": "自打承接了《Step by Step Guide to Building a CMDB (Updated for ITIL V3)》的翻译工作之后，由于平时工作太忙，翻译工程只能在业余时间完成；现在渐渐感到了此项工作的压力，每每想到读者对英文翻译版本读物的高期望和要求时，就愈加感到此项工作责任之重。不过本书对我来说还是一剂很好的补品，对我最近的ITSM项目都有直接的借鉴和指导作用。\n说来此书有很多实用且精彩之处，相信读了英文原版的人更能有所体会。我忍不住想把其中的部分内容提前与你们探讨，这里想与你们分享如下两个内容。\n\n\n上图还给所有CMDB用户一个清晰地CMDB功能点考察点，CMDB作为业务服务管理的核心，各个厂商其实并没有达成解决方案功能的标准和共识。通常情况下厂商提供的CMDB产品的发展和起源有以下几种情况：1）按照ITIL中对CMDB的需求和标准从无到有开发的标准CMDB产品；2）伴随变更流程或者业务影响管理而开发的CMDB功能模块；3）伴随配置自动化发现工具而开发的相应CMDB功能模块；4）应资产管理或者监控工具扩展而生的CMDB功能产品。用户在挑选CMDB产品的时候一定要明确CMDB的核心功能，除了以上功能外，其他的附加功能可能是nice to have的功能，而非必须。本图位于原版书的134页，如果您对我的翻译有建议请留言，多谢！\n\n\n上表为评估一个CMDB产品厂商的综合打分评价表样例。在选择并且评测一个CMDB厂商时，需要仔细考察的产品功能共有8点。用户需要注意的是一定要搞清楚其中的每一个功能是否是由厂商的CMDB产品的相关模块所提供的，如果不是的话需要搞清楚，每个功能是否是CMDB的外围或者其他产品模块，或者二次开发实现的。如果是这样的话，这种解决方案可能不是一套集成统一的解决方案，可能出现其他附加非CMDB产品的采购，可能在实施阶段付出不必要的集成和开发费用。虽然这些潜在因素在采购和实施阶段可能是隐形出现的。征集上表中相关术语的中文翻译：Weighted ，Weighted Rating Score，Total Weighted Score。有好的建议请留言。本图位于原版书籍的141页。\n",
    "ref": "/2009/11/19/how-to-select-a-cmdb/"
  },{
    "title": "下雪了",
    "date": "",
    "description": "",
    "body": "二零零九年的第二场雪，比以往的都来的大一点。\n昨天晚上的大雪让我感到惊喜，今天早晨空气非常好，不过地铁里的人很多。\n\n",
    "ref": "/2009/11/10/e4b88be99baae4ba86/"
  },{
    "title": "Knowing",
    "date": "",
    "description": "",
    "body": "这个电影的官方网站是很炫的，但是看后感觉真的不怎么样。http://www.knowing-themovie.com/ 看是感觉有点悬疑，接着又一点点的惊悚，然后算是带点科幻吧，地球被一个太阳的耀斑给毁灭。俩小屁孩被什么人/外星人接到了另外的一个星球上。难道这就是传说中的亚当与夏娃么？\n\n",
    "ref": "/2009/11/09/knowing/"
  },{
    "title": "汝亦知射乎",
    "date": "",
    "description": "",
    "body": "康肃问曰：“汝亦知射乎？吾射不亦精乎？”翁曰：“无他，但手熟尔。”康肃忿然曰：“尔安敢轻吾射！”翁曰：“以我酌油知之。”乃取一葫芦置于地，以钱覆其口，徐以杓酌油沥之，自钱孔入，而钱不湿。因曰：“我亦无他，惟手熟尔。”康肃笑而遣之。\nZT\u0026ndash; 欧阳修《卖油翁》\nMY VIEWPOINT：IT管理的好坏与否，不是依靠个体的技术能力和熟悉程度。铜钱上的孔，是衡量能力和筛选智慧的重要工具。智慧获取数据抽取-\u0026gt;分析-\u0026gt;转化的能力和工具。这三个过程中越往后对工具的依赖程度越低。\n\n如图所示，“数据包”是从一个层次传递到下一个层次。“智慧”层次具有作出明智决策必需的所有组成部分 —\n数据、信息和知识。当然，可以在任意层次作出决策，这取决于现有的结果和条件。下面的例子用于说明在各个层次进\n行决策的过程：\n**数据层：**服务台经理发现有二十位客户等待打入电话。他可能会决定临时增加一线客户服务人员的数量，这是根据\n一条数据制定的决策。\n信息层：在另一类似的情况下，有 20 位客户等待打入电话，但这次经理掌握了更多的数据。他知道有一台目前已\n停机但马上将恢复正常的服务器。在这种情况下，经理可能决定稍后再增加一线客户服务人员的数量，因为他（或她）\n怀疑这两个问题是相关的。在拥有多个数据源的情况下，经理掌握的信息更多，并将根据可用信息作出决策。\n**知识层：**服务台经理发现等待打入电话的客户不断增多，而且某台服务器即将接近满负荷运转。因为她拥有用以\n说明如何应对此情况的信息，所以可以立即采取适当的行动隔离并解决问题。这个决策是基于知识作出的。\n**智慧层：**IT 执行官正在温习上个月的知识，并发现某一供应商提供的几台服务器出了问题。他们将决定要求供应\n商评估其所有服务器，以确定其他服务器是否会出现同样的问题。这个决策是基于智慧作出的。\n尽管这些例子可能过于简单，但它们可作为理解“智慧分层体系”的参考。\n来源：行业外网\n",
    "ref": "/2009/11/03/how-to-get-smart/"
  },{
    "title": "选书名",
    "date": "",
    "description": "",
    "body": "好消息《Step by Step Guide to Building a CMDB (Updated for ITIL V3)》即将翻译成中文出版。市场里ITIL的书越来越多，但是讲CMDB的书却一直很少，能讲解清楚CMDB建设过程的的书就更少。可是国内ITIL用户CMDB建设之瓶颈却越来越明显，我们希望有一本好的书作为这项重要工作的参考指南。\n\n给此书起一个好的名字是头等大事，目前能想到的书名如下：\nStep by Step Guide to Building a CMDB 中文书名？(polls)\n寻求前100名投票者，请对以上书名投票，并评论；如果您有更好的书名，欢迎推荐；请在下面留言，请正确填写邮箱，您推荐书名一旦被选用必有感谢送上。\n",
    "ref": "/2009/10/29/pick-a-book-name-for-step-by-step-guide-to-building-a-cmdb/"
  },{
    "title": "小人物大英雄",
    "date": "",
    "description": "",
    "body": "又一个小人物大英雄的美国片。10-1前后红色电影充斥所有影院，这是近期看过的最好看的一部电影了。比较好的刻画了一个人物的多面性。影片中描写了很多耐人寻味的小概率事件。这个情节比较紧凑，高潮出现在主角被迫送钱。故事结尾他乘坐地铁，带着一加仑牛奶平安回家，看似一个小市民平常的一天。\n电影海报如下图所示。\n\n\n",
    "ref": "/2009/10/22/small-person-big-hero/"
  },{
    "title": "何谓云？",
    "date": "",
    "description": "",
    "body": "下面是两个Youtube上的视频，短短5分钟的视频就把云计算的相关核心概念解释的很清楚。\n好像国内吧Youtube给屏蔽了，上面的视频可能看不到，Google真的应该和中国政府把关系搞好，哎~~\n",
    "ref": "/2009/10/21/what-is-cloud-computing/"
  },{
    "title": "DELL如何管理IT？",
    "date": "",
    "description": "",
    "body": "Dell is a big company, if you wants to know how DELL does IT management with BMC, please check out this vide form Dell website.\nDELL是一个家喻户晓的公司，它是如何做IT管理的呢？请查看这段来自DELL网站的视频。视频中谈到DELL采用的是全套ITSM套件，提到很多的是相关流程是如何使用CMDB的配置信息的，从一个侧面我们可以看到配置管理的重要性。CMDB可以看着成熟客户的标志。\n",
    "ref": "/2009/10/20/how-dell-does-it/"
  },{
    "title": "手把手教您构建CMDB/CMS",
    "date": "",
    "description": "",
    "body": "If you have no idea about how to build a CMDB, you should check out this document. It come from http://www.bmc.com/products/product-listing/53556216-141391-2117.html\nDownload it: Step by Step Guide to Building a CMDB (Updated for ITIL V3) (pdf)\n该《手把手CMDB/CMS构建指导手册》包括了配置管理数据库/系统建设的所有相关流程、技术和指导性建议。如果你有CMDB的建设意向，该手册非常值得仔细阅读。\n欢迎留下一个反馈，投票或者留言都行。\n[poll id=\u0026ldquo;8\u0026rdquo;]\n",
    "ref": "/2009/10/17/step-by-step-guide-to-building-a-cmdb/"
  },{
    "title": "CMDB中存什么？",
    "date": "",
    "description": "",
    "body": "[caption id=\u0026quot;\u0026quot; align=\u0026ldquo;alignnone\u0026rdquo; width=\u0026ldquo;406\u0026rdquo; caption=\u0026ldquo;dmtf.org\u0026rdquo;][/caption]\n当然是配置项和它们之间的关系，即：CI 和 Relationship。 那么如何规划那些类型的CI和Relationship需要保存到CMDB中呢？可以参考的数据模型是DMTF的通用信息模型，它是以面相对象的方式来描述各类CI和关系。它是一个工具用来帮你对环境中的各种物理和逻辑的CI和关系进行分类，参考这个模型选择一些有用的类（广度），然后在参考它对每个类属性的描述（粒度）。这些类的选择只是一个初步的研究，每个CMDB厂商和工具对其实施和参考的力度都不同，也需要看您具体实施的是什么工具。例如：你需要描述银行基金业务系统，你可能选择的CI类包括：客户群、业务流程、业务活动、业务服务、IT服务、应用系统、应用、软件服务器、服务器、网络、存储等；关系包括：组件、依赖和影响。CI类和关系的选择也基本上遵循够用就好的原则；而且每个类对应的CI实例都需要有人负责管理维护，需遵循，谁负责、谁维护的原则保障其属性的精确性。对于整个CMDB来说如果存在没有Onwer的CI或者关系，如果它是由自动化配置发现工具来更新的；那么它可以存在，如果不是的话，它可能根本就不该存在。所以CMDB中保存的数据不是越多，越细越好；而是够用就好，能保证更新就好。由于数据根本就不是免费的，即使国内的人力成本低，也不应该雇用一帮专职更新CMDB的人。 综上所述：我们说明了CMDB中数据选取和存放的最基本原则和方法，在CMDB产品选型过程中需要着重考察产品的数据模型本身和其管理的能力，还包括其CI和关系的扩展和定制能力；包括数据类型的支持和界面定制的程度。那么CMDB中的CI和关系有该如何展现呢？这是CMDB系统的另外一个功能：可视化。下面是一个CI和关系展示的实例供参考：\n[http://media-001.yo2cdn.com/wp-content/uploads/266/26670/2009/10/s1-4-blog.swf#swf\u0026amp;width=320\u0026amp;height=320]\n全屏查看或者下载Flash文件\n第一代的配置展示方式是，纯数据表格方式。第二代具有一种固定格式的图形展示方式，除了那几张视图外，别的需要单独开发。下一代的具有各种视图定制功能，并且支持关系和ci的过滤等等。\n",
    "ref": "/2009/10/05/what-does-cmdb-store/"
  },{
    "title": "博客再次搬家回国",
    "date": "",
    "description": "",
    "body": "趁着国庆长假，我有空吧Blog从国外的免费虚拟主机搬回国，搬到了yo2.cn。原因意外，不知道为啥，访问martinliu.cn首页时，总是被重定向到myfacebook.net上，访问其它二级页面没有问题。这个问题让我着实抓狂了好几周，国庆前的几周一直在上海出差，比较忙，基本上9月九荒废了，别说解决这个问题，就连一篇blog也没有时间写啊！想到现在还是没有想清楚，被重定向的原因到底为何？可能是被黑了，可能是被强制添加了广告。\n不过这个事件也不全是我搬回国的原因，其它原因：\n\n 国内读者居多，从google的统计上可以看出，本blog的主要读者都在国内。  域名已经备案了，上次转到国外的原因是域名未备案  实在懒得自己维护插件和blog本身，我已经把blog模版恢复到了默认模版，插件已经减少到最少，这样blog也可以快一点  实在没有精力维护虚机和域名绑定之类的事，WordPress对我来说可能只剩下一种功能就是Publish，呵呵其它的工作都交给服务商吧。 目前用的是DNSPad的DNS服务，yo2的WordPress服务，他们两个好像都与针对国内电信、网通和教育网的加速功能。那么目前您觉得网站速度如何了呢？方便的话给我一个反馈哦。\n[poll id=\u0026ldquo;7\u0026rdquo;]  ",
    "ref": "/2009/10/05/bo-ke-zai-ci-ban-jia-hui-guo/"
  },{
    "title": "国庆掠影",
    "date": "",
    "description": "",
    "body": "[gallery link=\u0026ldquo;file\u0026rdquo; columns=\u0026ldquo;3\u0026rdquo; orderby=\u0026ldquo;ID\u0026rdquo;]\n图片说明：\n\n 十月一日，早晨在阳台上拍摄的空军演习，有8架战斗机  十月一日，早晨在阳台上拍摄的空军演习，有4架战斗机  十月一日，晚上到北京中轴线南端的“永定门”，准备观看天安门的礼花  图片4-6，十月一日,在天桥附近看到的天安门广场的礼花，很壮观 由于照相机有限，拍的不是很清楚，全当留个纪念吧。  ",
    "ref": "/2009/10/05/guo-qing-l/"
  },{
    "title": "MartinMarks for 29th August",
    "date": "",
    "description": "",
    "body": "New IT Job: CMDB Manager\n从此IT部门有多了一个职位CMDB经理，不过某人的工作量加倍了也没准哈哈，从这个文章中可以看出这并不是一个可有可无的职位，而且CMDB的建设和推广，以及管理和其他的ITIL流程没有区别，需要结合技术、流程和人老三样，而且要再次改造人们对于配置管理的行为方式和文化了。\nRole Overview: CMDB Manager\nCMDB经理负责管理和维护您的CI，工作内容都有了，CIT/CTO招不招这个人由您。\nCMDBs reduce costs, automate tasks\nCMDB更多的不是一种技术，更多的是流程，联邦技术让您从一个集中的CMDB来访问这个多元化多变的世界。CMDB信息需要多种来源、产品和工具。\nTop 10 reasons NOT to implement CMDB\n不去实施CMDB的10个理由\nTop Ten Reasons to Implement a CMDB\n实施CMDB的10个理由\nThe federated CMDB: Getting past the hype to the good stuff \ncmdbf标准的实施在各家产品中尚处于开始阶段，是否大家都会照着做呢。联邦让所有的配置数据更易访问。\nLogo Mark\n\n",
    "ref": "/2009/08/29/martinmarks-for-29th-august/"
  },{
    "title": "IT服务管理考核向左走向右走: CSF OR KPI?",
    "date": "",
    "description": "",
    "body": "最近做的一个项目中需要帮用户设计一个CMDB的成熟度模型，能够从该模型中持续的检查CMDB的建设程度。所以我研究注意了一下的一些书籍，考虑有机会可以买回来研究一下：\nIT服务管理的持续改进需要一定的手段实现，这是ITIL V3中的一个重要流程。CSF是关键成功因素，KPI是关键性能指标，这些都是metrics管理过程中需要关注的手段。每个流程都可以找到相应的CSF和KPI。CSF算是V3的新生事物，我想它可能会对IT管理质量的衡量和改进带来新的方式。\n别的不说，我只想说说KPI管理方法可能带来的坏处。举个例子：有个公司想通过“事件单数”来考核服务台一线人员的工作。结果当他们在执行了一段时间后，他们发现服务台中有大量重复的事件单，实际上服务台对每个收到的电话都新建一个事件单，并没有做重复事件匹配查找的工作。进一步的也影响了通过重复事件来做进一步的问题管理。\n从考核管理的角度看，ITSM的考核指标和体系如何建立的合理，如何才能建立的正确的设计和实施的确是一件大事。否则会有什么后果，我们可以想想三鹿毒奶粉事件，奶粉的蛋白质含量是奶粉质量的重要指标KPI，营养健康是奶粉的终极CSF目标。三鹿真的给了我们一个血的教训啊，想让你的IT服务质量如何呢？可以想想三鹿。不过还是需要多多学习所有可能的CSF和KPI，从何设计出确实可行的管理方式。\nImplementing Metrics for IT Service Management (ITSM)\nISBN: 9789087531140\nAuthor: David Smith, Micromation Canada\nMetrics for IT Service Management (Paperback)\nby Peter Brooks (Author)\nMeasuring ITIL: Measuring, Reporting and Modeling\n** ** - the IT Service Management Metrics That Matter Most to IT Senior Executives (Paperback)\nby Randy A. Steinberg\n**Step-by-Step Guide to Building a CMDB **\nby BMC Software; Inc (Author)\n后来发现了这个ITSM metrics modeling tools ，觉得这个真的不错。可行性很高。\nITSM Metrics Modeling Tool\n",
    "ref": "/2009/08/29/csf-or-kpi-matrix-itsm/"
  },{
    "title": "今年5.1去成都休假",
    "date": "",
    "description": "",
    "body": "吃成都小吃，看国宝熊猫，成都茶馆喝茶，果然是去了就不想走的地方。\n",
    "ref": "/2009/08/07/51-to-chengdu/"
  },{
    "title": "我们新疆好地方，最美是喀纳斯",
    "date": "",
    "description": "",
    "body": "新疆之行照片集，路径北京 乌鲁木齐 喀什 乌鲁木齐 布尔津 喀纳斯 布尔津 乌鲁木齐 北京\nhttp://picasaweb.google.com/liuzh66/Xinjiang\n看不到的访问这个链接：http://www.flickr.com/photos/41222865@N03/\n",
    "ref": "/2009/08/07/xinjiang-is-good-place-kanas-is-best/"
  },{
    "title": "关于ICP备案申请审核通过的通知",
    "date": "",
    "description": "",
    "body": "尊敬的用户[]：您的ICP备案申请已通过审核,备案/许可证编号为: 京ICP备09073554号 ，审核通过日期：2009-07-28。 \n[caption id=\u0026ldquo;attachment_491\u0026rdquo; align=\u0026ldquo;alignleft\u0026rdquo; width=\u0026ldquo;150\u0026rdquo; caption=\u0026ldquo;welcom to martinliu.cn thanks!\u0026quot;][/caption]\nThat is what I was dreaming about for almost half year. You can not even understand my blog had been closed, because it took me 4 times to got my doman name registered. Finally I did it by myself. Cheers! I\u0026rsquo;d like to put it on page foot.\n",
    "ref": "/2009/08/01/got-martinli-dot-cn-icp-registered/"
  },{
    "title": "BMC and Cloud computing",
    "date": "",
    "description": "",
    "body": "July 15, 2009 – BMC Software has announced that it is leveraging Amazon Web Services to provide a single, unified management solution meant to give customers control over existing internal IT assets and external cloud infrastructures, according to a company release.\nhttp://www.information-management.com/news/amazon_bmc_software_cloud_computing-10015748-1.html\nBTW: it seems the IT management is as important as infrastructure.\n",
    "ref": "/2009/07/16/bmc-and-cloud-computing/"
  },{
    "title": "CMS/CMDB 配置管理系统和发现工具",
    "date": "",
    "description": "",
    "body": "最近的一些CMDB项目和测试中都用到和测到了自动发现工具，很多用户对此的理解和看法还不是很到位。**首先：“自动化配置和关系发现工具是什么？” **\n它是CMS工具集当中的数据采集工具。 从产品名称上看，往外都带DDM，它是 Discovery Dependency Mapping的缩写。意思就是帮你发现CI和CI之间关系的工具。很多用户的各种IT管理工具都可以自动发现网络、服务器和应用的配置项以及之间的关系，那么为什么还需要在购买一个新的发现工具呢？其实发现工具解决的真实发现工具不统一和发现数据不统一的问题，更重要的是它可以发现配置项之间的依赖和影响关系。对于一个数据中心来说，变更会经常发生，那么一套应用运行了一段时间之后，你很难准确的说出它都连接了那些其他相关的设备，很难理解它当前的部署状态。我们希望发现工具能帮我们更好的洞察当前IT基础架构的构成，应用对设备的依赖，底层IT服务对业务的影响。\n**其次：“它是如何工作的？” **\n它的工作原理和其他所有的管理软件也没什么太大的差异。基本上讲有两种技术：无代理发现和有代理发现；三种产品形式：纯粹无代理扫描方式、纯有代理方式和混合方式。无代理采集必须依赖被采集设备的开放协议，常用的采集协议有：snmp,wmi,telnet,ssh,jmx,http等。往往需要在被采集设备上配合一定的账号和权限。采集动作往往是定时、周期性或者触发式执行。扫描结果返回一个数据库中，准备向CMDB同步。\n再次：“它是CMDB必须的工具么？”\n对于下面几种情况我个人认为它是一个必的工具：1）数据中心用户，服务器和应用成百上千套，变更每周都会进行，新业务系统增长快。CMDB需要使用它来自动更新配置项信息。2）应用多是多层的复杂应用，CI之间依赖关系复杂，物理连接图已经不足够用来做影响分析，CMDB需要它来自动化维护配置自己的关联关系，通过它可以减少进70%的手工工作量。从国外的一些项目经验上来看，50%的CMDB用户并没有使用配置自动发现工具，他们使用的配置数据多是监控管理系统中已有的，CI间的关系靠手工维护。\n最后：“它是如何与CMDB同步的？”\n有些厂商的CMDB是从发现工具上起家的，所以他们本来就使用的一个库，没有同步问题。有些厂商的发现工具是整合的其他产品工具或者收购的，他们自己的同步就需要一定得数据模型了。通过数据模型来解决数据字段映射的关系，一般来讲CMDB中会有数据模型CDM，发现工具同步的时候就以该模型为准，把CI和关系经过一定的过滤条件同步到CMDB中。不同厂商的发现工具和CMDB如果需要同步的话，需要满足起码这样几点需要：CMDB必须有标准的数据模型来做数据映射；需要有某种数据集成和同步的工具来连接两个数据库；CMDB中需要具有强大的数据调和功能来处理发现工具带来的数据。\n",
    "ref": "/2009/07/15/cms-cmdb-and-discovery-tools/"
  },{
    "title": "Cloud Computing Infrastructure and Architecture Guide-From SUN",
    "date": "",
    "description": "",
    "body": "** » 下载本指南** （中文版）\n《云计算基础设施和体系架构指南》\n** » 下载本指南** （英文版）\n《Cloud Computing Infrastructure and Architecture Guide》\n» 更多 Sun 白皮书、指南、蓝图 (英文版)\n",
    "ref": "/2009/07/14/cloud-computing-infrastructure-and-architecture-guide-from-sun/"
  },{
    "title": "martinliu dot cn is back",
    "date": "",
    "description": "",
    "body": "After 2 crazy months, I finished the longest PoC. This is for CCB CMDB testing. We are fightting with CA,HP,IBM and Utrual Power. It has 3 rounds, took me almost 3 month to finish.\nToday, I finally got have a chance to do something for my blog. I finally move to a new hosting and attached martinliu.cn domain name on it. Wordpress was updated to 2.8.1 with new theme. I love this theme for three reasons: 1)自动全屏显示； 2)大气；3)自带弹性的调整options。Now the only concern is MySQL space is only 50 MB. As far as I can tell it could be enough for my 2years blog. So, keep posting and happy blog.\n",
    "ref": "/2009/07/13/martinliu-dot-cn-is-back/"
  },{
    "title": "MartinMark for July 7th",
    "date": "",
    "description": "",
    "body": "\n The Apache Tomcat 5.5 Servlet/JSP Container - Load Balancer HOW-TO  [原创] Apache + Tomcat + Load Balancing - ChinaUnix.net  Clustering and Load Balancing in Tomcat 5, Part 1 - O\u0026rsquo;Reilly Media  How to test web load balance  Fronting Tomcat with Apache or IIS - Best practices  The Apache Tomcat Connector - Webserver HowTo IIS HowTo I will try to implement this load balancer (Tomcat and Apache/IIS)\nSoftware LB is easyly to setup and use. I might use it for my future PoC or so.  ",
    "ref": "/2009/07/07/martinmark-for-july-7th/"
  },{
    "title": "Transformers-Revenge of the Fall-Theme Music",
    "date": "",
    "description": "",
    "body": "Enjoy the movie and music\n",
    "ref": "/2009/07/06/transformers-revenge-of-the-fall-theme-music/"
  },{
    "title": "ByteactHosting-free hosting",
    "date": "",
    "description": "",
    "body": "\nNow, I am here at ByteactHosting. My blog was moved into this free web hosting.\nFree Web Hosting Plan\n\n 800MB 1GB (1024MB) of webspace  30GB of monthly transfer  10 MySQL databases  10 Addon domains  10 Addon subdomains  10 Parked domains  POP E-mail account (catch-all)  Direct FTP access  PHP support  NO FORCED ADS! It is close to the last one I bought from http://www.paangood.com/otherhost.php.\n总的来说这是一个非常好用的免费主机，Wordpress的安装只需要点3次Next就完成了。后台管理中可以安装多种开源的程序，有blog、CMS、BBS、B2B、CRM等很多流行程序。目前基本上感觉和使用国内的付费主机没太大差别。  ",
    "ref": "/2009/07/04/byteacthosting-free-hosting/"
  },{
    "title": "CMDB实施的几种误区",
    "date": "",
    "description": "",
    "body": "上面是ITIL v3的定义，CMDB的定义和v2没有变化。可以看出CMDB是一个存储配置记录的数据库，非常多的用户一拍脑门“不就是一个数据库么！我们也可以自己开发一个的。”。这样的情况下，IT组织的不同部门都可能会各自立门户，开发自己的配置管理信息库；例如：资产管理、终端分发和管理、机房管理等等。数据重复、数据不一致、配置信息不对称；无法得到跨部门和系统的报告。所以V3提出了CMS系统，它是CMDB系统的下一代管理系统。CMS系统需要 具有对现有信息资料的兼容性，CMS的建立不能忘记过去；一定要集成已有配置信息。\n错误一：配置信息是一个独立的配置管理系统，由专人负责数据的更新和维护，手工的管理和维护所有数据。\n错误二：最配置管理就是要做的细，我要管理到机房中的每一根网线，CI的属性需要设计的非常多，越细致越好。\n错误三：我们自己有开发人员，我们有CMDB的需求，那就开始做吧，先看法着看看，不就是一个数据的增删改查么！！\n配置管理或者说CMDB的建设可以说是目前，国内ITIL用户共同的瓶颈。ITIL项目中实施最多的三个流程是：Incident Management、Problem Management 和 Change Management。已经实施完毕以上三个流程的用户问的最多的一个问题是：一个故障单、问题单或者变更单一定要和CI想关联么？在解决处理的时候寻找目标CI或者根源CI是必须的么？\n如果ITIL是一种公共语言的话，那么Incident Management、Problem Management 和 Change Management等所有流程都是句式或者时态。而CI则是主语或者宾语，您觉得没有主语或者缺少宾语的句子，会传递怎么的信息呢？\n",
    "ref": "/2009/07/04/cmdbe5ae9ee696bde79a84e587a0e7a78de8afafe58cba/"
  },{
    "title": "ITIL v3 术语表",
    "date": "",
    "description": "",
    "body": "\n回顾或者实施ITILv3时，可以去下载一下术语表，http://www.get-best-practice.co.uk/glossaries.aspx 以上网站有原版中英文和其他语言的文档。术语表适用于对ITIL有一定了解的人，是受过ITIL培训的人或者正在实施ITIL的人的案头参考读物之一。我桌上有中英文打印版各一份，拳不离手，曲不离口。另外ITIL实施切忌本本主义和教条主义，需要注重实效和对标准的遵从。\n",
    "ref": "/2009/07/04/itil-v3-e69cafe8afade8a1a8/"
  },{
    "title": "Some useful tools",
    "date": "",
    "description": "",
    "body": "I am just cleaning up my bookmarks. Some of them could not be deleted. I\u0026rsquo;d like to list here.\nThis is a netflow monitor tool, you can capture, graph and store data.\nFounded in 1992, the Distributed Management Task Force, Inc. (DMTF) is the industry organization leading the development of management standards and integration technology for enterprise and Internet environments.\nSocial Networking Meets Business, Concursive have CRM, online communitie, collaboration tools.\n",
    "ref": "/2009/07/04/some-useful-tools/"
  },{
    "title": "德克虏伯大炮VS清红衣大炮",
    "date": "",
    "description": "",
    "body": "\n德克虏伯大炮：特点射程远，能360度旋转，能把上下调整仰角，炮弹的辐射面积非常广，操作复杂，需要高技能的操作手。操作弹性大。安装部署需要时间长，对环境改造多。\n清红衣大炮：射程短，只能朝一个方向发射，炮弹的打击面基本固定，操作简单，对操作者技术要求低。操作弹性低。 部署配置工作少。\n在IT管理工具的选择中，您是选择克虏伯式的超级人间大炮，还是选功能操作简洁的红衣大炮？真是一个两难的选择啊！\n“德克虏伯大炮”好比商业厂商的One-Size-Fit-All的超级企业级管理套件。 “清红衣大炮”好比开源的专门工具利器。    用户必须自己认真思考需求，却对不建议的做法：\n 将“德克虏伯大炮”买回家后，发现功能太复杂，接着把它定制成，操作简单的“清红衣大炮”。李鸿章很支持“师夷长技以制夷”，同理购买国外复杂管理套件而不去学习其中的管理方式方法，反而拘泥于自己对概念简单的理解也是成问题的观念。 把“清红衣大炮”三下五除二部署在家后，发现功能限制太多，集成几乎没有，失望的埋怨开源社区，坐观其他人的开发和参与。开源其实赋予你了无限的对开源技术应用的弹性，唯一要求就是有能力参与和进入社区的开发。   ",
    "ref": "/2009/07/04/e5beb7e5858be8998fe4bcafe5a4a7e782aevse6b885e7baa2e8a1a3e5a4a7e782ae/"
  },{
    "title": "Tomcat压力测试-挺住200并发",
    "date": "",
    "description": "",
    "body": "最近在CCB的测试中有一项是住系统登陆页面的压力测试。我一直就很担心是否能通过压力测试，因为一个同事告诉我上次他的结果是80就不行了。总结一下，我这次成功的原因主要就是两个地方：\n1）设置Tomcat启动和最大内存使用都是1500MB\n2）修改server.xml中关于连接数等参数(回头贴出我的那些配置内容)\n我的服务器配置如下：\nDell 2950 1C4核，8GB内存，单块136GB硬盘，Windows2003系统，JDK1.6，Tomcat 5.5.21\n另外，我一直以为Loadrunner需要真实Lic文件才能用，没想到的是，我随便在网上搜了一个也能用，真是神奇啊！ 不过还是反对盗版哈哈:)\n",
    "ref": "/2009/07/04/tomcate58e8be58a9be6b58be8af95-e68cbae4bd8f200e5b9b6e58f91/"
  },{
    "title": "For tomcat benchmark testing",
    "date": "",
    "description": "",
    "body": "Tomcat Configuration 查看一下可以配置的参数设置JVM的参数Setting JVM Options for Tomcat\nEdit the /usr/locat/apache-tomcat/bin/catalina.sh file and add the JVM options to the JAVA_OPTS environment variable.JVM Option Value Description\n-Xmx 4g The maximum Java heap size.\n-Xms 4g The initial Java heap size.\n-Xmn 1g The size of young generation.\n-XX:+UseParallelGC – To use parallel garbage collection for scavenges.\n-XX:PermSize 50m The initial size of permanent generation.\n注释：上面两个4g的值，我没试过，我用8GB内存windows的机器1.5GB能启动，超过了Tomcat服务就启动不了了。\n配置Tomcat Connector Attributes\nEdit the /usr/locat/apache-tomcat/conf/server.xml file and add the attributes listed in Table 3 to the Connector element.\n下面是个例子供参考\nTomcat Configuration Attribute Value Description\nThe maximum number of request processing threads to be created by this connector, which therefore determines the maximum number of simultaneous requests that can be handled. If not specified, the default value for this attribute is 40. If an executor is associated with this connector, this attribute is ignored and the connector executes tasks using the executor rather than an internal thread pool.\nmaxThreads 3000\nThe maximum queue length for incoming connection requests when all\npossible request processing threads are in use. Any requests received when\nthe queue is full are refused. The default value is 10.\nacceptCount 2000\nThe number of request processing threads that are created when this connector\nis first started. The connector also verifies that it has the specified number of\nidle processing threads available. This attribute should be set to a value smaller\nthan that set for maxThreads. The default value is 4.\nminSpareThreads 500\nThe maximum number of unused request processing threads that are allowed\nto exist until the thread pool starts stopping the unnecessary threads. The\ndefault value is 50.\nmaxSpareThreads 2000\nSet to “true” if you want calls to request.getRemoteHost() to perform DNS\nlookups in order to return the actual host name of the remote client. Set to\nenableLookups false “false” to skip the DNS lookup and return the IP address in String form instead\n(thereby improving performance). By default, DNS lookups are enabled.\n上面的值比我实际使用的大，我的200并发测试通过了，硬件配置见前一帖。\n",
    "ref": "/2009/07/04/for-tomcat-benchmark-testing/"
  },{
    "title": "Free WordPress themes",
    "date": "",
    "description": "",
    "body": "\n这里的theme都比较干净和简洁\nhttp://www.nodethirtythree.com/\n很可惜的是blog.ubuntu.org.cn不能自己更换theme，所能使用和选择的是固定的一些，都不好看，幸亏还WordPress默认的皮肤还在，否则真是不确定我还能用这里的WordPress。总之还是感谢网上有这么好的免费资源。\n",
    "ref": "/2009/07/04/free-wordpress-themes/"
  },{
    "title": "Stop to build CMDB for your IT - CMS是怎样炼成的？",
    "date": "",
    "description": "",
    "body": "ITIL在国内的实施也有8年之久，就我看过和做过的项目中：service desk是最多实施的工具，它包括IM/PM；还有Change Management；用户们还可能会常常认为，Release Management可以和变更流程可以混在一起搞。服务台一般先上，有的变更流程先上，服务台的共同特点还有PM一般形同虚设。就我所见所闻的项目和用户来说，CMDB没有那家能建的好用的好；CMDB的建设的缺失似乎成了所有ITIL用户的通病，应该也是想重点突破的瓶颈。\nITIL v3发布后，CMDB成了CMS中的一个数据库；而且，CMS中包括不止像CMDB这样的配置信息数据库，其实任何保存配置信息的数据库都算在CMS系统内。既然是一个系统，所以它就不光包含数据还包含一套配套工具集合，通过这套工具，维护和使用配置信息。CMS为其他所有ITIL流程提供基础的配置信息。它的结构如下图所示：\n[caption id=\u0026ldquo;attachment_435\u0026rdquo; align=\u0026ldquo;alignnone\u0026rdquo; width=\u0026ldquo;658\u0026rdquo; caption=\u0026ldquo;配置管理系统\u0026rdquo;][/caption]\n如果说上面这幅图比较还是比较抽象的话，那么请见下图：\n[caption id=\u0026ldquo;attachment_436\u0026rdquo; align=\u0026ldquo;alignnone\u0026rdquo; width=\u0026ldquo;714\u0026rdquo; caption=\u0026ldquo;CMS is a set of tools based on all configuration data\u0026rdquo;][/caption]\n从上图中我们看到，CMS系统一共可以分为四层。上三层是核心CMDB数据库和相关配套工具，最低层Data层则是是所有配置信息的基础来源。从ITIL v3的角度来说，只建设一个集中的CMDB数据库来存储所有的CI信息是不够的，CMS系统中必须能够包含和处理所有企业已有的各个系统中的配置数据。换言之，CMDB建设的局限性在于，它只是配置信息数据化，或者说电子化的第一步。\n当前依然有很多企业雄心勃勃的上马CMDB项目，不过切记在规划时，一定先好好阅读一下ITIL v3中和CMS相关的内容，适当调整项目的目标和预期总是好的，也可以规避一些项目风险。\nCMDB不只是一个数据库那么简单，更不可能在服务台的数据库中建立几张表就可以搞定。从企业IT管理的全局出发，按照ITIL v3的规范，建设CMS应该是所有ITIL项目的当务之急。CMS系统决不能遗忘过去，必须有效整个现有的各个配置信息数据源，无论其以何种形式存在。它必须是一个开放的平台，能过最大限度的和其他任何配置信息的消费者（ITIL流程，以及任何需要获取配置信息的任何应用）整合， \n以上的一些是我对CMS建设的一些认识。如果要落地到项目上还不许经过一个痛苦的过程，那就是产品选型。选项的过程中可以注重一下几点：\n\n 可视化：配置项和之间的关系按拓扑形式展现  标准化：软件、硬件配置项都有完整标准的CTI信息  归一化：与现有各种配置管理系统核心共存同时CMS保持一份完整的户口记录，任何CI都有ID  集成化：CMS中的数据以图形或者裸数据等形式供其他相关消费者流程或者人员使用  联邦化：CMS核心数据库中不保存动态变化的配置信息（DB的最大连接数，网络设备所使用的syslog服务器地址），这些信息通过联邦管理让用户从其他相关的工具系统中查看到最新的数据。 最近可能还会接触一下CMDB的项目，其他经验总结待续。  ",
    "ref": "/2009/03/01/stop-to-build-cmdb-for-your-it/"
  },{
    "title": "[ZT]辽宁海城大悲寺僧团实录",
    "date": "",
    "description": "",
    "body": "\n这是一个令人赞叹的僧团\n在默默中延续佛陀的慧命 天下僧人的心愿\n在他们身上逐步实现\n此片献给大家使我们大家进一步了解修行的道路和它深远的意义 \u0026mdash;-引自视频中\n",
    "ref": "/2009/02/14/zte8bebde5ae81e6b5b7e59f8ee5a4a7e682b2e5afbae583a7e59ba2e5ae9ee5bd95/"
  },{
    "title": "[網播] Born to MISrepresent 第二集：當 OpenNMS 遇上 SFLC ，催生了 Moglen Ravicher LLC",
    "date": "",
    "description": "",
    "body": "（原文於 2008-04-08 發表於 http://blog.roodo.com/ystuan/archives/5830995.html）\n這個音檔的授權是姓名標示-非商業性-相同方式分享 2.5 台灣，跟我的網誌一樣。\n下載ogg格式：Born_to_MISrepresent_EP2.ogg 下載mp3格式：Born_to_MISrepresent_EP2.mp3 前往存放在 Archive.org 上的頁面：Born to MISrepresent EP2，有更多資訊以及格式。\n內容摘要：\nOpenNMS 1.3.11 版發佈，並宣佈與 Hyperic 就雙方的產品進行合作。這項合作的推手是一個雙方的共同客戶。Hyperic 的 agent 預料將可和擁有強大平台但是拙於 agent (agent-less)的 OpenNMS 形成良好互補。（自 1.3.10 版就開始跟 Hyperic Agent進行整合，最近 OpenNMS 版本號已跳升至 1.5.90 ） Tarus 的 blog 有更多細節：The Year of Integration\nHyperic 跟 OpenNMS 的初步整合，可線上收看 Integrating Hyperic HQ and OpenNMS（瀏覽器需支援 flash 格式播放）\n當 OpenNMS 遇上 SFLC ：前一陣子 Tarus 跑去 Ask Slashdot ，嚷嚷說 Cittio Watchtower 使用 OpenNMS 的程式碼當然可以，但是使用的方式違反了（程式碼採用的）GPL授權。\n想也知道，跑去 Slashdot 一定會引來關注，他也尋求軟體自由法律中心（Software Freedom Law Center，SFLC）的協助。但是，SFLC服務對象僅限於非營利機構，結果呢，SFLC決定以成立一間新的律師事務所(Moglen Ravicher LLC)的方式，來服務支持自由軟體的營利機構， OpenNMS Group 因此成了 Moglen Ravicher LLC 的第一個客戶。\n喔，不用猜， SFLC 的新聞稿直接告訴大家，兩塊招牌底下都是同一群律師，事務所的所有利潤會回饋給 SFLC 。（嗯，其實我們也可以說 OpenNMS 有兩種，一種是 opennms.org - 社群，一種則是 opennms.com - 主要參與者所開的公司 OpenNMS Group。）\n筆者已經在 FLOSS Weekly 聽過 Eben Moglen 談 GPL 3.0 ，這次為多瞭解另一位大咖 Dan Ravicher （其實只是想搞清楚他的姓怎麼唸\u0026hellip;\u0026hellip;），找到了 Dan 談 GPL 3, Patents and Other Current Issues ，都很棒，推薦給大家，尤其是後者，其實 Dan 還回顧了 GPL 的誕生，解釋了 RHEL 的 subscription model 為何不違反 GPL 但又可以約束客戶（超意外收穫！解答了筆者幾百年前的疑惑）\n照例 Tarus 也在他的 blog 提到整件事：OpenNMS, Eben Moglen and Cittio\n",
    "ref": "/2009/02/04/e7b6b2e692ad-born-to-misrepresent-e7acace4ba8ce99b86efbc9ae795b6-opennms-e98187e4b88a-sflc-efbc8ce582ace7949fe4ba86-moglen-ravicher-llc/"
  },{
    "title": "It just looks like a Mac desktop",
    "date": "",
    "description": "",
    "body": "We all knows Mac OS X looks very nice, and works nice also. But, Mac can not be only system for you to use. Most of us are using Intel PC desktops and laptops. You can\u0026rsquo;t have your cake and eat it too. Chinese saying says \u0026ldquo;鱼和熊掌不可得兼\u0026rdquo; . So, you might need a new Mac skin for your desktop, no matter MS Windows or Linux OS. I\u0026rsquo;d like share two tips, you can make a Mac desktop in minutes.\n**For Windows: **FlyakiteOSX is a all-in-one package. It much more easier then making a Mac-buntu. Does it slow down you windows system? Of course, yes. it\u0026rsquo;s just a little bit and acceptable for me.\nFor Gnome Linux:\nThere is a open source prject on the SourceForge.net: http://sourceforge.net/projects/mac4lin You need download the package and un-tar it. A pdf document will walk you through every settings. I made my Mac-buntu just in 20 minutes. I do not like \u0026lsquo;global meun\u0026rsquo; and widget, so I ingored them. \nMy laptop is a dual boot Dell D630; with MS Windows Xp for work and Ubuntu for fun. Now, them all looks like Mac OS X Leopard. Check it out.\nhttp://picasaweb.google.com/liuzh66/ItJustLooksLikeMac\n",
    "ref": "/2009/02/02/it-just-looks-like-a-mac-desktop/"
  },{
    "title": "My firecrackers for beginning of the year of ox 2009",
    "date": "",
    "description": "",
    "body": "\n爆竹声声辞旧岁\n火树银花迎金牛 \nIn childhood, I was playing firecrackers everyday in the Spring Festival. The new year\u0026rsquo;s eve is the only chance for me to lit it again, I felt I like a 10 years child.\n",
    "ref": "/2009/01/27/my-firecrackers-for-beginning-of-the-year-of-ox-2009/"
  },{
    "title": "Welcome to The Year of the Ox",
    "date": "",
    "description": "",
    "body": "It\u0026rsquo;s Chinese New Year\u0026rsquo;s Eve right now. The Chinese lunar new year came, it\u0026rsquo;s \u0026ldquo;The Year of the Ox\u0026rdquo;. I think you may like the above cute little ox and fortune; I hope you all the best. There are some pics I took tonight.\n\nhttp://picasaweb.google.com/liuzh66/ChineseNewYearSEve\n",
    "ref": "/2009/01/25/welcome-to-the-year-of-the-ox/"
  },{
    "title": "gOS looks green",
    "date": "",
    "description": "",
    "body": "\nToday I installed gOS on my laptop; openSuSE did great work for me 3 years. I\u0026rsquo;d like to play some new things. So, check my new desktop out.\nhttp://picasaweb.google.com/liuzh66/GOS\nIf you go its wetsite http://thinkgos.com/, you will see it talks lots of cloud. It\u0026rsquo;s interesting, but it is not the reson i chose it. Ubuntu 8.04 is inside gOS. So, it time to learn a new linux system. I neve use a Derbin based system, I\u0026rsquo;m not sure it could run for me how long.\n",
    "ref": "/2009/01/24/gos-looks-green/"
  },{
    "title": "从云计算联想到第一代电脑系统",
    "date": "",
    "description": "",
    "body": "记得以前看过一本描写Bill Gets的书，他上中学的时候，在河滨中心通过一个远程终端，连接到某大学的计算机系统，输入程序代码，并且得到代码在远程电脑系统中的输出，输出好像是在屏幕上出现的，或从打印机上输出的。我基本上忘了那电脑系统的名称，不过它的特点基本上是这样的：当时电脑系统很少，可能全世界上也没有多少台功能全面的电脑；用户使用的特别像是一种计算服务，由于终端设备根本没有技术能力，当时还没有个人电脑；接入方式根本不是tcp/ip更不是internet，当时还没internet。在学习了云计算的一些概念之后，我迷惑了，这个时尚的技术，怎么越看越眼熟啊。\nIBM的主机系统可谓是当今电脑世界的恐龙化石级产品，他是一个活化石基本的技术，在经历了开放系统时代之后，我们即将进入云计算时代，我总感觉云计算是一种技术路线的复古。主机系统和第一代电脑系统最相似，区别是可以通过TCP/ip网络，和开放系统通信了。最为一种新兴起的技术，我试图follow http://www.johnmwillis.com/来学习云计算，遗憾的是从08年初以来并没有仔细听他所有的colud cafe；这个老兄在把blog改名为IT Management and Cloud Blog，真可谓是一高产的blogger，这哥们每天能发四五个post，强啊。最近找时间听了一段cloud cafe，我发现到目前为止还没有一个能让大多数人都认同的云计算的概念，基本上对云计算的感念方面有两道三种说法。可以看看 http://en.wikipedia.org/wiki/Cloud_computing 参考这上面的说法也只能有一个模糊的感觉。\n看看电脑技术打发展历程：最早的电脑系统，主机系统，开放系统，群集，网格，云计算。前一段时间看过一个非常抢眼的标题“以后世界上将只有5台电脑”。SaaS是一个比较火热的和云计算相关的技术，我认为它像是在web2.0发展到一定阶段后Web应用的一个发展，这方面的强者为salesforce之流。Google和Salesforce不同的是，Google提供网上office套件的同时，还开发他的平台，并提供与之配套的 SDK。Amazon不提供应用也没有SDK，他只提供平台，平台上包括基本的计算和存储服务。Google和Amazon说起来算是基础架构作为一种服务。抛开云计算本身不谈，用户使用和访问的方式并没有发生变化，在任何一个web浏览器存在的地方都能使用或者管理到云计算。客户端的计算和存储能力再次此退化到零，这不能说不是计算机技术发展的返祖现象吧！哈哈～～我也快糊涂了！\n",
    "ref": "/2009/01/19/e4bb8ee4ba91e8aea1e7ae97e88194e683b3e588b0e7acace4b880e4bba3e794b5e88491e7b3bbe7bb9f/"
  },{
    "title": "opennms 1.6.1-1 quick start guide",
    "date": "",
    "description": "",
    "body": "本安装手册为纯命令版，如果有什么疑问清参考官方安装手册，或给本贴留言。\n[install yum on your Linux box]\n选择任意Linux系统，安装上yum工具，在命令行测试 yum -v\n[testing internet connection with those two URL]\n测试是否能上网，用浏览器分别打开这两个网址\n\n http://www.martinliu.cn/2007/12/13/opennms-yum-install/  http://yum.opennms.org/repofiles/ 先别关闭这两个网页。\n[Install opennms 开始安装:\n yum install yum-fastestmirror  rpm -Uvh http://yum.opennms.org/repofiles/opennms-repo-snapshot-rhel4.noarch.rpm  yum list opennms  yum install opennms [ post-install and config] 开始配置：\n export OPENNMS_HOME=/opt/opennms  vi /var/lib/pgsql/data/pg_hba.conf\n1. 注释掉其中所有可用的行，加入下面三行\nlocal all all trust\nhost all all 127.0.0.1/32 trust\nhost all all ::1/128 trust  /sbin/service postgresql restart  /usr/java/jdk1.5.0_15/bin/java -version  $OPENNMS_HOME/bin/runjava -S /usr/java/jdk1.5.0_15/bin/java  $OPENNMS_HOME/bin/install -disU -l /usr/lib/jni:/usr/lib [ startup opennms and login ]启动登录：\n /etc/init.d/opennms start  http://localhost:8980/opennms  username and password are admin/admin  click Admin / Add Interface, input a ipaddress and press Add button OK， I have get oepnnms 1.6.1-1 installed on my home pc, I hope you good luck and have fun.  ",
    "ref": "/2009/01/11/161-1-opennms-quick-install-guide/"
  },{
    "title": "Top 25 OSS Projects on Jan 2009",
    "date": "",
    "description": "",
    "body": "This list is from SourceForge.net. You may have the question: How do we adapt open source? My answer might be you just should use them as much as you can. The world is facing economic crisis, you have to saving your budget. How do you deal with that? It\u0026rsquo;s time to think about OSS now.\n1. Shine J2EE Framework 开发框架\nhttp://j2sos.org/\nhttp://sourceforge.net/projects/shine-app\nShine is a Java-J2EE Application Framework/JWMS(Java Web Model\nService)Framework/MVC Framework/Service Oriented Framework. Shine Includes Ajax Lib/Server API/J2EE Architecture. Shine Supported JSF/Spring/AspectJ/Struts/Hibernate/ZK-Ajax/\u0026hellip; www.J2SOS.org\n7-Zip 解压缩软件\nhttp://sourceforge.net/projects/sevenzip\n7-Zip is a file archiver with the high compression ratio. The program\nsupports 7z, ZIP, CAB, RAR, ARJ, LZH, CHM, GZIP, BZIP2, Z, TAR, CPIO, ISO,MSI, WIM, NSIS, RPM and DEB formats.\n3. ADempiere ERP Business Suite 企业资源管理方案\nhttp://sourceforge.net/projects/adempiere\nADempiere Business Suite ERP/CRM/MFG/SCM/POS done the Bazaar way in an open and unabated fashion. Focus is on the Community that includes Subject Matter Specialists, Implementors and End-Users. We are a community fork of Compiere.\n4. Notepad++ 文本编辑器，我用了一次就把其他类似的都卸载了\nhttp://sourceforge.net/projects/notepad-plus\nNotepad++ is a generic source code editor (it tries to be anyway) and\nNotepad replacement written in c++ with win32 API. The aim of Notepad++ is to offer a slim and efficient binary with a totally customizable GUI.\n5. ffdshow tryouts 多媒体解码\nhttp://sourceforge.net/projects/ffdshow-tryout\nffdshow is a DirectShow filter and VFW codec for many audio and video\nformats, such as DivX, Xvid and H.264. Over 70 bugs have been fixed, codecs have been updated, and support for a few new formats has been added in the tryouts. Vista is now supported.\n6. DVDStyler 播放器\nhttp://sourceforge.net/projects/dvdstyler\nDVDStyler is a cross-platform DVD authoring application that makes possible for video enthusiasts to create professional-looking DVDs.\n7. PostBooks ERP, accounting, CRM by xTuple 企业应用套件\nhttp://sourceforge.net/projects/postbooks\nFree open source ERP, accounting, CRM package for small to midsized\nbusinesses. ERP client runs on Linux, Mac, and Windows (built with open\nsource Qt framework). Business logic resides in PostgreSQL database.\nInternational ERP, accounting, and CRM tools.\n8. Zenoss Core - Enterprise IT Monitoring 企业级IT监控\nhttp://sourceforge.net/projects/zenoss\nZenoss Core is an enterprise network and systems management application\nwritten in Python/Zope. Zenoss provides an integrated product for\nmonitoring availability, performance, events and configuration across\nlayers and across platforms.\n9. Azureus BT下载客户端\nhttp://sourceforge.net/projects/azureus\nAzureus: Vuze is a powerful, full-featured, cross-platform bittorrent client and open content platform.\n10. ZK - Simply Ajax and Mobile\nhttp://sourceforge.net/projects/zk1\nZK is Ajax Java framework without JavaScript. With direct RIA, 200+ Ajax\ncomponents and markup languages, developing Ajax/RIA as simple as desktop apps and HTML/XUL pages. Support JSF/JSP/JavaEE/Hibernate/.., and Ajax script in Java/Ruby/Groovy/Python/..\n11. phpMyAdmin 数据库管理工具\nhttp://sourceforge.net/projects/phpmyadmin\nphpMyAdmin is a tool written in PHP intended to handle the administration\nof MySQL over the Web. Currently it can create and drop databases,\ncreate/drop/alter tables, delete/edit/add fields, execute any SQL\nstatement, manage keys on fields.\n12. MinGW - Minimalist GNU for Windows 最小的Windows版GNU\nhttp://sourceforge.net/projects/mingw\nMinGW: A native Windows port of the GNU Compiler Collection (GCC), with\nfreely distributable import libraries and header files for building native\nWindows applications; includes extensions to the MSVC runtime to support\nC99 functionality.\n13. Ares Galaxy p2p客户端\nhttp://sourceforge.net/projects/aresgalaxy\nFilesharing-Bittorrent p2p client connected to TCP supernode/leaf network\nand UDP DHT network. Ares features a built-in directshow media player, a\npowerful library manager, shoutcast radio support and can be used to host\np2p Chatrooms.\n14. SMPlayer 多媒体播放器\nhttp://sourceforge.net/projects/smplayer\nSMPlayer is a complete front-end for MPlayer, from basic features like\nplaying videos, DVDs, VCDs to more advanced features like support for\nMPlayer filters, edl lists, and more.\n15. PhpGedView 家谱管理\nhttp://sourceforge.net/projects/phpgedview\nPhpGedView is a revolutionary genealogy program which allows you to view and edit your genealogy on your website. It has full privacy functions, can import from GEDCOM files, and supports multimedia. It also simplifies\nfamily collaboration.\n16. FileZilla 多协议文件下载客户端\nhttp://sourceforge.net/projects/filezilla\nFileZilla is a cross-platform graphical FTP, FTPS and SFTP client a lot of\nfeatures, supporting Windows, Linux, Mac OS X and more. FileZilla Server is\na reliable FTP server for Windows.\n17. Hyperic HQ Enterprise Monitoring 系统监控\nhttp://sourceforge.net/projects/hyperic-hq\nEnterprise monitoring and management for web apps on Linux, Mac, Unix \u0026amp;\nWindows. Auto-discovers 70+ technologies incl. hardware, networks,\nvirtualization, and apps. Includes: monitoring, alerts, remote diagnostics,\nand control actions from web console.\n18. Audacity 音频编辑器\nhttp://sourceforge.net/projects/audacity\nA fast multi-track audio editor and recorder for Linux, BSD, Mac OS, and\nWindows. Supports WAV, AIFF, Ogg, and MP3 formats.Features include envelope editing, mixing, built-in effects and plug-ins, all with unlimited undo.\n19. OrangeHRM - Human Resource Management 人力资源管理\nhttp://sourceforge.net/projects/orangehrm\nOrangeHRM is an Open Source Human Resource Management System that covers Personnel Information Management, Employee Self Service, Leave, Time \u0026amp; Attendance, Benefits, and Recruitment. Tags: HRM, HRMS, HCM, HRIS, EHRMS, Human Capital Management\n20. FreeNAS 最简单易行的NAS设备\nhttp://sourceforge.net/projects/freenas\nNAS (Network Attached Storage) server supporting: CIFS/SMB, FTP, NFS,\nRSYNC, SSH, AFP, Unison, UPnP, Webserver, iSCSI protocols, local and MS AD authentication, SoftRAID (JBOD,0,1,5), disk encryption, S.M.A.R.T, WebGUI. Requires only 32MB on DOM.\n21. Maxima \u0026ndash; GPL CAS based on DOE-MACSYMA 数学工具\nhttp://sourceforge.net/projects/maxima\nMaxima is a fairly complete computer algebra system written in lisp with an\nemphasis on symbolic computation. It is based on DOE-MACSYMA and licensed under the GPL. Its abilities include symbolic integration, 3D plotting, and an ODE solver.\n22. DeSmuME 任天堂模拟器\nhttp://sourceforge.net/projects/desmume\nDeSmuME is a Nintendo DS emulator.\n23. Openbravo ERP 企业资源计划管理应用\nhttp://sourceforge.net/projects/openbravo\nOpenbravo ERP is a Web based ERP for SME, built on proven MVC \u0026amp; MDD\nframework that facilitate its customization. Already in production,\nOpenbravo ERP encompasses a broad range of functionalities such as finance, supply chain, manufacturing \u0026amp; much more\n24. FreeMind 构思管理工具\nhttp://sourceforge.net/projects/freemind\nA mind mapper, and at the same time an easy-to-operate hierarchical editor with strong emphasis on folding. These two are not really two different things, just two different descriptions of a single application. Often used for knowledge and content mgmt.\n25. aTunes 音乐播放和管理器\nhttp://sourceforge.net/projects/atunes\naTunes is a powerful, full-featured, cross-platform player and manager,\nwith audio cd rip frontend. Currently supported formats are mp3, ogg, wav,\nwma, flac, mp4, ape, mpc, mac, radio streaming and podcasts.\nOSS应用的常见现象：\n1）在某电信构思的招标的答疑过程中，我被问道：你们的系统能支持Linux么？我回答：能支持RHEL 4，5 , SLES. 哦，那你们就说说能支持通用UNIX系统了，我们需要能运行在RHEL，或者RedFlag上。\n\u0026raquo;越来越多的用户考虑把IT管理系统安装部署到Linux平台上，并且认为这就是一种UNIX系统，他们以前在商业UNIX系统上的管理也使用经验都能适用于Linux系统。\n2）一次用户告诉我他们实在是不能使用Tomcat做为中间件，来运行我们的应用系统，他们必须用BEA。因为他们只有BEA的中间件的管理员，没有Tomcat的管理员。如果上报一个带有Tomcat的系统的话，安全部门不会审批的，因为安全认证还没通过，Tomcat从安全部门的角度讲安全性低。\n\u0026raquo;把BEA的管理员不当Tomcat的管理员是人员任用的严谨还是浪费？为什么商业应用比开源应用安全？其实用户自己人也说，这都是制度，他们也无能为力，IT变革势力似乎种弱于工作惯性。\n对于中小企业来说，应用某个开源技术难度应该比大企业要小很多。不过大型企业在很多方面也逐渐有，主动应用开源技术的趋势。这在我以前的post中也提到过。从人才的角度和当今的形势看，社会上的linux高手，开源大师其实是越来越多，在经济不景气的当下，开源技术的应用从任何角度上看，可能企业都应该放它到议事日程上了。  ",
    "ref": "/2009/01/07/top-25-oss-projects-on-06-jan-2009/"
  },{
    "title": "Training tips",
    "date": "",
    "description": "",
    "body": "上周一周都在广州，为中国最大的直销企业Amway做“Remedy Administration Part 2\u0026quot;的培训，这个培训是我今年第5次做；本周用户还给公司发来了感谢信，可见此次培训也是本年效果很好的一次。其实本月对我来说是一个培训月，第一周在新加坡接受一产品培训“BMC Configuration Automation For Network”；第二周在北京给‘中国人寿’做ITIL v3 Foundation的企业内训；第三周在广州，就是这个Remedy的培训。\nITIL v3培训和Remedy培训是两个不同类型的培训，一个是最好实践IT管理方法论的培训；另外一个是Remedy系统管理和开发的课程。一个注重理论的讲解，另外一个是注重实际操作的介绍。不过从讲师的角度来说，培训的准备和整个过程的控制都是殊途同归的。\n**准备篇\n**对整课程内容的整体把握是至关重要的，必须对每一个module的内容谙熟于胸，这样才能控制整个培训课程的节奏，才能对时间做到从容地分配。特别是4～5天的培训，把所有的课程从头到尾贯彻为一个整体，不失课程的整体性，让学员有整体感，不觉得你教的内容没有逻辑、琐碎是非常重要的。所以需要在准备课程的时候就想好，每个module之间的衔接方式，要准备好review的问题，从这些问题中总结上一个module，平滑的过度到下一个module，增加课程内容直接的衔接，可以提高学员对内容的整体理解和掌握。\n\n**领导篇\n**特别是做企业内训，企业方的领导如果能至开幕词那是最好不过了，他够让学员再次明确培训目标和培训的纪律等，给学员一定的学习压力，能是整个课程进行的有利保证。总的来说领导在此时应该帮忙唱一出黑脸，下面讲师讲的红脸就可以开始演出了。\n**教室篇\n确认教室中的投影仪和其他设施都就绪。对于需要上机操作的培训来说，最好每一个都有一台电脑，电脑的硬件和软件配置都最好相同。确认硬件配置足够能跑虚拟机环境，至少2GB内存以上。虚拟机软件和培训用虚拟环境的部署是比较费时的一个工作，对于15个学员的课堂，至少需要半天时间准备。对于企业来讲，有条件最好不好在自己的办公室进行，应该到一个远离办公场所的环境进行；宾馆会议室、城外的培训中心或者度假村都是非常好的选择。\n实例篇\n对于ITIL课程的讲解来说实例的引用是至关重要的，实例可以是以前的项目经验，工具的经验，一个社会现象，甚至是一个小的故事或者笑话都可以。对于这种外国人总结的理论，人们初次学习就像是“外国人听京剧”一样。语言的gap是客观存在的，很难在短短几小时内，把别人总结了几年甚至十几年的经验给讲明白。客观的讲：每个讲师都只是演绎了一个自己的版本，为了保证这个版本的正确性，一定要阅读原版ITIL v3的出版物，把其中的实例最好能联系到中国国情，中国特色的例子。例如 ：需要讲明白KPI（Key performance indicator ）和 ** CSF（Critical Success Factors）的区别，我引用了三鹿奶粉事件的案例，蛋白质含量是一个KPI，如果只关注这个指标，而生产出了对BB有害的奶粉了，那么这种质量管理是很可怕的。对于IT管理来说也一样，某个流程没有KPI是不行的，然而没有CFS那可是万万不行的，process owner或者IT管理经理需要看到流程的CSF中的至少一项或多项得到实现和落实，需要两手抓，两种指标都合格。在Remedy培训的课程中，我改变上来就对系统的over view介绍，而是从一个HelloRemedy程序入手，保证所有人在5分钟之内都开发出了一个具有增删改查四种操作的应用，学员对Remedy的开发流程一下子就有了了解，和以前的编程经验一下就联系起来了，对课程中lab的兴趣一下就提高了一大截。\n**辅助文档篇\n**一定要高估你的学员的学习能力，大多数人都是勤奋好学的，特别是看上去相对年轻的学员。课堂的内容往往不能满足他们一周的求知欲。对于ITIL v3的培训，可以提供给学员最新的英文和中文的ITIL术语表各一份，我还给学员提供了ITIL v3 Quick Reference Guide，这些内容可以帮助对课本内容学习和认证考试的准备。对Remedy的培训，我提供了Remedy Action Request System 7.1最新的所有产品文档，release notes，install guide等等。能更多提供相关的文档是充实课程内容的一个辅助方式。\n**课堂管理篇\n**签到表的管理也是很重要的，一般需要让学员知道，最后的结果会发给他们的HR。课堂时间的管理主要是根据课程内容的进行来自由安排，在每一个Break和Lab的时候都需要用最醒目的方式，告知开始和结束的时间。我的最佳实践是，电脑接上投影之后，使用屏幕扩展显示的方式工作，在ppt的演示配置中设置，把演示内容投影到第二个显示设备上。这样你就有两个可以工作的桌面，两个独立的桌面，在投影仪显示的那个桌面上，用白底黑字醒目的提示break或者lab的其实时间。原本的桌面你还可以上网或者备课用。\n工具技巧篇\n基于上一个技巧，还需要强调的是：电脑接上投影之后，才可以在桌面的显示属性的设置中看到第二个显示器，并且在这时候才能启用投影作为第二个显示器，把桌面扩展到投影上。如果显卡支持的话，一般在投影上显示的分辨率还是可以调节的，这就避免了桌面切换和桌面与投影支持分辨率不匹配的麻烦。在得到一个扩展桌面之后，投影会显示一个你空白桌面，背景图片和你的本机相同。这样在打开PPT之后，你在放映设置的菜单里就能看到相关对屏幕设置的选项；重要的是两个选项：1）投影的第二个显示器；2）显示演示者试图。第二个技巧是我以前的Manager教给我的，这个演示者视图是一个和ppt内容不同的视图，如图所示。我觉得有两个好处，一是在这个视图上有计时器，能知道你讲了多长时间，二是能看到ppt的注释部分。另外一个工具就是带激光的翻页器。它使你能够站在任何一个你觉得舒服的地方讲解，试着走到学员中间去讲解，是一个不错的方式，这样能让学员听的更清楚，而且也能让你容易融入到学员中。如果你也想使用这个工具的话，记得在电脑包中记得带一个没有拆封的备用电池。我的翻页器，如果使用激光指示过多的话比较费电，所以我一般都多带一节电池。\n课程考核篇\n中国人都比较重视考试，考试的压力能很好的驱动学员的学习。在上两个培训中都有考核的部分，一个是ITIL V3的官方认证考试；另一个是考核是我设计的。为了配合Amway的培训考核需求需要，由于这个培训是不提供试卷考试的，我就设计了一个对Lab结果的评估作为考试内容。所以学员在最后一天把lab的结果导出成一个文件中交给我，我从课程的几个方面来评估他们的结果，给出一个具体的分数。\n反馈篇\n在课程进行的过程中，可以向学员，特别是用户方培训的负责人征求反馈意见，及时了解学员的接受程度和期望。通过这些反馈信息，对后面的课程进行方式和内容做合理的调整。从而保证最终学员和用户对课程的满意。对于讲师来说，课程各个内容的质量可以看做是KPI，而用户的反馈和最终认可就可以看做是CSF了。说白了作为讲师而言，咱不能让人觉得白花了钱。\n以上是我最近的一些培训经验总结，如果您也有类似经验和经历，欢迎交流和分享。\n",
    "ref": "/2008/12/27/training-tips/"
  },{
    "title": "ITIL V3 Traininig For China Life",
    "date": "",
    "description": "",
    "body": "上周给“中国人寿”做了ITIL V3 Foundation Training， 这是一个定制的企业内训，包括3天的理论学习，一天的‘BSM机场模拟沙盘演练’，最后一天进行ITIL V3 Foundation 认证考试。总的来说培训的效果还是非常不错的，学员基本上都能够理解和掌握ITIL v3的基本理论；在随堂的模拟考试后，能够针对一些题和我做非常深入的讨论。BSM机场模拟沙盘演练对于这群基本上比较年轻的学员来说成了一个非常热烈的培训环节，培训教室温度和气氛都比较热，一轮游戏跑下来以后，有些人就已经是满脸通红了；可见沟通也是一件力气活 :) 从学员们填写的反馈表的结果显示，他们对我的平均满意度是 4.35；呵呵这证明经过多日来的备课准备和以前的项目积累还是比较有效的，相信下次能够比这做的更好。\n\n那么：什么人是需要参加ITIL V3培训的？我觉得IT部门的所有相关人员，都是有必要参加ITIL v3的基础培训，部分流程核心人员和管理人员需要继续参加更高级的培训。除非你认为：不需要应用ITIL作为IT服务管理的理论，而是应用的其他方法论总之ITIL作为当今的“good practice”，通常它还是非常推荐一种武装思想的必备武器。\nITIL培训还应该是整个实施过程中的一部不可缺少的部分，不同规格和内容的培训需要在不同阶段提交给组织的各个层面。有时候一些组织结构或者管理方法的调整和改进，一方面需要高层领导的大力关注和重视；更重要的是保证这个改进和改革的步伐能持续不断的推进下去。\n关于ITIL理论的持续性学习，其实企业内部也可以自己组织，可以对当前运作的或即将实施的特定的流程，进行回顾。主要是把定制和客户化之后的流程、角色、PKI，CFI等概念和涉及的流程工作说明做进一步深化。培训的组织可以是不举一个的，process owner应该和service manager一起运作和制定这些培训，确保企业内相关流程的有效性和效率。\n[poll id=\u0026ldquo;8\u0026rdquo;]\n相信企业运用了更多的ITIL之后，还可以总结出更多自己的经验。初级阶段应该是缓慢上升的过程，当ITSM达到一定的成熟度后，在应用其他未实施流程，应该会更快。 今天还发现了一个不错的ITIL Blog ，分享一下 http://itservicemngmt.blogspot.com/\n",
    "ref": "/2008/12/14/itil-v3-traininig-for-china-life/"
  },{
    "title": "[项目更新] OCS Inventory NG 1.02 RC3 available and GLPI 0.71.2 available",
    "date": "",
    "description": "",
    "body": "如果你了解OCS Inventory NG 的话，您可能会发现这个问题，在家里用adsl上网，可能访问不到这个项目的网站，所以要想下载这个项目的软件，可以去sorceforge.net下载。\n10/28/2008 OCS Inventory NG Server 1.02 RC3 发布了Patch1，Patch1主要是修复了一些数据库创建和更新的问题，具体的内容如下所示：\nIn the database creation/update process launched through Administration Console (install.php), défault settings for cache and download directories are missing.\nAlso, default values in dynamic group computation are not set correctly. So dynamic group of computers are not updated correctly in Communication Server.\nWe've also included Remi patch in install.php to avoid overriding database username and password if you've changed them. Thanks Remi. \nOCS Inventory NG在sorceForge的下载网址 http://sourceforge.net/projects/ocsinventory/\n**15 September 2008 GLPI 0.71.2 发布 **\n这也是一个bug修复的版本，没有新增什么功能。修复的问题如下所示。\n#1094 Auth Method Change if old one does not exists #1109 Clean update for end_warranty_buy on search system #1110 OEM Computer selection problem on licenses #1111 Keep reminder and bookmark when author is deleted #1112 Bookmark creation right problem #1113 Mail formatting #1114 Clean log on cartridge / consumable #1115 logout with noAuto for auto logged users #1119 Mailgate followup import problem due to author check #1120 Cartridge restore bug #1121 Clean Ignore process in software dictionnary #1122 Correct stats computation #1131 Search engine problem for plugin field which need group by #1133 Bug on database connection error\n\n\n\n\n ",
    "ref": "/2008/11/27/ocs-inventory-ng-102-rc3-available-and-glpi-0712-available/"
  },{
    "title": "[项目更新] OTRS project news update",
    "date": "",
    "description": "",
    "body": "\n当OTRS遇到OpenNMS **OTRS meets openNMS! **OTRS和OpenNMS发布了新的集成手册 http://www.opennms.org/index.php/OTRS_Integration 这个Web Service的接口应该能做方便的集成了，没有试过，总之OpenNMS+OTRS应该是不错的组合，黄金搭档送给你，到~~\n**The SIRIOS 2.2 modules for OTRS 2.3 are released **SIRIOS 2.2模块发布了。我一直以为SIROS是非开源的项目，今天才知道它也是开源的哦，有空试试看。这个是专门为安全管理定制的，主要是去管理企业的安全事件。\n自从2008-08-05 **OTRS 2.3.1 (Bora Bora) **发布之后，又发布了两个版本，2.3.2 和 2.3.3，这两个版本都是2.3.1的bug修复版，功能上没有增加。\nOTRS 2.3 中重大的改变如下：\n\n# \u0026ldquo;Performance, Performance, Performance!\u0026rdquo; 系统性能提高\n* Data base- \u0026amp; code-improvements increase lead to a general performance gain of up to 20%.\n* The support of an indexed full text search has been added. The feature is disabled per default because additional disc space is needed. The expected performance gain is 50%.\n* Reduced reloads by using AJAX technology\n* Instead of an ongoing recalculating of the escalation time during the run time, it is only recalculated when it changes due to an event in OTRS. It is then being stored in the ticket object which allows a direct access of external reporting tools to the data base as well as a more efficient reporting on escalations. This will also lead into a substantial performance improvement.\n# Search Functionality 搜索功能\n* Support of logical expressions: ticket-, customer- and FAQ- search supports logical expressions, utilizing the AND, OR and ! operators as well as structuring expressions with parentheses.\n* Search for ticket numbers by using the Browser OpenSearch feature (OpenSearch format).\n* Search for ticket titles in the agent ticket search form and in the generic agent.\n* Search for ticket close time in the agent ticket search form and in the generic agent.\n# Ticket Zoom \u0026amp; Ticket Move 工单伸缩和移动\n* Expand/Collapse of articles: the article view can be expanded to display all articles at once. The current article will remain in focus, and the preceding, or following articles will be displayed.\n* Structured article tree - The article tree has been changed to a table.\n* Printing of articles has been realized.\n* The ticket title of linked tickets are displayed in case of a mouse over action.\n* Merged tickets are displayed crossed out.\n* Multiple files can be attached while moving a ticket using the ticket move mask.\n# Ticket FreeText \u0026amp; FreeTime opportunities\n* When splitting a ticket, all FreeText and Free Time data will be copied to the new ticket.\n* Ticket Free Time fields can be declared as mandatory.\n* A URL can be configured that takes the value of a FreeText Field and displays it as an URL link in the ticket.\n* Added X-OTRS-TicketTime and X-OTRS-FollowUp-TicketTime.\n# IMAP, IMAPS, POP3 \u0026amp; POP3S support 对以上协议的支持\n* With OTRS 2.3 IMAP, IMAPS, and POP3S is supported to fetch mails from your MTA.\n# Security 安全方面\n* In case of a lost password, OTRS is sending an e-mail to the user with a \u0026ldquo;password reset link\u0026rdquo;. After clicking this link the new password is sent to the user in a second e-mail.\n# Notifications \u0026amp; Escalations 通知和升级\n* All agents that have a read permission on a certain queue can be selected for notification.\n* An escalation view has been added that displays all tickets sorted by their remaining time to escalation.\n",
    "ref": "/2008/11/19/otrs-project-news-update/"
  },{
    "title": "[发布说明] OpenNMS 1.6.0 (Stable) Released",
    "date": "",
    "description": "",
    "body": "OpenNMS 1.6.0 (Stable) Released\n似乎每年的10月以后我就会进入一个超级繁忙的状态，很长时间没有更新blog了，今天姑且转载一个OpenNMS的发布说明吧。\nOpenNMS, the world\u0026rsquo;s first enterprise-grade network management platform developed as 100% free and open software, has released version 1.6.0. This is a stable, production release that incorporates nearly three years of development.\n以上算是OpenNMS的广告语大家看看就是，需要注意的是一个企业级的产品实施费用是从很低的门槛一直到企业级的花费的。和其他的企业级解决方案的实施没有区别，差异在于，一个不同的许可证类型，此为开源许可证是也。\n\nThe last production version, 1.2.0, was aimed to compete squarely with Hewlett-Packard\u0026rsquo;s OpenView Network Node Manager product. This release builds upon that work to expand the reach of OpenNMS to other parts of the OpenView family as well as to provide an open source alternative to products such as Tivoli\u0026rsquo;s Netcool.\n以上是OpenNMS的精神所在：OpenNMS一直在叫嚣这和OpenView, NetCool较量；这足以说明了它的勇气，和发展方向，它的创始人Tarus从一个人单枪匹马开始，到现在有一般人inhouse开发这个产品，自己全世界出差，如果说没有实现和商业产品的抗衡的话，我个人觉得他起码实现了一个所有开源参与者的梦想“为需要自己的人工作，为自己工作”\nOpenNMS 1.6.0 sports a redesigned user interface, a number of scalability improvements and increased integration with other products. OpenNMS now runs on Windows, in addition to most flavors of Linux, Solaris and Mac OS X.\n上面说的是新版的用户界面重新设计了，目前我还没有时间安装，回头装好了一定上图片，新版的稳定性得到提高并增加了和其他产品的集成。现在OpenNMS也能在Windows上运行了，在我看这是早晚的是，它是个纯Java的应用，移植不是什么难事，不过我不推荐在windows上完开源的产品，有点不伦不类的感觉，而且从原生态的Linux环境中才哪呢个够获取开源的全部优势。\nOne of the major additions to the platform is the Alarms subsystem. OpenNMS can receive events from a number of sources, such as SNMP traps, syslog, TL/1, and custom scripts. A key can be configured for each event that will allow it to be turned into an alarm. Thus if a device is generating multiple, identical events, their number will be reduced into just a single alarm. This greatly reduces the amount of event \u0026ldquo;noise\u0026rdquo; that operators see.\n上面说告警子系统现在是增强了。OpenNMS能收到像是snmp trap，syslog， TL/1和自定义脚本发来的告警事件。某种键值能被设置，让一个事件能被出发成一个警报。报警事件经过了压制和降噪处理，较少了重复报的数量。\nIn addition, automated actions can be performed on alarms. For example, events that signal problem resolution, or \u0026ldquo;up\u0026rdquo; alarms, can be matched with \u0026ldquo;down\u0026rdquo; alarms to automatically clear them. Event workflow can be built into the system by using these automations to manage the alarm list, thus freeing up the operators to focus on the most important issues.\n另外，对于一个警报来说，可以和一个自动化的动作配合，例如某些up事件能去清除对应的down事件。\nWhile OpenNMS contains a robust automated discovery system, when managing tens of thousands of nodes it is often preferred to allow an external system to determine what OpenNMS is to monitor. Thus OpenNMS 1.6.0 contains a new \u0026ldquo;model importer\u0026rdquo; feature that allows node, interface and service information to be imported directly into the system using data in an XML format. One company uses this method to manage over 70,000 devices with a single instance of OpenNMS.\n同时OpenNMS现在的自动发现系统非常强大哦，档管理一万个节点的时候，OpenNMS往往倾向于使用一个外部的系统来决定什么是需要OpenNMS监控的。在1.6中包括这样一个新功能‘模型导入’，他能把xml格式的节点和端口数据自己导入到OpenNMS系统中。曾经一个公司用这个方法管理这7万个节点，都在一套OpenNMS系统内，好家伙~~也就是说这个功能有了之后，你就可以不用一个节点的去发现了，往往有些机器发现的那会正好不在线，那就漏掉很多的机器了。\nData collection saw many improvements as well. With the proper hardware, OpenNMS is able to collect over one million data points every five minutes. This data can be from SNMP (versions 1, 2c and 3), JMX, HTTP, or NSClient. The collected data can be exported via the web user interface. Reports showing the highest and lowest values for a particular set of data points (Top N Reports) can also be created, and 1.6.0 contains a vastly improved thresholding system. Thresholds can be generated on individual data points, combinations of data points, as well as a \u0026ldquo;relative change\u0026rdquo; such as when a value shows a sudden increase or decrease.\n数据的采集方面也有很多增强。利用一个合适的硬件，OpenNMS能够每5分钟把超过一百万的数据采集点采集一遍，要是采集稳定的话，这还是比较快的了。被采集的数据点可以使来自 snmp v1,2,3, JMX, http, nsclient。 采集来的数据能通过web界面到处了。这还是不错的功能，能有可能做一些系统之外的自定义报表了。自带的报表功能能够定制TopN的报表。OpenNMS现在的阀值管理系统也得到了增强。能为某一个数据点设置，也能为一组数据采集点，同时有了对 \u0026ldquo;relative change\u0026quot;的管理，也就是某个数据忽高忽低的管理，也即是某些瞬间的异常增的很高或降的很低。\nOpenNMS was originally designed for network service monitoring, and that functionality has been increased as well. New monitors for such things as Windows services are now available, as well as more advanced synthetic transactions. The Page Sequence Monitor was created to monitor a complete web-based transaction, while the Mail Transport Monitor determines the full round-trip availability of a mail service.\nOpenNMS天生是监控网络的。新增了很多monitor，例如windows服务监控，模拟交易监控。页面序列监控器用了监控一些列的web交易处理行为，还能通过Mail Transport Monitor 来确定邮件服务的可用性。\nProbably the biggest change was the development of distributed monitoring. Using a small Java webstart application installed on a remote system, OpenNMS is able to monitor service availability from the point of view of the remote system. Combined with the Page Sequence Monitor one can measure the user\u0026rsquo;s experience when visiting a website from various remote locations.\n最大的变更在这个版本中是‘分布式监控’，使用一个小的安装在远处的一个主机上的Java Webstat应用，opennms能过过这个监控服务点看到远程的系统上采集的数据。结合页面序列监控功能，它可以实现这样的功能：在南北方，网通电信的网络中找四个点安装这个程序后，模拟从不同网络位置监控某个web网站上一系列功能页面的可用性。这就是所谓的模拟交易管理，是Web应用管理方面中当下不可缺少的环节。\nAs OpenNMS was designed as a platform, there are numerous ways for external applications, both open and proprietary, to integrate with it. There is a new Trouble Ticketing API that allows for two-way communication between OpenNMS and a number of external ticketing systems such as Jira, Concursive (CentricCRM) and OTRS.\n像opennms这样的平台，可以提供给开源或者商业外部系统的接口。通过这些api的双向接口，你可以把报警事件送到外部的工单管理系统(事件管理流程平台)中，例如 Jira, Concursive (CentricCRM) and OTRS.、\nThese are just a few of the new features available in 1.6.0. As always, OpenNMS is 100% free and open software. Please check it out and let us know what you think. We hope you enjoy using it as much as we enjoy creating it.\n嗯，终于读完了整篇的发布说明，你能相信，它都发布了这么久了，我只有在周五晚上抽空仔细读完么。这周简直是太忙，天天加班，还有天天处理不完的状况。今天的一个教训就是“软件系统之间的集成不是简单能搞定的，需要小心，小心在小心”\n",
    "ref": "/2008/11/14/e58f91e5b883e8afb4e6988e-opennms-160-stable-released/"
  },{
    "title": "ITIL V3 Study Notes (2)",
    "date": "",
    "description": "",
    "body": "这就是全新的ITIL v3的模型个人觉得吧ITIL四个字母放在中间不如把Service放在中间，原因很简单，所有流程和原则都是围绕服务展开，V3是一个关于服务生命周期管理的最好实践集合。\n\n不管你是否学过ITIL v3，你需要了解的核心基本概念包括：Good practices, service, service management, function, roles, process, process model, RACI, generic roles。 想初步了解这些概念的话可以先看看ITIL V3的术语表。\n上图是一个最高level模型，告诉了V3的架构，要进一步细化的话,下面的这张图是我见过的最能说清楚整体框架，并且能点到为止的模型图。\n\n如果你觉得这个图形还是过于复杂，理解起来还有些困难的话，你需要看看下面的内容。\n下面是我整理的ITIL v3 概念快速参考：\n大流程套小流程\nService Strategy// Service strategy, demand management, service portfolio management, financial management 共4个流程\nService Design// service level management, service catalogue management, availability management, information security management, supplier management, capacity management, it service continuity management 共7个流程\nService Transition// change management, service asset and configuration management, release deployment management 共3个流程\nService Operation// Event management, incident management, request fulfillment, problem management, assess management, [functions] service desk, technical management, it operations management, application management 共5个流程加4个职能，术语表中也吧Function翻译成功能，我觉得不妥，职能应该更贴切一点。\nContinual service improvement// 7-step improvement 共1个流程\n所以v3一共是20个流程加四个职能。比较一下V2，V2有10个流程和一个职能，内容增加了一倍。如果系统的学习的话最好还是上一个正规的培训。现在正规的v3培训也不贵，而且一般认证考试也不难。\nV3和V2主要的不同点\n\n 对service的重新定义\n  **对Service management ****的重新定义 **  更强调processes是****闭环系统  ITIL从此进入Good practice时代  Generic Roles概念 ： process owner, service owner, process manager  ",
    "ref": "/2008/11/04/itil-v3-study-notes-2/"
  },{
    "title": "Some old stuff for sharing",
    "date": "",
    "description": "",
    "body": "I think the following open source software resources could be helpful to you.\n本页面上是我认为可能对您有用的资源连接，目的是让您能以最小的时间和精力代价来体验开源软件。使用一个虚拟应用可能是一个比较方便的途径；有些开源应用做的非常体贴用户，软件提供ISO文件下载，通过这个ISO文件甚至能一键安装，在一个物理和虚拟的硬件上试用这个软件了。\nVirtual Appliances / 虚拟应用 \n\n Asset Management 资产管理 OCS Inventory v1.02 RC1＋ GLPI v0.70.2，Download , 下载地址和虚拟说明。  IT Service Management \u0026ndash; Help Desk \u0026ndash; Ticket tracking system, OTRS2.6.6+OTRS::ITSM 1.0.94, Download , 下载地址和虚拟应用说明。  Network monitoring system:\n Zenoss 2 , it was made by Zenoss, not the newest version; download, 下载网址。  OpenNMS 1.5.91, download it from SourceForge; they like to keeping this vm appliance update. Download 下载网址。 ISO Appliances / ISO应用\n    \n Cacti + Nagios + nTop = CactiEZ  OSSIM is a open source security management suite. download, 下载网站  Network appliance: Vyatta could be firewall, router, gateway, dhcp server, etc\u0026hellip; download, 下载网站  Slax is a USB Linux, install in on usb key within 10 minutes, run it on any where, download Slax for CD 下载\n FSF mail list\nWelcome to the Free Software Supporter, the Free Software Foundation\u0026rsquo;s\nmonthly news digest and action update.  ",
    "ref": "/2008/10/29/some-old-stuff-for-sharing/"
  },{
    "title": "八达岭森林公园-红叶岭",
    "date": "",
    "description": "",
    "body": "[![](http://lh5.ggpht.com/liuzh66/SQW2ycea7sI/AAAAAAAAA5E/1xu0psqtrVA/s400/20081027-%20023.jpg)](http://picasaweb.google.com/lh/photo/aGEY72oIPhKJyJOcZsVEVA) \n\n发件人 [八达岭长城 红叶岭](http://picasaweb.google.com/liuzh66/SyrPvH) \n\n\n今天的天气很好且风不大，特意抽出一天时间出来看看红叶。没想到，到了山脚下就不太想上去了，不过本着踩点的想法还是上去看看。这里叫做“八达岭森林公园-红叶岭”，在红叶的季节可以在德胜门做919（红叶岭专线），一个多小时就可以到，中间不停车。下周是这个专线班车的最后一周，这个时间来显然是晚了。上山之后，发现在这几天的秋风后，红叶之剩下10%。在这看红叶的好处就是长城和红叶可以一同欣赏，长城非常有形，可惜的是长城是不能攀登的。这个公园的面积比较小，红叶树都比较小，品种应该也没有香山的多。总的来说这里比较小而精，浓缩长城和红叶与一处，比较适合半天的短游。 ",
    "ref": "/2008/10/27/e585abe8bebee5b2ade6a3aee69e97e585ace59bad-e7baa2e58fb6e5b2ad/"
  },{
    "title": "M$ Windows is eating your hard driver",
    "date": "",
    "description": "",
    "body": "No matter Bill says how friendly M$ Windows is. It is eating more and more my free disk space. Toady I figured out some tips for releasing disk space. In Windows file explore, you can not see the folder size without checking on property. So you may need a tool, something like FolderSizes. FolderSize helps me to know more about my heard diver. It shows me there is a folder \u0026lsquo;System Volume information\u0026quot;, this folder is 6.20GB big. What the hell is that??? I can not even see it in file explore. Then I check on Folder Options, here are so many hiding options for you. In order to take out that big folder, I unchecked \u0026lsquo;\u0026ldquo;Hide protected operating system files and folders\u0026rdquo;, then the folder shows up. But I can not open it sine I really wants to know what hell is been hidden in that folder. A error message box popup up\u0026quot;Assess is denied.\u0026quot; WOW this is my laptop, I am not able to access the folder. Is this a M$ asset? In FolderSize, I can go inside this folder; it has so many files. Everything in this folder looks like patch file. I have no idea where and when it went down my computer; or this dame OS made it. Now I\u0026rsquo;m deleting these files and folders in folder \u0026lsquo;System Volume information\u0026quot; from FolderSize. Another error message box popup up; it says \u0026ldquo;Cannot delete XXX000.ps1: It is being used by another person or program\u0026rdquo;. Kidding me? Does anyone share this laptop with me at this moment? Fortunately I have openSuSe, I issued rm -rf command after booted into openSuse. Now 6.2GB space was released.\n\nWithin FolderSize, one more fat folder was identified out, It is \u0026lsquo;\u0026lsquo;C:\\Documents and Settings\\LocalService\\Local Settings\\Application Data\\Google\u0026rsquo;. I have Google Desktop on my laptop, but I did not use Google desktop search too much, but it take me near 2GBs space. I realized Google desktop indexed my whole hard drive anyway. I have to uninstalled Google Desktop and deleted that folder. Now I got more 2GB space.\nM$ Windows also did anther favorite for me to created a fat pagefile.sys. It is 3.5 GB; Big~~ isn\u0026rsquo;t it? My laptop have 4GBs physical RAM, but XP only use 3.5GB. As same 32bit OS, openSuSE does use all of 4GB. Since I am short of free space, pagefile.sys was changed to 1.5GB. SO, 2GB spaces was saved.\nIn XP file system, there are some files can not be deleted. I bet you do have some files like that. Those files are already useless, but you can\u0026rsquo;t get rid of them. ForceDel.exe can delete them all. This tiny tool saved me more then 1GB space.\n6.2+2+2+1=11.2GB\nThere are more screen-shots, please check out: http://picasaweb.google.com/liuzh66/Mis and comment.\nOk now I\u0026rsquo;m be able to create at least two VMWare machines for my work. I hope those tips are helpful for you.\nIn this week, I\u0026rsquo;m so busy on a Bladelogic product POC testing for CCB which is one of the biggest bank in China. At evening, I usually had to study on ITIL v3 stuff in order to get myself ready for a upcoming training next month. But tonight I\u0026rsquo;d like to take time off of the work.\n**XP磁盘空间节省偏方**\n\n 通过类似于FolderSize的工具找出磁盘中占比重比较大的目录，识别需要删除的目录  对于System Volume information里的文件，可以用一个USB或者CD引导的Linux系统启动机器，删除；然后再关闭xp中的系统恢复功能  如果你不经常使用Google Desktop，或者已经删除了这个程序的话，一定记得删除它建的索引  ",
    "ref": "/2008/10/24/ms-windows-is-eating-your-hard-driver/"
  },{
    "title": "OTRS FAQ 1.5.3 : you have six reasons to use it",
    "date": "",
    "description": "",
    "body": "I have Christopher T. Kuhn Blog\u0026rsquo;s RSS feed in my blackberry. That\u0026rsquo;s the way I following with OTRS project. Christoper do the best job to explain new features and updated s. I did not try out OTRS FAQ 1.5.3 yet, but it look great from Chrisopher\u0026rsquo;s post.\n知识库、解决方案库或者KB的建设往往被人们忽视，对它的选择也是见仁见智。不过可能也有标准，就像你选择你最喜欢吃的水果一样。你最喜欢吃的水果就是：一年四季你到超市见到就想买的，一年四季都想吃的，而且必须是营养丰富有益于健康的。\nOTRS FAQ 1.5.3 新版的FAQ出来后，OTRS有了真正的Knowoledge Base； 虽然依然是一个简单版的KB，不过已经具备了作为一个KB应该具有的6个主要功能。\n\n **所见即所得的编辑方式 **创建包含图片和丰富文字和是的知识库或者FAQ条目。  **脚本导入工具 **可以导入已有的一些经验文档、操作规章手册等已有知识文档。  **关键字连接 **增加知识库的可搜秀性  **FAQ报表 **通过一些定期的报表计算出每一个知识库条目被查看的频率  **TOP10文章列表 **在知识库浏览界面中显示被浏览次数做多的前10篇  **知识审批流程 ** 你可以定义一个审批的流程，审批后的内容可以被显示在内部、外部或者公开区域。 目前我还没有时间测试这个知识库，相信应该是个不错的东西，相关测试截屏请拭目以待。如果你已经测过也请留步，留言告诉我你的体验。  ",
    "ref": "/2008/10/19/otrs-faq-153-you-have-six-reasons-to-use-it/"
  },{
    "title": "ITIL V3 Study Notes (1)",
    "date": "",
    "description": "",
    "body": "关于ITIL V3的简单网上已经有很多，我是从ITIL V2 Foundation认证升级到V3的，由于目前做的ITSM的项目还都是V2的内容。随着公司的产品逐渐想V3上靠，并且很多已经通过了V3认证了；所以自己必须好好在看看V3的内容，所谓温故而知新，我也希望能尽早把V3的内容都消化掉。\n下面的一些列帖子是我最近的一些学习笔记，也本着把后书读薄的目的，希望这些笔记能帮我把思路整理好。\nITIL V3的核心出版物有五本。\n如果有ITIL v2相关的理论或者实践经验 ，而且英文好的话建议直接从网上购买或者下载这五本书开始学习。不过过程可能会比较漫长，效果很难预测。我现在学的是一个公司的ITIL V3 Foundation认证培训的教材，这本书好在他其实整合了上面五本书的所有核心内容，而且通过实际用例来解释理论。它是本考试认证用书，所以上面还有考试辅导方面的内容，如考点提示之类的。对我来讲业余时间能很快把V3的内容过一遍，这本书应该在好不过了。\n\nITIL认证和其他IT认证没有什么本质区别。整个学习和认证架构是一个金字塔，在最顶端的当然是OGC，在最下层的当然是你了。OGC之下的是APMG，APMG 是OGC官方的唯一授权认证和考试机构，它可以授权一些组织成为ITIL的培训机构和考试机构。所以向认证的第一步就是找一家APMG授权的培训机构去培训了，接下来的认证考试可以有培训组织帮助联系。如下图所示：\n如果你没有ITIL v2的认证的话，你就是从上图的第三个框开始你的认知之路。\nhttp://picasaweb.google.com/liuzh66/ITILV3Training1/\nITIL和ISO20000的关系？\nITIL can be implemented without ISO/IEC 20000, but ISO/IEC 20000 cannot be achieved without ITIL.\n服务定义举例：\nLet’s use the analogy of the difference between a supermarket and a restaurant.\nBoth places are visited for purchasing food. At the supermarket, clients buy a product or a set of products with which they have the capability to create a meal. They go home, they prepare the food, and they serve dinner to their guests. Conversely, at the restaurant, the clients are buying the complete Service, the capability and resources to create the meal, as well as the overall experience of dining.\nFunction的定义：\nIt is important for us to understand the definition of function.\nA function is defined as a team or group of people and the tools it uses to perform one or more processes or activities. Functions are self-contained units of organizations, with their own capabilities and resources.\n举例没有Function的组织结构的特点：\nThe challenge most IT organizations face is that they are structured with a single focus on functions.\nThe functional organization in IT is typically aligned to the technology, for example: Network, Mainframe, and so on. IT came by this honestly, as each technology type requires specialized resources and capabilities to manage, thus meeting the definition of a function.\nHowever, when these same functions do not have clear understanding of their roles in processes and service delivery, it leads to “functional silos”, where work is completed without clear knowledge of the impact of this work on the quality of services.\nProcess models help avoid this problem with functional hierarchies. These process models improve cross-functional coordination and control. Well-defined processes can improve productivity within and across functions.\nRole举例：\nAs an example of roles and functions, the Technical Management department or function can perform the role of Problem Analyst when diagnosing the root cause of Incidents. This same department or function could also be expected to play several other roles at different times, such as assessing the impact of Changes, that is, the Change Management role.\nThe scope of the role and what triggers the role player to play that role are defined by the relevant processes and agreed by their Line Manager.\n流程的特点：\nYou can remember these characteristics by breaking them down into a mnemonic such as MSCR — Mary Sells Custom Rings.\n",
    "ref": "/2008/10/19/itil-v3-study-notes-1/"
  },{
    "title": "Open Source and Cloud Computing(开源与云计算)",
    "date": "",
    "description": "",
    "body": "Link：Open Source and Cloud Computing(开源与云计算)\nFrom above post:\n开源的成功有几个关键元素：\n1.许可证要允许和鼓励再发布、修改乃至发展分支；\n2.一个体系结构要使程序能被作为组件在任何可能的地方重用，以及可以被扩展，而不是被替换来提供新功能；\n3.低门槛，让新用户轻松上手一试。\n4.低门槛，让开发人员构建新的应用与大家分享。\n所以我给出我的第一个建议：如果你关心云计算的开源，**请在那些设计为联合而不是集中控制的服务上构建项目**。体系结构从来都是战胜许可证的。 \n个人认为：使用云计算的用户并不一定是租用土地的佃户；佃户把自己的收成都给了地主，自己剩下的少的可怜。云计算的用户会愿意付出多少成本给地主是可以计算的，计算的原则就是‘保证自己的利益、安全等’。\n ",
    "ref": "/2008/10/16/open-source-and-cloud-computinge5bc80e6ba90e4b88ee4ba91e8aea1e7ae97/"
  },{
    "title": "Welcome to my OSS forum",
    "date": "",
    "description": "",
    "body": "Now this forum is open for registration. Please feel free to post any of your idea or question. I hope you will have fun.\nhttp://www.martinliu.cn/forum\n论坛开张了:) 欢迎加入我的开源论坛！\n",
    "ref": "/2008/10/06/welcome-to-my-oss-forum/"
  },{
    "title": "Should I open a forum on my site?",
    "date": "",
    "description": "",
    "body": " 这个论坛软件看似还不错，而且号称简单、快速和优雅，比较吸引我。我的blog后台是Wordpress的，所以理论上讲可以和这个软件很好的集成，这可能是最吸引我的一个地方。对于本开源软件博客而言，是否需要增加论坛这个功能呢？其实本博客还是一个多作者博客，我邀请了几个开源的朋友供稿，不过他们也应该比较忙 :) 其中的两个朋友也有自己的论坛，分别是 www.itnms.net 和 www.zenosscn.com 。对于国内的很多朋友而言，可能论坛是一个更好的沟通方式，泡论坛已经是很多朋友上班中不可缺少的内容。\n考虑一下开设论坛的利弊。好处应该是会带来更多站点交互。坏处还没有想好，目前能想到的可能是：需要花更多的时间打理本站，还有就是抵御论坛的垃圾。总之还没想好是否增设论坛功能，如果您有什么意见和看法也请告诉我。\n[poll id=\u0026ldquo;7\u0026rdquo;] [poll id=\u0026ldquo;6\u0026rdquo;]\n",
    "ref": "/2008/09/23/should-i-open-a-forum-on-my-site/"
  },{
    "title": "How do you know who uses open source?",
    "date": "",
    "description": "",
    "body": "It\u0026rsquo;s hard to get a answer. But I am always thanking about this question. The people who use open source may not announce to the wold \u0026ldquo;we are running apache+tomcat as on-line banking service!!!\u0026rdquo;. As far as I know, more and more peoples going to choice open source software whenever they have this option.\nLet\u0026rsquo;s narrow down this question. That will be more interesting.\nWho are using [**OTRS**](http://www.martinliu.cn/orts/) as help desk on the **Internet**? \nNow this question is easier to be figured out. I did a litter bit research for that. The following is what I did\nUse a google search tips inurl.** **\nSearch \u0026ldquo;inurl:otrs/customer.pl\u0026rdquo; in google.\n\n [inurl:] Get to know it from http://www.xilinx.com/company/search-tips.htm  \u0026ldquo;/otrs/customer.pl\u0026rdquo; is csutomer logon page of OTRS.  ** 约有457项符合inurl:/otrs/customer.pl的查询结果，\u0026hellip;** From the searching result, we can know at least 457 OTRS users on the interest. If you are conserding OTRS as your internal help desk system. Here up to 500 reference OTRS users is ready for you to check out. I clicked few of them, most of them are customized; they looks more beautiful. The OTRS orcks! ",
    "ref": "/2008/09/21/how-do-you-knw-who-use-open-source/"
  },{
    "title": "NeDi - A Swiss Army Knife of network device management",
    "date": "",
    "description": "",
    "body": "\nThere is a shot list of its feature\n\n Auto discovery network deivce  Network Topology-Map  SNMP based monitoring  Network performance and inventory management [  NeDi movie will show you what it can do.](http://www.youtube.com/watch?v=lHDhmtPfC7c)\n",
    "ref": "/2008/09/13/nedi-a-swiss-army-knife-of-network-device-management/"
  },{
    "title": "Do you like Chrome?",
    "date": "",
    "description": "",
    "body": "Peoples always love whatever Google\u0026rsquo;s invention, I am using Gmail and GTalk every day too. But I think I couldn\u0026rsquo;t say I like google anytime. That\u0026rsquo;s just because Chrome. It was installed on my laptop yesterday. I\u0026rsquo;m trying it out when I access any of my google services (Gmail, Reader, Doc, etc\u0026hellip;). There are some App shortcuts are already on my XP deskdtop. Base on one day experience of Chrome, I\u0026rsquo;d like to talk about reasons I don\u0026rsquo;t like Chrome. I has not tested it too much at present, just few comments below:\nChrome\u0026rsquo;s Name: I still do not figure out how to pronounce this word, someone says it sounds like a man perfume; I do thinks so. But it\u0026rsquo;s ok for a name of software, I don\u0026rsquo;t care about too much what it called. FireFox is cool name, everyone know it.\nCrash Continually: It proved Chrome browser is on early stage. For me, I won\u0026rsquo;t any software on my laptop send out any piece of information which I don\u0026rsquo;t know or couldn\u0026rsquo;t understand. So, I will never turn on crash report option for any software. It is still crashing frequently, I might will not use it any more; or install it.\n**Bookmark on top: **My laptop has supper wide screen, so all of bookmarks are listing on the left side of Firefox/IE. I like to access bookmark from left side of screen. It is on the top and just below the address bar, I have to close it.\nADs in Gmail/anywhere it could be: In Firefox, I get really few AD showed up. Nobody love ADs, but Google can not do with our AD.\nWithout Add-ons: It is so important for extending the usage of your browser. Add-on makes a browser to do more jobs as you wash for. I can list some add-ons of Firefox, they are very helpful and I must have all of them.\nI thinks Google really good at marketing. it crashed into browser marketing, its ambition knows no limits. All in all, Chrome is not a good enough to be my default browser; Fixfox will keeping do this job for me. Chrome is a ok software, it is no offence to Googl\u0026rsquo;s fans.\n",
    "ref": "/2008/09/05/do-you-like-chrome/"
  },{
    "title": "best of open source  software [InfoWold OSS AWARRDS]",
    "date": "",
    "description": "",
    "body": "Are you running a open source project? If so, you may wash for this awards. Have you every vote for some\nOSS on InfoWorld? After I check out all of those lists, I realized there are some great softwares I still don\u0026rsquo;t know. For sure you are leveraging oss power, you may go with some champion projects.\nBest of open source productivity apps\nThe InfoWorld Test Center\u0026rsquo;s picks for the top free and open source productivity apps include office suite, Web browser, image \u0026hellip;\nAugust 4, 2008\nBest of open source developer tools\nThe InfoWorld Test Center picks the top free and open source RIA platform, Ajax framework, business rule management system, \u0026hellip;\nAugust 4, 2008\n\nBest of open source storage software\nThe InfoWorld Test Center turns up the top free and open source offering for network and online backup, network attached storage, \u0026hellip;\nAugust 4, 2008\nBest of open source enterprise applications\nInfoWorld Test Center picks the best free BPM, CRM, ERP, e-commerce, business intelligence, project management, application \u0026hellip;\nAugust 4, 2008\nBest of open source for collaboration\nThe InfoWorld Test Center picks the best for social networking, wiki, blogging, and groupware\nAugust 4, 2008\nBest of open source in networking\nThe InfoWorld Test Center chooses its top picks for IP telephony, VoIP monitoring, log analysis, Wi-Fi scanning, server and \u0026hellip;\nAugust 4, 2008\nBest of open source platforms and middleware\nInfoWorld Test Center picks the top free and open source operating systems, desktop and server virtualization, database, \u0026hellip;\nAugust 4, 2008\nBest of open source in security\nThe InfoWorld Test Center picks the top free and open source firewall, IPS, network gateway, password cracker, penetration \u0026hellip;\nAugust 4, 2008\n",
    "ref": "/2008/09/04/best-of-open-source-software/"
  },{
    "title": "Xen quick start guide on openSuSE Linux 10.3",
    "date": "",
    "description": "",
    "body": "If you had installed VMWare workstation on any Linux, you may have kernel source problem. Because a default Linux installation do not include kernel source package. I\u0026rsquo;m just saying that you should always play with open source Virtualization, Xen or Virtial Box are all good stuff to run ;) . I got some screen-shots for you if you don\u0026rsquo;t have idea how do install Xen. The true is Xen is faster then VMWare on my laptop. I would not work with VMWare anymore.\nMy laptop is a DELL D630 with openSuSE Linux 10.3 and XP (just for work).\n1) Install Xen packages via yast from DVD.\n\nI just installed all of six Xen packages. openSuSE Linux 10.3 installation DVD has Xen version 3.18\nThen Yast control center have one new group \u0026lsquo;Virtualization\u0026rsquo;\n\nYou should reboot machine, a new Xen section will be already in GRUB menu, after boot in Xen. Xen server will be started.\n2)Create a new Virtual machine by clicking \u0026lsquo;create virtual machines\u0026rsquo; icon\n\nI select opensuse because I have only install DVD in my hand.\n\nThe new virtual machine has only one 4GB virtual HD as default, it is actually a file, for sure your physical HD have enough free space. You must add at least one CD-Rom, it map to a physical CD/DVD-ROM.\n\nFor configure network, you might read Xen use guide. I use bridge for this virtual machine.\n\nReview all of settings, you can change anywhere at this window. Insert install DVD in DVD-ROM, and clicking Ok.\n\n**3)Inside a pop-up TightVNC window, Install Linux as normal **\n\n\n\nNotes:\n\n You\u0026rsquo;d better have your host machine on the network, if eth0 is not up; the virtual machine can not connect with the host machine.  You may turn on the full Virtualization support in BIOS, in order to create a Windows virtual machine. It depends on CPU.  ",
    "ref": "/2008/08/27/xen-quick-start-guide-on-opensuse-linux-103/"
  },{
    "title": "Open Source Total IT management Solution",
    "date": "",
    "description": "",
    "body": "在IT管理领域里，商业软件厂商中有自称Big 4的集团：CA，HP，BMC， IBM；在开源软件项目中也好像有自称“开源Big 4”的集团，他们是Groundwork、Hyperic、Qlusters和Zenoss公司。商业厂商向用户推出自己的产品的时候，往往都会打着一些比较大的概念和幌子，说“我们是IT管理的Total Solution”；潜台词是我们的产品非常多，可以满足您所有的需求，而且只要您选择了我们，我们能保证所有的产品模块之间是无缝集成的。事实上的确如此，商业厂商凭着后台开发团队的强大，还有本地服务商的支持，在解决方案的集成性上的确没有什么问题。对于开源软件来说，由于每个软件都在各自为政的状态下独立发展，即使是彼此之间的功能有着某种衔接和集成性，在多数的情况下也往往是各自独立发展；没有考虑到彼此的组合和集成。不过换一个角度看，既然是开源软件，人家把源代码都全开放出来了，如果你想做两个开源软件的集成的话，从技术的角度上说，没有任何障碍；对比商业的闭源软件产品来说，似乎他们又在这方面有着与生俱来的优势。\n开源的IT管理软件中有非常多的种类，就拿网管软件来说吧。我的blog上介绍了很多，其中很多的软件都是功能非常重复，而各有千秋的。要想组合一个纯开源的整体IT管理解决方案不是不可能的，需要的是对一些比较精华的软件系统有所了解，并且了解他们之间集成的方式和实现功能。在此基础上做出合理的组合，方能搭建出一个整体的方案。\n由于现在ITIL已经成为了大家耳熟能详的“GOOD PRACTICE”，这是08年V3之后的一个转变，V3提出之后，它就以一种亲民的身份，自称自己不再是“BEST PRACTICE”了。既然是要攒一个“开源IT管理整体解决方案”，同时为了保持本方案具有一定的理论高度 ;) 选择ITIL作为理论依据当然是不会错了呵呵～～ 不好意思今天心情比较好，废话实在太多，抱歉，下面将开始方案书写了。\n本方案将兼顾ITIL中的两大块：IT交付和IT支持。我所选取的是OpenNMS, Hyperic HQ 和 OTRS来分别支撑IT交付和IT支持者两个部分。OpenNMS和Hyperic HQ组合来完成网络和系统监控，它们为可用性管理、性能（容量）管理和服务水平管理提供支持和实现，注意这里说的是为这几个流程提供支持的工具，这些工具本身并不是流程工具。OTRS完成事件管理、问题管理、配置管理和服务水平管理等流程，OTRS本身是一个工单跟踪管理系统，他现在的ITSM模块以及发展到1.1的版本了，同时自称是ITIL兼容的软件。\nIT Delivery\nOpenNMS和Hyperic HQ的功能定位有所不同，在这里选择他们俩来作为监控网络和系统的平台由一下的一些理由。OpenNMS是agentless的监控软件，它的网络自动发现功能非常好使，而且现在能支持越来越多的网络设备，对于国内的华为等厂商的设备需要做一些定制后才能监控，否则只能看到标准的mib2的信息。最新的版本也能支持分布式的管理功能，也就是remote monitor的模块。我没有让Zenoss入选网络监控的一个重要原因是，OpenNMS是纯开源软件项目，它的所有功能都是可用的，而且它是Java程序，配置文件大多是xml文件。对支持非常大量的网络设备和端口，你需要有的是对Tomcat和Java应用的调优能力，和通过OpenNMS的邮件组来解决bug的能力。OpenNMS里面有非常好的告警事件管理功能，它本身是一个非常好的事件平台，事件升级、报警、过滤等功能都有。而且现在OpenNMS已经能和Hyperic HQ做事件集成，Hyperic HQ的报警事件能传递到OpenNMS中，这就意味着OpenNMS可以作为一个统一集成的事件管理平台，在这里对集中管理所有类型的告警事件。HQ是一种Agent based的监控软件，对于系统监控而言，很多商业厂商的软件功能都无法很好的做到单一代理的技术，当然我认为BMC的Patrol是例外，它的单一代理技术是我见到最好的。HQ的单一代理技术意味着，通过在一台服务器上部署一次代理程序后，其他的工作就都转到web console上了，在那里，你可以配置代理对各种资源的管理，它的代理能发现非常广泛的基础架构应用：Web， midtier, DB等。由于HQ是一个商业开源的软件，所以它对商业基础架构软件的平台支持的非常好，能支持目前流行的所有基础架构软件包括各种商业的操作系统、数据库、中间件；当然它对开源的软件也能够监控。监控参数很多，配置容易，有开放的接口提供功能扩展开发。从OpenNMS和HQ的各种图形上可以很好的评价和监控和各种IT服务的质量。OpenNMS中的界面中最多的就是对某个节点或者上面的某个服务可用性的计算。\nOpenNMS和HQ实现和完成的功能能为IT交付中的：可用性管理、性能管理和服务水平管理提供实时的数据支持，OpenNMS作为总的事件平台，同时它还监控所有的网络设备。HQ用来监控所有重要业务服务器，那些边缘的非重要的业务服务器或者是客户端设备也可以交给OpenNMS来管理，它的无代理监控，对这些设备也能管理的不错。\nIT Support\nOTRS本身是一个非常不错的工单跟踪系统，它在加载了ITSM模块之后，就把ITIL的很多精髓理论做了很好的诠释和实现。对于很多大型企业用户而言可能会笑话OTRS的简陋，不过实施ITIL的过程，我觉得应该是：把当前的繁杂工作，按照ITIL的几个流程简化梳理的过程，每个流程完成比较单一而纯粹的目标；流程之间又能有一定的集成就可以了。对于OTRS的研究，我目前也处于安装和读管理员手册阶段，没时间细看。选择OTRS的一个最重要原因是，今年也开发了一个事件集成模块，它能通过这个模块与Nagios，openNMS，OpenView，Tivoli等监控产品做事件集成，也就是说告警事件能自动在OTRS中生成事件单，而OTRS的事件管理模块就负责吧入站的事件单自动化的分配给相关的技术支持人员受理解决。详情请参考Automated System Monitoring with OTRS Download这个白皮书是在OTRS.com的网站上下载的，我当初怀疑这个事件集成模块是否是开源的软件，所以在Christopher T. Kuhn 的Blog上问他了一下，他向我确认该模块是开源的，并提供了下载地址。从技术路线上来说OTRS是实现了服务台的功能，并且实现事件、问题、配置和SLA管理；从界面上看它对这些流程的支持是比较简洁的实现，你完全不能把它和商业的服务台软件来比较。不过实施ITIL的道路，我觉得应该是丰俭由人的，我相信一定会有人走简洁路线的。想想Apple的产品，它的设计无比的简洁，它简洁并不丑陋，而且还很cool，很流行。\n由于这个方案攒的还是比较匆忙，而且技术上没有实际测试和验证，本文旨抛砖引玉的提出一些思路和想法，未经详细推敲，欢迎提出您的建议。\n",
    "ref": "/2008/08/23/open-source-total-it-management-solution/"
  },{
    "title": "配置管理中几个的误区",
    "date": "",
    "description": "",
    "body": "配置管理的项目可以从CMDB的建设开始，也可以从配置管理的流程建设开始。我在一些配置管理的项目中发现了一些用户容易犯的错误有很多。先说说配置管理，做ITSM的项目，往往CMDB的建设，或者配置管理流程大多不会非常重视，往往作为一种辅助性的环节在项目中得到实施。例如ITSM项目一上来就做服务台，然后是变更管理流程和其他流程；在一些后续的资产管理的项目中CMDB的到重视并建设。其实配置管理流程和CMDB是ITSM项目中非常重要的一环，它建设的效果对整体效果有乘法放大的效果。CMDB的主要功能我认为有两点：\n\n 提供唯一、精确的配置信息库，让所有IT团队的人都明确IT管理配置项范围，有了它所有人都起码能清楚“我管理的东西是什么有哪些？”。都说ITIL的语言是IT管理的共同语言，那么配置信息就是这个语言的主语和宾语；从这里可以看到，如果我们没有这样一个准确的配置信息库，我们彼此之间的沟通会出现多大的误解和迷惑。我在用户现场做项目的时间比较多，耳闻目睹很多沟通障碍；这些障碍不是沟通方式和技术造成的，而是大家没有能从一开始就说清楚“谈论的CI对象到底是什么”  实现一定程度上的业务影响分析。往往都是有IT部门牵头做CMDB，后期也主要是IT部门用。有效的业务影响分析能力，可以彻底提高事件管理的有效性。一般用户可能会有一个集中Event Console，从这个console中事件一般是以生成的时间先后顺序查看和处理的。最差的事件管理方式就是这种“先进先出”的处理应对方式。如果你能说清楚，发生事件的对象（配置项）对业务系统的影响程度，那么你就能够做到按照这些事件的优先级别来处理；事件的优先级就是该事件对业务系统所造成的影响的严重程度。需要做到业务影响分析，就必须做业务模型梳理。每一个业务服务和业务流程也是配置项，IT的人也需要能理解业务。 下面列出一些常见错误，这些错误发生在企业做ITSM项目的前后都有可能，不过多是在实施ITSM项目之前，或者上CMDB工具之前，或者过程中。\n1）目标不明确，实施结果无法衡量 Goal\n\n所谓目标不明确，并不是说没有目标，而是说：目标定的不太合理。不合理的原因有一下几种：目标过大、目标过于模糊、过于教条、拘泥于ITIL的书本、和实际的工作联系不紧密、没有衡量和控制的方式。在一定的项目时间周期内，总结之前配置管理的问题，作出一个切实可行的配置管理数据库建立目标应该不难，主要以使用为主，不要拘泥于细节。\n2）配置项信息混乱，信息结构无序 Scope\n\n这里的“信息结构”是说CMDB的CI配置项信息查看应该是立体的有结构的很直观的数据信息。在访谈的过程中，有些用户在讨论过程中认为配置项组成的信息结构应该是网状的。其实现实中的IT基础架构组件的确是以网状的形式相关联的，这种想法非常实际。不过人们都太偏重IT了，遗忘了IT部门的最终使命“为企业交付各种业务服务”。业务服务就是CMDB数据金字塔的顶端部分。从IT部门提供的业务服务开始来梳理和建立CMDB配置库是一种“自顶向下”有效方式，是IT部门做CMDB配置管理过程中，与业务部门沟通的“翻译机”。自顶向下的方式需要业务部门的配合，或者IT部门内有精通业务的强人。通过这种方式做出了的CMDB，CI之间的构成方式，从宏观上看：屏幕的投影是树根型的，立体的看是金字塔形的，业务系统模型是树根的根部，是金字塔的顶端部分。微观上看，局部可能是网状的，或者是星型的。没有业务服务作为头部，很难说出CMDB的scope究竟是多大，很难说清楚哪些CI可能会在CMDB中出现。\n3）配置信息随意堆积，纠缠于过多的CI属性 Level\n每一个CI都可能具有非常多的属性，成功选择的标准是：够用就好，精简是王。很多用户都存在的误区就是“复杂比简单好，越复杂越放心”；大多数用户在项目初期的需求整理的时候都觉得，需求提的越全面，越好，越保险。这种心情是可以理解的，毕竟ITSM项目的周期和投入通常都是非常多的。不过对于配置管理来说却，万万不能有这种想法；否则，CMDB的维护和审计的工作量将非常巨大。一个信息量过载的CMDB，就是一个不可用的配置库。一个只有10个属性的CI和有50个属性的CI展现在你面前的时候；你找到你所关心的信息花的时间上看，前者是后者的1/5时间。属性一定要精简，特别是CMDB从零开始的用户。在设计的初期一定预留属性扩展的可能性。\n4）疏于配置信息的准确性和实时性 ** update**\nCMDB一旦建立了之后，所有用户一定要对CMDB使用起来，要为CMDB提供反馈。最终使用配置信息的人，如果发现信息不准确，需要及时报告配置经理。配置经理需要及时维护。配置经理最重要的职责是，确保每一个大小变更实施完毕之后对要对相关CI做更新。你可以没有正规的变更流程系统去跑变更单，不过我所看到的是很多企业即使没有实施ITSM项目，其实他们手工变更单的流程跑的有板有眼，一点都不差。美中不足的是，变更后的结果没有地方更新和反馈。而CMDB就是这样一个变更结果反馈和汇集的目的地。在大家都频繁使用CMDB，并且每一个大小变更都更新CMDB的完美情况下，CMDB中的信息会随之时间的流逝，愈来愈精确，愈来愈完善。\n**5）拘泥于工具的功能，忽略了最终目标 Tool**\n我看到的最多的工具是MS Excel，也有使用自开发系统的，可有自开发系统最终丁不住在转向商业工具的 :( 无论何种工具，假如在一个正确的事实和使用的策略下，我觉得都是可以获得CMDB建设的成功的。一个好的工具还是有必要的。在选择一个成品工具或者开发一个CMDB工具时，需要考虑工具的几个方面。工具应该参考或者借鉴某种国际标准，这里的标准是指某种通用模型标准 Common Data Model (CDM)，例如DTMF的 Common Information Model (CIM),或者WMI等。好的工具需要能和其他ITSM流程紧密结合，特别是事件管理、问题管理和配置管理者三个流程。如果这三个流程是建立在某种工具平台之上的，那么CMDB的信息最好能无缝的整合的流程的处理过程中。  ",
    "ref": "/2008/08/15/e9858de7bdaee7aea1e79086e4b8ade587a0e4b8aae79a84e8afafe58cba/"
  },{
    "title": "one minute to build your wap version blog",
    "date": "",
    "description": "",
    "body": "Wap version of my blog **http://tinyurl.com/martinliu ** You could also build yours within one minute. I think it is worth to do, since more and more peoples are surfing from mobile device. You might get a wap link on your home page, I will do it after get this post publish out.\nNow, it time to explain how to do a wap blog.\n\n open Google Moblizer in your browser  enter your url of your blog, then click go button  google moblizer will adjust your blog page to flat wap version. only one font and same size, smaller pictures, white background; those are perfect to fit for more cell phones. it is also easy to read.  copy the current url into a text file, this url looks like \u0026lsquo;http://www.google.com/gwt/n?u=http%3A%2F%2Fwww.martinliu.cn'  go to www.tinyurl.com; paste the url to make a tinyurl  finally, you get a tiny url for your wap version blog  enjoy :) I\u0026rsquo;m using wordpress for my blog. Wordpress should have some sort of plugin to do this. If you know about it, please leve me a comment. Thanks!  ",
    "ref": "/2008/08/10/one-minute-to-build-your-wap-version-blog/"
  },{
    "title": "开源软件的能量",
    "date": "",
    "description": "",
    "body": "可惜yo2.cn开张的太晚了。\n否则我的blog http://www.martinliu.cn 就可能在这里了，先注册一个好的名字 opensource.yo2.cn 先呵呵～～ 如果有需要请和我联系，不想浪费这么好的blog地址。\n",
    "ref": "/2008/08/10/e5bc80e6ba90e8bdafe4bbb6e79a84e883bde9878f/"
  },{
    "title": "2008 Beijing Olympic Game introduce China to the world",
    "date": "",
    "description": "",
    "body": "中午后去超市购物；超市的人可真多啊，大家都在采购备战晚上的奥运哈哈。我也买的毫不手软啊，西瓜、王老吉、可乐、牛肉、蔬菜等等！回家后，先炖上一锅牛腩萝卜汤，昨天立秋，今天贴贴秋膘有不迟。\n准时5点就开始收获在电视机前。等待开幕式的开始。开幕式终于开始，虽然视觉上的冲击性不强，不过还是完美的展示了中华文化的精髓。通过四大发明的展示，以东方人含蓄和细腻的手法，把吾国浩浩汤汤2000多年的历史优美的展示与全球世人面前。地球村的创意我觉得非常好，最后刘欢站在最上方高歌一曲，挺好。兴致最好的时候牛腩汤经过几个小时的熬制，也香气扑鼻了，呵呵来上一碗，继续看\n总之真个文艺演出，文化气息十足，可圈可点之处也很多；唯一担心的是怕老外们理解不了。现在终于看到中国代表队在姚明的带领下，正缓缓入场；中国体育健儿的队伍可真大啊！！！\n中国加油!!! 哈哈忍不住了，我也在blog上喊一嗓子吧，明天奥运的战幕就缓缓拉开了，希望他们拿更多金牌为国争光。\n现在中国队走到了中场，期待圣火点燃的那一刻吧。顺便说一句，有人说中国队的服装配色有点借鉴了‘西红柿炒鸡蛋’的色彩，呵呵有点象，的确有点象，而且那时我的拿手菜:) 今年北京的天气，好的是，天公作美，真的憋住，愣是没有下雨；不好的是，桑拿的程度太高了。场内入场的所有运动员，从电视上可以看出都已经是大汗淋漓了，都在等待圣火。烟火，有事一波烟火，整个鸟巢像是个火锅一样，再次沸腾一次。\n中国画，由所有运动员参与绘制的一副巨画放到了场地中央，这幅画可谓整场的一个核心线索，这可能是老谋子的idea吧，和拍电影的道理一样，需要有一个线索贯穿始终，像是ice age2里的那颗坚果。不知道以后会把它放在那，细看这画很不错，写意，非常写意，还有点点现代气息。\n刘淇开始讲话了。不禁回想起，我在看圣火采集实况转播时候的激动心情，他在希腊的采集圣火的神殿哪里也发言了。LP说他在这发言可谓捡了一个不小的便宜，前人种树后人乘凉啊!!\n胡锦涛主席宣布“大会开始！！” :) 呵呵，有一波强烈烟火，太cool了！！ 奥运会旗入场了，八人举着会旗缓缓入场，8人都是奥运的元老人物。现在看到那些在场地周边，做分割线的MM们好像不用再跳跳跳的欢迎了，这些MM已经在入场式的时候跳了快2个小时了，体力不行还真去不了啊，辛苦辛苦了！哈哈！！护旗手开始升会旗，不得不说中国的护旗手世界上最cool，赞一个！！在赞一次天工吧，到现在为止，一滴雨都没下，真给面子啊！\n张怡宁右手抓五环旗开始宣誓，她表现的很腼腆：）黄利庭代表裁判员宣誓，慷慨激扬，强！！\n我看时间一定要拖到12点整了，不行我先把这个post发布一下啊，一定要讨到八月八的这个好彩头。发布ed\nDONE继续，很大很强的一个烟火在鸟巢上空喷出，绚烂啊！！许海峰手持火炬入场，开幕式的最大悬念缓缓揭开了。啊！点燃了高敏的火炬～～～转给李小双，继续跑，传给第四个占旭刚，跑～～这第五个张军该是最后一个了吧，都快是最后一分钟了，我和LP都猜，最后一个是谁呢？刘翔？？第六位了陈中，跑～第七个了，孙晋芳，第八个该是最后一个吧？继续跑～过0点了。火炬在晚上看，真好看，最后一个李宁了，被吊起来到空中，很高，很高，继续升高～～OH my god ，升到最高处，绕嘴上圈，在空中跑，创意啊！！！赞！！！画卷在他下面缓缓打开，画卷始终在他身后，缓缓打开，太强了，弓虽！！！牛啊～～～李宁依然在空中认真的跑着，要绕场一周了，看来，不知主火炬到底在哪里啊？？到了，主火炬终于出现了，点ing。。点了一个导火索，导火索螺旋上升，圣火熊熊绽放在北京夜空～～全城烟火一起点燃，烟火到达等顶峰。一个五环的烟火呀！！我坐在家里可以听到隆隆的烟火声，家里的视野不好，无奈啥也看不到！\n刚才急奔向楼顶，想看一眼最后的绚烂，可惜到了楼顶的门口发现，门已被锁，而且上了封条了。外面的烟火声还是有，心里一个字痒啊～～～不过无奈总是难免的，我的奥运开幕式实况转播也要结束了。\n动态奥运奖牌榜\n",
    "ref": "/2008/08/08/2008-beijing-olympic-game-introduce-china-to-the-world/"
  },{
    "title": "Systems Monitoring Shootout",
    "date": "",
    "description": "",
    "body": "Please download it here A paper from Open Management Consortium\nThis is a paper from \u0026ldquo;2008 Ottawa Linux Symposium\u0026rdquo;. It will give you a nice insight about some great NSM projects. It is talking about OpenNMS, Zabix, Zenoss, GroundWorks and Hyperic, those might b the hottest projects around NMS field. If you are looking for a open source network and system monitoring solution, or you are testing one of them; you should check it out. I got this paper from Open Management Consortium.\nSometimes, people might spend too much time on testing different projects; I know this is a kind of fun. But eventually they only got lots of comments about manny project. They still did not realize the value of open source. The best way to adpat open source is that you just pick one nice project and keeping to use it for months at least. I have a net admin frind who I had since helped to setup Cacti for all of his network devices. He don\u0026rsquo;t know so many NSM projects, but he really engoy Cacti. With Cacti, he can do a easier and better job then before. So, are you going to still watching open source world? Let\u0026rsquo;s get start your real open source journey.\n",
    "ref": "/2008/08/04/systems-monitoring-shootout/"
  },{
    "title": "This post is too later",
    "date": "",
    "description": "",
    "body": "很久没有更新这个blog了，本来想保持每周一帖的频率，不过最近总被一些事情所耽误了。今天终于有空闲坐下来写点什么了。\n昨晚无意间发现了这个叫做UnWakeAble的Theme，稍微看了一下马上就更换到这个主题了。这个主题有几个地方非常吸引我：它有自己的配置选项；能配置成2或者3栏的形式；提供3种内置的风格可以切换，这个太空船的黑色风格太吸引我了。我想在没有时间写正经post的时候，用有限的时间调整一下界面风格也不错呵呵，虽然之前曾经发誓，要把主要blog时间都放在提交高质量项目介绍和评论上，不过通过这个blog做适当的娱乐还是未尝不可的呵呵:) 可能是对Wordpress了解的很多了，用的也越来越多了，现在觉得它也可以作为一个公司内部的知识库来使用，知识库有可以说是一种特殊的CMS内容管理系统，它能方便用户查询和浏览相关的知识条目。昨天看了一下wordpress的roadmap，它以后可以提供更多的api，甚至于下离线的编辑内容的功能，我想这些都可以是外部系统和它集成的很好的接口。我说的外部系统可以是：IT管理的服务台系统，现在很多厂商的服务台都有现成的KB模块，不过把知识条目放到wordpress这样一个外部的系统中还是很有优势的。关于把wordpress用作CMS内容管理系统的一些考虑您可以看看这个post\n今天去西四的广济寺，途中经过了潘家园市场、虹桥市场、天坛北门、天桥、西单等。途中的景色令我可以说是非常吃惊，奥运真的把北京改变了很多。潘家园门口兜售和田玉的巴郎子（新疆人对少数民族的一种称呼，其实是维吾尔语‘小青年’的意思）没有了，随处摆的地摊也没了，随处乱扔的白色快餐饭盒没了，在路边拉黑活的黑车也没有了。虹桥市场门口的路上以前总能看到的那些专门向老外乞讨的人也没有了。天坛北门的街道两旁真是很干净啊，垃圾、墙上的办证都没了。天桥哪里更是变化巨大，以前道路两边破烂的小卖部都没了。西单更是夸张啊：过街天桥附近打扫的人真多啊，而且以前扫大街的人都是自动化了；没人在骑着老式的保时捷垃圾车，取而代之的是等自动扫街的电瓶清洁车。北京变了，北京准备好了。呵呵我也喊两句口号吧！甚至于我在考虑，开幕式那天晚上，我去哪里看焰火。我里永定门的距离不算远，听说那是放烟火的中轴线上的最南点，暂时把这作为我的plan A了。\n我也很想知道，你奥运期间如何度过呢？\n[poll id=\u0026ldquo;4\u0026rdquo;] [poll id=\u0026ldquo;5\u0026rdquo;]\n",
    "ref": "/2008/08/03/this-post-is-too-later/"
  },{
    "title": "MDTM：淺談FTP協定如何保留下載檔案的日期 / 時間",
    "date": "",
    "description": "",
    "body": "應該有很多朋友知道，用 FTP 下載檔案的時候，可以設定「保留下載檔案的日期 / 時間」。例如如果妳用的 FTP client 是 FileZilla 這個跨平台的自由軟體（以 2.2.32 版為例）：\n編輯 \u0026gt; 設定 \u0026gt; 檔案傳輸設定 \u0026gt; 保留下載檔案的日期 / 時間\nEdit \u0026gt; Settings \u0026gt; File transfer settings \u0026gt; Preserve date/time of downloaded files\n設定是很簡單，其他的 FTP client 軟體也都有這個設定，一般人知道怎麼設定（自己用的 FTP 軟體）也就夠了。\n但是，原理是什麼呢？\n我用 ftp preserve date/time of downloaded files 去 Google 撈過來撈過去\u0026hellip;\u0026hellip;\n原來，這是取決於伺服器端的，如果妳連上的 FTP server 有支援 MDTM 這個功能，那妳只要在 FTP client 端設定一下，就可以保留下載檔案的日期 / 時間囉。\n嗯，既然是通訊協定，一定在某一份 RFC 裡面有定義才是，這次改用 rfc ftp mdtm 撈，就撈到 RFC 3659 ，其中就有 File Modification Time (MDTM) 的定義\n要怎麼知道妳連上的 FTP 伺服器有支援這個功能呢？很簡單，只要下 FEAT 指令，看看有沒有這個 FEATure 。底下是我用 MS Windows XP 的 command prompt ，連上某個 ftp 站之後，下指令的結果：\nftp\u0026gt; quote FEAT\n211-Features:\nEPRT\nEPSV\nMDTM\nPASV\nREST STREAM\nSIZE\nTVFS\n211 End\nftp\u0026gt; quote SYST\n215 UNIX Type: L8\nftp\u0026gt; quote HELP\n214-The following commands are recognized.\nABOR ACCT ALLO APPE CDUP CWD DELE EPRT EPSV FEAT HELP LIST MDTM MKD\nMODE NLST NOOP OPTS PASS PASV PORT PWD QUIT REIN REST RETR RMD RNFR\nRNTO SITE SIZE SMNT STAT STOR STOU STRU SYST TYPE USER XCUP XCWD XMKD\nXPWD XRMD\n214 Help OK.\nftp\u0026gt; quote MDTM welcome.msg\n213 20080613045501\nftp\u0026gt;\n嗯，所以我們可以這樣取得 welcome.msg 這個檔案的時間戳記 (timestamp) 。不過，微軟提供的 ftp.exe 比較陽春，並沒有內建保留下載檔案的日期 / 時間這樣的功能，所以妳可以考慮使用 FileZilla 。如果一定要在命令列模式實現這樣的功能，可以考慮下載 NcFTP 的 MS Windows 版本，或者寫個 script 來控制 ftp.exe 。\n==\n喔，如果是 FileZilla 3.X 的話，這個設定放在：\n傳輸 \u0026gt; 保留傳輸檔案的時間戳記\nTransfer \u0026gt; Preserve timestamps of transferred files\n======\n有沒有發現，我們一直都在談「下載檔案」，那，用 FTP 上傳檔案，能不能保留檔案的日期 / 時間呢？有一些軟體拿 MDTM 來做這個功能，其實是不符合 RFC 3659的。比較正式的規範，目前應該是要用 MFMT 來做：\n目前有份 IETF draft 提到 MFMT (Modify Fact: Modification Time)， FileZilla FTP server 0.9.25 有支援這個功能，如果妳用的 FTP client 也有這個功能，就可以實現「保留上傳檔案的日期 / 時間」\nFileZilla 團隊有整理了 File Transfer Protocol 相關的文件。\n==\n為了答謝一直看到這裡的朋友，低調的提一下 Filezilla Password Recover :p\n（本文原載於 http://blog.roodo.com/ystuan/archives/6171547.html）\n",
    "ref": "/2008/07/15/mdtmefbc9ae6b7bae8ab87ftpe58d94e5ae9ae5a682e4bd95e4bf9de79599e4b88be8bc89e6aa94e6a188e79a84e697a5e69c9f-e69982e99693/"
  },{
    "title": "Running Linux from any machine without installation",
    "date": "",
    "description": "",
    "body": "Slax - your pocket operating system \n\n  Slax is a modern, portable, small and fast Linux operating system with a modular approach and outstanding design. Despite its small size, Slax provides a wide collection of pre-installed software for daily use, including a well organized graphical user interface and useful recovery tools for system administrators.     The modular approach gives you the ability to include any other software in Slax easily. If you're missing your favourite text editor, networking tool or game, simply download a module with the software and copy it to Slax, no need to install, no need to configure.     If you are a beginner or you're just too busy to make it yourself, follow a few steps to build your own customized operating system by using web-based interface here.    \nSlax How to\n\n* [Key features of Slax 6](http://www.slax.org/documentation_key_features.php) * [Slax distribution - Slax for CD](http://www.slax.org/documentation_burn_slax.php) * [Slax distribution - Slax for USB](http://www.slax.org/documentation_install_slax.php) * [Verify if your downloaded was not corrupted](http://www.slax.org/documentation_verify_download.php) * [Running Slax from USB Flash keys](http://www.slax.org/documentation_usb_troubleshoot.php) * [Using boot parameters (cheatcodes) in Slax](http://www.slax.org/documentation_boot_cheatcodes.php) * [Understanding the persistent changes](http://www.slax.org/documentation_persistent_changes.php) [ not finished ] * [Using Slax modules](http://www.slax.org/documentation_use_modules.php) \n\n\nSlax是一个USB Linux，安装它的方式很简单，[下载Slax](http://www.slax.org/get_slax.php)的tar文件到usb key。usb key最好是1GB以上，整个Slax大概六七百MB；usb key现在很便宜，建议买一个大的。如果你是在windows下面下载并安装这个东西，建议最好把usb key先格式化一下，别格式化成NTFS格式，我的usb第一次安装没成功，后来格式化一边在copy tar文件，解压缩后，运行那个安装文件，就是一个bat文件，它会把这个linux的启动菜单装到，usb的引导区。那个bat文件会一闪就停住，关闭窗口。安装就这个结束了，整个过程10分钟左右。推出windows，在笔记本电脑启动的时间，按F12，在系统启动菜单上选择从usb启动。很快slax的启动画面就显示出来了，在这个菜单中，我选择了copy slax to ram；这样它会把整个系统都装入内存运行；我的笔记本电脑有4G内存，所以我想充分利用这个资源提速。进入系统后，系统是一个KDE桌面非常熟悉。如果你想按照其他的程序的话，你可以到slax的网站上下载其他的模块，copy到那个制定的目录中，通过桌面里的模块管理工具或者命令行都可以激活新的应用，下面你就能在程序菜单中找到了。在slax的桌面系统中你可以直接访问到windows的分区，系统在启动时自动把windows的文件系统识别并且加载了。\n现在你拥有了随身携带的Linux系统了，把它放到包中随身携带吧：） ",
    "ref": "/2008/07/04/running-linux-from-any-machine-without-installation/"
  },{
    "title": "What is Google Infrastructure?",
    "date": "",
    "description": "",
    "body": "If you have no idea, you should read this post \u0026ldquo;Google spotlights data center inner workings\u0026rdquo;.\nThere are some notes I took as blowing.\nGoogle Infrastructure:\n\n clusters of 1,800 servers are pretty routine.  an ordinary Google search query that involves 700 to 1,000 servers  puts 40 servers in each rack  Google has 36 data centers across the globe; Google has more than 200,000 servers; growing every day.  Google largely builds its own technology.  to treat each machine as expendable; Google prefers to invest its money in fault-tolerant software. NOT hardware fault-tolerant.  Google uses ordinary hardware components for its servers, it doesn\u0026rsquo;t use conventional packaging. Google required Intel to create custom circuit boards.  As to the servers themselves, Google likes multicore chips, those with many processing engines on each slice of silicon.  three core elements of Google\u0026rsquo;s software: GFS, the Google File System, BigTable, and the MapReduce algorithm.  Google helps with** a lot of open-source software projects** that helped the company get its start, these packages remain proprietary except in general terms.  GFS stores each chunk of data, typically 64MB in size, on at least three machines called chunkservers; master servers are responsible for backing up data to a new area if a chunkserver failure occurs.  The largest BigTable instance manages about 6 petabytes of data spread across thousands of machines.  On any given day, Google runs about 100,000 MapReduce jobs; each occupies about 400 servers and takes about 5 to 10 minutes to finish. 总结一下上面的东西：\nGoogle不是买的成品服务器，而是去Intel定制的芯片自己攒的，特别喜欢使用多核的cpu，由于他们的程序都适应与多线程并行计算的方式。一个群集有1800个服务器是非常平常的。Google大概有二十万个服务器，每40个放在一个机架上，分布在全球36个数据中心。Google不使用商业的服务器包括数据库等软件，一来造价太高，二来无法满足扩展性的需求。Google使用了很多的开源软件项目，事实上它们就是站在开源软件的肩膀上发家的；GFS，BitTable等都是它们常用的。广泛使用软件容错技术。\n传统商业公司和google的不同：\n  \n 从硬件到软件基本都使用现成的商业产品。基础架构中的每个环境都是钱堆出来的。用钱来节省时间，不过google的时间和金钱的节省都是值得学习的。  在容错技术上硬件HA技术用的最多，群集中的服务器数量不多。  不同业务系统之间几乎是孤立的。从数据库到web到关联的网络设备都是一套独立的系统，甚至于按业务系统划分运维的团队。  系统的扩展性比较小，对核心部件：如核心应用服务器或者核心数据库服务器的扩展，垂直扩展比较多，追求单机的多CPU，高主频，高内存。而另一方面：在这些系统上的压力测试和性能调优工作异常的痛苦。  饱受被商业软件公司绑定之苦，如果数据库、应用服务器等出了产品的bug，厂商提供fix一般都需要一定的时间周期-时间代价比较高，原厂的现场技术支持服务金钱代价也比较贵。  从高层看：CTO、CIO、CEO没有正视开源技术。只要预算允许，引入和采购业内流行的商业技术似乎是永恒的明智之举。开源软件技术应用的有不过很少。  从基层看：工程师可能有足够的某项开源的技能，不过没有适当的渠道能反应到上层来提议使用该技术；如果在下面擅自使用了某种技术，非常担心出了IT事故后对后果的承担。开源技术对技术人员只是一个爱好而无法应用与自己的日常工作中。  特别是中国用户对最新潮的IT技术永远保持着极度的热情，不管是硬件和软件买就买最先进的，数据中心的机房最后成为博物馆，新老系统很难整合资源。把基础架构的彻底改变寄希望于未来的某种技术革命，实际上技术变革已经悄悄发生了好几波了，怎么管理现状怎么就是越来越艰难，越来越花钱呢？走中国特色道路真的值得提倡一下了。 Google的这些特点真是引人入胜，任何企业都无法复制；而且也不可能复制，它毕竟是一个商业公司而不是一个开源项目。如何使用现有的技术和人员来打造出你自己的完美基础架构呢？现实中这么多的role model已经证实了很多技术都是可用的，完美的境地也不是空中楼阁。如何集思广益并多多引入开源技术和人才可能是一个需要斟酌的题目。\n[poll id=\u0026ldquo;3\u0026rdquo;]  ",
    "ref": "/2008/06/21/google-infrastructure/"
  },{
    "title": "盛夏严防服务器中暑",
    "date": "",
    "description": "",
    "body": "哦不是中暑:-)而是发烧；夏天就要到了，监控服务器的主板温度和风扇是否工作正常有变的比较重要起来了。\n今天发现一个文档 Monitoring Temperature and Fan Speed Using Ganglia and Winbond Chips 这个是一个不错的文档，值得参考一下。\n文章是写如何在Ganglia中实现对主板温度和风扇的监控。以前也有人问过我这个问题“Ganglia的监控图上为什么没有温度也风扇的图”；相信您看后就知道怎么回事了。\n下面是我对关于温度和风扇监控的一点想法：\n\n 主板的芯片能提供这些数据的访问给操作系统  操作系统上有sensors这个命令工具用来采集这些数据  有合适的脚本分析上面命令的输出数据转换成能被监控工具（ganglia， cacti，nagios， opennms）采集的格式等  往往这两个参数并不是监控工具的默认采集数据，所以需要扩展采集工具的采集集合，收集并保存这些数据。  在监控工具如Ganglia中显示这些数据，当然如果有自动报警功能就好了，可以及时通知管理员给服务器消暑：） Ganglia是最好的网格或者群集的监控软件，不过当你用它的使用也要注意到下面这个问题：\nWhat does Ganglia not provide?\nGanglia does not attempt to address service monitoring or reporting (unlike Nagios). So far, we have not come across a single monitoring solution that addresses all of our needs effectively.\n上面所说的服务监控是说，它的特点不是想Nagios和OpenNMS那样对服务器系统做非常全面细致的监控，它默认的监控指标比较少不过对于监控网格或者群集这种数量巨大的对象来说这些比较经典的指标也够用了，特别是对服务器的可用性，CUP、RAM，网络资源利用率和工作负载等数据的采集也比较够用了。如果你使用它来监控数量不是很多服务器的话，你可以使用它的可扩展性加入任何想监控的KPI。我最喜欢的还是它能把服务做分组，而且垂直的方向上可以加N层的嵌套；这种组织方式能比较好的适用于业务系统众多而复杂的数据中心。  ",
    "ref": "/2008/06/15/monitoring-temperature-and-fan-speed-using-ganglia/"
  },{
    "title": "相逢一笑告乃翁",
    "date": "",
    "description": "",
    "body": "感謝劉征邀請我來這兒。我叫段逸時(Austin Tuan)，網路上常用的暱稱是 PowerOp。\n我爺爺在湖南衡陽生長，後來從軍，跟著國民政府軍隊征戰。爸爸是蘇州生的，在台灣台中長大。媽媽則是泰國曼谷生長的華僑。\n我在台灣台中生長，現在跟老婆、兩個女兒在台北生活。\n我的工作是在電信業做網路管理，主要是 Fault and Performance Management。之前在台灣安捷倫做了快七年，現在則是在 OSI 做了快一年。\n興趣是 自由軟體 / 開放原始碼軟體 。\n==\n標題是兩首詩詞湊出來的，應該不難猜吧 :p\n",
    "ref": "/2008/06/12/e79bb8e980a2e4b880e7ac91e5918ae4b983e7bf81/"
  },{
    "title": "A follow-up post",
    "date": "",
    "description": "",
    "body": "I\u0026rsquo;d like to know about this.\n[poll id=\u0026ldquo;2\u0026rdquo;]\n",
    "ref": "/2008/06/09/a-follow-up-post/"
  },{
    "title": "zenoss opennms comparison/比较",
    "date": "",
    "description": "",
    "body": "在我做任何比较之前还是先看看Wiki上对一系列网管监控软件的比较，源网页地址在 http://en.wikipedia.org/wiki/Network_monitoring_comparison\n上面一共列出了12中不同的开源软件，从13个方面以矩阵的方式来做比较。\n\nNagios和Cacit都是比较老牌的开源网管软件；OpenNMS是稍微点出现的项目，它集成了前两者的部分优点，界面是Java的界面，后台的自动发现机制非常的方便。Zenoss是一个比较年轻的项目，所谓长江后浪推前浪，它是纯python语言编写的一个软件，架构非常的不错，而其界面做的非常好，面向对象编程的理念处处可见。从根上可以看出它们的主要编程语言各有不同，这也决定了它们的特点和发展方向的不同，这里仅以此作为一个见到的比较和总结。其实我想写一个更好的比较表，如果您感兴趣的话请留言，我们可以一起做一个更好的比较。\n",
    "ref": "/2008/05/31/zenoss-opennms-comparison/"
  },{
    "title": "Zeuux Free software summit @Tsinghua",
    "date": "",
    "description": "",
    "body": "现在我坐在清华主教学楼里等待这个自由软件大会的开始。Zeuux社区组织在发一些免费的书籍和及时贴。我也领了几个，在笔记本上贴了三个：\n1）GNU\\Linux inside\n2)GNU牛头\n3）GNU\u0026amp;Linux the dynamic duo。\n这次也将会见到Richard Stallman，听听他今天能讲点什么。\n现在会议还没有开始，已经有很多学生来此等候，好像GPL v3的 T恤比较强手，很多学生都在找自己的号。为了获得Richard签名的人可以购买一本他的文件，附送一件这样的T恤，会后即可获得签名。\n发现www.gnu.org网站的速度非常慢，几乎打不开，通往自由的路其实是艰难的:P\n写在活动之后：\n现在已经是晚上11点，我坐在电脑前上网，把今天活动的收获整理一下。我做的第一件事情是把我的blog的标题改了，logo随后在改。从“LiuZheng\u0026rsquo;s OSS Blog” 到 “LiuZheng\u0026rsquo;s Free Software Blog”。Richard S.的一席话对我来说可谓醍醐灌顶了。我以前把Linux和open source软件都看做就是自由软件，可谓是一叶障目不见泰山。Richard今天把他对GNU所作的所有相关工作都做了一个回顾，并解释了Linux其实是Gnu-Linux的一部分而以，还介绍所谓开源软件的真实来由。这也让我能更加理解他彻底不同意Sun开源策略的原因。Linux的发展和产生依赖于Gnu项目下的所有自由软件，Richard认为如果Linux的发明人没有在当时创造出Linux内核的话，一个GNU free operation system kernel也早晚会产生。我认为Linux的产生也是有他的必然性，它是在软件发展历史上应运而生的；由于它站在了前人的肩膀上，能整合所有相关的自由软件，从而风靡一时，甚至声明远胜GNU。Richard认为开源软件是商业公司利用自由软件谋利的一种手段，open source这个词在商业公司市场宣传的运作下，声势也掩盖了GNU。我发现其实我的一些认识也一直受到潮流的影响，如果我是和Richard站在同一条战线的话，我可以说彻底的被潮流带到沟里去了。总之Richard给我一个清楚的自由软件的发展脉络。他几乎是一个斗士，坚定的认为：任何一个软件用户都要保护自己的自由，彻底的抵制任何私有软件；他把MS，RealPlay，Adaobe等商业软件批斗的非常狠。到结束时，他穿上他那标志性传道士的行头就地化身为自由软件教堂的一个圣徒，来呼唤和号召大家一起行动起来加入自由软件的行列。说实话我作为一个商业软件的从业人员，站在我个人立场上我很难说我是否要站到Richard的行列里，很难做到彻底的变成一个自由软件的卫道士。虽然现在可以说立场还是糊涂的，不过总算头脑边的清醒了，我应该会以这样的头脑来静静看待软件世界即将到来的变革吧！\n",
    "ref": "/2008/05/31/zeuux-free-software-summit-tsinghua/"
  },{
    "title": "Ganglia install and configure",
    "date": "",
    "description": "",
    "body": "我准备安装的版本是ganglia-3.0.7 ， 参考的安装文档是http://www.linuxsir.org/bbs/thread309837.html\nrpm的安装会比较省事。rpm安装都会很正常，不过在Suse下面需要注意一下两点：\n\n gmond和gmated的启动脚本不是rpm包中默认装上的那个，那个脚本适用于redhat linux；下载源码编译之后在gmond/ gmated/的文件夹里有后缀为 .SuSE的哪两个文件才对。  rpm吧gmated的web界面默认安装路径是/var/www/http/ ，SuSE下的apache的路径是 /srv/www/htdoc/；安装完后copy或者连接过来 配置：\n gmond.conf 更具我参考的安装文档产生这个文件的命令是 gmond -t \u0026gt; /etc/gmond.conf；rpm安装包中有这个文件，如果需要恢复到默认状态可以使用这个命令。  gmated.conf 是服务器端的主要配置文件，详细阅读一下源码包中的那个html文件对这个文件的配置会有帮助 安装过程中出现的问题如下：在启动gmond的时候启动失败，debug一下可以看到下面的错误。\nsles:~ # gmond \u0026ndash;debug=9\nslurpfile() open() error on file /sys/devices/system/cpu/cpu0/cpufreq/scaling_max_freq: No such file or directory\nudp_recv_channel mcast_join=239.2.11.71 mcast_if=NULL port=8649 bind=239.2.11.71\nError creating multicast server mcast_join=239.2.11.71 port=8649 mcast_if=NULL family=\u0026lsquo;inet4\u0026rsquo;. Exiting.\n在所有虚拟机（host-only 网络设置）上都遇到这个错误。一次一个NAT网络的虚机上正常\n至今觉得这是一个网络的问题，还没有想出正确的配置和解决方法。如果您有什么好建议请留言。  ",
    "ref": "/2008/05/24/ganglia-install-and-configure/"
  },{
    "title": "ISO open source software",
    "date": "",
    "description": "",
    "body": "There are some projects do have ISO file for downloading. That means you could run this solution with in 20 minutes on a physics machine or a vmware session. You can just download this ISO image file and burn it on a blank cd; then you will insert it into DVD/CD driver of your target machine, after press few enter keys; You finally got all software on this box. Reboot this machine, you get everything up an running on it; including a Linux OS and everything which the solution depends on.\nI had tested out only few of ISO open source software.\n\n CactiEZ  OSSIM It looks like actually two open source software collections. Let\u0026rsquo;s look inside those ISO files, it is a bootable Linux install disk with all necessary software.\nCactiEZ has following parts:\n   Cacti and plugins (Discovery, flowviewer, mac Track, nTop, syslog, Thold, etc..)  Nagios CactiEZ is focusing on Cacti. Now it does not provide free download. You will pay few $$$; it\u0026rsquo;s a great ISO open source software and worthy to pay for Jimmy\u0026rsquo;s effort. I have a old version for you to download. click here. 下载 cactiez\nThere is architecture picture of OSSIM. OAAIM use sensor for collecting data over network. A typical OSSIM Sensor configuration would do the following functions:\n  \n IDS (Snort)  Vulnerability Scanner (Nessus)  Anomaly Detection (Spade, p0f, pads, arpwatch, RRD ab behaviour)  Network Monitoring and Profiling (Ntop)  Collecting from local routers, firewalls, IDS’s, etc  It could even act as a Firewall I love ISO open source software, for the following reasons:\n   Easy to install on a physic machine.  Time Saving. You just use it right away after you load everything and reboot that machine. Linux is basically a ISO based open source software. If you know more others, not Linux; please let me know.  ",
    "ref": "/2008/05/16/iso-open-source-software/"
  },{
    "title": "Enterprise cloud computing",
    "date": "",
    "description": "",
    "body": "http://www.datacenterknowledge.com/\n这个网站还是不错，有很多关于数据中心的知识。它应该主要是收集业内在该领域里新咨询，先收录一下，回头慢慢学习。\n这个vido我觉得也可以学习一下。IBM和Google结成联盟开展企业云计算方面的研究，可能会建立“IBM-Google cloud ” 这个云会运行在Linux上，使用Xen 做系统虚拟和Apache Hadoop。同时Google和IBM都有自己巨大的数据中心，还不知道它们将来的研究成果会运行在谁家的设备上，让我们拭目以待。\nTips：\n有些网络视频比较大，在线看如果网速比较慢的话可能不能正常浏览。很多下载视频的工具好像都是要收费注册的，否则只能下载60％。我发现的一个方法是，把视频网址输入到这里 http://www.techcrunch.com/get-youtube-movie/ 它会给你生成一个http的下载连接，点击后一般的http下载工具就能下整个视频了，之后用视频浏览的软件查看，正在缓慢下载上边的视频。不知道你有什么好方法或者是工具可以推荐呢？\nhttp://youtubedownload.altervista.org/ 是我现在所使用的，不过下载的太慢了，不能支持多线程下载。\n",
    "ref": "/2008/05/12/enterprise-cloud-computing/"
  },{
    "title": "Install Oracle 10.2.01 on OpenSuSE 10.3",
    "date": "",
    "description": "",
    "body": "A) Download 10201_database_linux32.zip from Oracle website.\nB) Download 10gR2_openSUSE102_introduction.pdf and ora.rpm from ftp ftp.novelŀcom\nC) Install Oracle, following quick steps:\n1. Install openSUSE 10.2 with \u0026ldquo;C/C++ Development\u0026rdquo; selection.\n2. Download and Install orarun package.\n3. Enable and set password for newly created user oracle by orarun.\n4. Set updated kernel parameters by executing /etc/init.d/oracle start.\n5. Download and unzip Oracle 10gR2 Database SW.\nEdit file database/install/oraparam.ini to add \u0026ldquo;SuSE-10\u0026rdquo; to line #39.\n6. login as user oracle and run Oracle Universal Installer \u0026ldquo;database/runInstaller\u0026rdquo;.\nTroubleshooting:\n1) installer error:\n\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\noracle@Martin:~/database\u0026gt; ./runInstaller\nStarting Oracle Universal Installer\u0026hellip;\nChecking installer requirements\u0026hellip;\nChecking operating system version: must be redhat-3, SuSE-9, redhat-4, UnitedLinux-1.0, asianux-1, asianux-2 or SuSE-10\nPassed\nAll installer requirements met.\nPreparing to launch Oracle Universal Installer from /tmp/OraInstall2008-05-08_09-11-56AM. Please wait \u0026hellip;oracle@Martin:~/database\u0026gt; java: xcb_xlib.c:52: xcb_xlib_unlock: Assertion `c-\u0026gt;xlib.lock' failed.\n\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\nSolution :\n\n export LIBXCB_ALLOW_SLOPPY_LOCK=1  run runInstaller again 2) 在安装完成末期,需要root用户运行两个脚本，完了之后，我遇到一个错误对话框，点击过去之后好像没有发现安装失败，安装目前正常\nMore SQL scripts:\nhttp://cs-netlab-01.lynchburg.edu/courses/Oracle/SQLPlus.htm\nSQL\u0026gt; CREATE TABLESPACE AMP\n2 DATAFILE \u0026lsquo;/opt/oracle/oradata/orcl/AMP.dbf\u0026rsquo; SIZE 200M;\nTablespace created.\nSQL\u0026gt; CREATE USER AMP IDENTIFIED BY ca1234\n2 DEFAULT TABLESPACE AMP\n3 QUOTA UNLIMITED ON AMP;\nUser created.\nSQL\u0026gt; GRANT CONNECT, RESOURCE TO AMP;\nGrant succeeded.\nSQL\u0026gt; GRANT CREATE SESSION, CREATE TABLE TO AMP;\nGrant succeeded.\nHow to start oracle em manully?\n可能出现的错误如下，没有ORACLE_SID的 环境变量, 可能网络地址和环境发生变化,比如主机名修改等.\noracle@Martin:~/product/10.2/db_1/bin\u0026gt; ./emctl start dbconsole\nTZ set to PRC\nEM Configuration issue. /opt/oracle/product/10.2/db_1/localhost_orcl not found.\noracle@Martin:~/product/10.2/db_1/bin\u0026gt; ./emctl start dbconsole\nTZ set to PRC\nOC4J Configuration issue. /opt/oracle/product/10.2/db_1/oc4j/j2ee/OC4J_DBConsole_localhost_orcl not found.\n修正方式:\noracle@Martin:~/product/10.2/db_1/oc4j/j2ee\u0026gt; cp -R OC4J_DBConsole_Martin.bmc.com_orcl OC4J_DBConsole_localhost_orcl\noracle@Martin:~/product/10.2/db_1\u0026gt; cp -R Martin.bmc.com_orcl/ localhost_orcl\noracle@Martin:~/product/10.2/db_1\u0026gt; bin/emctl start dbconsole\nTZ set to PRC\nOracle Enterprise Manager 10g Database Control Release 10.2.0.1.0\nCopyright (c) 1996, 2005 Oracle Corporation. All rights reserved.\nhttp://Martin.bmc.com:1158/em/console/aboutApplication\nStarting Oracle Enterprise Manager 10g Database Control \u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;\u0026hellip;. started.\n\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\nLogs are generated in directory /opt/oracle/product/10.2/db_1/localhost_orcl/sysman/log\n启动了后访问: http://localhost:1158/em/\n手工启动Oracle实例的方法\n1) sqlplus\nsqlplus /nolog\nconnect sys/manager as sysdba\nstartup\n2) rcoracle\n需要修改如下几个文件：/etc/oraInst.loc /etc/oratab / /etc/sysconfig/oracle /opt/oracle/product/10.2/db_1/bin/dbstart /usr/sbin/rcoracle 修改这些文件中的路径等信息知道 rcoracle start 命令不出错为止。  ",
    "ref": "/2008/05/08/install-oracle-102-on-opensuse-103/"
  },{
    "title": "Deploy asset management solution",
    "date": "",
    "description": "",
    "body": "\nThis is my second virtual appliance, it suppose to work for production. This is a 100% open source solution for inventory/asset management, it including OCS Inventory NG and GLPI. I encourage you to deploy it in your school or company.\nAbout virtual appliance / 关于此虚拟应用\n  OpenSuSE 10.2 (root password is martinliu)\n  LAMP+Perl\n  OCS Inventory v1.02 RC1\n  GLPI v0.70.2\n  bridged network\n  You can download it from below.\nDownload it 下载 This source is not available any longer. I will offer it by DVD. 这个地址已经无法下载，请关注我即将推出的DVD版虚机。\nThanks BigYue.com for donated upload space. 感谢**BigYue.com****的空间。**\nRun Server / 运行管理服务器（\u0026gt;=2GB RAM）\n  un-zip the image on a computer which will be network with for any managed nodes to upload inventory information. This host machine should have at least 2GB RAM.\n  Download a wm player and install it.\n  Open virtual machine and power on.\n  At top of boot screen, you will find the ip address of this vm I assume you have a DHCP server on network. Otherwise you have to configure network manually for this vm.\n  Access to the home page (http://IP_address_Of_vm/) which I made it for you. On this page, there are login information and entry points.\n  Now you have a full function asset management solution up an running. You will configure security for the whole system before you do more work with it. You should change the password for root and mysql. Mysql have a blank password. After you done this, you must re-configure database connection for both OCS Inventory NG and GLPI accordingly. Please refer to administration guide.\nDeploy Agent / 安装部署代理\n  For any Unix-like system : you will manually install on each of target computer. Following the installation guide from OCS inventory NG.\n  For MS windows system: You can do manually installation too. Also you could distribute agent via AD domain policy automatically, all target machines must logon the AD domain at least once in order to get agent package installed. Agent is running as a windows service if it is installed properly; inventory information will update timely to the server. The Agent package can be copied to a USB key. You can use it for collecting inventory information for off-line computers, or a computer which you wont have any piece of OSS installed on it. I\u0026rsquo;m kidding, I guess you love to run OSS on any of your computers, PS: the more the better.\n  Management Asset / 管理IT资产\n  Synchronize inventory data from OCS Inventory NG to GLPI. GLPI can do it at interval that you set hourly or daily.\n  Those two OSS are just easy to use. You will still read some necessary documents on their web. 请阅读尽可能多的使用手册\n  As long as you use this virtual appliance, I can see your smile face. Don\u0026rsquo;t forget give me comment below and let me know how many nodes do you manage.\n  Enjoy and have a lot of fun.\n  Support / 支持 This virtual appliance comes with ABSOLUTELY NO SUPPORT. I will try my best to support you, but questions are not guaranteed for a quick answer. I strongly recommend you will go to open source community when you run into any error. I believe you can get support and might help others too. If you improved this virtual appliance, I am looking forward to see your share. I\u0026rsquo;d like to hear any good idea from you.\nNotes:\nFrom wikipedia: Comparison of open source configuration management software ",
    "ref": "/2008/04/28/deploy-asset-management-solution/"
  },{
    "title": "如何获得OSS支持？",
    "date": "",
    "description": "",
    "body": "这周我在繁密的出差当中，偶尔能用Blackberry看一眼邮件，不过完全没有可能回答读者任何问题。最近这两周有愈来愈多的博客读者给我发了邮件，问我了一堆问题，我很希望能给他们一个好的答案，不过这种可能性太小了，尤其是在这样的时间里。通过他们焦急的情绪，我忽然想到这个问题：如何获得开源软件的相关支持？其实这也是我的一个问题。于是乎我想到下面的一些东西。\n**搜索 **是最主要的一个途径，你会发现很多一般问题都能获得答案，仔细选择和尝试不通的关键词\n**邮件组/论坛 **每种开源软件都有这两种或者至少一种用户支持方式，其实这是用户互助的方式，用户之间的帮助往往更快。这些就是社区的载体，有些邮件组比较活跃，有些论坛比较活跃；例如：OpenNMS的邮件组就非常活跃，我订阅了其中的几个子项，问出问题往往能得到很快回复，其实OpenNMS的人每周有不人负责回答问题；Cacti的论坛就相当好，那里也是用户直接互相同享模板的主要地点，解决问题的功能也相当好。很多国内中文论坛也非常好，推荐一个http://www.itnms.net/ 更多的还需要你自己去发现。\n**线下用户团体 **我参加国BLUG的线下活动，感受非常深刻，当你面对很多来自不同背景不同技术特长的OSS认识的时候，找到合适的高手并不是困难的事。不要躲在网络后面捣鼓开源软件，走到现实世界来享用它吧。\n**商业支持 **有些开源软件有两个网址 oss.org 、oss.com；往往.com网址上有商业支持的说明，商业和开源并不矛盾，更具你的需求购买商业支持也是一个非常现实的方式。\n**聪明问问题 **如果你遇到问题，首先要学会正确描述问题，问题的描述信息包括：软件版本、运行环境、出错情景，以及其它任何关键或者有用的信息。很多软件都运行在某种技术堆栈的最高层，下层的环节包括OS、DB、Web、Php语言等；你应该清楚如果是这些环节出错，那么你该去响应的社区求助，要问对人，不要问错人，也不要问傻问题。\n**友好的交流 **每当我遇到一些开源高手的时候，幸运的是他们非常的nice，我可以轻松的问任何问题，无论简单、还是复杂。技术思想的沟通应该是一种愉快和友好的体验，保持一种谦虚正常的心态，这是自身素质和修养的表现。\n**语言 **对所有非英语人士，英文是必须要会的，英语不灵的话需要好好补习补习。\n**支持我的读者 **推荐通过留下comment的方式问你的问题，发给我邮件我很容易忽略，而comment是我必须处理的。如果我有答案的话，我会在3内给出回应；超过3天的话表明，很可能我目前还没有一个合适的答案。在留下问题的同时，一定多面出击寻找答案，别在这守株待兔。\n**关于此博客 **定义如下：技术型、记录型、日志型、开放型和共享型。对我自己来说，它是我记录研究开源软件的一个载体，是我向需要这方面信息的人分享的一个窗口。它不具有任何商业性，不承诺提供任何程度的支持。通过这个博客有相投兴趣的人也能相互交流。\n",
    "ref": "/2008/04/24/e5a682e4bd95e88eb7e5be97osse694afe68c81efbc9f/"
  },{
    "title": "Open Source Ticket Request System - OTRS 2.2.6",
    "date": "",
    "description": "",
    "body": "I made a OTRS 2.2.6 virtual machine for anyone who wants to test both OTRS and OTRS::ITSM. It was built on OpenSUSE 10.2, including OTRS 2.2.6 and OTRS::ITSM 1.0.94. OTRS::ITSM implements ITIL (R) focused IT service management. OTRS::ITSM 1.0.94 is still on Beta, you might have some bugs when using this virtual machine. Please download from my box.net, if you have an comment please just let me know. I\u0026rsquo;d like to invite you to improve this virtual machine if you have any good ideal.\nDownload it from here 点此下载。 This source is not available any longer. I will offer it by DVD. 这个地址已经无法下载，请关注我即将推出的DVD版虚机。\nThanks BigYue.com for donated upload space. 感谢**BigYue.com****的空间捐助。**\nCredentials 登录密码如下\n  OpenSuSE 10.2 : username / password is \u0026ldquo;root/ca1234\u0026rdquo;\n  MySQL : username / password is \u0026ldquo;root/ \u0026quot;\n  OTRS : admin username and password is root@localhost/root\n  Run 运行压缩文件中的虚拟机\n  Download and install VM Player, the machine should have 1GB RAM at least.\n  Un-zip OSS.rar in a partition, freespace must be 2.5+ GB.\n  Double MartinLiu.cn.vmx and power on this machine.\n  Click \u0026ldquo;keep\u0026rdquo; and OK button when you get a popup box。\n  The network connection of virtual machine is \u0026lsquo;bridged\u0026rsquo;. You will see the ip address of this virtual machine at 5th line one the top of boot screen. NOTE: you should have DHCP server on your network.\n  Access 访问虚拟机\n  SSH to it.\n  Agent login page: http://ip_address/otrs/index.pl\n  Customer login page: http://ip_address/otrs/customer.pl\n  Tips of OTRS installation 安装经验\n  Apache should have perl mod, configure perl for apache before you install OTRS. 这是一个Perl写的程序，所以在安装之前最好吧apache上的perl配置好，确认apache能运行perl的东西\n  Make sure your database accepts packages over 5 MB in size. Increase max_allowed_packet in my.cnf to 20MB. 修改my.cnf中的max_allowed_packet 参数到20MB，否则ITSM的包安装有问题。\n  OTRS需要一写附件的perl包的支持，手头最好有操作系统的安装dvd或者直接从网上安装。\n  Usage 用途\n  You can use it for any purpose, if you need any support you will contact OTRS。你可以用于任何用途，本博客不提供技术支持，请联系OTRS的邮件列表。\n  ITIL training, OTRS::ITSM implements ITIL (R) focused IT service management. 可以用于ITIL的培训，它能演示：incident management, problem management, configuration management 等。\n  This virtual machine comes with ABSOLUTELY NO WARRANTY. DO NOT USE it for production. 仅供测试使用，切勿用于生产环境。\n  If you like OTRS, you may try Request Tracer\n今天一个网友告诉我另外一个开源的类似系统Request Tracer ，有空的话回头也试试。\n",
    "ref": "/2008/04/21/open-source-ticket-request-system-otrs-226/"
  },{
    "title": "Clouds are coming",
    "date": "",
    "description": "",
    "body": "最近两周最吸引我的TAG是这个词“cloud computing”。在我前一个文章中稍微展望了一下云计算的前景“云计算吧电能转化成计算能力，然后向用电一样的来使用，我们甚至不需要使用PC这样的个人信息话设备来管理我们的信息，所有的信息和信息的处理都在云上发生”。在了解了更多的信息之后，这些可能实现，但是这种巨变需要时间，而且可能是很长时间；清醒之后不得不佩服Google在这方面的宣传。\n理性认识云计算的简单方式，扫扫盲：\n\n 阅读一下wikipedia对‘cloud computing’的解释  听听John Willi的两个Podcast  多看看非google来源的信息：）  读读这个GRIDtoday的文章 \u0026ndash; \u0026ldquo;Clouds are Looming and We Love It\u0026rdquo; 很多厂商都在参与这个热点，open source也要加油，期待开源在这个领域的发展。  ",
    "ref": "/2008/04/18/clouds-are-coming/"
  },{
    "title": "Using Ganglia for cluster and grid monitoring",
    "date": "",
    "description": "",
    "body": " Ganglia是一个用来监控群集和网格计算环境的软件。它是可以扩展的分布式监控系统，它基于多播协议，数据存储和传输的格式都是基于开源的标准：XML/XDR/RRDTool/APR/Apache/php等。\n应用Ganglia的几个理由：\n 在一个点上监控包含很多服务器的群集，单个cluster内服务器的数量比较多，需要从整体看某个cluster的可用性和性能，也要能看到单独某个机器的运行情况。 监控分布式的cluster环境，例如跨网段和地域的灾备的环境。 需要监控系统能分N级的查看方式，以银行为例：北数据中心\u0026ndash;\u0026gt;网络银行业务\u0026ndash;\u0026gt;个人网银系统\u0026ndash;\u0026gt;web server 群集\u0026ndash;\u0026gt; WebSvr001；可以按业务逻辑和系统架构逻辑。 需要724365的监控整个系统，能得到可用性、性能和容量等方面的报表。  应用Ganglia的几个好处：\n 监控能力的无限扩展，被管理服务器数量达数千个甚至根多。 纯web前端，apache和php的应用页面方便定制 强壮的系统结构，并且具备可以任意扩展采集数据KPI的特点 适合高性能计算或者网格计算环境。  Ganglia应用需要注意的方面：\n 在每一个节点上需要部署一个代理程序，考虑到对代理配置的变更的工作量，在部署代理之前，需要彻底的分析需求，尽量减少部署过程中配置变更带来的多于调试的工作量。 部署后期的变更工作，如果比较频繁的话将导致后台维护工作量增大，可以考虑使用一些开源的软件分发和自动化配置管理的工具。这些配置的初始化工作可以与OS的安装部署工作一起考虑。  它被很多大学和专业机构研究并使用，所以有非常多的专业文档可以参考，哪行文档多分析了Ganglia的系统架构和特点，多系统的原理介绍的非常细致。下面是我收集的几个关于这个软件的文档请参考。并且在它们的网站上也可以看到很多相关的资源连接，都是非常好的实施方面的详细文档。\nIf you need more detail please take look those documents below.\n",
    "ref": "/2008/04/16/using-ganglia-for-cluster-and-grid-monitoring/"
  },{
    "title": "DO you have a google App Engine?",
    "date": "",
    "description": "",
    "body": "There is what I got from http://appengine.google.com/\nThanks for checking in! When space in the Google App Engine preview release becomes available, we'll notify you by emailing liuzh66@gmail.com\nDon't worry--you don't have to wait to start building applications! You can get started now by downloading our SDK and reading through our documentation. \nI read a post last night, Developers, start your engines Even I am not a developer, I definitely look forward to sing up appengine. . But I can not have it, that\u0026rsquo;s pity. Let\u0026rsquo;s see how to create a \u0026lsquo;hello world\u0026rsquo; appp on google appengine.\nLet me see your app on google. See more on http://appgallery.appspot.com/\nGoogle App Engine是一个开放的应用运行平台，它提供给你的应用无限的扩展性，并免费的在后台运行。记得以前和同事曾经有过一个话题“GOOGLE的基础架构是怎么搭建的？”，google的成功和它对基础架构资源的结构方式是密不可分的，大家都想知道这个秘密。不过现在好像你不需要模仿并拥有一个相同或者相似的了，你有可能免费访问并使用了。Google把它定义为一种服务，和邮件服务好像没有任何区别。IT基础架构实现和提供的是计算资源，而以后随着‘云计算’等技术的实现，使用这种资源可能会想使用电一样方便。不需要拥有发电厂，你的电灯依然会亮。\n",
    "ref": "/2008/04/10/do-you-have-a-google-app-engine/"
  },{
    "title": "Get right-size of OSS",
    "date": "",
    "description": "",
    "body": "6yeas ago, I had a open source talk with my friend Tom Chen. The topic was \u0026quot; does oss suppose to work for large enterprise for mission critical business?\u0026quot; Until last week, I thought I found answer by myself; the OSS does works for bank business in China. During last week, I deployed my company\u0026rsquo;s product on CCB\u0026rsquo;s machines. Those machines are part of e-banking system, 1/4th of them are on Redhat Enterprise Linux 4 update6. As we all know CCB is one of big four bank in China, those Linux machines are running Apache for web-tier of e-banking system. A 160MB installation image was ftp to every managed nodes, untar it then ran a same install script. I felt Linux boxes took less time then other HP-UX boxes, they are similar servers I mean similar hardware. Actually CCB have many Linux servers all over the country then I touched at this time.\nI had a business travel in Urumchi lat year. I met another bank customer there. When we were talking about what kind of OS they have. They impressed me very much. They said part of servers are on SuSE Enterprise Linux, they are just virus-free and lower maintenance cost then M$ Windows. They are just use those SuSE Linux to running IBM DB2 database for some bank business. They like Linux, but not use it everywhere. I didn\u0026rsquo;t tell them that is my favorite Linux distribution. Just look back 5 years, I would say more and more companies are using OSS or they are considering have more OSS for their business.\nLet\u0026rsquo;s get back to my topic: what OSS could be good for you? Do you have confidence for have more OSS for your business system? I think you need to just have the right-size of OSS. You have to figure by yourself. The following are my suggestions:\n\n OSS adoption might take years, you should have a plan.  Starting from one single on-going project, you could migrate all or part of a business system to OSS(Linux for OS, Tomcat for mid-tier, or what every you\u0026rsquo;d like to use)  Monitoring the entire IT by same way by 24 hours. You must have availability and performance report for every node. Then you could analyses those history report to figure out if OSS does a good job or not. A incident report of whole IT support org is highly recommended.  Having more OSS engineers might speed up the process you move forward to OSS. If you like my thought in this post, you would like to see this old one.  ",
    "ref": "/2008/04/05/get-right-size-of-oss/"
  },{
    "title": "PostgreSQL基本操作指南",
    "date": "",
    "description": "",
    "body": "安装\n我的安装环境是虚拟机下面安装的CentOS4.4；在安装的时候需要注意的是：在安装选择的时候PostgreSQL一共有十几个可选的包，把可能会用到的包都尽量选中，否则就要手工去安装了，手工解决包之间的依赖关系烦啊。从光盘上装的好处就是它自己帮你把用户和启动脚本建好了，安装后需要检查如下两个文件：1）/etc/init.d/postgresql是否存在；2）/etc/passwd里面有没有postgres用户。\n启动数据库\n第一次启动，用root用户登录，运行命令：[root@RBA init.d]# service postgresql start ；如果需要数据库在系统启动是就启动的话需要运行：\n[root@RBA init.d]# chkconfig postgresql on ； \n检查结果\n[root@RBA ~]# chkconfig --list postgresql\npostgresql 0:off 1:off 2:on 3:on 4:on 5:on 6:off \n数据库管理\n先切到postgres用户 su postgres\n新建一个数据库 createdb amp\n新建一个超级用户，需要在shell下运行：\nbash-3.00$ createuser amp\nShall the new user be allowed to create databases? (y/n) y\nShall the new user be allowed to create more new users? (y/n) y \n链接到数据库之后，确认以下：\namp=# \\du\nList of database users\nUser name | User ID | Attributes\n-----------+---------+----------------------------\namp | 100 | superuser, create database\npostgres | 1 | superuser, create database\n(2 rows) \n给用户加一个密码：\namp=# ALTER USER amp with password 'amp';\nALTER USER \n其他参考信息\n# Put your actual configuration here\n# ----------------------------------\n#\n# CAUTION: The default configuration allows any local user to connect\n# using any PostgreSQL user name, including the superuser, over either\n# Unix-domain sockets or TCP/IP. If you are on a multiple-user\n# machine, the default configuration is probably too liberal for you.\n# Change it to use something other than \"trust\" authentication.\n#\n# If you want to allow non-local connections, you need to add more\n# \"host\" records. Also, remember TCP/IP connections are only enabled\n# if you enable \"tcpip_socket\" in postgresql.conf.\n# TYPE DATABASE USER IP-ADDRESS IP-MASK METHOD\n#访问来源 数据库 用户 IP-地址 子网掩码 认证方式\nlocal typhoon typhoon md5\n#对于来自本地的访问，数据库“typhoon”对用户“typhoon”采用“md5”加密口令认证\nlocal typhoon all reject\n#对于来自本地的访问，数据库“typhoon”对上面没提到的所有用户无条件拒绝认证\nhost typhoon typhoon 255.255.255.255 127.0.0.1 md5\n#对于来网络的访问，数据库“typhoon”对用户“typhoon”，如果提出访问的是本机，采用“md5”加密口令认证\nhost typhoon all 0.0.0.0 0.0.0.0 reject\n#对于来网络的访问，数据库“typhoon”对上面没提到的所有用户，不管提出访问的哪台机器，也不管它来自哪个子网，无条件拒绝认证\nlocal all all md5\n#对于来自本地的访问，上面没提到的数据库对上面没提到的所有用户采用“md5”加密口令认证\nhost all all 0.0.0.0 0.0.0.0 md5\n#对于来网络的访问，数上面没提到的数据库对上面没提到的所有用户，不管提出访问的哪台机器，也不管它来自哪个子网，采用“md5”加密口令认证\n########################################\n# Others are all denied 其他访问一概无条件拒绝\nlocal all all reject\nhost all all 0.0.0.0 0.0.0.0 teject\n########################################\n########################################\n# All denied permissed, not safe\n# 对所有访问都信任，太不安全，被我禁止掉了，只作为参考\n#local all all trust\n#host all all 0.0.0.0 0.0.0.0 trust\n########################################\n这些认证的规则是从上到下一条一条加载的，要注意的是，里面的“all”并不是真正意义上的“所有”，只是前面的规定中没有提到的那部分。个人感觉用“other”也许更恰当。\n这样，最终的结果是：\n所有用户都能通过加密口令访问“typhoon”以外的数据库，但是只有用户“typhoon”能以加密口令访问数据库“typhoon”。\n操作篇\n[客户端基本连接操作]====================\n*查看PostgreSQL的系统表：\n(摸索/查找中)\n*终端登录：\npsql -l[主机名/IP] -d[数据库名] -U[用户名]\n*连接到另外一个数据库：\n\\c [数据库名]\n*断开终端：\n\\q\n========================================\n[基本用户管理]==========================\n*添加用户：\ncreate user [用户名];\n*修改用户密码：\nalter user [用户名] with password [口令];\n*删除用户：\ndrop user [用户名];\n*查看用户信息：\n(摸索/查找中)\n========================================\n[基本数据库操作]========================\n*创建数据库：\ncreate database [数据库名];\n*查看数据库列表：\n\\d\n*删除数据库：\ndrop database [数据库名];\n*修改数据库的所有者：\n(摸索/查找中)\n========================================\n[数据库内基本操作]======================\n*给予某用户在某数据库创建表的授权：\n(摸索/查找中)\n*收回某用户在某数据库创建表的授权：\n(摸索/查找中)\n创建表：\ncreate table ([字段名1] [类型1] ,[字段名2] [类型2],......);\n*查看表名列表：\n\\d\n*查看某个表的状况：\n\\d [表名]\n*重命名一个表：\nalter table [表名A] rename to [表名B];\n*修改表的所有者：\n(摸索/查找中)\n*删除一个表：\ndrop table [表名];\n========================================\n[表内基本操作]==========================\n*在已有的表里添加字段：\nalter table [表名] add column [字段名] [类型];\n*删除表中的字段：\nalter table [表名] drop column [字段名];\n*重命名一个字段：\nalter table [表名] rename column [字段名A] to [字段名B]; ",
    "ref": "/2008/04/03/postsql-basic-admin/"
  },{
    "title": "虚拟让你轻松玩开源",
    "date": "",
    "description": "",
    "body": "开源一般都是谁在玩？我觉得还是开发人员比较多，通常有开发背景的人才会比较轻松的去下载源代码，编译并运行。现在网上有很多能让您轻松搞定开源软件的方法，虚拟技术的发展使我们能更轻松的获取并运行开源的解决方案。向往糖果盒子中放巧克力一样容易。\n最近我收到了几个OTRS的新版发布的新闻邮件。先说说关于OTRS的一些新闻，2008-03-31发布了最新的一个版本 OTRS 2.2.6 (Ipanema)。这个版本是一个2.2.6的安全补丁修复版，修复了一些安全的bug，同时有提供了另外两种语言的支持：土耳其和越南语；当然OTRS是能够支持简繁体的中文的。而且关于语言方面的翻译对照表也是可以自行修改的，可以把流程当中的一些术语翻译成符合你企业实用习惯的名称。OTRS后台能支持非常多的数据库，包括Oracle，MS SQL等非开源数据库，它的核心程序是用Perl写的，这些程序运行在Apache web服务器上，客户端是用的纯web的方式，后台的管理提供Web和命令行两种方式。它的安装对于我来说不是很方便，安装文档中并没有写的很详细需要哪行Perl的包，apache上需要安装哪行Perl相关的东西；不过您对Perl非常熟练的话相信没有这个问题。导致的问题是我在安装了ORTS之后，它或者它的某些程序运行不了。\n总结一下体验开源软件可能的一些步骤：\n\n 安装某个版本的Linux  下载开源软件的安装包或者源码，开发人员可能更多回去下载源码，编译安装  寻找次软件相关的安装文档和攻略，一步一步的照做。  配置系统来满足次软件的安装和运行条件  管理和运行该软件需要的服务，例如MySQL，apache等  运行该软件  继续查看软件的使用文档，学更多内容，体验感兴趣的功能 在这一个过程中可能遇到的问题有：\n   痛苦与重新安装操作系统，往往系统中的一些包会缺少或者版本不符合安装需求，如果对Linux系统包管理不熟练的话这是最容易出现的问题。  痛苦与对底层支持应用的配置和管理，底层依赖的系统服务可能有数据库、web服务器或者应用服务器等；至今记得我第一次被迫在PostgreSQL中创建数据和用户的痛苦  有些OSS项目文档做的非常好，有些不好，那么安装和配置OSS的过程也可能会非常麻烦；毕竟很多配置文件的修改都需要手工修改配置文件   那么如何清除体验OSS的拦路虎，轻松无痛体验OSS呢？ \n应用虚拟技术可能是一个比较好的方式，目前我找到两个比较好的网站能提供OSS虚拟应用下载的，如下所示。\nhttp://www.rpath.com/rbuilder/\nhttp://www.jumpbox.com/\n这两个网站的区别是：JumpBox是提供开源软件包下载和相关服务的，当然下载肯定是免费的；rPath不但提供下载而且能给你空间去攒一个你自己的虚拟应用。\n当然VWMare的网站也能提供这些虚拟应用的下载：http://www.vmware.com/appliances/\n这里不想讨论虚拟技术的好处，不过它确实给体验和应用OSS带来很多方便。我第一次下载的虚拟应用是Zenoss，下载总共花了10分钟，下载的过程当中我在看Zenoss的文档，下载的虚拟机运行起来之后，我做的第一件事情就是运行自动发现网络设备的命令了。\n通过虚拟这个桥梁，更加节约了我们体验和应用OSS的时间。我想这应该是开源和虚拟共同给我们带来的好处，道理很简单如果你下载并且使用一份包含Windows操作系统的应用，而没有给MS交钱的话，那么你就是盗版使用Windows了。更没有人会给你免费安装配置一套商业应用软件。\n那么让我们从体验OTRS开始把，什么是OTRS请参考本博客中的文章。你可以从JumpBox下载并运行OTRS2.2.6，下载地址是：http://downloads2.jumpbox.com/otrs-1.0.1.zip \n",
    "ref": "/2008/04/02/vm-jumpbox-rpath-play-oss/"
  },{
    "title": "化繁为简",
    "date": "",
    "description": "",
    "body": "这几天我对blog做的做多的工作就是找一个好看的Theme。由于受blogspot的影响，所找到的都是黑色两列的；后来觉得样式还是太花哨了，花哨的外表和化繁为简的思想不相投啊。简单并不意味着丑陋，想想Apple就行了，看看它的产品吧，外观上无不简洁大方。\n今天对blog做了一些简化工作：\n\n 对左侧模块的精简，去掉了不需要的模块，把模块标题字数减少。  删除了所有之前下载的Theme，以后就用Wordpress默认的模板。  删除了不用的插件，把Google sitemap插件装好。  导入以前Blogspot里的文章  删除了站内不需要的文件，数据库和配置。 wordpress默认theme是我唯一只能挑出最少毛病的模板，其他的模板总体来说还是可以的，不过总有至少一个让你不能忍受的缺陷，这也成了删除它的不二理由。\n回归wordpress默认theme让我更加关注在它本身的功能上，让我更专心在内容质量上，同时降低了以后的升级工作量。联系一下开源软件(Open Source Software)，OSS也都以简为美，简单而开放让OSS绽放了无限魅力。如果没有wordpress的简单开放，那么就没有全球这么多的bloger天天去网上淘好看的theme和插件了；就不会有这么多的开发人员了，他们的创造使得wordpress魅力绽放。\nOSS基本上都是功能注重型的，开发人员都关注软件的核心功能，OSS的简单开放一定会被人们更加关注。  ",
    "ref": "/2008/04/01/simple-is-everything/"
  },{
    "title": "搬家成功纪念一下",
    "date": "",
    "description": "",
    "body": "纪念一下吧~~~从blogger搬到此处，真的非了很多的周折~\n本博客介绍：\n我曾经有过好多个Blog，其中最喜欢是 http://lzheng.blogspot.com。在这个Blog之前我曾经在chinaunix.net上有过两个blog，一个 okwiner.cublog.cn,后来有专门为OpenNMS新开了一个 opennms.cublog.cn； 其实对这两个blog更新的还是挺多的，特别是第一个CUblog。不过后来，还是觉得google的blog有非常多的功能，就把以前写的好的文章都搬 去blogspot了。目的有二，一来是想用一个功能能强大的blog，二来呢觉得google对自己的blog的搜索一定会更好，通过google可以 能带来更多读者。不过不幸的是去年两会的时候blogspot就被封了，期间偶尔也开放过一两。有一次我还以为真的是有恢复了，一夜没睡觉，更新了 blog的样式准备重新开始继续更新。可是第二天就有访问不了了，其实平时在公司或者在公司的VPN上是可以访问的，由于是走的国外的网络；从blog流 量统计上可以看出，http://lzheng.blogspot.com的访问量是平均大约每天12个，访问者基本上都是从国外和港台地区。不过我觉得我的读者是应该面向国内的，写这个博客的目的还是向国内的中文用户提供开源的信息和技术。所以就申请了自己的域名，购买了一个虚拟机（LAMP），在虚机上安装了wordpress。wordpress和blogspot的内容是可以互相兼容的，把blogspot里的文章导出成xml文件在导入到这个站点当中，这样完成了blog的搬家工程。工程虽然不是很浩大，不过毕竟还是费了一番周折，目的只有一个，以前写的东西有些还是有用的舍不得丢。\n以后会把我在开源方面的心得和想法都更新到这个博客上，希望能够为您提供一点点的帮助。在这里呢会对开源技术提供全景式介绍，做的力求比较全面内 容。不过我一直以来呢是做IT管理这个方向的，所以从我的文章分将有70%以上是这方面的内容，30%介绍其他内容。不过您如果有其他任何相关的想法也欢 迎和我探讨。\n",
    "ref": "/2008/03/29/moveback/"
  },{
    "title": "Hyperic HQ 3.2 new features",
    "date": "",
    "description": "",
    "body": "If you\u0026rsquo;d like to check out release note, please click here. http://support.hyperic.com/confluence/display/DOC/HQ+3.2+Release+Notes\nI had a quick install on RHEL 5. For some features what I saw, I took some screenshots as bellowing. I hope this helps you to understand what\u0026rsquo;s new in 3.2 and save a little bit time for you if you do not wants to install it. I will describe in Chinese.\nNew Nav menu 新导航菜单 \n导航菜单的名称变成了：Dashboard \u0026ndash; Resources \u0026ndash; Analyze \u0026ndash; Administration 菜单的风格稍微有一点变化。Analyze下面可以进入Alert Center去查看报警信息。我觉得3.2毕竟是一个小的功能增进板，添加了支持MY SQL的支持。增强了对Nagios的集成。对Nagios的集成对它还是很有好处的，由于它自己是Agent Based的监控方法，而Nagios是Agentless的监控方法；集成之后通过它的web界面能统一管理，还是挺好的。不过和Nagios具体能集成到什么程度，我还没有试过。\nCurrently Down Resources当前宕机资源 \n如果所示：各种有问题的资源安装各种分类都显示出来，同实现时什么时间出的问题，持续了多久，点击放大镜后查看相关的报警信息。上图显示的是：HQ Agent在w2k3vm这一Windows服务器上没有启动的情况，它报告了包括hq agent自身以及所有相关资源的都宕机的情形。同时作为一个监控系统来说，管理员最需要看到的信息可能主要包括两种：1）有那些资源出了问题；2）当前有什么样的告警事件。这里对这两类信息提供了一个非常不错的访问入口。\nLive Exec Data实时数据获取 \nHQ-agent本身只能周期性的采集matrix，在汇报给管理服务器。实时的数据采集对排错还是非常有帮助的。此功能我觉得是3.2版中的最好的增强。它应该是远程的让agent去执行一下命令在把最终结果返回到页面上：\n\n Cpuinfo CPU信息  Cpuperc CPU利用率  Df 磁盘利用率  Ifconfig 网卡ip信息  Netstat 网络端口信息  Top  Who 这些信息的获取通过agent完成所以和平台无关，即使是Window平台也能收到相同的信息。\n  HQ Health Check 管理服务器自身检查 \n一个真正的自监控功能最好能做到对相关指标的报警处理。能设置一些条件，在不正常情况发生的时候报告管理员说出管理服务器那里有问题了。上图可以看出，hq已经做出了第一步，能采集并且显示很多HQ服务器运行的状态信息。\nSummary： \n在3.2的发布说明中还提到它自身的扩展性也很大的增强，这一点对hq来说尤为重要。由于它的结构是基于代理的，当监控的设备和资源都非常多时，hq管理服务器自身的处理能理将会成为瓶颈，如果它的处理，存储和网络上的任何一个环节出现了问题，整个监控系统就失效了。由于事件有限，目前还留下了一些问题：\n\n Global Alert Disable是在那里设置的？  报警阀值的设置是否有全局设置的地方？（例如：对所有windows机器都设置一个CPU\u0026gt;80％的阀值） 如果您对以上两个问题有些答案请回复告诉我。关于HQ的其它文章，清在本blog中搜索。  ",
    "ref": "/2008/02/02/hyperic-hq-32-new-features/"
  },{
    "title": "Build Zenoss 2.1.2 on Redhat Enterprise Linux 5",
    "date": "",
    "description": "",
    "body": "Well, it is the first time to running a RHEL 5 for me, at same time got zenoss built successfully on it. zenoss-2.1.2 was build from source, the whole process went a while since RHEL is in one of my VMware session; CPU %sy was pretty high during building source code.\nBuild zenoss-2.1.2 \nThe INSTALL.txt file is good enough, my installation how-to can be really sample:\n\n Read INSTALL.txt  add zenoss user  start mysql  upload zenoss tarball to zenoss home directory  login as zenoss  untar zenoss tarball then run the following, good luck!   -bash-3.1$ ls\nappliance_update.sh conf install-functions.sh shared-functions.sh\nautoinstall COPYRIGHT.txt install.sh zen2dump.py\nbuild-functions.sh docs INSTALL.txt ZEN2UPGRADE.txt\nbuild-noprompt.sh externallibs libzenoss zensocket\nbuild.sh fs LICENSE.txt zenwipe.sh\nCHANGES.txt genpatchdeps.py MacOS\ncheckall.sh GNUmakefile rpm\n-bash-3.1$ ./install.sh This installer actually builds Zenoss.\nFor a simpler installation try the VMPlayer Appliance image,\nor use RPMs for Redhat based systems. Building... Password for the Zenoss \"admin\" user [zenoss]:\nEnter the password again:\nMySQL server hostname [localhost]:\nMySQL server root username [root]:\nMySQL server root password []:\nMySQL event database name [events]:\nMySQL username for Zenoss events database [zenoss]:\nMySQL password for zenoss [zenoss]:\n/usr/bin/python2.4 genpatchdeps.py .patchdeps\ninstalling into //usr/local/zenoss\nbuild log is in zenbuild.log\nunpacking Zope-2.8.8-final in build/\nconfiguring build/Zope-2.8.8-final/makefile\ninstalling libzenos/Products.tar.gz\ninstalling libzenos/bin.tar.gz\ninstalling libzenos/extras.tar.gz\nmkdir -p //usr/local/zenoss/skel/etc\ncp conf/zope.conf.in //usr/local/zenoss/skel/etc/zenoss.conf.in\ninstalling zope\nunpacking TwistedSNMP-0.3.13 in build/\npatching file snmpprotocol.py\npatching file v3/agentproxy.py\npatching file v3/agentproxy.py\npatching file tableretriever.py\npatching file snmpprotocol.py\nunpacking pysnmp-3.4.3 in build/\npatching file pysnmp/proto/rfc1155.py\npatching file pysnmp/proto/rfc1155.py\npatching file pysnmp/proto/rfc1155.py\npatching file pysnmp/proto/rfc1155.py\ninstalling pysnmp\nunpacking Twisted-2.5.0 in build/\npatching file TwistedCore-2.5.0/twisted/internet/process.py\nHunk #1 succeeded at 315 (offset -20 lines).\nunpacking pycrypto-1.9a6 in build/\ninstalling pycrypto\ninstalling twisted\ninstalling twistedsnmp\nmaking zensocket\ngmake[1]: Entering directory `/usr/local/zenoss/zenoss-2.1.2/zensocket'\ngcc -o zensocket -Wall -pedantic -D__GNU_LIBRARY__ -g zensocket.c\nrm -f //usr/local/zenoss/bin/zensocket\ncp zensocket //usr/local/zenoss/bin/zensocket\ngmake[1]: Leaving directory `/usr/local/zenoss/zenoss-2.1.2/zensocket'\nunpacking pynetsnmp-0.27.0 in build/\nunpacking ctypes-1.0.1 in build/\ninstalling ctypes\ninstalling pynetsnmp\nunpacking MySQL-python-1.2.0 in build/\npatching file setup.py\npatching file _mysql.c\nHunk #1 succeeded at 440 (offset -37 lines).\nHunk #3 succeeded at 460 (offset -37 lines).\nHunk #5 succeeded at 526 (offset -37 lines).\ninstalling mysql-python\nunpacking rrdtool-1.2.23 in build/\nunpacking libart_lgpl-2.3.17 in build/\nconfiguring build/libart_lgpl-2.3.17/Makefile\ninstalling libart\nunpacking freetype-2.1.9 in build/\nconfiguring build/freetype-2.1.9/Makefile\ninstalling freetype\nunpacking libpng-1.2.8-config in build/\nconfiguring build/libpng-1.2.8-config/Makefile\ninstalling libpng\nconfiguring build/rrdtool-1.2.23/Makefile\ninstalling rrdtool\nrm -rf //usr/local/zenoss/share/rrdtool/examples\nrm -rf //usr/local/zenoss/lib/perl\nunpacking epydoc-3.0beta1 in build/\npatching file epydoc/apidoc.py\npatching file epydoc/docbuilder.py\npatching file epydoc/docintrospecter.py\ninstalling epydoc\nunpacking python-snpp-1.1.1 in build/\ninstalling snpp\nunpacking Yapps-2.1.1 in build/\ninstalling yapps\nunpacking nagios-plugins-1.4.5 in build/\nconfiguring build/nagios-plugins-1.4.5/Makefile\ninstalling nagios\nunpacking libsmi-0.4.5 in build/\nconfiguring build/libsmi-0.4.5/Makefile\ninstalling libsmi\nunpacking wmi-0.1.5 in build/\nunpacking pyip-0.7 in build/\npatching file icmp.py\ninstalling pyip\nunpacking simplejson-1.4 in build/\ncp externallibs/setuptools*.egg build/simplejson-1.4\ninstalling simplejson\ninstalling conf/snmpd.conf\ninstalling conf/zenactions.conf\ninstalling conf/zenbackup.conf\ninstalling conf/zencommand.conf\ninstalling conf/zendisc.conf\ninstalling conf/zeneventlog.conf\ninstalling conf/zenhub.conf\ninstalling conf/zenmib.conf\ninstalling conf/zenmigrate.conf\ninstalling conf/zenmodeler.conf\ninstalling conf/zenpack.conf\ninstalling conf/zenperfsnmp.conf\ninstalling conf/zenping.conf\ninstalling conf/zenprocess.conf\ninstalling conf/zenrender.conf\ninstalling conf/zenstatus.conf\ninstalling conf/zensyslog.conf\ninstalling conf/zentrap.conf\ninstalling conf/zenwin.conf\ninstalling conf/zenwinmodeler.conf\ninstalling conf/zenxevent.conf\ninstalling conf/zope.conf.in\ninstalling conf/hubpasswd\nWrote file /usr/local/zenoss/etc/zeo.conf\nWrote file /usr/local/zenoss/bin/zeoctl\nChanged mode for /usr/local/zenoss/bin/zeoctl to 755\nWrote file /usr/local/zenoss/bin/runzeo\nChanged mode for /usr/local/zenoss/bin/runzeo to 755\nStarting Zope Object Database\n. daemon process started, pid=15476\nLoading initial Zenoss objects into the Zeo database\n(this can take a few minutes)\nZentinelPortal loaded at zport\nStarting Zope Server\n. daemon process started, pid=15499 =========================================================\nzensocket must be setuid. As root, execute the following:\nchown root:zenoss /usr/local/zenoss/bin/zensocket\nchmod 04750 /usr/local/zenoss/bin/zensocket\n========================================================= Successfully installed Zenoss \nStart Daemons: \nbash$ $ZENHOME/bin/zenoss start\nbash$ $ZENHOME/bin/zenoss status\n\n Then I access to Zenoss portal, got this error.   HTTP Status 404 - /zport/dmd \n* * *   **type** Status report**message** _/zport/dmd_**description** _The requested resource (/zport/dmd) is not available._\n  * * *     ##### Apache Tomcat/5.5.20    \nI reboot the RHEL server, then start mysql and zenoss. Finally, everything goes smoothly. Let\u0026rsquo;s take this nice zenoss portal.\n\nOn my RHEL, mysql, snmp and python were installed with OS; other packages might installed from zenoss source tarball. I am not sure about this, you could check above to see my install log.\nInstall tips:\n\n Package dependence should be consider before you build Zenoss source code. A full RHEL install is a lazy idea to solve this problem; but it is still the best practice if you are new to both Linux and Zenoss.  Start zenoss daemons might take one minute or more. If you access to zenoss portal immediately, you could get a HTTP Status 404 error. Before you see balance stone, please be patience.   Auto-Discovery of Devices \nIt\u0026rsquo;s time to read ZenossAdminGuide211.pdf; BTW that\u0026rsquo;s a good document. I will go ahead to note down what I did in my testing evn. Please turn to P47, I will go from there. For sure you have something discovered, please read the following tips:\n\n The Zenoss machine should have snmp installed, including the following packages:   [root@localhost ~]# rpm -qa|grep snmp\nnet-snmp-libs-5.3.1-19.el5\nnet-snmp-5.3.1-19.el5\nnet-snmp-utils-5.3.1-19.el5\nnet-snmp-perl-5.3.1-19.el5 \nAs far as I know net-snmp-utils-5.3.1-19.el5 is a necessary. Without this package, you do not have ability to snmpwalk any device via SNMP protocol; in other word you can not get enough information about that remote device.\n\n Add a right network ID, here is a example:   ID: 192.168.6.0 -- for 192.168.6.0/24 subnet \n\n snmpwalk at least one snmp-enable device, here is a example:   [root@localhost snmp]# snmpwalk -v 1 -c public 192.168.6.131 system\nSNMPv2-MIB::sysDescr.0 = STRING: SunOS unknown 5.10 Generic_120012-14 i86pc\nSNMPv2-MIB::sysObjectID.0 = OID: NET-SNMP-MIB::netSnmpAgentOIDs.3\nDISMAN-EVENT-MIB::sysUpTimeInstance = Timeticks: (146417) 0:24:24.17\nSNMPv2-MIB::sysContact.0 = STRING: \"System administrator\"\nSNMPv2-MIB::sysName.0 = STRING: unknown\nSNMPv2-MIB::sysLocation.0 = STRING: \"System administrators office\"\nSNMPv2-MIB::sysServices.0 = INTEGER: 72\nSNMPv2-MIB::sysORLastChange.0 = Timeticks: (96) 0:00:00.96\nSNMPv2-MIB::sysORID.1 = OID: IF-MIB::ifMIB\nSNMPv2-MIB::sysORID.2 = OID: SNMPv2-MIB::snmpMIB\nSNMPv2-MIB::sysORID.3 = OID: TCP-MIB::tcpMIB\nSNMPv2-MIB::sysORID.4 = OID: IP-MIB::ip\nSNMPv2-MIB::sysORID.5 = OID: UDP-MIB::udpMIB\nSNMPv2-MIB::sysORID.6 = OID: SNMP-VIEW-BASED-ACM-MIB::vacmBasicGroup\nSNMPv2-MIB::sysORID.7 = OID: SNMP-FRAMEWORK-MIB::snmpFrameworkMIBCompliance\nSNMPv2-MIB::sysORID.8 = OID: SNMP-MPD-MIB::snmpMPDCompliance\nSNMPv2-MIB::sysORID.9 = OID: SNMP-USER-BASED-SM-MIB::usmMIBCompliance\nSNMPv2-MIB::sysORDescr.1 = STRING: The MIB module to describe generic objects for network interface sub-layers\nSNMPv2-MIB::sysORDescr.2 = STRING: The MIB module for SNMPv2 entities\nSNMPv2-MIB::sysORDescr.3 = STRING: The MIB module for managing TCP implementations\nSNMPv2-MIB::sysORDescr.4 = STRING: The MIB module for managing IP and ICMP implementations\nSNMPv2-MIB::sysORDescr.5 = STRING: The MIB module for managing UDP implementations\nSNMPv2-MIB::sysORDescr.6 = STRING: View-based Access Control Model for SNMP.\nSNMPv2-MIB::sysORDescr.7 = STRING: The SNMP Management Architecture MIB.\nSNMPv2-MIB::sysORDescr.8 = STRING: The MIB for Message Processing and Dispatching.\nSNMPv2-MIB::sysORDescr.9 = STRING: The management information definitions for the SNMP User-based Security Model.\nSNMPv2-MIB::sysORUpTime.1 = Timeticks: (88) 0:00:00.88\nSNMPv2-MIB::sysORUpTime.2 = Timeticks: (88) 0:00:00.88\nSNMPv2-MIB::sysORUpTime.3 = Timeticks: (88) 0:00:00.88\nSNMPv2-MIB::sysORUpTime.4 = Timeticks: (88) 0:00:00.88\nSNMPv2-MIB::sysORUpTime.5 = Timeticks: (88) 0:00:00.88\nSNMPv2-MIB::sysORUpTime.6 = Timeticks: (90) 0:00:00.90\nSNMPv2-MIB::sysORUpTime.7 = Timeticks: (96) 0:00:00.96\nSNMPv2-MIB::sysORUpTime.8 = Timeticks: (96) 0:00:00.96\nSNMPv2-MIB::sysORUpTime.9 = Timeticks: (96) 0:00:00.96\nAs you can see here: it is a Solaris 10 system. I just downloaded it last night, get it up and running in another VMWare session on my laptop. You should configure snmp service for Solaris in order to monitoring it via snmp protocol. I will past my /etc/snmp/conf/snmpd.conf below:\n# cat snmpd.conf\n# Copyright 1988 - 07/17/00 un Microsystems, Inc. All Rights Reserved.\n#ident \"@(#)snmpd.conf 2.24 00/07/17 SMI\" # See below for file format and supported keywords sysdescr Sun SNMP Agent,\nsyscontact System administrator\nsysLocation System administrators office\n#\nsystem-group-read-community public\n#system-group-write-community private\n#\nread-community public\n#write-community private\n#\ntrap 192.168.6.130\ntrap-community SNMP-trap\n#\n#kernel-file /vmunix\n#\n#managers lvs golden\nmanagers 192.168.6.130\n192.168.6.130 is Zenoss ip address; you have to restart snmpd daemon after you change something in this file. Here is another tips for Solaris OS. Be default root can not login via ssh or telnet; you have to add another user. You will login as this new user, then su to root. \nLet\u0026rsquo;s see what I got after done all of above.\n\n\nZenoss has a pretty good network map, it is a flash map; you can drag things on this map. Before I end this blog, I\u0026rsquo;d like to summary my questions blow:\n\n Because my RHEL installation is big enough, I don\u0026rsquo;t know what are dependence packages for Zenoss; no time to list all of them. Does have this list?  I\u0026rsquo;ve no idea how to configure snmpd on Solaris. What I did was just modified /etc/snmp/conf/snmpd.conf  How to restart snmp daemon for Solaris?  Do you have any good blog about zenoss? I will write a Chinese blog after this one to conclusion zenoss installation. Please give a hint if you have any comment.  ",
    "ref": "/2008/01/30/build-zenoss-212-on-redhat-enterprise-linux-5/"
  },{
    "title": "网管系统的测试工具",
    "date": "",
    "description": "",
    "body": "很多网络系统管理软件都有Trap管理的功能，在系统的安装和配置过程中；验证系统是否能正常处理Trap是很麻烦的事情。原因有很多，发送trap的设备没有，设备上的snmp没有启用，或者设备都正常，到网管系统的网络可能有防火墙吧snmp给堵住了。\n为了方便的测试和配置网络管理监控系统，需要手工生产和验证trap的发送和接收。最近偶然在网上发现了这样几个免费（非OSS软件）软件工具，可以做这件事。\n下载的网站是：http://www.ncomtech.com/ 下面吧我所下载和测试的软件做一个小结，希望对您有所帮助：\n\n Trap Receiver http://www.trapreceiver.com/ 是一个Windows程序非常小，安装了之后会在windows安装一个服务。程序的启动目录是C:\\Program Files\\Trap Receiver\\TrapRcvr.exe 程序界面非常简单，如下图所示： \n点击configure按钮后可以做一些配置：Action －－当收到某些特定的trap是出发邮件、声音等动作；logging－－把收到的trap信息按照某种格式记录在文件中；Mibs－－导入目标设备的trap文件，让这个接收器能认识到另外的trap格式。还有其他配置信息也非常简单。\n  \n **TrapGen **http://www.ncomtech.com/trapgen.html 顾名思义－这就是一个手工生产和发送trap的工具，是一个命令行工具。example: trapgen -d 192.168.2.3；上图中的第一条和第三条就是用这个命令发出的trap。欲知详细帮助信息，使用\u0026quot;trapgen -h\u0026quot;  I/F Spy http://www.ncomtech.com/ifspy.html 是一个网络接口枚举工具，它通过snmp协议去访问目标设备的IFMIB信息，显示所有IFMIB相关信息。  UDP Listen http://www.ncomtech.com/udplisten.html UDP协议的监听程序，是命令行工具，有linux和Solaris版，能用作一个debug工具。  Thingy http://www.ncomtech.com/thingy.html是一个Windows下的GUI工具，能帮你监控三个SNMP指标，采集并做大于等于和小于的逻辑判断然后显示不同的信号灯。 这几个小工具都很小，都能在windows下安装和使用对网络系统监控软件的安装、配置和排错应该有一定的帮助。如果您有什好的小工具也请回复一下本文。  ",
    "ref": "/2008/01/21/trap-tools/"
  },{
    "title": "Hyperic HQ Engerprise 3.1.4 测试报告",
    "date": "",
    "description": "",
    "body": "多系统/跨平台支持 \n如下图所示，我安装了并运行了四个代理程序。HQ的服务器是安装在我的笔记本上的是Windows XP平台的。HQ管理服务器在windows下的安装是非常简单的，两分钟就能完成。安装包中包括了Jboss和PostgreSQL。其它三个测试的代理程序分别安装在OpenSUSE Linux 10.3 （VM），AIX 5.3 和 Solaris 10 （5.10），代理程序的安装过程非常简单，需要注意的是保证代理和管理服务器的时钟同步。否则数据收集和显示的时间会错位。\n\n对不同平台的数据采集是不同的，代理能根据操作系统而已采集不同的数据指标；比如CPU的监控指标windows、linux，Aix和Sun都有细微差别。\nDashboard首页－－仪表盘 \nHQ登陆后的首页，第一个感觉是－专业。算是一个Portal门户界面。页面顶端是最新的两个报警信息，和水平导航条。右边的模块有：资源搜索、保存的资源图、可用性图和最近增加的平台等。右边的模块有：自动发现、最爱资源，最近报警、控制动作问题资源和监控指标视图等。整体来看：所有的模块都可以配置、拖拽、添加和删除；您可以按照自己的喜好设置布局。对于网管来说：最近报警、和问题资源和监控指标视图应该是非常重要的；通过这些内容可以立刻了解到所关心的资源和服务的整体状况。\n浏览资源 \nPlatforms平台－－四个监控对象：所显示的是所有被监控对象，HQ主要是Agent based的监控方式，当然也可以通过snmp方式监控网络设备，不过这个我没测过它监控网络设备的能力。我安装测试的是HQ企业版，所以我只能监控到4个被监控对象；当然如果是付费用户的话就可以增加被管理目标的数量了，多话钱是肯定的了；好像HQ是按照被监控节点的数量收钱的。测试这个企业版的目的是，浏览一下它所有的功能，下面所说的有些功能是企业版才有的开源版本是没有的。\nServers服务器－－21被管理服务器：HQ的自动发现功能不仅能发现到服务器上的基础资源（CPU、文件系统和网络）；还能自动发现被监控平台上的数据库、web和App服务等。这些服务有的是需要一些配置才能采集到数据的，例如对数据库的监控，MySQL需要在HQ服务器上输入一个MySQL的用户名和密码（密码不能为空），这个用户需要有能运行status命令的权限。Oracle数据库需要按照HQ页面上的提示在数据库实例上，用DBA的权限运行一个命令，也建立一个用户。代理程序是通过这个用户通过JDBC链接到数据库上采集监控指标的。对于Apache来说，是需要配置Status模块的。HQ也算得上是单一代理的监控方式了，这一个特性是非常重要的；和BMC公司的Patrol产品有些相似。单一代理能很好的降低被监控服务器的额外负担。\n告警事件规则 \n默认情况下所有HQ里没有任何一个报警规则的。不过你可在它的问题资源模块上看到OOB次数。OOB是Out Of Bound的简称，意思是超出边界，那么边界在那？边界在Baseline上，baseline会在每几天算一次，它并不是平均值，某个监控资源的实际忙闲程度水平的参考面。例如如果你的CPU平时都不超过30％的话，它的基线可能是20％，如果某次采样数据是24％了，OOB的数量就被加一；它表明该资源的使用异常了，需要引起你的注意了。HQ企版可以设定固定fix阀值，也可以设定动态阀值。所谓让很多企业级用户梦寐以求的动态阀值，其实就是比对BaseLine来报警的机制。HQ的报警规则可以是：例如CPU使用率超出Baseline的15％；那么这样CPU使用率的报警范围就是动态的了。报警规则的设置可以根据不同的platform而定，可以给某了platform定义一套默认的规则级应用到所有监控对象上。还能在某个监控对象上设置特殊的报警规则。报警条件可以是多条件的逻辑判断。报警事件可以每次触发时都发出，也可以在某个时间段上持续到达多少次才发出，发出的告警信息可以发给某个人或者某组人，还能在时间内升级等。显然这就是某些用户梦想中的事件压缩、峰值抑制、事件升级等功能。HQ的企业版还能从事件上触发Action。\n报表中心 \n默认的报表好像是有7个，可以输出成PDF，excel，csv和html格式。不得不说的是HQ的数据采集方式应该是从HQ服务器上向Agent发起的，取得了数据后，保存在Postgresql数据库中。HQ服务器端保存了所有数据，不过如果在某个时间端，HQ服务器不能和agent通信的话，这段数据就是空白的。这一点可呢功能和所有其它开源软件都一样。而CA的UDPM和BMC的Patrol是不同的，Agent采集到的数据可以短期的保存在被管服务器端；采集数据的连续性不受网络影响。\n总结 \nHQ企业版的功能太强大了，可以与商业软件媲美；单基于Baseline的动态阀值报警就是Big four所不能提供的。不过企业版是不能用的：虽然能使用到所有功能，不过只能监控4个服务器。在浏览HQ网站文档的时候，某个功能如果后面有一个红色的星号，那么它就是企业版的功能，需要付费使用了。不过它开源版的功能已经非常不错了，而且有这么优秀的一个框架使用；能支持二次开发和扩展。下次在提供一个开源版的测试报告。\n",
    "ref": "/2008/01/12/hyperic-hq-engerprise-testing/"
  },{
    "title": "Top 100网络安全工具",
    "date": "",
    "description": "",
    "body": "＃１Nessus : 首要的UNIX 弱点/漏洞评估工具\n\nNessus是最好的网络漏洞扫描工具之一，此软件最好是运行在UNIX上。它被持续不断地更新，有超过11,000的免费插件(但是需要注册或者接受EULA)。主要的特点包括远程和本地的执行安全检查，带有GTK图形用户界面的client/server架构，一个用来写自己的插件的内置脚本语言。从Nessus 3开始停止开源 now closed source，但是他依然是免费的除非你想要最新的插件。查看所有的漏洞扫描器 vulnerability scanners\n＃2 Wireshark :附着在Internet上的嗅探器\n\nWireshark (在2006年夏之前名为Ethereal )是一个Unix和Windows上fantastic的开源网络协议分析器。它能让你分析在线的网络数据和捕获的数据文件。你能方便的浏览捕获数据，深入研究到你需要级别的数据包的细节。Wireshark还有几个强大功能包括，包括丰富的过滤显示语言和能去查看TCP链接重建的过程。它能支持几百种协议和网络介质类型。一个需要注意的方面是Ethereal现在遭受这很多可远程利用的安全漏洞，因此保持它的更新和提防在非信任的或者敌对的网络上运行它。查看所有包嗅探器 packet sniffers\n \n＃3 Snort :所有人都喜欢的开源IDS 这个轻量级网络入侵检测和阻止系统擅长于IP网络上的流量分析和包记录。通过协议分析，内容搜索和各种预处理，Snort能探测上千种蠕虫, 利用漏洞企图，端口扫描和其他可疑行为。Snort使用一个弹性的基于规则的语言去描述它应该收集或者忽略的网络通信流量，和一个模块化的检测引擎。从此链接产看更多的基本分析和安全引擎，有一个Web用户界面来分析Snort告警。开源的Snort被一些个人、小企业和部门用的很不错。它的母公司SourceFire提供了一个非常全的产品线；具有很多的企业级功能和实时规则更新。它们提供了一个免费的（需注册）的5天延迟的规则更新源，你还能在Bleeding Edge Snort找到很多非常好的免费规则。 查看所有入侵检测系统intrusion detection systems\n＃4 Netcat :网络瑞士军刀\n\n这个简单的工具通过TCP或者UDP网络链接读写数据。它被设计为一个可靠的后端工具：能被直接和通过其他程序或脚本简单地驱动执行。同时，它也是一个功能丰富的网络调试和探索工具，因为它能生成几乎所有类型的你需要的网络链接，包括接受绑定了端口的外来链接。最初版本的Netcat released 是Hobbit在1995年发布的，但是不论它是多么的流行也没有被持续。它有时候很难被找到nc110.tgz。利用这个工具的弹性和用途去开发了很多其他的Netcat的实现极大的推广了这个工具- 经常的很多现代的功能都不能在原始版本中找到。其中最有趣的是 Socat，扩展Netcat去支持很多其它socket类型、SSL加密、SOCKS代理和更多。它甚至按自己的意图扩展。还有 Chris Gibson\u0026rsquo;s Ncat，提供了甚至更多功能同时能保持可移植性和简洁性。其它流行的Netcat包括 OpenBSD\u0026rsquo;s nc, Cryptcat, Netcat6, PNetcat, SBD, 和 GNU Netcat。查看所有 Netcats\n＃5 Metasploit Framework : Hack星球\n Metasploit 在它2004年发布的时候给安全界带来风暴。没有其它什么工具能出现在这个列表的前15中， Metasploit 以第五位进入榜单，超过了很多知名的开发超过10年的工具。它是一个高级的开源平台。The extensible model through which payloads, encoders, no-op generators, and exploits can be integrated has made it possible to use the Metasploit Framework as an outlet for cutting-edge exploitation research. It ships with hundreds of exploits, as you can see in their online exploit building demo. This makes writing your own exploits easier, and it certainly beats scouring the darkest corners of the Internet for illicit shellcode of dubious quality. Similar professional exploitation tools, such as Core Impact and Canvas already existed for wealthy users on all sides of the ethical spectrum. Metasploit simply brought this capability to the masses. 查看所有 vulnerability exploitation tools\n如需了解全列表，请参考源列表页面：http://sectools.org/\n",
    "ref": "/2008/01/04/top-100-security-tools/"
  },{
    "title": "看图学话，学ITIL(v2)系列 之1",
    "date": "",
    "description": "",
    "body": "前言 \n在2007年ITILv3推出之后，ITIL这个概念从最佳Best practice实践变成最好Good practice实践。从此称呼的转变能够看出ITIL思想的普及化、平民化。ITIL v2已经使用了快20多年了，看看如今的ITIL的用户，成熟度依旧参差不齐。有的已开始琢磨着如何完善所有ITIL Support流程并开展实施ITIL Delivery中的各个流程；有的已经在开始实施帮助台并建立事件和问题管理；有的依然处于扫描阶段。\n在ITILv3即将普及的2008年，v2对于各类用户来说还是基础，是最可实施的框架。v2是v3的核心内容，为了及时的升级到v3，熟练掌握v2的概念是当务之急。下个月公司有ITILv3升级的认证考试，本系列文章可能算是一个v2的复习笔记吧。\n\n一图胜过千言，本系列通过对一些经典图形的回顾来复习v2的部分概念。由于是看图学话版，所以目标观众是ITIL的学龄前儿童呵呵，学习内容是ITIL Delivery。如果您已经是小学以上水平，请忽略:)\nITIL Service Delivery介绍 \nITIL的全称是IT Infrastructure Library，开发于1980年；成果要素：Public domain framework公共领域框架－放之四海皆准；Best practice framework最佳事件框架－现在成最好事件了；De facto standard事实上的标准－90年ITSM推广； Quality approach质量解决方案－IT质量保障；itSMF IT服务管理论坛。\n\nJigsaw diagram ～ 锯齿图 OGC设计了这个图，用此来说明ITIL有5个主要部分组成；每个部分之间都相互接口并联系着。\n\nService Delivery; the coverage ～服务交付涵盖如图5个不同流程。\n\nBS15000 Service Management processes～BS1万5中的服务流程图示。它涵盖了ITIL的所有流程，以控制为中心的增强版。\n \nRelationship between Change Management, Configuration Management, Capacity Management and Release Management～变更、配置、能力和发布管理之间的关系。\n\nProcess improvement model ～ 流程改进模型：发展方针和业务目标，评估、流程改变和指标追踪。\n",
    "ref": "/2007/12/31/itilv2/"
  },{
    "title": "OTRS.ORG，it is time to check it out；不得不：）",
    "date": "",
    "description": "",
    "body": "一贯喜欢按照Google的指引在互联网上穿梭的你，是否发现了下面的这个现象。如果你搜索itil，无论选择所有网页、中文网页还是简体中文网页；你是否发现了在右边的赞助商连接中，OTRS.org总是能出现在第四个。OTRS.ORG是什么？和ITIL有什么关系？\n\n热衷于开源ITSM的我不得不揭示这些答案。\n什么是OTRS \n这是一个开始于2001年的开源项目。OTRS是Open Ticket Request System的缩写。它的老家在www.otrs.org；下面是来自它首页的简介：\n\nOTRS is an _O_pen source _T_icket _R_equest _S_ystem (also well known as trouble ticket system) with many features to manage customer telephone calls and e-mails. The system is built to allow your support, sales, pre-sales, billing, internal IT, helpdesk, etc. department to react quickly to inbound inquiries. Do you receive many e-mails and want to answer them with a team of agents? You\u0026rsquo;re going to love the OTRS! It is distributed under the GNU General Public License (GPL) and tested on Linux, Solaris, AIX, FreeBSD, OpenBSD, Mac OS 10.x and Windows. The ((otrs)) company provides commercial services (e.g. support, consulting, training, pre-build-systems, etc.) for the OTRS (English and German). Try our demo system to get an impression of this kind of magic.\n从这个简介中可以看出，这就是著名的‘问题单管理系统’；用来管理用户的电话或者邮件的请求。它能帮你的很快的受理各种问题和查询。比方说很多企业的IT支持部门，大多数都是工作在救火队模式下；对于期待问题解决的用户来说，也只能做到把奶喂给会哭的孩子；往往IT支持部门分身乏术，好像天天都处于缺奶的状态。对于IT支持或者运维部门的挂历者来说，他们也很难说出：我的员工很忙，都忙于什么事情。显然这是一种缺乏管理，缺乏流程的状态；不过要对这种局面进行管理，提高管理往往是非常难。最难的是在跨出第一步：记录，跟踪，处理所有问题。来自OTRS的问题：您是不是收到很多email（或者电话），并且希望通过一个支持团队回答？那么你将爱上OTRS!\nOTRS是一个在GPL许可证下被分发的软件，被在Linux, Solaris, AIX, FreeBSD, OpenBSD, Mac OS 10.x 和Windows下测设过。\n((otrs)) 公司提供OTRS的技术支持、咨询、培训、安装等商业服务。由于这个软件是德国人开发的，所以他们提供英语和德语的服务。\n我跟踪这个项目大概有一年左右的时间，亲眼目睹了它从一个普通的问题单管理系统变为一个兼容ITIL的服务台工具的过程。它从07年4月的它发布了第一个ITIL兼容的版本OTRS::ITSM 1.0 BETA2；这应该也是开源领域里的一个大事件吧，第一个像样的开源ITSM解决方案横空初始。按照它官方的声明，它做为OTRS的一个重要的插件（我是这么理解的，或者说是扩展模块）能支持ITIL中的事件管理、问题管理和配置管理/cmdb。\nOTRS有哪些功能 \n详细的功能描述在http://otrs.org/feature/\n我简单总结以下几点：\n\n 纯Web用户界面支持包括简体中文，繁体中文在内的10＋种语言，能够灵活定制界面，支持附件，支持单点登陆。  邮件接口，支持MIME附件，能自动回复，自动根据邮件头分派邮件，自动邮件提示用户Ticket状态的变化。  Ticket功能，定义不同的受理队列，支持Ticket的锁定、回复、历史、优先级、受理时间计算、批量处理、等待等操作。支持全文检索，工作量和访问列表控制。  系统功能，按照日历时间计算SLA，提供LDAP和SQL数据库认证用户，自定义订单号格式，数据库支持MySQL, PostgeSQL, MaxDB/SAPDB, Oracle and DB2，前端和后台都支持UTF-8字符集  系统架构图 http://otrs.org/images/BigPicture.gif   如何使用OTRS \n下载和安装都非常简单，您可以参考它们的官方文档，文档非常详细，能看出德国人的细严谨的风格。下载网址： http://otrs.org/download/ 文档： http://doc.otrs.org/2.2/en/html/ 安装说明：选择一个文档中支持的操作系统，建议Linux；如果是新手而且对Perl，apache和mysql不熟悉，建议直接选择完全安装；下载安装包，参考文档安装，使用。\n后记 \nOTRS一个非常经典的项目，德国工艺，德国品质保证～～～Oops怎么听起来像是卖假木地板或者家具的广告呵呵！！个人非常喜欢此项目，相信您用了之后不会后悔；真的后悔了也别和我联系哈:-) have fun～～\n",
    "ref": "/2007/12/27/otrs/"
  },{
    "title": "如何配置OpenNMS中的 Path outage －路径失效",
    "date": "",
    "description": "",
    "body": "这个功能是是1.3.2之后加入的。它解决的问题是：当OpenNMS系统和被监控节点之间的网络路径失效了，或者网络链路down了，那么OpenNMS就需要抑制发送这个节点的告警。例如，如果一个广域网链路down了，所有由这个链路连接的远程站点的所有节点就都看起来down了。因为你将会得到一个路由器上远端链路无响应的告警，而不需要得到在这个路由器后所有节点Down的告警。如果当一个远程节点不响应了，OpenNMS会测试一下那个远程路由器广域网接口的ip，通过对这个ip的测试OpenNMS觉得是否该发出此节点Down的告警。OpenNMS测试的这个节点叫做此节点的Critical Path IP Address（关键路径Ip地址）。\n给一个节点配置Path Outage\n在OpenNMS的节点配置上，点击Admin, 点击 Configure Path Outage，输入对于这个节点来说关键的ip地址。点击Submit按钮。\n配置基于规则的Path outage\n可以为一组节点配置一个规则。在总导航条上选中Admin，Configure Notifications，点击Configure Path Outages，在Define the Critical Path下面输入一个Ip地址，例如：192.168.0.1（这种格式）；在Current Rule下面输入地址范围，例如：IPADDR IPLIKE 192.168.0.*；可以选中Show matching node list后的box，点击Validate Rule Results连接；在下面的页面可以查询到受那个关键Ip地址所影响的所有节点；最后点击Finish按钮完成配置。\n查看Path Outage\n在总导航条上选中Path Outages，在页面中你可以看到你配置的所有Path Outages的规则。\n这个文章基本上翻译的是http://www.opennms.org/index.php/Path_Outage_How-To 只是觉得这是个不错的功能，所以就大概翻译了一下，希望对感兴趣的朋友们有帮助。由于手头硬件环境的限制，我还没有真实测试过这个功能，如果您对此功能做了什么测试的话，也欢迎和我交流，请留言或者或发邮件给我。\n",
    "ref": "/2007/12/23/opennms-path-outage/"
  },{
    "title": "如何使用OpenNMS中的StrafePing功能",
    "date": "",
    "description": "",
    "body": "自从1.3.7之后OpenNMS加入了Smokeping功能，取名为StrafePing。从此OpenNMS也成了Smokeping的银牌赞助商。\n\n安装：\n\nStafePing做为一个Poller默认被安装在1.3.7后的软件中，不需要单独安装和配置。\n\n配置：\n\n没有单独的配置文件，相关的配置信息需要修改文件： poller-configuration.xml中的相关部分。需要在 标记中加入需要使用的Ip地址范围。启用之后StrafePing做为一个被监控的服务显示在这个节点上。\n\n默认安装OpenNMS并不使用这个服务，是为了减小网络流量；推荐根据OpenNMS硬件的能力只对部分节点做这种监控。\n\n使用：\n\n需要产品StrafePing的图形有两种方式。1）在OpenNMS首页上，点击右侧的Resources Graphs，选中产看的机器，在Response Time下面的列表中选中需要产看的Ip地址，点击Submit，即可产看到图形。2）在节点产看页面，选中Resources Graphs，在Response Time下面的列表中选中需要产看的Ip地址，点击Submit，即可产看到图形。\n\n如何想看懂StafePing****的图\n\n请参考我以前的blog http://lzheng.blogspot.com/2007/02/smokeping-rttround-trip-time-tcp-tcp.html\n\n参考Smokeping的网站http://oss.oetiker.ch/smokeping/doc/reading.en.html\n",
    "ref": "/2007/12/21/opennms-strafeping/"
  },{
    "title": "发送告警短信的方法，德国工艺服了",
    "date": "",
    "description": "",
    "body": "在OpenNMS的邮件组中偶然发现的这个解决方案，利用这个方案你可以用串口连接外置的GSM modem来发送短信。\n这个方案的名称叫做：SMS Server Tools 网址在－\u0026gt; http://www.meinemullemaus.de/smstools/index.html\n工作原理 －\u0026gt; http://www.meinemullemaus.de/smstools/slideshow/page1.html\n据说是可以运行在任何平台上，能支持很多设备，不过我没用试过，记录一下日后可能有用。\n",
    "ref": "/2007/12/14/gsm-modem-alert-sms/"
  },{
    "title": "如何用通过OpenNMS监控Windows 服务器",
    "date": "",
    "description": "",
    "body": "OpenNMS可以监控可用性和性能参数。下面看看OpenNMS监控Windows服务器的三种情况。\n第一种情况：\nWindows机器上没有安装SNMP服务，在自动发现了这个节点后，它会被加入节点列表，之后它被定期的轮询。如果这个节点断网了，OpenNMS会报警；同时这个节点的可用性被计算。自动发现还会发现这个机器上的服务。ICMP是肯定会有的，还可能有http等其他的服务；这些服务也会被定时的轮询，如果某个服务停了，这个节点的整个的可用性受到影响。这种情况下该节点的所有服务的响应时间会被OpenNMS收集并保持历史数据。\n第二种情况：\n安装了SNMP服务。先说一下windows服务的安全性，默认情况下public是默认的只读密码；为了更加安全可以配置其他的只读密码，并指定某些特定的IP才能访问这个节点。这个策略在Windows的觉策略中很容易实现，或者说建议使用域控制器来管理这个策略，比较方便。假定OpenNMS能访问该节点的snmp服务的情况下。这些数据会增加：SNMP Attributes；在选择了资源图后，可以看到snmp的节点数据和接口数据。进入后可以看到，其实收集 的是一个tcp／ip接口上基本的信息：流量，连接数，丢包，错包等。个人认为流量是个最有用的数据，特别是对于一些简单的web/ftp服务器也就够用了。\n第三种情况：\n我们需要监控到操作系统的性能数据cpu/disk/RAM等。就需要安装一个snmp代理，这个代理可以提供这些信息，opennms才能通过snmp协议收集这些数据。需要到下面网址下载一个免费的snmp代理，当然这个产品也有收费版本：http://www.wtcs.org/informant/download.htm 这个代理很小需要在windows机器上安装一下。默认情况下OpenNMS的对windows采集模板中包含了对cpu/disk/ram等数据的采集，等到下一次OpenNMS在采集这个机器的时候相关数据就会被显示在节点snmp数据下面。\n这里是通过这个免费的snmp代理能采集到的数据：\n/Program Files/SNMP Informant/standard/mibs/informant-std-tree.txt\n\u0026ndash;standard(1.3.6.1.4.1.9600.1.1)\n|\n+\u0026ndash;logicalDiskTable(1)\n| |\n| +\u0026ndash;logicalDiskEntry(1) [lDiskInstance]\n| |\n| +\u0026ndash; r-n InstanceName lDiskInstance(1)\n| +\u0026ndash; r-n Gauge32 lDiskPercentDiskReadTime(2)\n| +\u0026ndash; r-n Gauge32 lDiskPercentDiskTime(3)\n| +\u0026ndash; r-n Gauge32 lDiskPercentDiskWriteTime(4)\n| +\u0026ndash; r-n Gauge32 lDiskPercentFreeSpace(5)\n| +\u0026ndash; r-n Gauge32 lDiskPercentIdleTime(6)\n| +\u0026ndash; r-n Gauge32 lDiskAvgDiskQueueLength(7)\n| +\u0026ndash; r-n Gauge32 lDiskAvgDiskReadQueueLength(8)\n| +\u0026ndash; r-n Gauge32 lDiskAvgDiskWriteQueueLength(9)\n| +\u0026ndash; r-n Gauge32 lDiskAvgDiskSecPerRead(10)\n| +\u0026ndash; r-n Gauge32 lDiskAvgDiskSecPerTransfer(11)\n| +\u0026ndash; r-n Gauge32 lDiskAvgDiskSecPerWrite(12)\n| +\u0026ndash; r-n Gauge32 lDiskCurrentDiskQueueLength(13)\n| +\u0026ndash; r-n Gauge32 lDiskDiskBytesPerSec(14)\n| +\u0026ndash; r-n Gauge32 lDiskDiskReadBytesPerSec(15)\n| +\u0026ndash; r-n Gauge32 lDiskDiskReadsPerSec(16)\n| +\u0026ndash; r-n Gauge32 lDiskDiskTransfersPerSec(17)\n| +\u0026ndash; r-n Gauge32 lDiskDiskWriteBytesPerSec(18)\n| +\u0026ndash; r-n Gauge32 lDiskDiskWritesPerSec(19)\n| +\u0026ndash; r-n Gauge32 lDiskFreeMegabytes(20)\n| +\u0026ndash; r-n Gauge32 lDiskSplitIOPerSec(21)\n|\n+\u0026ndash;memory(2)\n| |\n| +\u0026ndash; r-n Gauge32 memoryAvailableBytes(1)\n| +\u0026ndash; r-n Gauge32 memoryAvailableKBytes(2)\n| +\u0026ndash; r-n Gauge32 memoryAvailableMBytes(3)\n| +\u0026ndash; r-n Gauge32 memoryCommittedBytes(4)\n| +\u0026ndash; r-n Gauge32 memoryCacheBytes(5)\n| +\u0026ndash; r-n Gauge32 memoryCacheBytesPeak(6)\n| +\u0026ndash; r-n Gauge32 memoryPageFaultsPerSec(7)\n| +\u0026ndash; r-n Gauge32 memoryPagesInputPerSec(8)\n| +\u0026ndash; r-n Gauge32 memoryPagesOutputPerSec(9)\n| +\u0026ndash; r-n Gauge32 memoryPagesPerSec(10)\n| +\u0026ndash; r-n Gauge32 memoryPoolNonpagedBytes(11)\n| +\u0026ndash; r-n Gauge32 memoryPoolPagedBytes(12)\n| +\u0026ndash; r-n Gauge32 memoryPoolPagedResidentBytes(13)\n| +\u0026ndash; r-n Gauge32 memorySystemCacheResidentBytes(14)\n| +\u0026ndash; r-n Gauge32 memorySystemCodeResidentBytes(15)\n| +\u0026ndash; r-n Gauge32 memorySystemCodeTotalBytes(16)\n| +\u0026ndash; r-n Gauge32 memorySystemDriverResidentBytes(17)\n| +\u0026ndash; r-n Gauge32 memorySystemDriverTotalBytes(18)\n|\n+\u0026ndash;networkInterfaceTable(3)\n| |\n| +\u0026ndash;networkInterfaceEntry(1) [netInstance]\n| |\n| +\u0026ndash; r-n InstanceName netInstance(1)\n| +\u0026ndash; r-n Gauge32 netBytesReceivedPerSec(2)\n| +\u0026ndash; r-n Gauge32 netBytesSentPerSec(3)\n| +\u0026ndash; r-n Gauge32 netBytesTotalPerSec(4)\n| +\u0026ndash; r-n Gauge32 netCurrentBandwidth(5)\n| +\u0026ndash; r-n Gauge32 netOutputQueueLength(6)\n| +\u0026ndash; r-n Gauge32 netPacketsOutboundDiscarded(7)\n| +\u0026ndash; r-n Gauge32 netPacketsOutboundErrors(8)\n| +\u0026ndash; r-n Gauge32 netPacketsReceivedDiscarded(9)\n| +\u0026ndash; r-n Gauge32 netPacketsReceivedErrors(10)\n| +\u0026ndash; r-n Gauge32 netPacketsReceivedUnknown(11)\n| +\u0026ndash; r-n Gauge32 netPacketsReceivedPerSec(12)\n| +\u0026ndash; r-n Gauge32 netPacketsSentPerSec(13)\n| +\u0026ndash; r-n Gauge32 netPacketsPerSec(14)\n|\n+\u0026ndash;objects(4)\n| |\n| +\u0026ndash; r-n Gauge32 objectsProcesses(1)\n| +\u0026ndash; r-n Gauge32 objectsThreads(2)\n|\n+\u0026ndash;processorTable(5)\n| |\n| +\u0026ndash;processorEntry(1) [cpuInstance]\n| |\n| +\u0026ndash; r-n InstanceName cpuInstance(1)\n| +\u0026ndash; r-n Gauge32 cpuPercentDPCTime(2)\n| +\u0026ndash; r-n Gauge32 cpuPercentInterruptTime(3)\n| +\u0026ndash; r-n Gauge32 cpuPercentPrivilegedTime(4)\n| +\u0026ndash; r-n Gauge32 cpuPercentProcessorTime(5)\n| +\u0026ndash; r-n Gauge32 cpuPercentUserTime(6)\n| +\u0026ndash; r-n Gauge32 cpuAPCBypassesPerSec(7)\n| +\u0026ndash; r-n Gauge32 cpuDPCBypassesPerSec(8)\n| +\u0026ndash; r-n Gauge32 cpuDPCRate(9)\n| +\u0026ndash; r-n Gauge32 cpuDPCsQueuedPerSec(10)\n| +\u0026ndash; r-n Gauge32 cpuInterruptsPerSec(11)\n|\n+\u0026ndash;system(6)\n|\n+\u0026ndash; r-n Gauge32 systemSystemUpTime(1)\n最后记得在看看这个许可证文件：\nProgram Files/SNMP Informant/standard/license.txt\nLICENSE.TXT\n\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;\nFREE OF CHARGE SOFTWARE PROGRAM LICENSE AGREEMENT for\nSNMP INFORMANT STANDARD EDITION (The Software)\n\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\nCopyright(c) 2005, Informant Systems, Inc. (www.informant-systems.com), and\nCopyright(c) 2003-2005, Williams Technology Consulting Services (www.wtcs.org)\n\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\nProduct names used in this document are trademarks of their respective owners.\n* IMPORTANT-PLEASE READ CAREFULLY BEFORE INSTALLING THE SOFTWARE.\n\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\n后面略\u0026hellip;.\n在安装了snmp代理之后，我们可以看到OpenNMS可以帮助我们完成windows服务器的可用性和性能管理。\n",
    "ref": "/2007/12/14/opennms-monitoring-ms-windows/"
  },{
    "title": "OpenNMS的Yum的安装方式，安装简单了很多",
    "date": "",
    "description": "",
    "body": "OpenNMS网站的安装文档：\nhttp://www.opennms.org/index.php/Installation:Yum\n下面是我在一个CentOS4的机器上按照上面文档安装的。\n\n\n 先浏览一下这个页面 http://yum.opennms.org/repofiles/ 找到适合你的OS的那一行。  我选择安装的是1.3.10-0.8030.snapshot 这是当前开发的最新版本的OpenNMS； 运行命令： rpm -Uvh http://yum.opennms.org/repofiles/opennms-repo-snapshot-rhel4.noarch.rpm  检查是否安装成功， 运行命令： yum list opennms ；我能看到如下输出结果   [root@jng-hkg-48-dyn3328831 ~]# yum list opennms\n\nRepository opennms-stable-common is listed more than once in the configuration\n\nRepository opennms-stable-rhel4 is listed more than once in the configuration\n\nSetting up repositories\n\nReading repository metadata in from local files\n\nAvailable Packages\n\nopennms.noarch 1.3.10-0.8030.snapshot opennms-snapshot\n\n\n\n4. 安装这个版本的OpenNMS，运行命令： yum install opennms ; yum会处理包的依赖关系，把需要安装的包都从网络下载并安装上，所以我按y键开始安装，根据网络快慢的情况不同，您需要等待～～ Dependencies Resolved\n\n=============================================================================\n\nPackage Arch Version Repository Size\n\n=============================================================================\n\nInstalling:\n\nopennms noarch 1.3.10-0.8030.snapshot opennms-snapshot-common 5.0 k\n\nInstalling for dependencies:\n\niplike i386 1.0.6-1 opennms-snapshot-rhel4 10 k\n\njdk i586 2000:1.5.0_13-fcs opennms-snapshot-common 46 M\n\njicmp i386 1.0.4-1 opennms-snapshot-rhel4 43 k\n\nopennms-core noarch 1.3.10-0.8030.snapshot opennms-snapshot-common 47 M\n\nopennms-webapp-jetty noarch 1.3.10-0.8030.snapshot opennms-snapshot-common 27 M\n\npostgresql i386 7.4.17-1.RHEL4.1 update 2.0 M\n\npostgresql-server i386 7.4.17-1.RHEL4.1 update 3.0 M\n\nTransaction Summary\n\n=============================================================================\n\nInstall 8 Package(s)\n\nUpdate 0 Package(s)\n\nRemove 0 Package(s)\n\nTotal download size: 125 M\n\nIs this ok [y/N]: y\n\n\n5. 建立/opt/opennms目录；导出到环境变量 export OPENNMS_HOME=/opt/opennms 6. 配置数据库；启动数据库，第一次启动之后才能得到相关的配置文件； 运行命令： /sbin/service postgresql start 7. 修改/var/lib/pgsql/data/pg_hba.conf 文件；内容如下。 local all all trust\n\nhost all all 127.0.0.1/32 trust\n\nhost all all ::1/128 trust\n\n\n8. 修改 /var/lib/pgsql/data/postgresql.conf文件；内容如下 tcpip_socket = true\n\nisten_addresses = \u0026lsquo;localhost\u0026rsquo; (这一行加入了好些数据库启动不了了，去掉就行了，不知原因)\n\n\n9. 重新启动数据库服务；运行命令： /sbin/service postgresql restart 10. 告诉OpenNMS JDK在那里； 运行命令：$OPENNMS_HOME/bin/runjava -S /usr/java/jdk1.5.0_13/bin/java 11. 初始化OpenNMS的数据库；运行命令：$OPENNMS_HOME/bin/install -disU -l /usr/lib/jni:/usr/lib 12. 启动OpenNMS；运行命令：/etc/init.d/opennms start 13. 访问OpenNMS； http://ip:8980/opennms 用户名和密码都是admin 14. 进入管理部门，配置自动发现的ip范围，配置提示邮件。 15. Enjoy open source software, have fun. ",
    "ref": "/2007/12/13/opennms-yum-install/"
  },{
    "title": "破门而入Zenoss总部–Break in at Zenoss HQ",
    "date": "",
    "description": "",
    "body": "Zenoss 2.1 Beta版有什么新功能，看了这部三分钟的电影您就能知道了：http://content.screencast.com/media/c01d3364-2df0-4ccd-90f8-964f9268c326_ee342243-dec3-4aaf-bb9e-c82f06220438_static_0_0_Zenoss Beta 2_1 Compromised.wmv这部电影使用了碟中谍的背景音乐，和星际的片尾字幕显示。为了方便大家的观看，下面是片中部分台词\n赶快进入看看能找到什么？Zenoss在那，它在哪？就在这，打开门来看看是否有一Zenoss2.1 bate正在运行？快来看看这什么东西，干嘛的？这什么玩意？我不确定我能做这事！这是什么？看上去是一个地图么？Google Map，这是Google Map么？对啊，是Google Map～这些绿色的圆点是什么？来点击一下看看～看上去像是显示了一个数据中心之类的东西！Locations～哦!你可以拖拽这些东西？是的～这看上去，好像布局是可以配置的？哦 My god！哦你可以单击来选择一个最喜欢的布局？是啊，来看看～哇哦～～看这些黄色的按钮，他们是图标还是按钮？来点击一下看看先！这就来到了事件窗口了～来看看这个网络map怎么样？这些玩意还真的是浮动的！！非常cool！这个小企鹅是个啥？这个可能是个Linux服务器～哦，你可以告诉我windows服务器是啥，那个是windows服务器的图标？哦 My God！！！你可以点击之后看到一个小圈在上面。哇！！是在是cool！！我喜欢它！！\n在拍摄这个电影期间没有Zenoss的员工受伤，如需更多zenoss Beta 2.1的信息请联系我们www.zenoss.com\n观后感：\n一个貌似比较无知比较神经质傻哥们对Zenoes的新特色进行了一番探索，一个开发人员尝试给他做了一个演示。从一定程度上看出Zenoss开发人员比较兴奋，从侧面可以看出他们比较happy比较喜欢他们的工作，喜欢这个产品。我想这可能是一个产品创造性的主要源泉。开源软件人的创造性大于商业软件，商业软件是金钱驱动的，是商业；我觉得商业软件的开发人员很难把自己的创作性投入产品中，起码在中国是这样。\n关于Zenoss 2.1，废话少说最快的体验方法莫过于直接使用它。一种不需要安装的方式是直接下载安装好的VMWare虚拟机。你只需要到VMWare下载一个VMWare Player，在下载这个Zenoss的虚拟机压缩文件就成：http://nchc.dl.sourceforge.net/sourceforge/zenoss/zenoss-2.1.1-x86.vmware.zip下载并且解压缩后您就可以使用了。它是使用DHCP的在启动之后就能在root登录的console上看到登录的网址，请登录端口8080的那一个。登录密码是admin/zenoss，have fun～～～\n功能点评：\n先请看：http://www.zenoss.com/community/code/zenoss-2.1/zenoss-core-2-1 文中提到的电影下载自本页。我仅仅感受了一下界面并没有深入功能。就界面上讲，我觉得他们做的非常好。界面上的每一块基本上都是可以伸缩和隐藏的，好像在非IE的浏览器里显示的更好。主页上的Dashboard是可以配置的象MSN Space的页面一样的定制方式。Google Map的引入使人眼前一亮，我曾经在OpenNMS，Cacti，Unicenter中尝试Map功能;Zenoss在这个功能上创意和功能都大大超出了其他产品。他的网络地图怎一个cool字了得，做到这个份上对于3层网络拓扑图来说算是一种很高的境界了。\n我准备使用的是它的自动发现功能和对JXM监控的功能。如果您对这个软件有什么心得的话别告诉我。\n后记：\n我仔细看了一下Zenoss.com网站，发现两年之内变化还是蛮大的。最大的方面是在它提供的技术支持和服务上。Zenoss Enterprise Edition的 Zenoss Subscriptions定价从66$到150$不等，同时还提供了培训、实施和定制等服务。前一段时间看到的相关新闻中提到了Zenoss可以列入10大最赚钱的开源软件之一（网管类）。他们的Zenoss很happy，他们公司也很happy。还真是鱼和熊掌兼得。\n",
    "ref": "/2007/12/07/zenoss-21-beta/"
  },{
    "title": "GLPI资产管理系统－－功能列表",
    "date": "",
    "description": "",
    "body": "常规\n* 多用户管理多种用户认证方式（local, LDAP, Active Directory, Pop/Imap, CAS)\n* 权限系统\n* 分页系统\n* 多语言支持（包括中文的14种语言支持）\n* 搜索模块显示字段列表配置\n* pdf和cvs格式导出数控\n* SQL格式保存和恢复\n* 数据XML格式导\n* 出可配置的下拉框系\n* 统更新检查\n* UTF8界面\n* HTML4.0.1兼容\n**资产清单**\n* 从OCS Inventory NG导入资产数据\n* 计算机资产清单管理以及与设备的连接关系，TOC总拥有成本\n* 管理显示器资产清单管理以及与计算机的关联关系\n* 网络设备资产清单管理以及和设备之间的连接(IP, Mac adresses, VLANs\u0026hellip;).\n* 打印机资产清单管理以及和计算机的连接关系，耗材，以及耗材使用的阀值报警\n* 其他外设的资产清单(scanners, graphical tables\u0026hellip;)，管理和计算机的连接关系\n* 软件资产清单管理，许可证和过期时间管理安装物理位置（房间，楼层、、）分配\n* 硬件商业和财务信息管理（采购，合同等、、）\n* 管理硬件的状态\n* 与外部其他应用的接口管理\n* 资产清单信息的更改历史管理\n**跟踪**\n* 跟踪资产清单中各种组件的故障请求单\n**Final user**\nFinal user frontend for intervention demand Mail tracking of the intervention demand feature Interventions history consultation Possibility of adding comments at the request of intervention\n**Technicians\n** Interventions demands priority management Tracking of interventions demands Mail tracking of interventions Assignment of interventions demands Opening/Closing/Re-opening of interventions Assignement of a real time of interventions Realised interventions history Displaying of the interventions to realise by a technician Displaying of the history of the interventions for a given hardware Posting of the interventions to be realized by technician Posting of the history of the interventions for a given material Management of plannings of intervention\n统计\n* 统计报表，月报，年报\n* 全局\n* 按技术人员和企业按硬件，位置或者类型\n* 按用户\n* 按分类\n* 按优先级\n* 管理企业（制造商，供应商，物流，收货人\u0026hellip;)\n* 管理和相关的合同\n* 管理联系人\n* 管理（租赁，保险和服务等）资产相关的文档和合同\n* 文档授权类型管理\n**预约**\n* 管理资产租赁的预约\n* 日历模式的预约用户界面\n**知识库**\n* 管理基本系统的知识分类条目\n* 管理公共的FAQ\n**报表**\n* 报表生产可以按照设备的类型、相关的联系人和商务信息\nTranslate from：http://www.glpi-project.org/spip.php?article53\n",
    "ref": "/2007/11/08/glpi-features-list/"
  },{
    "title": "GLPI资产管理系统－－系统简介",
    "date": "",
    "description": "",
    "body": "GLPI是一个信息资源管理器。你可以用它来给你公司建立一个资产清单（计算机，软件，打印机、、、）数据库。它的增强的功能可以是管理员的日常工作简单化，例如带有邮件提醒功能的工作跟踪系统等。它最首要的功能包括：1）所有技术资源精确的资产清单。资产的所有属性将被存储在同一个数据中。2）管理流程、维护工作的历史。这是一个动态的应用，它直接连把需要发出支持请求的用户和技术人员连接起来。（注：上文来自http://www.glpi-project.org/spip.php?article43）\n在ITpub上发过一个非常不错的帖子，请点击：http://www.itpub.net/762653.html 这个人是今年四月在他们公司使用的总结贴，对该项目的主要功能介绍的比较全面。本人同期发布的文章：GLPI \u0026ndash;IT资源生命周期管理\n",
    "ref": "/2007/11/07/glpi-features-list2/"
  },{
    "title": "Zenoss 2.0 安装失败：）",
    "date": "",
    "description": "",
    "body": "今天是在没有心情搞了。快被Zenoss的网站给搞糊涂了。\n我准备好了一个Suse10的机器来装Zenoss。\n首先想到的是上http://zenoss.com\n在下载的页面，我有点差异了，怎么系统兼容表里命名写这有suse10的rpm包，而下载连接的列表里确只有redhat和centos的安装包，奇怪！！！！\n接着看看文档把，发现新的希望：http://www.zenoss.com/community/docs/install-guides/install-on-suse-10/ \n看看这文档，乍一看很不错啊，写的步骤非常清晰，大喜。没看完我有纳闷了，他明明也说Zenoss-2.0.0-0.sles10.i386.rpm这样一个安装文件啊。算了去google搜一下把，看到的帖子都来自zenoss的论坛啊，发现满世界的人都在找这个文件，哦，地球人都知道啊 ！\n还是不死心，去sourceforge搜，结果一样，也没有。\n我昏啊，你们明明写这支持，还有安装文档，为啥就不提供一个下载的连接呢？？？\nZenoss的人你们都脑子进水了么！！呵呵第一次这么说开源的人，这次真的是无奈得很，以前把这种信息的搜寻和troubleshooting做为一个乐趣，现在真的没这样耐心了。\n最终zenoss的安装，宣告失败！！ :-)\n一晃三个月都没更新这个blog了！！！～～～！！！！继续开源ing ",
    "ref": "/2007/09/06/zenoss-20-install/"
  },{
    "title": "How to install  hyperic-hq on openSuse 10.2",
    "date": "",
    "description": "",
    "body": "\n \n  Make the hq and group \ngroupadd hq useradd -c \u0026lsquo;hyperic hq\u0026rsquo; -d /home/hq -g hq -s /bin/bash hq mkdir /home/hq chown -R hq.hq /home/hq\n \n  ****Untar installer package and install **** \ncd /home/hq tar zxf hyperic-hq-installer-3.0.4-389-x86-linux.tgz chown -R hq.hq . su hq hq@Suse:~\u0026gt; cd hyperic-hq-installer/ hq@Suse:~/hyperic-hq-installer\u0026gt; ls LICENSES.txt agent-3.0.4.tgz installer-3.0.4 server-3.0.4.tgz setup.bat setup.sh shell-3.0.4.tgz hq@Suse:~/hyperic-hq-installer\u0026gt; ./setup.sh Unpacking JRE to temporary directory /tmp/jre Initializing Hyperic HQ 3.0.4 Installation\u0026hellip; Loading taskdefs\u0026hellip; Taskdefs loaded Choose which software to install: 1: Hyperic HQ Server 2: Hyperic HQ Shell 3: Hyperic HQ Agent You may enter multiple choices, separated by commas. 1,2,3 HQ server installation path [default \u0026lsquo;/home/hyperic\u0026rsquo;]: /home/hq HQ shell installation path [default \u0026lsquo;/home/hq\u0026rsquo;]: HQ agent installation path [default \u0026lsquo;/home/hq\u0026rsquo;]: Loading install configuration\u0026hellip; Install configuration loaded. Preparing to install\u0026hellip; Validating agent install configuration\u0026hellip; Validating shell install configuration\u0026hellip; Validating server install configuration\u0026hellip; Checking server webapp port\u0026hellip; Checking server secure webapp port\u0026hellip; Checking server JRMP port\u0026hellip; Checking server JNP port\u0026hellip; Verifying admin user properties Validating server DB configuration\u0026hellip; Installing the agent\u0026hellip; Looking for previous installation Unpacking agent to: /home/hq/agent-3.0.4\u0026hellip; Installing the JRE \u0026hellip; Unpacking JRE x86-linux-glibc2-jre.tar.gz to: /home/hq/agent-3.0.4\u0026hellip; Setting permissions on agent binaries\u0026hellip; Fixing line endings on text files\u0026hellip; \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; Installation Complete: Agent successfully installed to: /home/hq/agent-3.0.4 \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; You can now start your HQ agent by running this command: /home/hq/agent-3.0.4/hq-agent.sh start Installing the shell\u0026hellip; Unpacking shell to: /home/hq/shell-3.0.4\u0026hellip; Installing the JRE \u0026hellip; Unpacking JRE x86-linux-glibc2-jre.tar.gz to: /home/hq/shell-3.0.4\u0026hellip; Setting permissions on shell binaries\u0026hellip; Fixing line endings on text files\u0026hellip; \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; Installation Complete: Command shell successfully installed to: /home/hq/shell-3.0.4 \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; You can now start the HQ shell by running this command: /home/hq/shell-3.0.4/hq-shell.sh Installing the server\u0026hellip; Unpacking server to: /home/hq/server-3.0.4\u0026hellip; Creating server configuration files\u0026hellip; Copying binaries and libraries to server installation\u0026hellip; Copying server configuration file\u0026hellip; Copying server control file\u0026hellip; Copying server binaries\u0026hellip; Copying server libs\u0026hellip; Setting up server database\u0026hellip; Now login to another terminal as root and execute this script: /home/hq/hyperic-hq-installer/installer-3.0.4/data/hqdb/tune-os.sh This script sets up the proper shared memory settings to run the built-in database. Press Enter after you run the script to continue this installation. Setting up JDBC driver\u0026hellip; Copying database files\u0026hellip; Configuring database\u0026hellip; Starting repopulation of configuration table\u0026hellip; Waiting for built-in database to start (on port 9432)\u0026hellip; Starting built-in database\u0026hellip; Preparing database\u0026hellip; Vacuuming database\u0026hellip; Waiting for server to stop\u0026hellip; Stopping built-in database\u0026hellip; Built-in database stopped. Installing the JRE \u0026hellip; Unpacking JRE x86-linux-glibc2-jre.tar.gz to: /home/hq/server-3.0.4\u0026hellip; Setting permissions on server binaries\u0026hellip; Fixing line endings on text files\u0026hellip; \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; Installation Complete: Server successfully installed to: /home/hq/server-3.0.4 \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash; You can now start your HQ server by running this command: /home/hq/server-3.0.4/bin/hq-server.sh start Note that the first time the HQ server starts up it may take several minutes to initialize. Subsequent startups will be much faster. Once the HQ server reports that it has successfully started, you can log in to your HQ server at: http://Suse.opensource.org:7080/ username: hqadmin password: hqadmin To change your password, log in to the HQ server, click the \u0026ldquo;Administration\u0026rdquo; link, choose \u0026ldquo;List Users\u0026rdquo;, then click on the \u0026ldquo;hqadmin\u0026rdquo; user. Setup completed. A copy of the output shown above has been saved to: /home/hq/hyperic-hq-installer/installer-3.0.4/hq-install.log Deleting temporary JRE hq@Suse:~/hyperic-hq-installer\u0026gt; hq@Suse:~/hyperic-hq-installer\u0026gt; /home/hq/server-3.0.4/bin/hq-server.sh start Starting HQ server\u0026hellip; Initializing HQ server configuration\u0026hellip; Checking jboss jndi port\u0026hellip; Checking jboss mbean port\u0026hellip; Starting HQ built-in database\u0026hellip; HQ built-in database started. Booting the HQ server\u0026hellip; HQ server booted. Login to HQ at: http://127.0.0.1:7080/ hq@Suse:~/hyperic-hq-installer\u0026gt;\n \n  ****Startup a Linux agent **** \nlogin as: hq Using keyboard-interactive authentication. Password: Have a lot of fun\u0026hellip; hq@Suse:~\u0026gt; pwd /home/hq hq@Suse:~\u0026gt; ls agent-3.0.4 hyperic-hq-installer-3.0.4-389-x86-linux.tgz shell-3.0.4 hyperic-hq-installer server-3.0.4 hq@Suse:~\u0026gt; cd agent-3.0.4/ hq@Suse:~/agent-3.0.4\u0026gt; ls agent.properties hq-agent.exe jre pdk README.txt background.bat hq-agent.sh lib product_connectors tmp background.sh jaas.config log rcfiles hq@Suse:~/agent-3.0.4\u0026gt; ./hq-agent.sh Syntax: ./hq-agent.sh hq@Suse:~/agent-3.0.4\u0026gt; ./hq-agent.sh start Starting agent - Unable to load agent token file. Generating a new one \u0026hellip; Done - Invoking agent - Starting agent process Agent successfully started [ Running agent setup ] What is the HQ server IP address: 127.0.0.1 Should Agent communications to HQ always be secure [default=no]: What is the HQ server port [default=7080]: - Testing insecure connection \u0026hellip; Success What is your HQ login [default=hqadmin]: What is your HQ password: What IP should HQ use to contact the agent [default=127.0.0.2]: What port should HQ use to contact the agent [default=2144]: - Received temporary auth token from agent - Registering agent with HQ - HQ gave us the following agent token 1182416897800-4295885070579017509-616515886345923858 - Informing agent of new HQ server - Validating - Successfully setup agent hq@Suse:~/agent-3.0.4\u0026gt; Note: this agent and server are same machine.\n \n  ****Access to Web console **** \nhttp://Ip_address:7080/ default username and password [hqadmin/hqadmin]\n",
    "ref": "/2007/06/21/how-to-install-hyperic-hq-on-opensuse-102/"
  },{
    "title": "OCSNG 代理程序生成的清单扫描信息",
    "date": "",
    "description": "",
    "body": "\n Linux 硬件是下面的Windows机,软件是openSuse10.2运行在VMWare中.\n  ** Information ** \n** Value ** \n\nTag \nLiuZheng \n\n\n**PROCESSOR(S)** \n\n\n** Type ** \n** Processor Speed (Mhz) ** \n** Number** \n\nIntel(R) Core(TM)2 CPU 6400 @ 2.13GHz \n2126 \n1 \n\n\n**MEMORY** \n\n\n** Caption ** \n** Description ** \n** Capacity (MB) ** \n** Purpose ** \n** Type ** \n** Speed ** \n** Slot number ** \n\n\nDIMM \n512 \n\nDRAM \nUnknown \n0 \n\n\nDIMM \nNo \n\nDRAM \nUnknown \n0 \n\n\nDIMM \nNo \n\nDRAM \nUnknown \n0 \n\n\nDIMM \nNo \n\nDRAM \nUnknown \n0 \n\n\n**STORAGE** \n\n\n** Name ** \n** Manufacturer ** \n** Model ** \n** Description ** \n** Type ** \n** Disk size (MB) ** \n\n\nVMware \nVMwareVirtual S \nSCSI \ndisk \n83886 \n\n\n?? \nVMware Virtual IDE CDROM Drive \nIDE \nremovable \n3789 \n\n\n**DISK(S)** \n\n\n** Letter ** \n** Type ** \n** File System ** \n** Total (MB) ** \n** Free (MB) ** \n** Designation** \n\n\n/dev/sda2 \next3 \n20157 \n16308 \n/ \n\n\nudev \ntmpfs \n252 \n251 \n/dev \n\n\n/dev/sda3 \next3 \n58449 \n55142 \n/home \n\n\n**BIOS** \n\n\n** Serial number ** \n** Manufacturer ** \n** Model ** \n** BIOS Manufacturer ** \n** BIOS Version ** \n** BIOS Date ** \n\nVMware-56 4d b2 4c 00 88 78 67-4c 69 00 04 0f 38 74 e7 \nVMware, Inc. \nVMware Virtual Platform \nPhoenix Technologies LTD \n6.00 \n12/03/2005 \n\n\n**SOUND** \n\n\n** Manufacturer ** \n** Name ** \n** Description ** \n\nEnsoniq ES1371 [AudioPCI-97] \nMultimedia audio controller \nrev 02 \n\n\n**VIDEO CARD** \n\n\n** Name ** \n** Chipset ** \n** Memory (MB)** \n** Resolution** \n\nVMware Inc [VMware SVGA II] PCI Display Adapter \nVGA compatible controller \n\n\n\n\n**INPUT DEVICES** \n\n\n** Type ** \n** Manufacturer ** \n** Caption ** \n** Description ** \n** Interface ** \n\nkbd \n\nKeyboard[0] \n\nStandard \n\nmouse \n\nMouse[1] \n\nIMPS/2 \n\n\n**MONITOR(S)** \n\n\n** Manufacturer ** \n** Caption ** \n** Manufactured on (week/year) ** \n** Type ** \n** Serial number ** \n\nVMware, Inc \nvmware \n\n\n\n\n\n**NETWORK(S)** \n\n\n**Description ** \n** Type ** \n** Speed ** \n** MAC address ** \n** Status ** \n** IP address ** \n** mask** \n** Gateway ** \n** Network number ** \n** DHCP IP ** \n\neth0 \nEthernet \n\n00:0C:29:38:74:E7\n(Vmware, Inc.) \nUp \n10.100.113.174 \n255.255.252.0 \n10.100.112.3 \n10.100.112.0 \n\n\n\n**PORT(S)** \n\n\n** Type ** \n** Name ** \n** Free ** \n** Description ** \n\nSerial Port 16550A Compatible \nJ19 \nDB-9 male \n9 Pin Dual Inline (pin 10 cut) \n\nParallel Port ECP/EPP \nJ23 \nDB-25 female \n25 Pin Dual Inline (pin 26 cut) \n\nKeyboard Port \nJ11 \nCircular DIN-8 male \nNone \n\nKeyboard Port \nJ12 \nCircular DIN-8 male \nNone \n\n\n**CONTROLLER(S)** \n\n\n** Manufacturer ** \n** Name ** \n** Type ** \n\nIntel Corporation 440BX/ZX/DX - 82443BX/ZX/DX Host bridge \nHost bridge \nrev 01 \n\nIntel Corporation 440BX/ZX/DX - 82443BX/ZX/DX AGP bridge \nPCI bridge \nrev 01 \n\nIntel Corporation 82371AB/EB/MB PIIX4 ISA \nISA bridge \nrev 08 \n\nIntel Corporation 82371AB/EB/MB PIIX4 IDE \nIDE interface \nrev 01 \n\nIntel Corporation 82371AB/EB/MB PIIX4 USB \nUSB Controller \n\n\nIntel Corporation 82371AB/EB/MB PIIX4 ACPI \nBridge \nrev 08 \n\nVMware Inc [VMware SVGA II] PCI Display Adapter \nVGA compatible controller \n\n\nLSI Logic / Symbios Logic 53c1030 PCI-X Fusion-MPT Dual Ultra320 SCSI \nSCSI storage controller \nrev 01 \n\nAdvanced Micro Devices [AMD] 79c970 [PCnet32 LANCE] \nEthernet controller \nrev 10 \n\nEnsoniq ES1371 [AudioPCI-97] \nMultimedia audio controller \nrev 02 \n\n\n**SLOT(S)** \n\n\n** Name ** \n** Description ** \n** Designation ** \n\nISA Slot J8 \n16-bit ISA \n\n\nISA Slot J9 \n16-bit ISA \n\n\nISA Slot J10 \n16-bit ISA \n\n\nPCI Slot J11 \n32-bit PCI \n1 \n\nPCI Slot J12 \n32-bit PCI \n2 \n\nPCI Slot J13 \n32-bit PCI \n3 \n\nPCI Slot J14 \n32-bit PCI \n4 \n\n\n**SOFTWARE **\n软件部分省略.\n\n Windows XP 硬件是Dell optiplex 745\n  ** Information ** \n** Value ** \n\nTag \nassetid3456 \n\n\n**PROCESSOR(S)** \n\n\n** Type ** \n** Processor Speed (Mhz) ** \n** Number** \n\nIntel(R) Core(TM)2 CPU 6400 @ 2.13GHz \n2126 \n2 \n\n\n**MEMORY** \n\n\n** Caption ** \n** Description ** \n** Capacity (MB) ** \n** Purpose ** \n** Type ** \n** Speed ** \n** Slot number ** \n\nPhysical Memory Array \nPhysical Memory Array \n0 \nSystem Memory \nEmpty slot \nN/A \n3 \n\nPhysical Memory Array \nPhysical Memory Array \n0 \nSystem Memory \nEmpty slot \nN/A \n4 \n\nPhysical Memory \nDIMM_1 (Single-bit ECC) \n1024 \nSystem Memory \nUnknown \n667 \n1 \n\nPhysical Memory \nDIMM_2 (Single-bit ECC) \n1024 \nSystem Memory \nUnknown \n667 \n2 \n\n\n**STORAGE** \n\n\n** Name ** \n** Manufacturer ** \n** Model ** \n** Description ** \n** Type ** \n** Disk size (MB) ** \n\nFloppy disk drive \n(Standard floppy disk drives) \nFloppy disk drive \nFloppy disk drive \n\n\n\nST3160812SV \n(Standard disk drives) \n//./PHYSICALDRIVE1 \nDisk drive \nFixedxhard disk media \n152625 \n\nWDC WD2500JS-75NCB1 \n(Standard disk drives) \n//./PHYSICALDRIVE0 \nDisk drive \nFixedxhard disk media \n238417 \n\nTSSTcorp DVD+-RW TS-H653A \n(Standard CD-ROM drives) \nTSSTcorp DVD+-RW TS-H653A \nCD-ROM Drive \nCD-ROM \n\n\nGeneric DVD-ROM SCSI CdRom Device \n(Standard CD-ROM drives) \nGeneric DVD-ROM SCSI CdRom Device \nCD-ROM Drive \nCD-ROM \n3535 \n\n\n**DISK(S)** \n\n\n** Letter ** \n** Type ** \n** File System ** \n** Total (MB) ** \n** Free (MB) ** \n** Designation** \n\nA:/ \nRemovable Drive \nN/A \n0 \n0 \nN/A \n\nC:/ \nHard Drive \nNTFS \n20512 \n9390 \n\n\nD:/ \nHard Drive \nNTFS \n217897 \n75686 \nDOCs \n\nE:/ \nCD-Rom Drive \nN/A \n0 \n0 \nN/A \n\nF:/ \nCD-Rom Drive \nN/A \n0 \n0 \nN/A \n\nG:/ \nHard Drive \nNTFS \n129999 \n34610 \nNew Volume \n\n\n**BIOS** \n\n\n** Serial number ** \n** Manufacturer ** \n** Model ** \n** BIOS Manufacturer ** \n** BIOS Version ** \n** BIOS Date ** \n\nJB5152X \nDell Inc. \nOptiPlex 745 \nDell Inc. \nDELL - 14;Phoenix ROM BIOS PLUS Version 1.10 2.2.0 ;Phoenix ROM BIOS PLUS Version 1.10 2.2.0 ;Phoenix ROM BIOS PLUS Version 1.10 2.2.0 - SMBiosVersion: 2.2.0 \nN/A \n\n\n**SOUND** \n\n\n** Manufacturer ** \n** Name ** \n** Description ** \n\nAnalog Devices \nSoundMAX Integrated Digital HD Audio Driver \nSoundMAX Integrated Digital HD Audio Driver \n\n\n**VIDEO CARD** \n\n\n** Name ** \n** Chipset ** \n** Memory (MB)** \n** Resolution** \n\n256MB ATI Radeon X1300PRO \nRadeon X1300 Series (0x7183) \n256 \n1280 x 1024 \n\n256MB ATI Radeon X1300PRO Secondary \nRadeon X1300 Series Secondary (0x71A3) \n256 \n0 x 0 \n\n\n**INPUT DEVICES** \n\n\n** Type ** \n** Manufacturer ** \n** Caption ** \n** Description ** \n** Interface ** \n\nKeyboard \n\nEnhanced (101- or 102-key) \nUSB Human Interface Device \nN/A \n\nPointing \n(Standard system devices) \nUSB Human Interface Device \nUSB Human Interface Device \nUSB \n\n\n**MONITOR(S)** \n\n\n** Manufacturer ** \n** Caption ** \n** Manufactured on (week/year) ** \n** Type ** \n** Serial number ** \n\nDell Computer Corp. \nDELL 1908FP \n22/2007 \nRGB color \nKU79075SGDLD \n\n\n**NETWORK(S)** \n\n\n**Description ** \n** Type ** \n** Speed ** \n** MAC address ** \n** Status ** \n** IP address ** \n** mask** \n** Gateway ** \n** Network number ** \n** DHCP IP ** \n\nVMware Virtual Ethernet Adapter for VMnet8 \nEthernet \n100 Mb/s \n00:50:56:C0:00:08\n(Vmware, Inc.) \nUp \n192.168.110.1 \n255.255.255.0 \n\n192.168.110.0 \n255.255.255.255 \n\nVMware Virtual Ethernet Adapter for VMnet1 \nEthernet \n100 Mb/s \n00:50:56:C0:00:01\n(Vmware, Inc.) \nUp \n192.168.190.1 \n255.255.255.0 \n\n192.168.190.0 \n255.255.255.255 \n\nBroadcom NetXtreme 57xx Gigabit Controller #2 - Packet Scheduler Miniport \nEthernet \n1 Gb/s \n00:19:B9:43:E3:0F\n(Dell Inc.) \nUp \n10.100.113.171 \n255.255.252.0 \n10.100.112.3 \n10.100.112.0 \n10.100.112.27 \n\nVCD VNC Adapter - Packet Scheduler Miniport \nEthernet \n100 Mb/s \n02:50:F2:3D:00:01 \nDown \n0.0.0.0 \n0.0.0.0 \n\n0.0.0.0 \n\n\n\n**PORT(S)** \n\n\n** Type ** \n** Name ** \n** Free ** \n** Description ** \n\nSerial \nCommunications Port (COM1) \nCommunications Port (COM1) \nCommunications Port \n\nParallel \nLPT1 \nLPT1 \nLPT1 \n\n\n**PRINTER(S)** \n\n\n** Name ** \n** Driver ** \n** Port ** \n\nHP LaserJet 2200 Series PCL 5e \nHP LaserJet 2200 Series PCL 5e \nIP_10.100.98.10 \n\n\n**CONTROLLER(S)** \n\n\n** Manufacturer ** \n** Name ** \n** Type ** \n\n(Standard floppy disk controllers) \nStandard floppy disk controller \nFloppy Controller \n\nIntel \nIntel(R) ICH8 4 port Serial ATA Storage Controller - 2820 \nIDE Controller \n\n(Standard IDE ATA/ATAPI controllers) \nPrimary IDE Channel \nIDE Controller \n\n(Standard IDE ATA/ATAPI controllers) \nSecondary IDE Channel \nIDE Controller \n\nIntel \nIntel(R) ICH8 2 port Serial ATA Storage Controller - 2825 \nIDE Controller \n\n(Standard IDE ATA/ATAPI controllers) \nPrimary IDE Channel \nIDE Controller \n\n(Standard mass storage controllers) \nD347PRT SCSI Controller \nSCSI Controller \n\nIntel \nIntel(R) ICH8 Family USB Universal Host Controller - 2834 \nUSB Controller \n\nIntel \nIntel(R) ICH8 Family USB Universal Host Controller - 2835 \nUSB Controller \n\nIntel \nIntel(R) ICH8 Family USB2 Enhanced Host Controller - 283A \nUSB Controller \n\nIntel \nIntel(R) ICH8 Family USB Universal Host Controller - 2830 \nUSB Controller \n\nIntel \nIntel(R) ICH8 Family USB Universal Host Controller - 2831 \nUSB Controller \n\nIntel \nIntel(R) ICH8 Family USB Universal Host Controller - 2832 \nUSB Controller \n\nIntel \nIntel(R) ICH8 Family USB2 Enhanced Host Controller - 2836 \nUSB Controller \n\n\n**SLOT(S)** \n\n\n** Name ** \n** Description ** \n** Designation ** \n\nSystem Slot \nSystem Slot \nSLOT1 \n\nSystem Slot \nSystem Slot \nSLOT2 \n\nSystem Slot \nSystem Slot \nSLOT3 \n\nSystem Slot \nSystem Slot \nSLOT4 \n\n\n**SOFTWARE 软件部分信息省略\n** \n\n\nOCSNG使用总结:\n\n 安装难度是中  使用简单  能支持中文和多种语言   ",
    "ref": "/2007/06/15/ocsng-inventory-windows-linux/"
  },{
    "title": "How to install OCSNG 1.0.1 on OpenSuse 10.2",
    "date": "",
    "description": "",
    "body": "下面我将描述如何安装OCSNG服务器和客户端.服务器的安装在openSuse Linux中,文中将提到Linux和Windows代理的安装方法.最终能在界面中看到两个节点的清单信息,不过只有Linux的哪个会每天更新.\nThis article is talking about how to install OCSNG 1.0.1 on a openSuSE 10.2 system.\n\n Requirements: You have to meet the following requirements.\n Apache version 1.3.33 or higher / Apache version 2.0.46 or higher.\n Mod_perl version 1.29 or higher.\n Mod_php version 4.3.2 or higher.\n PHP 4.3.2 or higher, with ZIP and GD support enabled.\n PERL 5.6 or higher.\n Perl module XML::Simple version 2.12 or higher.\n Perl module Compress::Zlib version 1.33 or higher.\n Perl module DBI version 1.40 or higher.\n Perl module DBD::Mysql version 2.9004 or higher.\n Perl module Apache::DBI version 0.93 or higher.\n Perl module Net::IP version 1.21 or higher.\n Perl module SOAP::Lite version 0.66 or higher (not mandatory)\n MySQL version 4.1.0 or higher with InnoDB engine active.\n Make utility like GNU make.\nIf you can use yast for managing package, I believe you could install all of them within 20 minutes. I won\u0026rsquo;t say more about this.\n Installing Management/communication Server and Web Console You must have root privileges to setup management server. Login OS as root, then do the following:\n1)Download install package from http://nchc.dl.sourceforge.net/sourceforge/ocsinventory/OCSNG_LINUX_SERVER_1.01.tar.gz\n2)unpack it\nSuse:/mnt/hgfs/win/OCSNG # cp OCSNG_LINUX_SERVER_1.01.tar.gz /root\nSuse:/mnt/hgfs/win/OCSNG # cd\nSuse:~ # tar zxf OCSNG_LINUX_SERVER_1.01.tar.gz\nSuse:~ # cd OCSNG_LINUX_SERVER_1.01/\nSuse:~/OCSNG_LINUX_SERVER_1.01 #\n3)run installer\nSuse:~/OCSNG_LINUX_SERVER_1.01 # sh setup.sh\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\n| |\n| Welcome to OCS Inventory NG Management server setup ! |\n| |\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\nCAUTION: If upgrading Communication server from OCS Inventory NG 1.0 RC2 and\nprevious, please remove any Apache configuration for Communication Server!\nDo you wish to continue ([y]/n)?y\nAssuming Communication server 1.0 RC2 or previous is not installed\non this computer.\nStarting OCS Inventory NG Management server setup from folder /root/OCSNG_LINUX_SERVER_1.01\nStoring log in file /root/OCSNG_LINUX_SERVER_1.01/ocs_server_setup.log\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\n| Checking for database server properties\u0026hellip; |\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\nYour MySQL client seems to be part of MySQL version 5.0.\nYour computer seems to be running MySQL 4.1 or higher, good ;-)\nWhich host is running database server [localhost] ?\nOK, database server is running on host localhost ;-)\nOn which port is running database server [3306] ?\nOK, database server is running on port 3306 ;-)\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\n| Checking for Apache web server daemon\u0026hellip; |\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\nwhich: no httpd in (/sbin:/usr/sbin:/usr/local/sbin:/opt/gnome/sbin:/root/bin:/usr/local/bin:/usr/bin:/usr/X11R6/bin:/bin:/usr/games:/opt/gnome/bin:/opt/kde3/bin:/usr/lib/mit/bin:/usr/lib/mit/sbin:/opt/opennms/bin)\nwhich: no apache in (/sbin:/usr/sbin:/usr/local/sbin:/opt/gnome/sbin:/root/bin:/usr/local/bin:/usr/bin:/usr/X11R6/bin:/bin:/usr/games:/opt/gnome/bin:/opt/kde3/bin:/usr/lib/mit/bin:/usr/lib/mit/sbin:/opt/opennms/bin)\nwhich: no apache2 in (/sbin:/usr/sbin:/usr/local/sbin:/opt/gnome/sbin:/root/bin:/usr/local/bin:/usr/bin:/usr/X11R6/bin:/bin:/usr/games:/opt/gnome/bin:/opt/kde3/bin:/usr/lib/mit/bin:/usr/lib/mit/sbin:/opt/opennms/bin)\nWhere is Apache daemon binary [] ?/usr/sbin/httpd2\nOK, using Apache daemon /usr/sbin/httpd2 ;-)\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\n| Checking for Apache main configuration file\u0026hellip; |\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\nWhere is Apache main configuration file [/srv/www//etc/apache2/httpd.conf] ?/etc/apache2/httpd.conf\nOK, using Apache main configuration file /etc/apache2/httpd.conf ;-)\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\n| Checking for Apache user account\u0026hellip; |\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\nWhich user account is running Apache web server [] ?wwwrun\nOK, Apache is running under user account wwwrun ;-)\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\n| Checking for Apache group\u0026hellip; |\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\nWhich user group is running Apache web server [wwwrun] ?www\nOK, Apache is running under users group www ;-)\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\n| Checking for PERL Interpreter\u0026hellip; |\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\nFound PERL Intrepreter at ;-)\nWhere is PERL Intrepreter binary [/usr/bin/perl] ?/usr/bin/perl\nOK, using PERL Intrepreter /usr/bin/perl ;-)\nDo you wish to setup Communication server on this computer ([y]/n)?y\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\n| Checking for Make utility\u0026hellip; |\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\nOK, Make utility found at ;-)\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\n| Checking for Apache Include configuration directory\u0026hellip; |\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\nSetup has found Apache Include configuration directory in\n.\nIf you are not using Include directive, please enter \u0026lsquo;no\u0026rsquo;.\nWhere is Apache Include configuration directory [] ?/etc/apache2/conf.d\nOK, Apache Include configuration directory /etc/apache2/conf.d found ;-)\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\n| Checking for Apache mod_perl version\u0026hellip; |\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\nChecking for Apache mod_perl version 1.99_22 or higher\nFound that mod_perl version 1.99_22 or higher is available.\nOK, Apache is using mod_perl version 1.99_22 or higher ;-)\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\n| Checking for Communication server log directory\u0026hellip; |\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\nCommunication server can create detailled logs. This logs can be enabled\nby setting interger value of LOGLEVEL to 1 in Administration console\nmenu Configuration.\nWhere to put Communication server log directory [/var/log/ocsinventory-NG] ?\nOK, Communication server will put logs into directory /var/log/ocsinventory-NG ;-)\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\n| Checking for required Perl Modules\u0026hellip; |\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\nChecking for DBI PERL module\u0026hellip;\nFound that PERL module DBI is available.\nChecking for Apache::DBI PERL module\u0026hellip;\nFound that PERL module Apache::DBI is available.\nChecking for DBD::mysql PERL module\u0026hellip;\nFound that PERL module DBD::mysql is available.\nChecking for Compress::Zlib PERL module\u0026hellip;\nFound that PERL module Compress::Zlib is available.\nChecking for XML::Simple PERL module\u0026hellip;\nFound that PERL module XML::Simple is available.\nChecking for Net::IP PERL module\u0026hellip;\nFound that PERL module Net::IP is available.\nChecking for SOAP::Lite PERL module\u0026hellip;\nFound that PERL module SOAP::Lite is available.\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\n| OK, looks good ;-) |\n| |\n| Configuring Communication server Perl modules\u0026hellip; |\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\nWARNING: INSTALLSITESCRIPT is not a known parameter.\nChecking if your kit is complete\u0026hellip;\nLooks good\n\u0026lsquo;INSTALLSITESCRIPT\u0026rsquo; is not a known MakeMaker parameter name.\nWriting Makefile for Apache::Ocsinventory\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\n| OK, looks good ;-) |\n| |\n| Preparing Communication server Perl modules\u0026hellip; |\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\n| OK, prepare finshed ;-) |\n| |\n| Installing Communication server Perl modules\u0026hellip; |\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\n| OK, Communication server Perl modules install finished;-)|\n| |\n| Creating Communication server log directory\u0026hellip; |\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\nCreating Communication server log directory /var/log/ocsinventory-NG.\nFixing Communication server log directory files permissions.\nConfiguring logrotate for Communication server.\nWriting communication server logrotate to file /etc/logrotate.d/ocsinventory-NG\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\n| OK, Communication server log directory created ;-) |\n| |\n| Now configuring Apache web server\u0026hellip; |\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\nWriting communication server configuration to file /etc/apache2/conf.d/ocsinvent\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\n| OK, Communication server setup sucessfully finished ;-) |\n| |\n| Please, review /etc/apache2/conf.d/ocsinventory.conf\n| to ensure all is good. Then restart Apache daemon. |\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\nDo you wish to setup Administration server (web administration console)\non this computer ([y]/n)?y\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\n| Checking for Apache root document directory\u0026hellip; |\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\nWhere is Apache root document directory [] ?/srv/www/htdocs\nOK, Apache root document directory is /srv/www/htdocs ;-)\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\n| Checking for required Perl Modules\u0026hellip; |\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\nChecking for DBI PERL module\u0026hellip;\nFound that PERL module DBI is available.\nChecking for DBD::mysql PERL module\u0026hellip;\nFound that PERL module DBD::mysql is available.\nChecking for XML::Simple PERL module\u0026hellip;\nFound that PERL module XML::Simple is available.\nChecking for Net::IP PERL module\u0026hellip;\nFound that PERL module Net::IP is available.\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\n| Installing files for Administration server\u0026hellip; |\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\nCreating directory /srv/www/htdocs/download.\nCreating directory /srv/www/htdocs/ocsreports.\nCopying files to /srv/www/htdocs/ocsreports.\nFixing directories and files permissions.\nConfiguring IPDISCOVER-UTIL Perl script.\nInstalling IPDISCOVER-UTIL Perl script.\nFixing permissions on IPDISCOVER-UTIL Perl script.\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\n| OK, Administration server installation finished ;-) |\n| |\n| Point your browser to http://server/ocsreports to |\n| configure database server and create/update schema. |\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\nSetup has created a log file /root/OCSNG_LINUX_SERVER_1.01/ocs_server_setup.log. Please, save this file.\nIf you encounter error while running OCS Inventory NG Management server,\nwe can ask you to show us his content !\nDON\u0026rsquo;T FORGET TO RESTART APACHE DAEMON !\nEnjoy OCS Inventory NG ;-)\nSuse:~/OCSNG_LINUX_SERVER_1.01 #\nSuse:~/OCSNG_LINUX_SERVER_1.01 # /etc/init.d/apache2 restart\nSyntax OK\nShutting down httpd2 (waiting for all children to terminate) done\nStarting httpd2 (prefork) done\nSuse:~/OCSNG_LINUX_SERVER_1.01 #\nAs we can see the installation is successful. If you are running a different Linux, you should input other settings.\n  \n Configuring Management Server The following is a post-install setup for management server. Y will go through it from a web browser. Open FireFox it is my current favorite browser and point it on URL http://Ip_address/ocsreports\nThe first warning message should be this.\nWARNING: You will not be able to build any auto deployment package with size greater than 2M.\nYou must raise both post_max_size and upload_max_filesize in your php.ini to correct this.\nDo the following to fix it:\n# vi php.ini\nThe default post_max_size is 8M, we are going to increase upload_max_filesize to 12M\n; Maximum allowed size for uploaded files.\nupload_max_filesize = 12MWe should restart apache to take it effect\nRun this command:\n/etc/init.d/apache2 restart\nPress F5 to refresh the first web page, this warning is still there. Let\u0026rsquo;s just go ahead to input the mysql \u0026gt;\n  MySql login : \n\n\nMySql password : \n\n\nMySql HostName : \n\n\n\n\n\n\n\nroot\nxxxx\nlocalhost\nClick Send button.\nThere is a text box as the following:\n**\nPlease enter the label of the windows client tag input box:\n(Leave empty if you don't want a popup to be shown on each agent launch).**\nI'd like to use \"Asset ID\" for this field. Click 'Submit Query' button to finish it.\nNow, you are able to log into web console from http://Ip_address/ocsreports/\nBefore you input admin/admin , you could use different languages. OCSNG 1.01 support 11 languages.\n\n Setting up Agents on openSuse and a Windows Xp client. Download agent packages from internet.\nInstalling a Linux agent:\nSuse:~ # tar zxf OCSNG_LINUX_AGENT_1.01.tar.gz\nSuse:~ # cd OCSNG_LINUX_AGENT_1.01/\nSuse:~/OCSNG_LINUX_AGENT_1.01 # sh setup.sh\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\n| |\n| Welcome to OCS Inventory NG Agent setup ! |\n| |\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\nWriting log to file /root/OCSNG_LINUX_AGENT_1.01/ocs_agent_setup.log\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\n| Checking for previous installation\u0026hellip; |\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\nPrevious installation of OCS Inventory NG agent not found\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\n| Checking for supplied parameters\u0026hellip; |\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\nNo parameter found\nOCS Inventory NG Agent setup running in user interactive mode\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\n| Checking for OCS Inventory NG Agent running method\u0026hellip; |\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\nOCS Inventory NG Agent can be run through 2 methods:\n- local: inventory will be generated locally to a file, without\ninteracting with Communication Server. Inventory results\nmust then be imported manually into the server through\nAdministration Console.\n- http: Agent can connect to Communication Server and will interact\nwith it to know what is has to do (inventory, ipdiscover,\ndeployment\u0026hellip;)\nWhich method will you use to generate the inventory ([http]/local) ?\nOK, OCS Inventory NG agent will be running in mode ;-)\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\n| Checking for OCS Inventory NG Communication Server\u0026hellip; |\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\nWhich host is running OCS Inventory NG Communication Server [] ?localhost\nOn which port is running OCS Inventory NG Communication Server [80] ?\nOK, OCS Inventory NG Communication Server is running on host\nand port \u0026lt;80\u0026gt; ;-)\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\n| Checking for TAG administrative information value\u0026hellip; |\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\nWhat is the value of TAG ([]) ?LiuZheng\nOK, OCS Inventory NG agent will use\nas ;-)\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\n| Checking for PERL Interpreter\u0026hellip; |\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\nOK, PERL Intrepreter found at ;-)\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\n| Checking for C/C++ Compiler\u0026hellip; |\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\nOK, C/C++ Compiler found at ;-)\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\n| Checking for Make utility\u0026hellip; |\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\nOK, Make utility found at ;-)\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\n| Checking for dmidecode binaries\u0026hellip; |\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\nFound dmidecode binaries version \u0026lt;2.8\u0026gt; at ;-)\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\n| Checking for Compress::Zlib PERL module\u0026hellip; |\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\nOK, PERL module Compress::Zlib is available ;-)\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\n| Checking for XML::Simple PERL module\u0026hellip; |\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\nOK, PERL module XML::Simple is available ;-)\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\n| Checking for Net::IP PERL module\u0026hellip; |\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\nOK, PERL module Net::IP is available ;-)\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\n| Checking for LWP::UserAgent PERL module\u0026hellip; |\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\nOK, PERL module LWP::UserAgent is available ;-)\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\n| Checking for Digest::MD5 PERL module\u0026hellip; |\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\nOK, PERL module Digest::MD5 is available ;-)\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\n| Checking for Net::SSLeay PERL module\u0026hellip; |\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\nOK, PERL module Net::SSLeay is available ;-)\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\n| Installing IPDISCOVER binary\u0026hellip; |\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\nBuilding IPDISCOVER version 3\nInstalling IPDISCOVER version 3 into /usr/sbin\nOK, IPDISCOVER version 3 setup successfully ;-)\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\n| Installing OCS Inventory NG Agent\u0026hellip; |\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\nConfiguring OCS Inventory NG Agent\nBuilding OCS Inventory NG Agent\nInstalling OCS Inventory NG Agent\nCreating OCS Inventory NG Agent symbolic link\nOK, OCS Inventory NG Agent setup successfully ;-)\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\n| Creating OCS Inventory NG Agent log directory\u0026hellip; |\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\nCreating OCS Inventory NG Agent log directory .\nConfiguring logrotate for OCS Inventory NG Agent.\nWriting OCS Inventory NG Agent logrotate to file\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\n| Installing OCS Inventory NG Agent configuration files\u0026hellip; |\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\nCreating OCS Inventory NG Agent configuration file\nCreating OCS Inventory NG Agent configuration directory\nWriting OCS Inventory NG Agent configuration file\nCreating OCS Inventory NG Agent configuration file\nWriting OCS Inventory NG Agent configuration file\nOK, OCS Inventory NG Agent configuration files setup successfully ;-)\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\n| Installing OCS Inventory NG Agent cron configuration\u0026hellip; |\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\nCreating OCS Inventory NG Agent cron configuration file\nWriting OCS Inventory NG Agent cron configuration file\nOK, OCS Inventory NG Agent cron configuration file setup successfully ;-)\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\n| Lauching OCS Inventory NG Agent\u0026hellip; |\n+\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-+\nOK, OCS Inventory NG Agent runs successfully ;-)\nSetup has created a log file /root/OCSNG_LINUX_AGENT_1.01/ocs_agent_setup.log. Please, save this file.\nIf you encounter error while running OCS Inventory NG Agent,\nwe can ask you to show us his content !\nEnjoy OCS Inventory NG ;-)\nSuse:~/OCSNG_LINUX_AGENT_1.01 #\nThe installer will install agent and a cron job on target Linux system. The job will launch OCS Inventory NG Agent once a day under root account, that means a update will get into database every day. Now you will see one single node in the web console.\n-\u0026gt;Installing a Windows Agent\nOCSNG 1.01 does not support Vista yet, so I tested it on Windows Xp/2K/2K3 and it works very well.\nYou will donwload OCSNG_WIN32_AGENT_1.01_repack.zip\nUnzip it and run ocsagent.exe. I\u0026rsquo;d like to test a standalone version agent, it is not a service version agent.\nDouble click ocsagent.exe, then you will get a new folder C:\\ocs-ng\nCreate a batch file in this folder.\nMy scan.bat file as below:\n\nOCSInventory.exe /server:Ip_Address_of_server /np /tag:\u0026ldquo;LiuZheng\u0026rdquo; /hkcu /force\n\nIn order to get inventory scan into database, you will double click scan.bat file. Now, you will get one more node in web console. It is a good idea to copy c:\\ocs-ng folder on a USB key. Then you are able to run inventory scan on other Windows machines. If you are going to get update inventory from Windows machines, you have to install OcsAgentSetup.exe agent on them.\nIf you have any issue please add a comment blow or send me a email. I could help you later if I might have any idea.\nOCSNG现在还没有中文的界面,它的代理和服务器端是支持中文的.如果你在一些中文的操作系统上做了清单扫描,扫描的某些信息在Webconsole中查看的结果可能是乱码.这时候,你可以进入浏览器的内码设置,设置成中文后,你会看到正常的中文显示.这说明它是可以支持多语言的.\n为了在做资产管理的时候对于用户比较方便,我们可以是用gpli项目. GPLI有中文界面,而且能提供流程支持.GPLI的安装和配置手册待续.\n这个安装手册用英文写,如果给您带了了不便请谅解,您有什么问题的话欢迎给我留言,谢谢观看!  ",
    "ref": "/2007/06/15/how-to-install-ocsng-101-on-opensuse-102/"
  },{
    "title": "开源IT管理工具大全之All in one虚拟机",
    "date": "",
    "description": "",
    "body": "我做开源工具测试时,90%以上是在VMWare虚拟机中实现的,本人比较懒一直没有学习Xen虚拟机的用法,等下次吧,一等要彻底开源是我的一个梦想呵呵!\n说说这个All in One虚拟机的想法,我只是想把所有的我熟悉的工具都安装和配置在一个虚拟机里,这样当有人需要给做Demo的时候,我可以很快的做一个分享.如果有朋友感兴趣的话,我可以刻盘他.总的来讲希望能分享一下我的学习成果给大家.\n第一步:安装虚拟机\n这个虚拟机我不像使用很多的Snapshoot,我以前是这么做的,从一个基础的OS发出许多分支到不同的工具;这样做的缺点有二:1)特别占磁盘空间;2)不能同时访问多个系统.\n我选择的Linux是Open Suse Linux 10.2;Suse的包管理对我来说真的很方便,从安装DVD上用Yast可以方便安装各种软件,无须考虑包之间的依赖性问题.\n我选择的是最小图形化系统安装,安装完之后,vmdk文件的大小好像是2GB多.\n接下来安装的是所有的必须的包,大致如下:Apache,Perl,MySQL,PostgreSQL,rddtool,net-snmp,php,gcc,Kernel-source(for vmware tools)\u0026hellip;等安装完之后用chkconfig on 命令设置需要自动启动的服务;然后把apache等服务逐个启动一下验证是否工作正常.\n然后安装的是VMWare tools,这个好像也不是必须,不过还是装上比较好,方便虚拟机和host机共享文件.我的虚拟机的版本是5.5.3workstation版本.\n第二步:安装各种开源软件\n下面可能会是一个很长的change log\n1. 安装OpenNMS 1.3.2 安装方法 设置了opennms的自动启动,还没有设置tomcat5.5.23的自动启动.\n2.安装Cacti **0.8.6j **安装方法, 使用的poller.php,尝试安装cactid,安装失败,原因可能是OpenSuse10.2好像没有net-snmp lib包. 暂时不安装cactid\n3.安装OCSNG 1.0.1 安装方法\n4.安装 hyperic-hq 3.0.4-389 安装方法, 2007-6-21th\n5.安装 OTRS 2.2.1-1 安装方法很简单，执行rpm安装既可, 2007-7-28th\n",
    "ref": "/2007/06/15/e5bc80e6ba90ite7aea1e79086e5b7a5e585b7e5a4a7e585a8e4b98ball-in-onee8999ae68b9fe69cba/"
  },{
    "title": "How to install Cacti on OpenSuse 10.2",
    "date": "",
    "description": "",
    "body": "1.\nDownload Extract the distribution tarball\nSuse:/opt # wget http://www.cacti.net/downloads/cacti-0.8.6j.tar.gz\nSuse:/opt # tar zxvf cacti-0.8.6j.tar.gz\n2.\nCreate the MySQL database:\nSuse:/opt # mysqladmin \u0026ndash;user=root create cacti\n3.\nImport the default cacti database:\nSuse:/opt/cacti-0.8.6j # mysql cacti \u0026lt; user=\u0026ldquo;root\u0026rdquo;\u0026gt; GRANT ALL ON cacti.* TO cactiuser@localhost IDENTIFIED BY \u0026lsquo;cacti\u0026rsquo;;\nQuery OK, 0 rows affected (0.03 sec)\nmysql\u0026gt; flush privileges;\nQuery OK, 0 rows affected (0.00 sec)\nmysql\u0026gt; quite\n5.\nEdit include/config.php and specify the MySQL user, password and database for your Cacti configuration.\nSuse:/opt/cacti-0.8.6j # vi include/config.php\n/* make sure these values refect your actual database/host/user/password */\n$database_type = \u0026ldquo;mysql\u0026rdquo;;\n$database_default = \u0026ldquo;cacti\u0026rdquo;;\n$database_hostname = \u0026ldquo;localhost\u0026rdquo;;\n$database_username = \u0026ldquo;cactiuser\u0026rdquo;;\n$database_password = \u0026ldquo;cacti\u0026rdquo;;\n$database_port = \u0026ldquo;3306\u0026rdquo;;\n6.\nSet the appropriate permissions on cacti\u0026rsquo;s directories for graph/log generation. You should execute these commands from inside cacti\u0026rsquo;s directory to change the permissions.\nSuse:/opt # mv cacti-0.8.6j /srv/www/htdocs/cacti\nSuse:/opt # useradd cactiuser -d /srv/www/htdocs/cacti\n7.\nAdd a line to your /etc/crontab file similar to:\nSuse:/srv/www/htdocs/cacti # vi /etc/crontab\n*/5 * * * * cactiuser php /srv/www/htdocs/cacti/poller.php \u0026gt; /dev/null 2\u0026gt;\u0026amp;1\n8.\nPoint your web browser to:\nhttp://10.100.113.138/cacti/index.php\n9.\nInstall cacti patches\nAccess to http://www.cacti.net/download_patches.php\nBe sure that you are in your Cacti directory when you execute these commands.\nwget http://www.cacti.net/downloads/patches/0.8.6j/ping_php_version4_snmpgetnext.patch\nwget http://www.cacti.net/downloads/patches/0.8.6j/tree_console_missing_hosts.patch\nwget http://www.cacti.net/downloads/patches/0.8.6j/thumbnail_graphs_not_working.patch\nwget http://www.cacti.net/downloads/patches/0.8.6j/graph_debug_lockup_fix.patch\nwget http://www.cacti.net/downloads/patches/0.8.6j/snmpwalk_fix.patch\npatch -p1 -N \u0026lt; ping_php_version4_snmpgetnext.patch\npatch -p1 -N \u0026lt; tree_console_missing_hosts.patch\npatch -p1 -N \u0026lt; thumbnail_graphs_not_working.patch\npatch -p1 -N \u0026lt; graph_debug_lockup_fix.patch\npatch -p1 -N \u0026lt; snmpwalk_fix.patch\n10.\nInstall cactid\nDownload Cacti.tar.gz\nSuse:/srv/www/htdocs/cacti # wget http://www.cacti.net/downloads/cactid/cacti-cactid-0.8.6i.tar.gz\nSuse:/srv/www/htdocs/cacti # tar zxvf cacti-cactid-0.8.6i.tar.gz\nSuse:/srv/www/htdocs/cacti # cd cacti-cactid-0.8.6i/\nSuse:/srv/www/htdocs/cacti/cacti-cactid-0.8.6i # ./configure\nencounter a error:\nconfigure: error: cannot find SNMP headers. Use \u0026ndash;with-snmp to specify non-default path.\nIt seems OpenSuse does not have SNMP headers within installtation DVD. Install cactid latter.\nThis article is referring Installation Guide for Unix/Linux from cacti.net\n",
    "ref": "/2007/06/14/how-to-install-cacti-on-opensuse-102/"
  },{
    "title": "建立一个开源企业",
    "date": "",
    "description": "",
    "body": "需求分析\n如果你开一个公司的话，如果你的公司需要提供人们某些在线服务的话，如果有的office 需要200人同时上网工作的话，如果您在在线业务需要三层结构的话，如果您的服务器需要7×24小时监控的话，如果您的ITsupport工程是需要同时 照顾50个服务器和200个最终用户的话，如果您的企业随时收到黑客的攻击的话、、、、、、挑战\n如果您是公司的总裁或者CTO的话，试想您将如何为公司节约成本？如果建立一个可管理的基础架构？如果保证IT满足业务的需求？如果相应各种IT维护需求？如果降低企业的运行维护成本？、、、、、、\n开源领域里的可选组件如下\n外界链接设备\n\n Vyatta路由器，可运行于低端PC，能实现DHCP，DNS，Firewall，NAT，DMZ以及多种路由协议 http://www.vyatta.com/  Asterisk PBX交换机，可以实现VoIP，语音菜单和信箱，软分机，IP电话 http://www.asterisk.org/  OpenVPN 是一个全功能的SSL VPN解决方案 http://openvpn.net/ 应用服务器\n Linux 多种版本可供选择和免费使用  Apache、Tomcat、JBoss、Perl，PHP可以建立多层的Web企业  Mysql，PostgreSQL 比较稳定和流行的数据库，能支持双机等功能 桌面机\n Ubuntu  SuSE 帮助台\n ORTS ITIL 兼容的ITsupport服务管理工具，比较好的支持对内部IT支持的流程 http://otrs.org/  SugarCRM 能和SalesForce抗衡的CRM系统，能管理客户信息，销售活动和售后支持活动 http://www.sugarcrm.com/ IT监控管理软件\n OpenNMS，Nagios，Cacti、、、网络系统监控，我的blog上还有很多可选项  GLPI ＋ OCSNG IT资源生命周期管理，您需要知道您都有那些设备和资产  Nmap网络扫描，SNORT网络入侵检测，OSSIM等工具帮助网络安全管理 不知道有没有人愿意建立这样一个开源企业？呵呵！！\n如果您有什么新的想法和补充请一定分享给我。  ",
    "ref": "/2007/06/12/e5bbbae7ab8be4b880e4b8aae5bc80e6ba90e4bc81e4b89a/"
  },{
    "title": "Go Open Source,GO! Vyatta开源软件挺进网络硬件领域",
    "date": "",
    "description": "",
    "body": "\n这是一个比较新的产品，提供开源的软件路由的解决方案；他们的目标直指Cisco这些大牌网络硬件厂商。它能简单的安装和运行在32bit的普通计算机硬件上，实现路由器的几乎所有功能；能支持的硬件平台和路由协议还真不少，请查看 Datasheet；下载网址\n在VMWare中安装了一下发现它可以完全满足我需求：\n1）在公司中办公网络建立一个隔离的测试网。\n2）测试网中提供DHCP,DNS服务\n3）提供NAT,Firewall\n4）安装简单，硬件需求低\n准备在公司实际环境中安装测试，安装和配置信息待续。\n现在我正在Vyatta Router后面的小网内更新这个Blog。\n上午的安装过程如下：\n（硬件准备）\n测试机一台 Dell Gx620，主板上带Intel的内置网卡一块TP-LINK TG-3269C，网线若干\n（网络环境）\n在一台办公网的机器上，寻找一个未使用的IP地址，这个地址会分配给Router的Internet网卡上；然后运行 ipconfig /all 记录下默认网关、默认DNS和子网掩码，这些信息会配置到Router上。\n（安装过程）\n\n 下载Vyatta的试用手册 Quick Eval Guide - Boot, Configure \u0026amp; Test the Vyatta software翻到手册的第三页，重新标准出你的网络信息，注意后面的配置跟这里的信息有关。为了简单起见，我就改了对外链接的哪个网卡的IP地址，至于内网么，有什么ip地址范围都无所谓了呵呵  下载刻录Vyatta软件 Vyatta Community Edition 2 - CD-ROM Image 刻录到一张空白CD上  把可好的CD放入机器中，从CDROM启动，这其实是一个livecd。启动过程可以无需关心，看似是一个Linux PE的CD，启动之后用root进入操作系统，root的密码是vyatta。进入后可以查看一下 vi /var/log/dmesg 主要看看你的两个网卡它是否能真确识别。我的测试机是Intel CPU的，不知道AMD的机器是否呢个装，没试过。  其它的配置过程文档中说的非常详细，不用我在多说。 安装之后的小节：\nRouter有两个网卡，在对外的网卡上做了，NAT，firewall，在对内的网卡上做了DHCP,DNS，现在我的笔记本在Router后的小网里，运行ipconfig /all的结果如下\nEthernet adapter Local Area Connection:\nConnection-specific DNS Suffix . : mycompany.com\nDescription . . . . . . . . . . . : Broadcom 570x Gigabit Integrated Con\ntroller\nPhysical Address. . . . . . . . . : 00-0F-1F-BB-B2-92\nDhcp Enabled. . . . . . . . . . . : Yes\nAutoconfiguration Enabled . . . . : Yes\nIP Address. . . . . . . . . . . . : 10.0.0.150\nSubnet Mask . . . . . . . . . . . : 255.255.255.0\nDefault Gateway . . . . . . . . . : 10.0.0.1\nDHCP Server . . . . . . . . . . . : 10.0.0.1\nDNS Servers . . . . . . . . . . . : 192.168.172.200\n10.100.112.27\nLease Obtained. . . . . . . . . . : 2007年6月12日 11:57:30\nLease Expires . . . . . . . . . . : 2007年6月13日 11:57:30\n总之这是一个非常成功的测试，这个产品真的非常Coooooool！！！！！它让我看到了OpenSource的东西不仅可以在纯软件领域和商业产品有所比较，它还能在硬件领域有所作为。\n  ",
    "ref": "/2007/06/09/go-open-sourcego-vyatta-network/"
  },{
    "title": "谁来关心核心业务系统",
    "date": "",
    "description": "",
    "body": "注:本文是我的处女作呵呵,发布在\u0026quot;网管员世界\u0026quot; 三月B刊上,原文如下:\n谁来关心核心业务系统\n——简要比较IBM Tivoli 与HP OpenView\n导语：随着IT的快速发展，中国用户对先进技术的追逐和应用正日益高涨。回想我们已经建立的这些业务系统。我们不得不用如下几个词来形容：复杂、动态、故障多和管理难。在繁琐的日常运维工作中，来自各个部门的人，似乎又在默契地担负和实现着这样的同一个使命：保持关键核心业务系统正常运转。网络系统监控软件是用来帮助IT运维人员，缩短故障解决时间和提高工作效率的有力工具。选购网络系统监控软件的技巧在于对自己的IT系统深刻的理解和对管理需求深刻的理解。假设您的用户是通过这样的一个访问路径来查看客户信息：浏览器àInternetàWeb服务器à中间件服务器à数据库；首先标出在这个路径中的每个点上，开发、测试和运行维护等各部门人员是怎样分布的。假设在每一点都有这样的一个自底向上的技术堆栈：网络à服务器操作系统à数据库à中间件àWeb服务器à客户端。再让各部门的每个相关的人员标出在哪些区间所消耗的时间和遇到的故障是最多的；这些故障是什么？记住把这些信息记录下来，并打印出来，无论如何这样的原始数据都是IT管理优化非常好的参照。在得到这样一个管理需求的分布图后，接下来就可以按图索骥来挑选相关的管理平台以及相应管理模块。一个好的监控管理系统并不一定试图监控和管理到技术堆栈中的所有对象，而是在您最需要帮助的核心部分提供有利的支持，为您清晰呈现IT系统的这样几个关键因素：可用性、性能和故障状况。记录和分析核心业务系统在这些方面的变化情况是IT监控管理软件的主要功能。\n\nIBM Tivoli和HP OpenView是主流IT监控管理套件中的两个重量级角色。它们是两个著名的市场品牌，旗下丰富的管理模块组成了非常全的产品线。选择标准如何确定呢？管理工具提供的管理功能永远超过其它因素，做单纯产品线长短的比较是没有意义的。一个清晰的管理需求定义可以使您能够非常轻松的考察和比较不同品牌的管理产品。由于它们都属于管理平台型产品，管理功能都非常的丰富和全面。本文对这两个产品的介绍和分析，无法面面俱到，所以只能对它们的工作方式、特性和原理等方面做粗略的比较；旨在抛砖引玉，引起读者注意，给您提供若干提示和思路。下面就网络管理和应用系统故障管理（操作系统、数据库、Web应用等）这两方面来做一个简要的分析和比较。这也是对核心业务系统监控管理的最基本内容。\n\n**网络管理方面：**IBM NetView和HP OpenView Network Node Manager都是很好的产品，有很多可选的功能模块。众所周知NetView产品是当年IBM从HP购买的，NetView和OpenView NNM算是一对孪生兄弟。后来，它们在各自的家庭里慢慢的长大，成为个性不同的两个产品。如今的OpenView NNM在下面的一些方面可能比NetView做的更为出色一些：1）很好的支持多种行业标准的管理协议：多个版本的SNMP、ROMON、Netflow、Ipv6、OSPF、HRSP、CDP等；2）提供全面的网络管理视图，包括二层和三层的网络拓补图；以及VLAN和其它协议视图；3）有效的内嵌事件关联引擎和事件管理配置工具，对用户处理事件和相关事件非常有帮助。OpenView NNM毕竟是具历史悠久的成熟产品，不过在IBM收购了Micromuse后；今后可能在网络管理方面,IBM和HP也可以不相伯仲了。网络管理的特殊性在于：只能通过行业标准的管理协议来从这些硬件设备上获得所需要的信息。网络监控系统一般作为网络设备的数据收集器和网络设备SNMP Trap的目的地。在多厂商设备的网络环境中，监控系统需要的是对各种硬件设备的兼容性；从实际环境出发，选择更能反映真实运行环境，更易于理解，而且容易使用的产品。\n\n\n**应用系统故障管理：**这个管理范畴中包含最多的管理功能和管理模块，它管理操作系统和操作系统之上运行的一切对象：各种数据库、Web应用、中间件、Web服务、邮件服务和标准商业应用等。它与实际业务应用系统同时运行在同一个网络环境当中，是它肩负着对核心业务系统的监控。由于这部分的功能最多最复杂，它往往被看作是管理监控的平台或者框架，是监控系统的核心部分。所有管理对象的故障告警事件都汇聚到里，其它各个功能模块都以它作为通讯平台和数据存储中心。Tivoli Monitoring和OpenView Operations就是这样的核心模块产品；它们都有很多其它相关的管理模块，这些模块大多数需要加载到这个核心框架上运行；部分模块是可以独立运行，同时和它们做故障事件集成。用户使用界面、管理策略定制、管理对象轮询、故障事件报警和管理报表等功能都关联到这里。下面将从四个不同角度简单比较一下Tivoli Monitoring和OpenView Operations的各种特性。\n\n1****、监控代理的差异 在监控主机上安装监控代理是各个厂商的相同做法，代理程序运行在被监控主机上和管理服务器通讯；执行各种数据收集任务和管理策略。操作系统代理是最基础的模块；有的厂商可以通过操作系统监控代理程序来实现对数据库、Web应用、中间件、Web服务和邮件服务等的监控，有些需要安装和配置多个代理监控程序。\n\nIBM Tivoli Monitoring\n\n\n\n\n\n2****、告警机制的差异 代理程序在采集和整理实时和历史的监控数据时，需要随时检查各种报警条件是否满足。监控最好能在故障状况发之前，将各种迹象以不同级别的事件精确地、及时地汇总到管理服务器端，以邮件，短信等方式通知到相关工作人员。\n\nIBM Tivoli Monitoring\n\n\n\n在监控对象阈值设置上可以实现复杂的逻辑。对于某个采集点在某时间点或者时间段上的数值，可以设置它和另外一个数值的几乎所有算术关系的比较；还可以逻辑上和其它采集点的状况做关联。告警条件的定义可扩展到：在给定的时间内、多资源、多阈值的情况。告警条件的判断是在代理程序端完成，最终发送告警事件到管理服务器。能定义在临界值到达时的自动触发处理动作。\n\n\n\nHP OpenView Operations\n\n\n\n告警条件的设置可以对于某个采集点在某时间点上的数值，能提供大于和小于的比较条件；其它的情况可以通过VB、Perl脚本来实现复杂条件判断。能设置尖峰持续时长，对有本地重复事件报警抑制功能；代理程序可以在临界值的到来、持续和结束三个不同阶段，定义和发出不同的事件提示；执行不同的故障修复动作。\n\n\n\n\n\n3****、用户使用界面的差异 图形化用户界面是产品选型的重要因素之一，易用性高的用户使用界面可以降低软件的复杂度。IT管理软件功能的复杂性是很多用户望而却步的一个主要因素。中国用户对报表的需求是比较特殊和苛刻的，往往需要定制和开发特定的管理报表，所以需要详细考察预定义报表和相关开发接口。\n\nIBM Tivoli Monitoring\n\n\n\n窗口用户界面和Web界面保持高度的一致性，用户可以通过Java客户端和Web浏览器连接到相同的工作区上。Tivoli用户界面非常像是一个报表分析系统。在工作区中有很多预定义的窗口，能方便的开始系统状态的查看和监控策略的定制。管理平台内置的基于权限和角色的管理也由用户界面得到了实现；分权和分区域管理是很多大型企业环境的必要需求。\n\n\n\nHP OpenView Operations\n\n\n\n图形用户界面能提供业务管理的业务视图，管理员进行面向业务的管理，实现故障定位、分析、跟踪和解决等相关管理工作。用户界面还包括各种预定义的策略模版、工具和报表。多种不同层面的中文管理报表，可以满足客户对网络性能、故障、配置等各方面的管理要求。Web用户界面和窗口用户界面稍有不同。\n\n\n\n\n\n4****、体系架构的差异 根据企业环境和管理需要的不同，监控系统有时候需要能够跨地域全网监控；有时候也只限于监控某个IT中心的核心系统。监控系统有时候和生产系统在同一个网络，有时候又只能部分运行于生产环境。在完成所有监控任务的同时，还要能被用户方便的访问；对网络的适应和防火墙的友好性是必不可少的。\n\nIBM Tivoli Monitoring\n\n\n\n它的三层管理结构可以实现分布式多级系统管理。内置了基于角色和权限分工的安全机制，所有的权限定义在管理平台中实现。IP.PIPE协议可以满足跨火墙地址转换的管理需要。同时，IP.PIPE也对防火墙端口的设置有最小的要求，以适应企业越来越严格的安全规范。\n\n\n\nHP OpenView Operations\n\n\n\n能支持灵活的分布式管理模式；能实现包括对等中心、向阳式和互为备份管理中心等多种方式。用这些架构特点可以保证跨地域和跨广域网统一集中管理的实现。两层的管理结构使得管理架构相对简捷和易于部署。\n\n\n\n\n\n上述四点是应用系统故障管理的几个关键部分。其中的技术细节和实现方式和运行细节往往比较复杂。其实任何一个具体的IT环境对监控产品都是非常具有挑战性；监控产品也可能在某些环境中无法工作；也可以对系统造负面影响。然而，深刻理解监控管理需求和实际IT环境的您则只需要做好对产品功能和架构特性的考察即可；同时将所有其他影响都降低到最小化的可以接受的范围。\n\n\nIT监控管理系统的复杂性和企业对业务应用系统管理需求的动态性，使我们很难简单的总结出一个管理秘笈或者产品技术宝典。IT管理工作的开展除了选择好用的管理监控工具外，还一定要遵循：“二分工具，八分流程”的二八管理原则。如果您机房中的电缆正像蜘蛛网一样蔓延；您的IT运维人员天天都在抱怨的电话中度过；您的硬件维护开支在漫无边际的增长；这是您可能需要学习借鉴一下ITIL最佳管理实践模型，对IT管理的优化和改革不仅需要各种监控工具的帮助，也需要通过改造管理流程来提高工作效率。总之：核心业务系统不仅需要好的IT监控管理工具，也需要CIO/CTO来设计和驾驭优良的管理流程。\n",
    "ref": "/2007/06/07/core-business-hp-ibm/"
  },{
    "title": "There is the easiest way to run IT management tool",
    "date": "",
    "description": "",
    "body": "If you are not a Linux guru, windows is the OS you can use only. It does not matter. You could easily try it on your Windows Laptop probably. Since VMware Player is free for using, and there are lots of VMware applications on the internet. So, you just download whatever you need and run them on everywhere. Then you get a fancy IT management solution running on your computer; you really do not even know about Linux and open source. You will see it rocks for you; you won’t troubleshoot for installation issues.\n\n   http://www.vmware.com/download/player/\n\n\n OpenNMS 1.3.2-CentOS4   http://sourceforge.net/project/showfiles.php?group_id=4141\u0026amp;package_id=227240\n\n\n Zenoss 1.1.1   http://downloads.sourceforge.net/zenoss/zenoss-1.1.1-x86.vmware.zip\n\n\n GroundWork 5.1   http://www.groundworkopensource.com/downloads/full_download.html#vmw\n\n\n OpenESM (ZABBIX) http://www.openesm.com/s1/\n  More will coming soon.\n",
    "ref": "/2007/06/01/there-is-the-easiest-way-to-run-it-management-tool/"
  },{
    "title": "[转]10大优秀开源网络管理工具",
    "date": "",
    "description": "",
    "body": "转载ITmanagement的一个文章；全文的部分翻译。个人以为这个文章的把网管的开源工具做了一个小结，英文好的同志请直接访问原文地址：click Here \n“最高评分的管理管理工具不会使人不得不花未来的钱。来考虑一下这些自由且低成本的开源软件吧。”\nLeslie T. O’Neill May 24th, 2007\n\n如果您的公司排名在Fortune 1000强和中小企业之间，那么您网络管理的选择形势看似比较严酷。你既不能在小市场上收集一堆拙劣的玩意来组成一个解决方案；你也不能花很多钱买一些真正不需要的高科技产品。这里有一个很好的选择：试用可一个开源的网络管理方案，加专业服务，包括开发和技术支持。\n**Open Source = Flexible **开源＝灵活性\n\n一个开源的解决方案对厂商来说也是非常灵活性的，他们很快地增加新技术的支持，比改进一个私有系统更快。例如：当Ubuntu 7.04 “Fiesty Fawn”四月份发布之后, Hyperic HQ在发布的第二天就宣布了对其提供技术支持。\n\n当谈到开源的网络管理方案时，公司最需要也用的最多的技术莫过与监控功能。不过监控技术在很大程度上已经变成了日用品。\n通常的，专业化版本的开源IT管理软件平台集成多个其他开源项目在一个框架中，象Nagios网络监控等；并且加入统一的网络界面；并且提供技术支持服务。另外，他们都想通过强大的社区来提高和改进代码，跟踪bug等。\n六个企业级平台\n\n下面的六个开源IT管理都可能用作HP, IBM, CA 和 BMC大型管理套件的替代品。每一个都能提供低价的专业服务和免费软件下载。它们的不同支持在与所提供的功能和支持的操作系统\n\nQuest Big Brother\n\n这个Web-based系统和网络监控产品能支持 Windows, Unix 和Linux等操系统, 还有一个通过用户投稿形成的脚本知识库，利用它能容易地定制Big Brother取管理你的网络。它的GUI是一个不错的特色，使用相同的颜色代码；红色代表不好，绿色代表好。\n\n\nGroundWork Open Source Monitor Professional\n\n2004年发布，它是最早的企业级网络管理产品之一。它集成了超过100种最好的开源项目，包括Nagios, Apache 和 NMap, 在这个框架之上有添加了很多特有功能，例如Web-based用户界面等。Monitor提供了集中化的监控和管理，管理和监控你的企业网络，包括Linux, Unix 和Windows 服务器, 应用, 数据库和网络设备。\n\nHyperic HQ Enterprise\n\n瞄准的是一个数据中心，Hyperic被设计为去监控和管理Web应用的所有层次， 包括硬件、中间件、虚拟化、Web和开放式应用。它还提供基线和趋势分析。它支持 Apache, JBoss, Linux和更多应用。\n\nOpenNMS\n\n这个 Java-based 网络管理工具专注于网络服务轮询，数据采集和事件/告警管理。它目前支持多种开放式操作系统，包括Linux, Mandrake 和Solaris,还有Mac OS X; Windows 系统的支持计划在OpenNMS 2.0中实现。\n\nOpenQRM\n\n也瞄准了数据中心的管理，OpenQRM不仅能管理数以千计的Linux和Windows服务器，还能跟踪计量你的数据中心的使用率和效率。 他还能做自动化基于策略的provisioning。它也集成了Nagios作为监控功能。\n\nZenoss Core\n\n基本上都是Python写的，这个管理平台提供了服务器、网络设备、OS和应用的事件管理、可用管理、和性能管理。Zenoss 能运行于Linux, FreeBSD 和 Mac OS X；它也可以作为一个Zenoss 虚拟应用运行在VMplayer 里。\n\n\n四个无支持的项目\n\n这四个项目位于TOP10 开源网络管理工具中。不象那六个产品，它们不提供商业的服务和企业级的增强功能。但是它们是绝对的free，而且你可以拥有所有需要的网络健康性检查功能。\n\nNagios\n\n这是一个开源的运行在Linux操作系统上的主机、服务和网络监控程序。\n\n\nJust For Fun Network Management System (JFFNMS)\n\nJFFNMS能监控标准的SNMP (Simple Network Management Protocol) 网络设备，服务器、路由器和TCP端口。它工作在Linux, FreeBSD 和Windows 2000/XP。\n****\n\nBig Sister System and Network Monitor\n\n这个项目包括了real-time system 和network health monitor, 一个Web 应用框架和一个系统管理应用。\n\nNetdisco\n\n这个Web-based应用被设计为管理中道大型网络和其中的SNMP网络设备。\n\n\n \n相关文章:\n\n· Interview with Hyperic\n\n· Top 5 Upstart Monitoring Companies\n\n· The Advantages of Open Source Management\n\n· 10 Simple Steps to a Green Datacenter\n\n\n \n\n",
    "ref": "/2007/06/01/top-10-nsm-tools/"
  },{
    "title": "Hyperic HQ小测手记",
    "date": "",
    "description": "",
    "body": "\nHQ的网站是一个显的非常商业化的网站；看上去制作的比较精良也比较专业。从HQ的官方文档（好像没找到pdf手册）中看出它能监控的东西还真的非常多，无论是商业的软件还是开源的都有一大串的matrix；他们在被监控的及其上是需要安装和运行代理的。所以从这一点上讲和商业软件也没有什么区别，总之看的数据多应该比较好，不过数据收集的多有时候会给监控对象代理太重的workload。\n如何安装\n下载HQ\\hyperic-hq-installer-3.0.4-389-x86-linux从HQ的网站。这个压缩文件包含：安装程序，服务器端程序（好像包括一个内嵌的PostgreSQL数据库），代理程序，服务期端shell程序，JRE。\nBTW:服务器端和代理都是Java程序，如果自己配置好JRE的话可以下载不包含JRE的安装包。Windows上的代理包是一个zip文件，为了方便我都下载的含有JRE的安装包。\n由于是纯Java的应用所以服务器端和代理端看似好像都没有任何依赖性要求，只是需要在服务器端安装xorg-x11-libs包，否则不能正常绘图，看不到图形。\n在Linux下的安装过程大致如下。\nmkdir /opt/hq\nuseradd hq -G root -d /opt/hq\nsu hq\ntar zxvf hq.tgz\ncd hyperic-hq-installer/\n./setup.sh\n/opt/hq/server-3.0.4/bin/hq-server.sh start\n注意最好建立一个新的用户为HQ，服务期端本身需要被非root用户安装和启动。另外代理和服务器端都需要特殊的两个端口通信，所以安装完之后必须停止或者配置防火墙；否则不能访问服务器，服务器也不能和代理通信。启动代理之前需要配置好防火墙。\n试用：\n总体说HQ的安装和配置都是非常简单的，不过他的Web界面更是简洁。当代理启动了之后，会自动出现在Auto-Discovery下面，点击Add Resource按钮将它变成一个正式的监控对象。默认的情况下，代理会收集一定数量的监控指标；大概是可收集数量的20%左右。当在某个监控对象上（例如Memory Used）设置了收集间隔之后，服务器端就开始了定时的数据收集，所收集的数据默认情况下用折线图的形式展示。可以根据某个指标建立一个告警，告警的逻辑也相当的完整：逻辑判断，巅峰判断，升级处理；看似能想到的都有了。由于是第一次使用展示没有看的如何建立一个告警规则应用于所有监控对象的。我用HQ对我的一个服务器（iis,MS Sql,.net）做了监控，从数据收集和展现效果上来说，真的堪称可与商业软件媲美。\n使用结论：\n安装简单方便，在Linux下代理端完全无需关照包依赖性。代理配置的安装配置需要一定量的工作，必须配置服务器地址，通信端口等。\n代理程序对服务器的工作负担还是比较大的，特别是在启动的那几分钟内。代理进程对CPU的使用率可以达到50～80%，之后就比较低了。对内存的利用一般是30MB左右，当然这应该是可以通过降低收集数的数量和频率来降低的。\n用户界面的使用还真的是很方便，还支持告警信息的RSS访问。总之HQ是一个开源软件中的重量级选手：功能强，复杂性高，代理程序负担较重。其他使用小结，待续。\n",
    "ref": "/2007/05/30/hyperic-hq-testing/"
  },{
    "title": "ZABBIX特点介绍，转自它们的网站",
    "date": "",
    "description": "",
    "body": "FROM：http://www.zabbix.com/features.php\nZABBIX offers functionality that will make your IT resources look more transparent, and it will also help to easily identify performance and availability problems. ZABBIX greatly increases the productivity of system administrators by providing simple-to-use monitoring system.\nKey features\n\n 开源的方案Open Source solution  能编译运行在多种OS：AIX, FreeBSD, HP-UX, Linux, MacOS X, NetBSD, OpenBSD, Solaris, Tru64/OSF  SQL database存储配置、性能等各种信息  Web interface 简单易用的访问  提供实时和历史的监控分析数据  Data 可视化和影射  高性能的监控代理 (UNIX, Win32)  监控 \u0026ldquo;agentless\u0026rdquo; 环境  维护和监控SLA of IT Services  监控 SNMP (v1,v2,v3) devices IT Services 提供IT基础架构（组建/服务/硬件）等和业务逻辑的联系和对应\nZABBIX\u0026rsquo;s unique technology allows you to relate your applications and underlying servers or network to a IT Service such as application, location, server, network device, region, etc. This technology allows you to correlate your business to your IT infrastructure and identify the impact of your IT infrastructure to the delivery of business service to your customers.\nData visualisation\nZABBIX provides excellent visualisation of statistical and real-time information, ranging from simple graphs to complex views containing graphs, maps and text information. All graphical information is accessible from WEB interface. The wealth of information available such as the trend analysis (days to threshold), the historical graphs and histograms allow you to make informed decisions about the weaknesses and performance of your IT infrastructure.\nApplication monitoring 应用监控\nEnterprise applications such as Oracle, WebSphere, WebLogic, Exchange, Apache, etc. can be monitored using SNMP. In many cases, agentless technology can be used, cutting down on the deployment and management costs.\nZABBIX agents can be easily extended to perform monitoring of any aspect of your applications. It is matter of writing a shell script which would return required data back to the agent.\nServer monitoring 服务器监控\nVirtually all server platforms are supported including but not limited to UNIX, Win32 and Novell Netware. ZABBIX native agents take care of CPU utilisation, memory utilisation, disk usage, network I/O, temperature of CPUs and mainboards, status of processes, etc. All real-time performance data is immediately available by WEB interface.\nNetwork monitoring 网络设备监控\nZABBIX supports monitoring of Cisco, Juniper, 3Com, Nortel, Foundry and other routers as well as firewalls from Netscreen, Fortinet, Cisco or Checkpoint. Any network devices (routers, hubs, printers, etc) having SNMP support can be easily monitored by ZABBIX.\nZABBIX makes possible creation of network maps which give very clear representation of monitored network infrastructure. The maps show network devices, connections, statuses of the devices, and reasons if a device is not available or has any problems.\nIntegration of Fault and Performance Management集成化的故障和性能监控\nThe need to effectively integrate fault and performance management is becoming increasingly apparent to IT organizations seeking to ensure quality delivery of business services. ZABBIX generates real-time notification of threshold violations based on scheduled performance tests.  ",
    "ref": "/2007/05/22/zabbix-key-features/"
  },{
    "title": "What is ZABBIX?",
    "date": "",
    "description": "",
    "body": "\n第一次看到这个软件是在OpenNMS的邮件讨论组中，他们计划做一个vmware的image放到VMTN上 。我在VMTN里哪里点击了一下监控管理这一类，一个叫OpenESM的项目进入了我的视线。它能引起我的注意是因为，它在项目的描述中说:我们理解ITSM、、、、Check it out! 大致浏览了一下他们的网站，发现他们的目的是在Zabbix的基础上作一下优化和开发，加入若干特色：GSM modem发短信、新报表、SLA监控等。\n现在很多项目都有迅速实施的解决方案。对于很多开源项目来说，它们对于新手的相同门槛就是安装。安装上了，不会配置；配置好了，不会用；用上了解决不了问题。\n我先下载了OpenESM ，一个不算太大的文件1.3GB。解压缩之后用VMWare打开运行，猜出root的用户名是openesm，登陆之后发现它是一个Fedora的虚拟机。登陆OpenESM的控制台， http://ip/ 接下来就需要去www.openesm.com上下载手册了，否则无法继续下去。照着手册安装代理，在我的两个Windows的机器上。安装需要先下子代理安装包，允许安装命令的时候需要制定自己的主机名和服务器的主机名。在控制台中加入这两个安装了代理的机器，由于是初次使用没用玩自动发现之类的功能。收集了一阵子数据之后，很快发现了很多有趣的数据。\n最终总结如下\n\n 这是我安装的第一个有代理程序的开源监控软件，感觉在Windows下代理的安装还是比较方便的。比我想象的简单，安装文件只有一个exe文件，装完之后形成一个服务。我记得在查阅文档的时候看到了一文档，上面列出了所有代理程序能收集的数据的表格，说明了什么数据在什么操作系统中支持，那些不支持。它能在多种操作系统上安装，他的安装时说从代码编译安装，windows上不需要，在非windows上就以为这需要安装编译器什么的。这好像并不是特别好。  可用性和性能的数据都能收集。  事件管理功能，能触发action，还没有试过，能触发邮件和GSM短信等。没有试过。  没有试的还挺多，还需要进一步研究。   ",
    "ref": "/2007/05/22/what-is-zabbix/"
  },{
    "title": "Install OpenNMS 1.3.2 on OpenSuse 10.2 system (The simplest version  )",
    "date": "",
    "description": "",
    "body": "1\u0026gt;Install dependence packages\nzliu3:~yast -i rrdtool\nzliu3:~yast -i postgresql\nzliu3:~ # rpm -qa |grep rrdtool\nrrdtool-1.2.15-25\nzliu3:~ # rpm -qa |grep postgresql\npostgresql-8.1.5-13\npostgresql-libs-8.1.5-13\npostgresql-contrib-8.1.5-13\npostgresql-pl-8.1.5-15\npostgresql-server-8.1.5-13\nrcpostgresql start\ncopy jdk/tomcat 5.5 package files to /opt\ncd /opt\ntar xzvf jdk1.5.tar.gz\ntar xzvf tomcat5.5.tar.gz\nexport JAVA_HOME=/opt/jdk1.5.0_09\nexport OPENNMS_HOME=/opt/opennms\nexport CATALINA_HOME=/opt/apache-tomcat-5.5.20\nexport PATH=$PATH:$JAVA_HOME/bin\njava -version\n$CATALINA_HOME/bin/startup.sh\nTest Tomcat 5.5 http://Ip_address:8080/\nvi /var/lib/pgsql/data/postgresql.conf\n# - Connection Settings - max_connections = 256\nvi /var/lib/pgsql/data/pg_hba.conf\n[refer to install guide] #local all all ident sameuser\nlocal all all trust\nhost all all 127.0.0.1 255.255.255.255 trust\nhost all all ::1 ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff trust\nrcpostgresql restart\n2\u0026gt;Install and configure OpenNMS\nCopy OpenNMS rpm packages to /root\nrpm -ivh opennms*\n$OPENNMS_HOME/bin/runjava -s\n$OPENNMS_HOME/bin/install -dis\n$OPENNMS_HOME/bin/install -y -w $CATALINA_HOME/conf/Catalina/localhost\n$CATALINA_HOME/bin/shutdown.sh\n$CATALINA_HOME/bin/startup.sh\n/etc/init.d/opennms start\n/etc/init.d/opennms -v status\nOpenNMS.Eventd : running\nOpenNMS.Trapd : running\nOpenNMS.Dhcpd : running\nOpenNMS.Actiond : running\nOpenNMS.Capsd : running\nOpenNMS.Notifd : running\nOpenNMS.Scriptd : running\nOpenNMS.Rtcd : running\nOpenNMS.Pollerd : running\nOpenNMS.PollerBackEnd : running\nOpenNMS.Collectd : running\nOpenNMS.Threshd : running\nOpenNMS.Discovery : running\nOpenNMS.Vacuumd : running\nOpenNMS.EventTranslator: running\nOpenNMS.PassiveStatusd : running\nTest OpenNMS login page http://ip_address:8080/opennms\n",
    "ref": "/2007/05/13/install-opennms-132-on-opensuse-102-system-the-simplest-version/"
  },{
    "title": "OpenNMS网络和系统管理简介",
    "date": "",
    "description": "",
    "body": "1.1 概述 \nOpennms能够帮助IT管理部门持续的监控分布式的异构系统和网络设备的运行状态，它可以支持SNMP网络管理协议确保管理的扩展性，并且提供非常灵活的定制功能从而有利于管理范围的伸缩。它内置的故障事件管理以提供故障事件的记录和分析的能力，快速隔离非根源事件并迅速发现故障原因。Opennms良好的设计可以快速部署实施，简单友好的图形界面能够使得用户迅速掌握，从而降低操作的复杂度，提高IT管理效率。\n\n1.2 体系架构 \n作为一个通用的网络系统故障监控平台，其体系架构应如下图所示：\n\n \n\n**附图1. ** Opennms****体系架构\n\n我们从下至上对Opnnms体系架构作一一的介绍：\n\nu 被管理对象层，SNMP代理程序是数据采集和动作执行层。对应网络设备来讲，该层对应与网络设备本身的网络管理功能，不需要在设备上单独部署功能模块；对计算机来讲，该层是运行在目标计算机上的SNMP服务，负责采集该系统运行状况、性能等数据，并向管理层汇报。\n\nu Opennms监控引擎是实现网络和系统可用性、故障管理的业务逻辑和策略的处理层。他利用特定的轮询策略：从代理程序层收集数据、更新和维护被管理对象状态、执行相关的报警事件通知。\n\nu 管理对象数据库是网络和系统管理的数据存储层。其中以面向对象的方式保存着网络和系统资源的模型，记录着他们的配置、描述和状态等信息。这些模型和信息是通过Opennms网络扫描模块自动建立起来的，并由管理者层自动维护。\n\nu 图形用户界面是网络和系统管理的数据表示层。他以各种直观、生动的用户界面向用户展示网络和系统中各种对象的关系、配置、状态和故障情况，是优秀的用户接口。\n\n\n针对某企业简称user short name的环境，其IT故障监控子系统的管理框架为：\n\nu 被管理对象层——启动核心路由器和交换机的SNMP网管协议，作为网络设备故障的数据提供源；在所有需要管理的服务器上运行SNMP服务，作为监控操作系统故障的数据提供源。\n\nu Opennms网络监控服务器——新增一台服务器，部署Opennms的监控引擎模块，由该模块对被管理对象层的数据源进行自动的数据采集和翻译采集的结果。并实时发送报警信息。\n\nu 对象存储库——在和Opennms监控引擎安装的机器上安装PostgreSQL，作为Opennms监控模块的对象存储库。\n\nu 图形用户界面——某企业简称user short name管理员可使用任何的WWW浏览器连接Opennms网络监控服务器的用户界面，使用合适的用户名，在某种适当的权限下查看和浏览网络监控信息、状态信息、可用性报表和性能报表。\n\n1.3 功能介绍 \n1.3.1 网络节点自动发现 \n对象存储库中的信息并不是靠管理员手工输入和维护的，而是由Opennms网络监控引擎－自动扫描模块自动从用户的计算机系统中搜索发现出来的。\n\n\n**附图2. ** 网络节点自动发现\n\n1.3.2 图形用户管理界面 \n在某企业简称user short name这 样的网络和系统中，需要一些友好的监控视图。目的是使得管理员能够通过直观的界面，迅速发现故障，从而在最短的时间内解决故障。该用户界面视图可使得管理 员通过管理工具看到现实世界对象的真实反映，而不是抽象的符号。使用户能够监控整个系统的概貌，系统的大体分布和总体运行状况等。并且决策适当的故障排除 方案，各种界面视图可通过Intranet进行浏览查看。\n\n\n**附图3. ** 网络管理员管理主页\n\n该用户界面的最左边是：Nodes with Outages，表格中列出了最近发生故障状况的12个节点，这些节点可能是网络故障，或者是某些网络服务出错等。\n\n用户界面的中间是：各种网络服务的服务水平报告。它列出了最近24小时之内各种网络服务的服务质量水平；其中的网络服务可能包括：网络接口的UP时间、Web服务、DNS和DHCP服务和数据库服务等。\n\n最右侧的是一些比较常用的功能选项：报警提示信息、节点的性能报表、节点网络服务相应时间报表和自定义的性能报表。\n\n1.3.3 故障监控 \n被管理对象的数据采集和状态维护是由Opennms的监控引擎模块实现的。每个所管理的所有对象存储在数据库中。可以管理的对象包括：\n\nu 支持SNMP网管的网络设备\n\nu 部署了SNMP服务的服务器上的操作系统\n\nOpennms采取统一的通讯方式从这些管理对象上采集可用性和故障信息，信息的采集有两种方式：\n\nu Opennms主动地通过SNMP协议定期查询被管理对象状态\n\nu Opennms被动接收被管理对象发来的SNMP Trap\n\n\nOpennms得到被管理对象的轮询或Trap信息后，根据收到的信息类型、对象原来的状态和网络系统管理的策略和逻辑判断对象的状态是否发生变化。如果发生了变化，则可以按照管理策略采取若干更新操作。\n\n1.3.4 故障事件管理 \n当 被管理对象的运行状态发生变化时，就会产生事件。如果该事件是由正常变为故障，则会产生故障报警。事件管理是通过收集、确认事件，对事件进行分类和过滤， 关联不同来源的事件完成对事件的处理和响应。通过事件管理，系统管理人员可以方便、迅速、及时掌握系统运行的故障和警报，及时进行处理，保障系统的正常、 稳定运行。\n\nIT系统管理人员所关注的问题，如系统资源出现短缺、数据库连接失败、网络通信中断、主机文件系统溢出等等都会以事件的形式表现出来。\n\n\n**附图4. ** 事件管理控制台\n\n\n1.3.5 操作系统监控 \nOpennms对各种计算机操作系统的可用性、运行状况和故障的集中监控是通过本身的SNMP服务程序完成的。这些SNMP代理程序是SNMP服务的组成部分。在本次建议的方案中，在所有的被监控服务器上其监控的主要内容包括：\n\nu CPU利用率，显示系统、用户、空闲时间的百分比；\n\nu 虚拟内存(Virtual memory)利用率；\n\nu 文件系统使用情况，显示磁盘空间使用情况；\n\nu 监视文件系统的使用率，当使用率超过特定阈值时向系统管理员报警；\n\nu 监控网络端口的输入、输出、错包，以及端口是否被停用或者删除；\n\nu UNIX系统还可以监控\n\n² Load Average：服务器平均处理量\n\n² 共享内存\n\n1.3.6 网络节点配置信息管理 \n被监控对象节点在数据中的配置信息是IT设备的资产信息，每个网络节点都是一个特定的IT资产设备。每个节点在数据库中有很多属性字段供选择填写，主要有三类属性信息：\n\n   配置种类信息：配置分类、告警分类、轮询属性和阈值分类。    \n  标识信息：资产描述、厂商、型号、资产编号、操作系统等    \n  位置信息：负责人、部门、楼层、房间、机架编号等    \n\n**附图5. ** 节点资产信息\n\n\n1.3.7 全面的节点监控 \n每个被监控的节点都能被细致的记录和监控。当查看某节点的信息时，有这样几类信息：状态信息、各种网络服务总的可用性、SNMP属性、各个接口熟悉、最近发生的5个事件和最近的故障事件。\n\n\n**附图6. ** 节点监控视图\n\n在查看某个节点是，界面上的信息分为三类：网络服务可用性报表、当前状态和监控事件信息。在菜单栏还能有很多功能选项：查看故障事件、资产信息、响应时间报表、SNMP性能报表、重新扫描、节点管理和更新SNMP信息。\n\n\n1.4 特点和优势 \nOpennms在网络和系统管理方面，有非常广泛的用户，特别是中小企业用户，Opennms具有很多极好的特点：\n\nu 方便易用的用户管理界面——Opennms可以提供故障事件视图、节点视图、相应时间视图、性能视图等各种管理视图。\n\nu 基于Open Source协议开发——用户可以按照自己的需求，通过修改软件本身或者软件的源代码来定制。\n\nu 跨平台管理——Opennms支持任何能运行标准SNMP协议服务的操作系统系统，并且可以从一个单一的用户界面分别管理其局域网（LAN）。\n\nu 切实可行的事件管理系统——Opennms通过方便易用的交互式控制台，为IT管理员显示关键事件，提供自动的事件响应，可以以电子邮件方式发出事件通知。\n\nu 方便的集成——Opennms可以与第三方产品集成。例如Opennms可以方便的与Dell、HP、IBM等厂商的服务器自带的SNMP故障管理软件集成。\n\nu 2005 Linux World推荐管理产品 ——Opennms获得2005年Linux世界大会的“最佳网络系统管理软件”的荣誉。已经被认定开源软件世界中的最佳网络系统管理软件。\n\n\n版权所有，如果转载请著名出处。\n\n曾被www.vshj.com转载：http://www.vshj.com/Article/2006/200607/Article_97842.htm\n\n\n文章中所提到的图片请参阅我的相册。 \n\n\n",
    "ref": "/2007/05/08/what-is-opennms/"
  },{
    "title": "OpenNMS常问问题All-in-One",
    "date": "",
    "description": "",
    "body": "**问：OpenNMS是什么？\n**答： OpenNMS是第一个开发在开源模式下的企业级网络管理平台应用。OpenNMS的目标是成为一个真真的分布式、可升级的网络管理平台，尽管它看似一个 FCAPS网络管理模型，使之可用于开放源码和商业领域。目前：OpenNMS专注与以下三个方面：服务轮询 － 检查应用服务的可用性，产生可用性报表。数据收集 － 收集、保存和报表网络信息数据，并设定和触发门限值。事件和提示管理 － 接受事件系统内部的和外部的事件，将源事件提供给强大的故障告警和故障升级系统。OpenNMS Group是开发和支持OpenNMS应用的一个商业性的实体。\n问：为什么要开源？\n答： 我们坚信真真的创新不会来自规模巨大的企业。我们还相信网络管理软件领域比Linux操作系统更适合开源模式。不像Linux，网络管理要去监视和控制来 自不同厂商的很多的技术。考虑到每年都有很多新的网络设备面世。商业软件公司并不希望追赶这种更新产品的工作负荷，相反它们只能依赖与它们的通用管理技术 （最小化的通用性）。相反，对于一个开源项目中的每一个人－－厂商、用户或者技术顾问－－都能对项目做出自己的共享，从而保障了这个项目成功的几率。\n**问：OpenNMS是用什么语言写的？\n**答： OpenNMS主要是用Java语言写的。OpenNMS2.0的目标是：让它成为一个以一堆.jar文件形式来安装的产品。还有一些非Java的部分： icmpd-Java1.4 API不能理解ICMP。因为ICMP回答请求（ping）是一个最简单的来测试基于Ip的网络设备是否可以服务的方法，没有那个网络管理应用程序不用的 它的。将ICMP功能分离为一个独立的守护进程的目标是，如果系统中有ICMP的功能那么OpenNMS就用，如果没有OpenNMS就率略它。 OpenNMS不需要ICMP来监控网络设备。数据库－OpenNMS现在使用PostgreSQL作为它的地层数据库，PostgreSQL 是用C写 的。OpenNMS2.0会使用几个能通过Hibernate适配器访问到的数据库。rrdtool－OpenNMS当前的版本实时的选择使用 RRDtool或jRobin（Java会使用RRDtool）。最终这个选项的默认使用jRobin，也可以选择使用RRDtool。\n**问：OpenNMS有图形的显示么？\n**答： 这可能是一个对于OpenNMS新人来说最常问的问题：OpenNMS的图形监控界面在那？简单的问答是我们没有一个这样的地图，如果你想听听我们的解释 请继续往下看。OpenNMS是被一些经验丰富的网络管理技术顾问开发出来的。HP的Openvew NNM是一个很流行的商业软件，它能生产一个可定制化的网络监控图形。OpenNMS Screenshot\n\n[![](http://lh4.google.com/image/liuzh66/Rl19YgD97vE/AAAAAAAAAE8/hFVbteNWiR0/s160-c/OpenNMS.jpg)](http://picasaweb.google.com/liuzh66/OpenNMS) \n\n[OpenNMS](http://picasaweb.google.com/liuzh66/OpenNMS) \n\n\n**原文地址** [http://www.opennms.org/index.php/FAQ-About](http://www.opennms.org/index.php/FAQ-About) ",
    "ref": "/2007/05/08/opennms-faqs/"
  },{
    "title": "GLPI –IT资源生命周期管理",
    "date": "",
    "description": "",
    "body": "\n GLPI是一个法国的开源项目，之所会了解到这个项目，是由于OCSNG的原因。当我安装并使用了一下它之后立刻产生了以下问题：1）它仅仅是一个对现有设备Inventory的工具，对新设备的采购和计划无法实现。2）它仅仅是一个技术工具，能提供CMDB相关的配置信息数据，相关的流程如何实现：计划，采购，使用，变更和报废。\n没想到在安装试用了GLPI之后着一切都疑问都散去了。那就先讲讲安装过程。环境准备，我的测是环境如下：Dell Inspiron 600M笔记本（70GB HD, 1GB RAM），由于硬件资源实在有限，所以我喜欢使用VMWare作为测试环境。在VMWere中安装SuSE 10.1，最小安装；安装apache,perl,php,mysql和其它相关的包，由于Yast的包管理实在好用，所以为整个安装过程带来了很多方便。如果您也想测试的这个软件系统的话，最简单的方式则是：找一个物理的机器做SuSE 10.1的全安装，这样的安装过程绝对不会有找不到那些依赖组建的问题。软件安装：OCSNG / GLPI的安装模式都是相同的基本相似的比较简单；再次就不多话了；我猜您可能会碰到的问题有：GLPI的登陆用户名和密码的问题。所有可以利用的相关文档里好像没用提到这个信息，昏！可能是我的运气不好，的确没找到，不过最终被我猜到：）[登录密码在安装向导的导数第二个页面上]\nOCSNG需要安装Agent，Agent会在目标设备上做清单扫描，上传Inventory信息；它的三层结构可能会是企业级用户的好消息，它还能方便的通过Windows 域的组策略部署代理，也就是说只要用户登陆域，代理就能顺利安装部署。OCSNG趋向做全面的客户端管理：inventory、license管理等方面。\n从上面的GPLI的screenshot可以看出和一个笔记本电脑相关的一切。先讲讲它的来由，GPLI解决的是OCSNG的上层问题：计划，购买，部署，跟踪，变更，维护，退休。它管理的是所有业务和流程层面的东西。GPLI的数据来自OSCNG的数据库，它能自动从OSCNG中定期更新inventory信息。截屏中的电脑是我在我的笔记本上安装了OSCNG后，做的首次扫描后的结果，在GPLI中配置了和OSCNG的集成后，它就变成了一个GPLI中的管理数据。可以看到，和一个电脑资产相关的所有硬件信息，软件信息，help desk请求，文档，链接，注释和变更历史记录等。GPLI中有对外的HelpDesk模块，这能方便最终用户对设备维护的请求。\nGPLI和OSCNG很好的结合可能做到“IT资源生命周期管理”，参考文档：http://glpi-project.org/wiki/doku.php?id=en:cyclevie\n如果对把它们所实现的功能和ITIL框架对应一下，或许IT服务财务管理，能力管理，配置管理和发布管理等流程能与之能有某些联系。\n",
    "ref": "/2007/04/30/glpi-it-asset-mgmt/"
  },{
    "title": "OCSNG － IT资产管理软件",
    "date": "",
    "description": "",
    "body": "\n最近在网上又发现了一个不错的开源软件，这就是OCSNG资产管理软件。他能提供非常好的Inventory功能，发现并、更新计算机系统上的软硬件清单信息。下面是从他们的网站上找到特色介绍的信息：\n\n Relevant inventory 资产清单管理.  Powerfull deployment system 强大的部署系统，代理程序软件部署方便宜用。.  Web Administration Console 基于Web的管理控制界面.  Multiple operating systems support,多操作系统支持 Microsoft Windows, Linux, *BSD, Sun Solaris, IBM AIX, HP-UX, MacOS X.  Lightweight bandwith usage: 轻量网络带宽使用，Windows系统的全部清单信息大约5 KB .  High performance: 高性能，1 000 000 电脑每天做清单扫描，使用的服务器是bi-Xeon 3 GHz /4 GB RAM.  3-Tier architecture 三层架构设计，支持http/https/xml等协议河标准.  基于有名的开源产品实现， Apache web 服务器, MySQL 数据库服务器, PHP 和 PERL 脚本语言.  Web service 提供 SOAP 接口的Web服务访问.  Plugins support 通过API提供插件支持. Used with a IT and Asset Management Software such as open source tool GLPI, you will have a powerfull inventory and asset management software with automatic updates of computer configuration, license management, help desk and more.\n根据ITIL的定义，CMDB是配置管理的主要数据库；其它相关的流程也非常依赖配置数据库；CMDB不一定是一个物理的数据库，它可以是一套数据库的集合。OCSNG能为CMDB提供有效的数据信息。  ",
    "ref": "/2007/04/29/ocsng-it-asset-management/"
  },{
    "title": "Nmap — Network Mapper(网络映射器)",
    "date": "",
    "description": "",
    "body": "\nNmap (“Network Mapper(网络映射器)”) 是一款开放源代码的 网络探测和安全审核的工具。它的设计目标是快速地扫描大型网络，当然用它扫描单个 主机也没有问题。Nmap以新颖的方式使用原始IP报文来发现网络上有哪些主机，那些 主机提供什么服务(应用程序名和版本)，那些服务运行在什么操作系统(包括版本信息)， 它们使用什么类型的报文过滤器/防火墙，以及一堆其它功能。虽然Nmap通常用于安全审核， 许多系统管理员和网络管理员也用它来做一些日常的工作，比如查看整个网络的信息， 管理服务升级计划，以及监视主机和服务的运行。\nNmap输出的是扫描目标的列表，以及每个目标的补充信息，至于是哪些信息则依赖于所使用的选项。 “所感兴趣的端口表格”是其中的关键。那张表列出端口号，协议，服务名称和状态。状态可能是 open(开放的)，filtered(被过滤的)， closed(关闭的)，或者unfiltered(未被过滤的)。 Open(开放的)意味着目标机器上的应用程序正在该端口监听连接/报文。 filtered(被过滤的) 意味着防火墙，过滤器或者其它网络障碍阻止了该端口被访问，Nmap无法得知 它是 open(开放的) 还是 closed(关闭的)。 closed(关闭的) 端口没有应用程序在它上面监听，但是他们随时可能开放。 当端口对Nmap的探测做出响应，但是Nmap无法确定它们是关闭还是开放时，这些端口就被认为是 unfiltered(未被过滤的) 如果Nmap报告状态组合 openfiltered 和 closedfiltered时，那说明Nmap无法确定该端口处于两个状态中的哪一个状态。 当要求进行版本探测时，端口表也可以包含软件的版本信息。当要求进行IP协议扫描时 (-sO)，Nmap提供关于所支持的IP协议而不是正在监听的端口的信息。\n除了所感兴趣的端口表，Nmap还能提供关于目标机的进一步信息，包括反向域名，操作系统猜测，设备类型，和MAC地址。\n摘自：nmap中文文档 nmap首页\n",
    "ref": "/2007/04/28/nmap-network-mappe/"
  },{
    "title": "OpenNMS 安装说明－精简版",
    "date": "",
    "description": "",
    "body": "Per-install Checklist:\n\n SuSE 10.1 Linux install CD  OpenNMS rpm packages for SuSE Linux  JDK 1.5 package  Tomcat 5.5.20 package Here we go:\n  \n Insert install CD into Cd/Dvd rom  Do SuSE Linux mini install  Logon in OS, run \u0026lsquo;yast firewall\u0026rsquo; to open 8080 tcp port on firewall  upload all packages to /opt  untar JDK  untar Tomcat  install postgresql through yast; run \u0026lsquo;rcpostgresql start\u0026rsquo;  Export some variables export JAVA_HOME=/opt/jdk1.5.0_09\nexport OPENNMS_HOME=/opt/opennms\nexport CATALINA_HOME=/opt/apache-tomcat-5.5.20\nexport PATH=$PATH:$JAVA_HOME/bin\n  \n Test Java and Tomcat java -version\n$CATALINA_HOME/bin/startup.sh\n  \n Modify this file, vi /var/lib/pgsql/data/pg_hba.conf , then run \u0026lsquo;rcpostgresql restart\u0026rsquo; #local all all ident sameuser\nlocal all all trus\nthost all all 127.0.0.1 255.255.255.255 trust\nhost all all ::1 ffff:ffff:ffff:ffff:ffff:ffff:ffff:ffff trust\n  \n install OpenNMS rpm packages; rpm -ivh xxx.rpm  $OPENNMS_HOME/bin/runjava -s  $OPENNMS_HOME/bin/install -dis  $OPENNMS_HOME/bin/install -y -w $CATALINA_HOME/conf/Catalina/localhost  restart Tomcat  start OpenNMS; $OPENNMS_HOME/bin/opennms start  Check opennms status; $OPENNMS_HOME/bin/opennms -v status  login web console 以上仅仅是我一个偷懒的方法，可以比较快的部署运行OpenNMS。这种方式的好处如下：\n   Mini安装可以是最快的安装，总共只有几百MB就得到一个Linux操作系统  SuSE的包管理比较好用，配合一张安装DVD，几乎所有软件招之即来，不需要下载任何东西  Java和Tomcat的安装包是从以前的机器上直接把安装目录tar出来的，这也直接解压来用速度比较快。 这个安装方式的缺点：\n 并不是最优的安装，没用设置服务的自动重启  没用优化PostgreSQL  没用优化Java和Tomcat；ONMS是java应用，性能可能会是个问题  没用对ONMS做任何配置    Post-install Checklist:\nChange Admin password for ONMS\ncustomize ONMS per your requirements\noptimize Tomcat/Postgresql/ONMS configuration   ",
    "ref": "/2007/04/26/opennms-install-sample/"
  },{
    "title": "OTRS的第一个ITIL兼容版本",
    "date": "",
    "description": "",
    "body": "从来没用这么期待过一个软件的问世，虽然工具和技术不能画等号，不过它应该是第一个主动与ITIL看起，并且靠拢的开源软件。\n1下载安装\n需要下载的软件是OTRS 2.2.0 BETA2 和OTRS:ITIL 1.0；后者只是一个压缩包，它包含了所有ITIL相关的软件包。此次安装并不顺利，归咎于很多Apach上perl的配置；安装之后的问题多是其它依赖的软件包不全造成的。\n2 CMDB\n说不上它是一个很好的CMDB，不过用起来到是很方便。在Admin里把所有CI的类都建立出来后，相关的工作人员就能登陆上来，把相关的CI添加尽量。你需要从车轮开始做起，在这里可以说是非常适用，它不想商业软件内置了一堆的预定义的东西。CI直接的联系关系也可以得到表达。\n3其它功能试用中待续\n",
    "ref": "/2007/04/23/otrs-itil-compatible/"
  },{
    "title": "[转] 十问ITIL",
    "date": "",
    "description": "",
    "body": "想实现IT与业务融合的目标吗？\n想让IT部门踏上自我管理之路吗？\n想在IT规范的丛林里找到清晰的管理思路吗？\n在IT与业务战略融合的过程之中，ITIL（IT基础设施库）和ITSM（IT服务管理）规范将为企业用户提供实现诸多IT与业务管理目标的真实路径。1989年，英国政府商务部在发现企业对IT提供服务和自我管理的方式存在混乱认识的问题后，发布了长达44卷的ITIL规范。目前所实行的第二版于2001年发布，容量减至9卷。而最新的消息显示，ITIL第三版本有望于2007年4月正式发布。\n在ITIL诞生并成长的10余年间，ITIL及ITSM理念都经历了巨大的变化和发展，并有望在ISO 20000中成为全球标准。目前的ITIL既是一个词汇库，也是一系列旨在概括性描述IT最佳实践的概念性流程。对企业而言，要使IT更有效地实现自我组织和自我管理，兑现ITIL对于管理的承诺，是一项足以用“浩大”二字形容的工程。所以，您需要先确定一个起点，并了解目前与ITIL有关的10项核心内容。\n** 1. 我能够通过ITIL实现哪些过去无法实现的目标吗？**\n如果实施得当，ITIL可以提高客户满意度、减少IT部门中的浪费，并降低运营成本。下面是两个简单的案例：\n● 在2000年，Caterpillar公司的IT部门解决Web事件的目标响应时间是30分钟，但是该部门达到这一目标的几率只有30%。实施ITIL后，其IT供应商达到该响应目标时间的几率提升至90%，而Caterpillar在过去5年实现了业务的几何级增长，IT预算只上升了1%。\n● 两年前，Liberty Mutual的IT管理员只有在用户打投诉电话后才能发现某个关键网络应用已停止工作。部署ITIL后，管理员可以在故障发生前对应用的运行速度和异常活动进行监视，并且通常可在用户感觉到异样之前解决问题。\n**2. 是否需要通读ITIL全部9卷的内容，哪些是重点章节？**\n《服务支持》和《服务交付》这两卷包含了ITIL的核心知识，其他几卷都是补充性的。《服务支持》卷介绍了5个关键流程：即事件管理、问题管理、变更管理、发布管理和配置管理。尽管服务桌面被认为是一项功能，而非流程，但它仍被包含其中，并且被认为是IT服务的客户报告事件、发出请求和与IT基础设施与业务部门进行沟通的重要接触点。\n事件管理的主要内容是，在发生事件（例如服务器崩溃）后尽可能快速地恢复正常的业务运营。问题管理将注意力集中在查找和消除事件的根源，防止其死灰复燃。\nITIL的独特能力是它可以将“事件”与“问题”隔离开来。通常，支持人员在查找事件的根源时，IT部门的支持服务就会暂时处于停顿状态。ITIL优先考虑的是为业务部门提供服务，其次才是在后台修复问题的根源。\n变更管理是协调和控制IT基础设施自身变化的过程。ITIL将其视作实现适当批准、授权和质量保证步骤的一项协调工作。\n发布管理指的是IT变更的实际实施，包括人员、流程、技术、培训、推广、沟通和业务领域活动，以及设计的建立、测试和变更发布等内容。对大多数IT运营活动而言，将各种变更打包为发布单元，可以有效地降低业务所受到的影响。\n配置管理包括日志记录、跟踪、控制和验证基础设施信息的过程，这些信息用于描述IT基础设施中的每一个组件，以及各个组件之间的关系。这一过程的重点是这些项目，即所谓的CI（配置项）之间的相互关系。所有这些信息都保存在一个逻辑CMDB（配置管理数据库）中。\n**3. CMDB到底有多重要？**\nCMDB是建设整个IT基础设施的蓝图，它描述各个配置项（CI），包括硬件、软件、事件、协议、服务水平、文档等之间的相互关系，同时还用于描述整个元系统（metasystem）的工作情况。CMDB已经成为迅速查找IT基础设施信息的基础，同时也是实现有效管理决策的基础。在理想条件下，每个CI都有各自的可配置属性。如果可能，CMDB应该能够自动发现CI的相关信息，并在发生变化时对其进行跟踪，从而将维护配置项所需要的管理工作量降至最低。\n**4.《服务交付》卷关注哪些内容，重要性如何？**\n《服务交付》卷关注的是IT服务的交付和增强方式，该卷重点强调了5个关键的流程：即服务水平管理、可用性管理、容量管理、IT服务连续性管理和IT财务管理。\n服务水平管理涉及SLA（服务水平协议）的规划、协调、监视和报告。它会以连续的方式对服务进行评估，确保这些服务能够以高性价比的方式交付，同时还要满足用户的服务目标。\n可用性管理负责协调、设计、测量和管理IT基础设施的可用性，并会综合考虑基础设施和支持机构的各方面情况。它可以协调和集成各个松散结合的“孤岛”，确保IT能够按照必要的水平和成本提供所需的服务。这一过程会将一些关键原则结合在一起，其中包括每种服务的可靠性、可服务性、可管理性、安全性和响应性。\n容量管理考虑的是适应业务工作量和业务目标的IT容量、性能和吞吐量。从历史上看，大多数IT部门都会根据IT资源的使用方式来管理容量。ITIL则要求IT部门首先了解容量的业务驱动需求，并在将其实施到IT基础设施之前，通过建模和预测发展将其转化为服务工作量。\nIT服务连续性管理可以确保IT服务能够在发生重大灾难时得到恢复。它引入了关键业务功能概念，迫使IT部门将注意力放在服务的恢复上，不再仅仅关注技术的修复。\nIT财务管理可以提供IT成本和支出管理所需的预算、会计和收费服务。IT部门通常不了解其提供IT服务所发生的成本，这也是其总被公司董事会质疑的原因之一。IT部门必须开发出一种能力，来明确说明IT服务成本以及IT部门的贡献，IT财务管理将赋予他们这样的能力。 ITIL强调其参与业务活动的具体方法，这方面，服务台意义重大。在典型的业务部门中，业务用户和客户每天都会与服务台建立联系，而且这已经成为服务支持工作流程的一个必要组成部分。同时，行政和管理部门也需要与服务水平管理过程建立接口，从而实现新服务的部署，并调查服务提供工作流程所使用的服务质量。\n**5. 其他7卷的作用和意义？**\n在理解了基本概念后，您会对其余的7卷有更多的了解。例如，《ITIL简介》介绍了构成ITIL服务管理的基本概念；《实施ITIL服务的规划》解释了某个部门通过ITIL获得帮助的一些必要步骤；《ICT基础设施管理》涉及了一些关键问题，比如网络服务管理、运营管理、计算机安装和验收等；《应用管理》重点讨论了软件开发和支持周期，对要求和IT服务的测试进行了定义。 《业务展望》卷事实上是两本书，一本面向IT人员，另外一本适用于商业经理。这两本书讨论了业务连续性管理、伙伴关系、外包、生存几率、以及剧烈变化过程中随机应变的业务实践。《安全管理》以ITIL的视角对各项安全规范和标准进行了讨论。最后一本是《软件资产管理》，它提供了管理软件和软件授权的最佳实践。\n** 6. 为什么在美国的部署远远落后于欧洲？**\n美国在IT基础设施管理的规范化方面一直落后于欧洲。最近美国开始重视ITIL的原因之一是，许多在美国经营的欧洲和亚洲企业都在呼吁：在更大范围内让IT运营符合ITIL的要求。另外，很多美国企业发现，有超过2/3的IT预算被全新的、不可任意支配的运营成本所吞噬，而它们对此根本没有任何控制能力。 ITIL将改变这一现状，它可以针对具体的商业目标实施连续的小型项目，而且所有结果都是可测量的。典型的目标包括缩减IT成本、减少服务中断、为重大IT计划或商业变化做好准备，比方说企业兼并、搬迁或收购。\n** 7. 除大型企业外，还有哪些企业需要ITIL？小型企业或个人是否也可使用ITIL？**\n任何为企业提供IT服务的部门和/或为企业客户提供服务的部门都能从ITIL中受益。 例如，一家小型企业面临着网络经常中断的困扰，那么这家企业可以使用ITIL的问题管理流程来改善其网络环境。如果一家中型企业的IT基础设施非常复杂，那么这家企业就可以利用ITIL的配置管理解决方案，针对各类变更和新应用进行优化与评估，并为其实施绘制蓝图。\n**8. 在对ITIL有了充分了解的前提下，该如何启动ITIL呢?**\n首先要接受培训并获得认证。几乎所有的大型硬件/软件厂商和一些中小型企业都可以提供ITIL培训。您可以在网上搜索相关的ITIL培训机构。完成培训后，您需要利用书本、网络研讨会、图书馆材料和在线资源填补您的知识空白。比较好的ITIL资源包括：IT Service Success（itServiceSuccess.com）、服务水平管理（slminfo.org）和ITSM Watch（itsmwatch.com），以及美国IT服务管理论坛中主要的用户组站点（itsmfusa.org）。\n**9. 是否应该聘用一些人员做ITIL实施？**\n许多公司都提供ITIL咨询和实施服务，但这只是采用曲线中最初级的部分。目前的市场中尚不存在所谓的领导型企业。您可以根据他人的经验来选择适当的服务商。 ITIL告诉了我们“要做什么”，但有关“怎么做”的问题却涉及较少。目前，ITIL被称为“IT部门的ERP”，它需要结合企业自身情况将人员、流程和工具相互融合。因此，ITIL要在企业成功实施首先需要领导的积极推动，同时必须在企业中结合角色设置流程经理来落实设计的流程。在推动的过程中，企业应当考虑聘用顾问协助实施，让企业员工对ITIL有更为深刻的理解和认识，这对整个项目的成功帮助极大。\n** 10. ISO 20000与ITIL的关系是什么？ **\nITIL主要是一些流程，它并不提供任何衡量标准。而最近发布的ISO 20000是评测IT服务管理和改善IT服务的基础。它定义了针对服务商的要求，并且帮助您确定自己的工作是否符合可接受的IT服务管理标准。ISO 20000可以提供具体、可测量的标准，能够用于对范围、定义条款、规划和实施服务管理、管理系统要求、全新或变更服务规划及实施、服务提供过程、关系过程、控制过程、决议过程和发布过程等领域进行审查。\nITIL资源站点\n■ 国外站点：\n\n Pink Elephant (www.pinkelephant.com) 澳大利亚ITSM/ITIL权威研究咨询机构  NAI (www.nouriassociates.com) 美国ITSM/ITIL  HDI (www.thinkhdi.com) 美国帮助台协会官方网站  ITSMF (www.itsmf) ITIL推广专业协会itSMF组织网站  ITIL官方网站 (www.itil.co.uk)  ITSM门户网站 en.itsmportal.net ■ 国内网站：\n ITSM/ITIL专业论坛 www.simaone.org   ",
    "ref": "/2007/03/31/itil-faqs/"
  },{
    "title": "ntop ~ Web-based network traffic monitor",
    "date": "",
    "description": "",
    "body": "\n安装方法：\n最简单的安装方法应该是从Linux的安装光盘中安装，因为它比较小只有2～3MB；很多Linux都包含这个软件。在SuSE Linux 10.1中可以找到ntop-3.2-17。\n配置使用：\n安装之后参考说明文档做首次初始化运行，如果是通过rpm从Linux光盘中安装；相关的系统服务也已经帮你安装。在SuSE里运行rcntop start就可以启动后台进程。访问ntop的界面http://myserver:3000/。\nTips：\nntop会吃掉比较多的内存资源，不建议在生产机上安装。它工作在第二层，采用实时抓包的方式；ntop像是网络探针来捕获和分析网络活动，产生一些分析报表，部署时需要考虑它的部署位置。\n于其它系统的集成：\n该系统界面的访问比较的直接，没有用户认证过程。所有报表和分析结果的按两个方式保存和呈现：host和协议。它通过rdd存储数据，通过web页面展示图片；本身不需要依赖web server。准备尝试把它集成到Nagios和OpenNMS中。\nntop的英文说明\nFrom: http://www.ntop.org/Monitoring.html\nNTOP is helpful as an \u0026ldquo;emergency\u0026rdquo; tool. When you are experiencing response time delays or you suspect that something is wrong with your network, NTOP allows you to easily monitor the protocols running on your LAN and to determine the utilization of each.\nNTOP comes very well when suspicious behavior is found on your network. Suppose you have a set of local clients accessing a database on your LAN. They claim that time response is very poor. You embark on a search to determine who or what is to blame. You generally have 2 options: the application or the network. You ask the application engineer(s) to determine that the application is OK. They determine that it is. You move on to the network engineers who come to find out that you have a very high retransmission packet rate caused by the server\u0026rsquo;s faulty network card (a problem to be detected by the sysadmin using standard linux/unix commands). In a situation like this, it is likely that they were able to determine this by using a tool like NTOP. Without the help of NTOP and similar tools, finding the cause of the problem could have been extremely tedious.\nSome very useful sections of NTOP include:\n\u0026lsquo;Active TCP Sessions\u0026quot; - shows what is taking place on your network at that specific moment. For example:\nClient Server Data Sent Data Rcvd Active Since Last Seen Duration\n123.231.213.1 mail_server 3.6 MB 3.8 MB 12/08/99 19:40:01 12/20/99 20:47:31 12 day(s) 1:07:02\nAll this information can be accessed using any standard web browser. To have enough information to work on, you may wish to run NTOP for at least a couple of days (non-stop) in a production environment. (This may vary depending on the size of your network. For a medium departmental LAN, a couple of days should be fine).\n\u0026lsquo;Connection Matrix\u0026rsquo; - shows which station is talking to what\nserver and the amount of traffic being exchanged\nMonitoring of the most intensive bandwidth senders and receivers - Heavy traffic is not only caused by physical media but also by other system intensive actions (e.g. users downloading large files). This can cause severe bottlenecks to your LAN.\nThe NTOP data presentation is impressive. Bar and Pie charts are used to demonstrate protocol utilization and packet size distribution. Data gathered from the monitoring can be logged in a file for posterior plotting using any spreadsheet application such as Sun\u0026rsquo;s Star Office. If you want to keep all of the information stored for future structured retrieval, NTOP gives you the option to store it in a SQL database.\n",
    "ref": "/2007/03/21/ntop-web-based-network-traffic-monitor/"
  },{
    "title": "GroundWork rpm 安装会导致原系统的一些改变",
    "date": "",
    "description": "",
    "body": "GroundWork rpm安装对系统造成的改变有：\n\n /etc/init.d/apache2 被改名为 apache2-save 导致，以前的Apache不能启动  会在/etc/ld.so.conf中加入一行/usr/local/groundwork/lib ；不知道为什么这会导致一下系统的服务不能正常运行，如：PostgreSQL和snmpd。修复方法是注释掉这一行，然后运ldconfig命令。还不知道GroundWork在没有这一行的情况下有什么问题，注释掉之后好像它还是能正常运行的。   ",
    "ref": "/2007/02/28/groundwork-rpm-error/"
  },{
    "title": "GroundWork和OTRS系统的集成问题",
    "date": "",
    "description": "",
    "body": "为了节省服务器，我们可能不得不把所有的监控以及相关的系统都安装到一个物理的机器上。如果是从原代码安装，我相信一定有很多选项能避免它们之间的冲突。假如你是后安装的GroundWork，它会更改系统默认的Apache2的配置，导致以前安装的所有的Web应用都不能用。\n在我的测试机上，先安装的OTRS，rpm安装，后安装的GroundWork，也是rpm安装。GroundWork安装之后，OTRS不能登陆。根据GroundWork的一些文档我做了，如下的修复步骤。\n1）vi /etc/apache2/conf.d/otrs.conf 可以看到如下OTRS的web配置信息。\n# \u0026ndash;# added for OTRS (http://otrs.org/)# \u0026ndash;# agent, admin and customer frontendScriptAlias /otrs/ \u0026ldquo;/opt/otrs/bin/cgi-bin/\u0026ldquo;Alias /otrs-web/ \u0026ldquo;/opt/otrs/var/httpd/htdocs/\u0026quot;# load all otrs modulesPerlrequire /opt/otrs/scripts/apache2-perl-startup.pl# Apache::Reload - Reload Perl Modules when Changed on DiskPerlModule Apache2::ReloadPerlInitHandler Apache2::ReloadPerlModule Apache2::RequestRec# set mod_perl2 options# ErrorDocument 403 /otrs/customer.pl ErrorDocument 403 /otrs/index.pl SetHandler perl-script PerlResponseHandler ModPerl::Registry Options +ExecCGI PerlOptions +ParseHeaders PerlOptions +SetupEnv Order allow,deny Allow from all# directory settings AllowOverride None Options +ExecCGI -Includes Order allow,deny Allow from all AllowOverride None Order allow,deny Allow from all# MaxRequestsPerChild (so no apache child will be to big!)MaxRequestsPerChild 400\n2）在GroundWork的主目录下其实也有一个Apache目录，它是原系统Apache的替代品。进入这个目录。\n3）vi conf/httpd.conf 把otrs.conf文件中所有的内容都粘贴到这个文件中\n4）GroundWork的apache好像没用用到perl模块，需要加入perl模块的支持；找到有很多“LoadModule”的地方加入下面这一行\nLoadModule perl_module modules/mod_perl.so\n5）Copy系统中的mod_perl.so文件到/usr/local/groundwork/apache2/modules\n6）重新启动gwhttpd服务，也就是GroundWork系统的web服务\n7）访问OTRS系统 http://ip/otrs/customer.pl 成功。\n下面需要做的是把OTRS的登陆也集成到GroundWork的单点登陆当中；如果在能把GroundWork的报警也自动的集成到OTRS那就是完美了，欲知后事如何，且听下回分解。：）\n",
    "ref": "/2007/02/27/groundwork-and-otrs/"
  },{
    "title": "OTRS::ITSM期待中的开源ITIL工具",
    "date": "",
    "description": "",
    "body": "\n下个月就OTRS::ITSM 1.0 Beta1就发布了。OTRS是一不错的开源的帮助台程序。之所以说它还不错是由于以下几点：\n\n 能支持平台非常广。操作系统有Linux、Unix还有Windows；数据库有MySQL，PostgreSQL，Oracle和SQL Server。这些东西里多一个东西，多于商业软件来讲测试的工作量起码就要乘二。  安装和配置是相当的简单。我用的是SuSE Linux，是用RPM包安装，整个安装配置过程只需要10分钟。  支持多语言，目前能支持的语言有10几种，包括简繁体中文。  纯Web操作界面，Web界面可以定制；很好的邮件系统集成。有问题单生成接口，能够将第三方网络系统监控的故障告警变成问题单，再自动分配到相关的维护组。 从它的名字可以看出，他是一个“开放式问题单系统”或者说是“帮助台”“Help Desk” “工单跟踪系统”。一个单纯的问题单系统本身到没有什么特殊，不过能做到像OTRS这样像ITIL靠拢，试图做成一个遵从ITIL的开源IT服务管理解决方案的，可真的是不容易了。在看看其它的Help Desk的开源项目，都是在简单的在实现“问题管理”这个功能而已。\nOTRS现在最新的版本是otrs-2.1.5-01，等2.2正式发布后，OTRS::ITSM 1.0 就作为其中的一个模块也发布了。其实做到一个真真ITIL兼容的帮助台还真的不容易，我将期待它的CMDB，变更管理，以及各个流程之间的衔接。\n登陆这个OTRS的Demo系统来看看它到底怎么样，Check it out！！\nAgent/Admin Interface:\nhttp://demo.otrs.org/\nCustomer Interface:\nhttp://customer.otrs.org/\nFAQ Public Interface:\nhttp://faq.otrs.org/\nEmail:\ndemo@otrs.org\nSystem:\nIntel(R) Celeron(R) CPU (2 GHz) with 256 MB RAM and an IDE harddrive (current tickets ~55.000 - 2005-05-02)  ",
    "ref": "/2007/02/26/otrsitsm-itil/"
  },{
    "title": "Nagios华丽的外衣NagVis",
    "date": "",
    "description": "",
    "body": "如果你用过Nagios的话，它的2D、3D Map一定会给你留下一些印象；2D Map的确能比较试用一点，不过看上去还是挺难看的。NagVis就是看到了这一点，它力求能让各种状态信息表达的更炫，更好看；它可以说是Nagios的一个不错的插件，直接copy到Nagios的相关目录下，配置一下就行了。它的效果如下图所示：说的在玄虚一点它可以是一个“业务流程管理视图”[CA Unicenter中的名词，OpenView里也有类似的概念]。其实就是把原子的监控对象：被监控节点和节点上的服务；和业务系统或者IT的逻辑关系相结合起来。例如：我的业务系统A的其中一个数据库服务器的数据库进程停了，这个可以影响到所有物理包含或者逻辑包含它的对象的状态。NagVis试图用漂亮的图标来表达这些状态和关系，是管理者能看的更加直观。\n",
    "ref": "/2007/02/25/nagios-nagvis/"
  },{
    "title": "Install Smokeping via yum",
    "date": "",
    "description": "",
    "body": "From :http://ai.net.nz/horde/wicked/display.php?page=SmokePing\nInstall needed packages \nrrdtool\n`yum install rrdtool \u0026lt;br /\u0026gt;**perl-CGI-SpeedyCGI**\u0026lt;br /\u0026gt; `yum install perl-CGI-SpeedyCGI\n \nfping\n`yum install fping \u0026lt;br /\u0026gt;** Or do them all together:**\u0026lt;br /\u0026gt; `yum install rrdtool perl-CGI-SpeedyCGI fping\n \nSmokeping\n`wget http://people.ee.ethz.ch/~oetiker/webtools/smokeping/pub/smokeping-2.0.9.tar.gztar xvzf smokeping-2.0.9.tar.gzmv smokeping-2.0.9 /usr/local/smokepingchown -R root:root /usr/local/smokeping\u0026lt;br /\u0026gt;\u0026lt;br /\u0026gt;cd /usr/local/smokeping/binfor foo in *.dist; do cp $foo `basename $foo .dist`; done\u0026lt;br /\u0026gt;\u0026lt;br /\u0026gt;cd /usr/local/smokeping/etc/for foo in *.dist; do cp $foo `basename $foo .dist`; done\u0026lt;br /\u0026gt;\u0026lt;br /\u0026gt;cd /usr/local/smokeping/htdocsfor foo in *.dist; do cp $foo `basename $foo .dist`; done \u0026lt;br /\u0026gt;**pico /usr/local/smokeping/bin/smokeping**\u0026lt;br /\u0026gt;\u0026lt;table class=\u0026quot;table\u0026quot; \u0026gt;\u0026lt;br /\u0026gt;\u0026lt;tr \u0026gt;\u0026lt;br /\u0026gt; \u0026lt;td class=\u0026quot;table-cell\u0026quot; \u0026gt;_**Default**_ \u0026lt;/td\u0026gt;\u0026lt;br /\u0026gt; \u0026lt;td class=\u0026quot;table-cell\u0026quot; \u0026gt;_**New**_ \u0026lt;/td\u0026gt;\u0026lt;br /\u0026gt;\u0026lt;/tr\u0026gt;\u0026lt;br /\u0026gt;\u0026lt;tr \u0026gt;\u0026lt;br /\u0026gt; \u0026lt;td class=\u0026quot;table-cell\u0026quot; \u0026gt; #!/usr/sepp/bin/perl-5.8.4 -w \u0026lt;/td\u0026gt;\u0026lt;br /\u0026gt; \u0026lt;td class=\u0026quot;table-cell\u0026quot; \u0026gt; #!/usr/bin/perl -w \u0026lt;/td\u0026gt;\u0026lt;br /\u0026gt;\u0026lt;/tr\u0026gt;\u0026lt;br /\u0026gt;\u0026lt;tr \u0026gt;\u0026lt;br /\u0026gt; \u0026lt;td colspan=\u0026quot;2\u0026quot; class=\u0026quot;table-cell\u0026quot; \u0026gt;_ _ \u0026lt;/td\u0026gt;\u0026lt;br /\u0026gt;\u0026lt;/tr\u0026gt;\u0026lt;br /\u0026gt;\u0026lt;tr \u0026gt;\u0026lt;br /\u0026gt; \u0026lt;td class=\u0026quot;table-cell\u0026quot; \u0026gt;use lib qw(/usr/pack/rrdtool-1.0.49-to/lib/perl); \u0026lt;/td\u0026gt;\u0026lt;br /\u0026gt; \u0026lt;td class=\u0026quot;table-cell\u0026quot; \u0026gt;use lib qw(/usr/lib64/perl5/vendor_perl/5.8.5/x86_64-linux-thread-multi/auto/RRDs); \u0026lt;/td\u0026gt;\u0026lt;br /\u0026gt;\u0026lt;/tr\u0026gt;\u0026lt;br /\u0026gt;\u0026lt;tr \u0026gt;\u0026lt;br /\u0026gt; \u0026lt;td colspan=\u0026quot;2\u0026quot; class=\u0026quot;table-cell\u0026quot; \u0026gt;** or if a i386 system use** \u0026lt;/td\u0026gt;\u0026lt;br /\u0026gt;\u0026lt;/tr\u0026gt;\u0026lt;br /\u0026gt;\u0026lt;tr \u0026gt;\u0026lt;br /\u0026gt; \u0026lt;td class=\u0026quot;table-cell\u0026quot; \u0026gt;use lib qw(/usr/pack/rrdtool-1.0.49-to/lib/perl); \u0026lt;/td\u0026gt;\u0026lt;br /\u0026gt; \u0026lt;td class=\u0026quot;table-cell\u0026quot; \u0026gt;use lib qw(/usr/lib/perl5/vendor_perl/5.8.5/i386-linux-thread-multi/auto/RRDs); \u0026lt;/td\u0026gt;\u0026lt;br /\u0026gt;\u0026lt;/tr\u0026gt;\u0026lt;br /\u0026gt;\u0026lt;tr \u0026gt;\u0026lt;br /\u0026gt; \u0026lt;td class=\u0026quot;table-cell\u0026quot; \u0026gt;use lib qw(lib); \u0026lt;/td\u0026gt;\u0026lt;br /\u0026gt; \u0026lt;td class=\u0026quot;table-cell\u0026quot; \u0026gt;use lib qw(/usr/local/smokeping/lib); \u0026lt;/td\u0026gt;\u0026lt;br /\u0026gt;\u0026lt;/tr\u0026gt;\u0026lt;br /\u0026gt;\u0026lt;tr \u0026gt;\u0026lt;br /\u0026gt; \u0026lt;td colspan=\u0026quot;2\u0026quot; class=\u0026quot;table-cell\u0026quot; \u0026gt;_ _ \u0026lt;/td\u0026gt;\u0026lt;br /\u0026gt;\u0026lt;/tr\u0026gt;\u0026lt;br /\u0026gt;\u0026lt;tr \u0026gt;\u0026lt;br /\u0026gt; \u0026lt;td colspan=\u0026quot;2\u0026quot; class=\u0026quot;table-cell\u0026quot; \u0026gt;use Smokeping 2.000008; \u0026lt;/td\u0026gt;\u0026lt;br /\u0026gt;\u0026lt;/tr\u0026gt;\u0026lt;br /\u0026gt;\u0026lt;tr \u0026gt;\u0026lt;br /\u0026gt; \u0026lt;td colspan=\u0026quot;2\u0026quot; class=\u0026quot;table-cell\u0026quot; \u0026gt;_ _ \u0026lt;/td\u0026gt;\u0026lt;br /\u0026gt;\u0026lt;/tr\u0026gt;\u0026lt;br /\u0026gt;\u0026lt;tr \u0026gt;\u0026lt;br /\u0026gt; \u0026lt;td class=\u0026quot;table-cell\u0026quot; \u0026gt;Smokeping::main(\u0026quot;etc/config.dist\u0026quot;); \u0026lt;/td\u0026gt;\u0026lt;br /\u0026gt; \u0026lt;td class=\u0026quot;table-cell\u0026quot; \u0026gt;Smokeping::main(\u0026quot;/usr/local/smokeping/etc/config\u0026quot;); \u0026lt;/td\u0026gt;\u0026lt;br /\u0026gt;\u0026lt;/tr\u0026gt;\u0026lt;br /\u0026gt;\u0026lt;/table\u0026gt;\u0026lt;br /\u0026gt;**pico /usr/local/smokeping/htdocs/smokeping.cgi**\u0026lt;br /\u0026gt;\u0026lt;table class=\u0026quot;table\u0026quot; \u0026gt;\u0026lt;br /\u0026gt;\u0026lt;tr \u0026gt;\u0026lt;br /\u0026gt; \u0026lt;td class=\u0026quot;table-cell\u0026quot; \u0026gt;_**Default**_ \u0026lt;/td\u0026gt;\u0026lt;br /\u0026gt; \u0026lt;td class=\u0026quot;table-cell\u0026quot; \u0026gt;_**New**_ \u0026lt;/td\u0026gt;\u0026lt;br /\u0026gt;\u0026lt;/tr\u0026gt;\u0026lt;br /\u0026gt;\u0026lt;tr \u0026gt;\u0026lt;br /\u0026gt; \u0026lt;td class=\u0026quot;table-cell\u0026quot; \u0026gt;#!/usr/sepp/bin/speedy -w \u0026lt;/td\u0026gt;\u0026lt;br /\u0026gt; \u0026lt;td class=\u0026quot;table-cell\u0026quot; \u0026gt;#!/usr/bin/speedy -w \u0026lt;/td\u0026gt;\u0026lt;br /\u0026gt;\u0026lt;/tr\u0026gt;\u0026lt;br /\u0026gt;\u0026lt;tr \u0026gt;\u0026lt;br /\u0026gt; \u0026lt;td colspan=\u0026quot;2\u0026quot; class=\u0026quot;table-cell\u0026quot; \u0026gt;_ _ \u0026lt;/td\u0026gt;\u0026lt;br /\u0026gt;\u0026lt;/tr\u0026gt;\u0026lt;br /\u0026gt;\u0026lt;tr \u0026gt;\u0026lt;br /\u0026gt; \u0026lt;td class=\u0026quot;table-cell\u0026quot; \u0026gt;use lib qw(/usr/pack/rrdtool-1.0.33-to/lib/perl); \u0026lt;/td\u0026gt;\u0026lt;br /\u0026gt; \u0026lt;td class=\u0026quot;table-cell\u0026quot; \u0026gt;use lib qw(/usr/lib64/perl5/vendor_perl/5.8.5/x86_64-linux-thread-multi/auto/RRDs); \u0026lt;/td\u0026gt;\u0026lt;br /\u0026gt;\u0026lt;/tr\u0026gt;\u0026lt;br /\u0026gt;\u0026lt;tr \u0026gt;\u0026lt;br /\u0026gt; \u0026lt;td colspan=\u0026quot;2\u0026quot; class=\u0026quot;table-cell\u0026quot; \u0026gt;** or if a i386 system use** \u0026lt;/td\u0026gt;\u0026lt;br /\u0026gt;\u0026lt;/tr\u0026gt;\u0026lt;br /\u0026gt;\u0026lt;tr \u0026gt;\u0026lt;br /\u0026gt; \u0026lt;td class=\u0026quot;table-cell\u0026quot; \u0026gt;use lib qw(/usr/pack/rrdtool-1.0.49-to/lib/perl); \u0026lt;/td\u0026gt;\u0026lt;br /\u0026gt; \u0026lt;td class=\u0026quot;table-cell\u0026quot; \u0026gt;use lib qw(/usr/lib/perl5/vendor_perl/5.8.5/i386-linux-thread-multi/auto/RRDs); \u0026lt;/td\u0026gt;\u0026lt;br /\u0026gt;\u0026lt;/tr\u0026gt;\u0026lt;br /\u0026gt;\u0026lt;tr \u0026gt;\u0026lt;br /\u0026gt; \u0026lt;td class=\u0026quot;table-cell\u0026quot; \u0026gt;use lib qw(/home/oetiker/data/projects/AADJ-smokeping/dist/lib); \u0026lt;/td\u0026gt;\u0026lt;br /\u0026gt; \u0026lt;td class=\u0026quot;table-cell\u0026quot; \u0026gt;use lib qw(/usr/local/smokeping/lib); \u0026lt;/td\u0026gt;\u0026lt;br /\u0026gt;\u0026lt;/tr\u0026gt;\u0026lt;br /\u0026gt;\u0026lt;tr \u0026gt;\u0026lt;br /\u0026gt; \u0026lt;td colspan=\u0026quot;2\u0026quot; class=\u0026quot;table-cell\u0026quot; \u0026gt;use CGI::Carp qw(fatalsToBrowser); \u0026lt;/td\u0026gt;\u0026lt;br /\u0026gt;\u0026lt;/tr\u0026gt;\u0026lt;br /\u0026gt;\u0026lt;tr \u0026gt;\u0026lt;br /\u0026gt; \u0026lt;td colspan=\u0026quot;2\u0026quot; class=\u0026quot;table-cell\u0026quot; \u0026gt;_ _ \u0026lt;/td\u0026gt;\u0026lt;br /\u0026gt;\u0026lt;/tr\u0026gt;\u0026lt;br /\u0026gt;\u0026lt;tr \u0026gt;\u0026lt;br /\u0026gt; \u0026lt;td colspan=\u0026quot;2\u0026quot; class=\u0026quot;table-cell\u0026quot; \u0026gt;use Smokeping 2.000008; \u0026lt;/td\u0026gt;\u0026lt;br /\u0026gt;\u0026lt;/tr\u0026gt;\u0026lt;br /\u0026gt;\u0026lt;tr \u0026gt;\u0026lt;br /\u0026gt; \u0026lt;td colspan=\u0026quot;2\u0026quot; class=\u0026quot;table-cell\u0026quot; \u0026gt;_ _ \u0026lt;/td\u0026gt;\u0026lt;br /\u0026gt;\u0026lt;/tr\u0026gt;\u0026lt;br /\u0026gt;\u0026lt;tr \u0026gt;\u0026lt;br /\u0026gt; \u0026lt;td class=\u0026quot;table-cell\u0026quot; \u0026gt;Smokeping::cgi(\u0026quot;/home/oetiker/data/projects/AADJ-smokeping/dist/etc/config\u0026quot;); \u0026lt;/td\u0026gt;\u0026lt;br /\u0026gt; \u0026lt;td class=\u0026quot;table-cell\u0026quot; \u0026gt;Smokeping::cgi(\u0026quot;/usr/local/smokeping/etc/config\u0026quot;); \u0026lt;/td\u0026gt;\u0026lt;br /\u0026gt;\u0026lt;/tr\u0026gt;\u0026lt;br /\u0026gt;\u0026lt;/table\u0026gt;\u0026lt;br /\u0026gt; `cp /usr/local/smokeping/htdocs/smokeping.cgi /var/www/cgi-bin\npico /usr/local/smokeping/etc/config\n \netc/config\n*** General ***\n_**Default**_ \n_**New**_ \n\nowner = Joe Random \nowner = Tony Someone \n\ncontact = joe@some.place.xyz \ncontact = tony@somehhere \n\nmailhost = smtp.mailhost.abc \nmailhost = smtp.somewhere \n\nsendmail = /usr/lib/sendmail \n\nimgcache = /home/oetiker/public_html/.simg \nimgcache = /var/www/html/smokeping/img \n\nimgurl = ../.simg \nimgurl = http://mail.somewhere.net/smokeping/img \n\ndatadir = /home/oetiker/data/projects/AADJ-smokeping/dist/var \ndatadir = /usr/local/smokeping/var \n\npiddir = /home/oetiker/data/projects/AADJ-smokeping/dist/var \npiddir = /usr/local/smokeping/var \n\ncgiurl = http://people.ee.ethz.ch/~oetiker/smokeping/smokeping.cgi \ncgiurl = http://mail.somewhere.net/cgi-bin/smokeping.cgi \n\nsmokemail = /home/oetiker/data/projects/AADJ-smokeping/dist/etc/smokemail.dist \nsmokemail = /usr/local/smokeping/etc/smokemail \n\ntmail = /home/oetiker/data/projects/AADJ-smokeping/dist/etc/tmail.dist \ntmail = /usr/local/smokeping/etc/tmail \n\n_ _ \n\nsyslogfacility = local0 \n\n\n*** Alerts ***\nto = \nto = someone@your.place \n\nfrom = smokealert@ \nfrom = smokealert@your.smoke.server \n\n\n*** Presentation ***\ntemplate = /home/oetiker/data/projects/AADJ-smokeping/dist/etc/basepage.html.dist \ntemplate = /usr/local/smokeping/etc/basepage.html \n\n\n*** Probes ***\nbinary = /usr/sepp/bin/fping \nbinary = /usr/sbin/fping \n\n\nFor some strange reason I had to make this change to /usr/sbin/fping\nchown apache /usr/sbin/fping\n*** Targets ***\n+ World \n\nmenu = World Connectivity \n\ntitle= World Connectivity \n\n_ _ \n\n++ New Zealand \n\nmenu = New Zealand Servers \n\ntitle = New Zealand Server \n\n_ _ \n\n+++ a Server \n\nmenu = My Server \n\ntitle = My Server \n\nhost = something.newskies.net \n\n\n_ _\n``` `mkdir -p /var/www/html/smokeping/imgchown -R apache:apache /var/www/html/smokeping/img\nmkdir /usr/local/smokeping/var\n/usr/local/smokeping/bin/smokeping \u0026\n#ps aux | grep smokeroot 8384 0.0 2.5 14976 3272 ? Ss May24 0:01 /usr/local/smokeping/bin/smokeping [FPing]apache 8435 0.0 1.7 11100 2168 ? Ss May24 0:02 /usr/bin/speedy_backend -w /var/www/cgi-bin/smokeping.cgiapache 8436 0.3 3.9 12648 5036 ? S May24 2:04 /usr/bin/speedy_backend -w /var/www/cgi-bin/smokeping.cgi ``` \u0026lt;br /\u0026gt; `vi /etc/rc.d/rc.local/usr/local/smokeping/bin/smokeping \u0026amp;\n \n ",
    "ref": "/2007/02/16/install-smokeping-via-yum/"
  },{
    "title": "如何看懂Smokeping图表",
    "date": "",
    "description": "",
    "body": "\n\n_RTT(Round-Trip Time) _\n\n简单说它是一个数据报在网络上两点中间往返一次的时间。是影响TCP性能和表征网络运行状况的重要参数。在网络中实时、准确地测量大量TCP设备和系统的RTT参数是网络管的重要环节之一。Smokeping就是这样的自动测试系统，它向目标设备和系统发送各种类型的测试数据包，测量、记录和展示RTT。\n\n\n_Median RTT _****中间数\n\n它是中间数并不是平均值。Smokeping有多种类型的探针，探针在默认的设置下，每300秒向目标设备发送20测探测数据包。假如这20个数据包都返回的话，它就记录下了20个RTT，那么Median RTT就是第十个包的RTT；如果有5个包丢失的话，那么Median RTT就是第八个返回的包的RTT值。\n\n\n_Avg RTT _****评价值\n\n它是每一个测试回合中所有RTT的算术评价值。\n\n\nAvg pkt loss\n\n它是丢包率。\n\n\n上图中测试的三个服务器，是用默认的FPing探针探测该服务器是否在线。Smokeping就装在OpenNMS上，可以看出它的RTT最小；奇怪的是它的丢包率却是最大。其它的，一个是美国的一个Web服务器，另一个是美国的Exchange邮件服务器。\n\n\n\nLast 3 Hours 最近的3小时\n\n_Median Ping RTT （__506.2 ms avg）_中间数的平均值是5.6.2毫秒。如果是绿色的短横线，说明一个300秒的周期内所有的包都返回都有RTT的时间记录下来；如果是蓝色的短横线则说明有2个包丢失。\n\n_Packet Loss：_丢包率。从上图中我们看出全都是绿线，所以丢包率当然是0。\n\n_Probe：_10 HTTP pings using echoping(1) every 300 seconds\n\n这张图是2007-1-11 12:00:05生成的。每一个绿色的短横线都是一个测试回合300秒内用echoping测试HTTP协议10次。绿色画出的是中间数的位置，一个回合中的其它值都在它附近被以灰度的形式被刻画；灰度的范围越小越好，灰色的范围像是烟雾一样笼罩在中间数附近。在中间数附近的烟越小越好，说明网络很平稳。RTT曲线的起伏还显示了网络的负载情况。\n\n点击这里看一个网上的Demo\n\nupdate : 2008-1-18\n\n现在OpenNMS把smokeping集成了，你可以在OpenNMS中配置使用这个功能。\n",
    "ref": "/2007/02/15/smokeping-chart/"
  },{
    "title": "翻译[opennms-discuss]邮件组里的一个讨论“Nagios转变”",
    "date": "",
    "description": "",
    "body": "全文在＝》China OpenNMS\n \u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;\n我们已经在一个中等规模的企业实施了Nagios，用来监控一堆Cisco设备：交换机、路由器、防火墙，还有各种类型的服务器\n（Windows,Linux和Unix）。对我们来说Nagios工作的非常好。我们现在看OpenNMS，是由于她有好看的用户界面和集成的服务资源\n图。我喜欢Nagios是由于它的模块化。我能很容易的写一个插件来完成任何相关的事情。\n我看到OpenNMS有NRPE和NSCLIENT的能力，但是有一些邮件和资源图不能彻底的采集到。有人正打算用OpenNMS作为Nagios或者其他\n软件的替代品？我的答案是非常确定的，可是我也非常想听到一些关于OpenNMS的成功或者不很成功的故事。我正在测试环境中使用\n的是OpenNMS1.3.2。\nThanks!\nJon Christensen\n\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;\n我们也有一个和你类似的环境（路由器、交换机、各种服务器），目前有大约250个节点。\n使用一个CentOS4的服务器，我们已经在上面安装了OpenNMS1.2.9，Syslog-NG，Swatch, Logtool(http://xjack.org/logtool/)，\n在Windows上用Informant MIB，在几乎所有Linux/Unix上的是NET-SNMP，和它们一起的还有很多在客户端的自定义脚本；它们中的\n大多数都使用send-event.pl或者和它无关。\n应为所有这些，我们已经能完全替代了HP OpenView，虽然这是我的一面之词：这个架构是如此的模块化，以致于我们能做的比我们\n使用OpenView的还要多，因种种理由。\nTim Selivanow\nNOC Technician\nEasyStreet Online Services, Inc.\n______________________________________\n我的个人观点：\n从Nagios转到OpenNMS上，其实不太容易。由于一下因素：\n1）Nagios非常模块化，架构让人决定非常稳定可靠；它没有用到Java。\n2）它的文档非常好，包括它官方的使用手册和用户上传的文档；从文档可以看出这个欧洲Base的项目非常踏实，风格严谨。开发ONMS的那帮老米显得比较自作聪明一点。\n3）Nagios的论坛很好，有很多人可以互相帮助。\n",
    "ref": "/2007/02/01/opennms-discuss-nagios/"
  },{
    "title": "Cisco网络设备如何配置SNMP代理",
    "date": "",
    "description": "",
    "body": "Cisco是网络设备的老大，它的设备以稳定、成熟和高性能著称。很多用户都以自己的网络设备是99％的Cisco设备而自豪。\n对于任何一个网络设备如果没有配置SNMP代理，就不能被任何管理工具管理。下面的这个连接就是关于如何配置Cisco的SNMP服务：http://www.cisco.com/univercd/cc/td/doc/product/software/ios122/122cgcr/ffun_c/fcfprt3/fcf014.htm\n可网管网络设备都内置有SNMP代理，很多网管不喜欢配置、enable SNMP服务的理由如下：不希望SNMP服务占用CPU、内存等资源；不信任SNMP服务的安全性；不认确认SNMP管理协议的价值。我个人认为：通过SNMP协议对网络设备管理的价值将远远高于它对设备造成的消耗和带来的风险。如果你同时面对和管理30台以上的网络设备，试想把它们的运行状况做一遍检查，您需要花的时间是多长。\n网络管理系统和网络设备的互动如下：\n\n 网管系统主动定时读取MIB的值，存储和分析得到的数值，产生报表和报警事件。  网管系统被动作为网络设备发送Trap的目的地，网管系统需要能翻译各种网络设备的Trap信息的意义。   ",
    "ref": "/2007/01/28/cisco-network-configure/"
  },{
    "title": "联络",
    "date": "",
    "description": "",
    "body": "",
    "ref": "/contact/"
  }]
